Authors,Author full names,Author(s) ID,Title,Reviewer1,Reviewer2,Overall,Year,Link,Abstract,Publication Stage,Open Access
Lezcano L.; Sánchez-Alonso S.; Roa-Valverde A.J.,"Lezcano, Leonardo (36173252800); Sánchez-Alonso, Salvador (8951086600); Roa-Valverde, Antonio J. (36061477400)",36173252800; 8951086600; 36061477400,A survey on the exchange of linguistic resources: Publishing linguistic linked open data on the Web,,,,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880630048&doi=10.1108%2fPROG-06-2012-0030&partnerID=40&md5=38bea75e149d7e5682cbe9ac9b8ad682,"Purpose: The purpose of this paper is to provide a literature review of the principal formats and frameworks that have been used in the last 20 years to exchange linguistic resources. It aims to give special attention to the most recent approaches to publishing linguistic linked open data on the Web. Design/methodology/approach: Research papers published since 1990 on the use of various formats, standards, frameworks and methods to exchange linguistic information were divided into two main categories: those proposing specific schemas and syntaxes to suit the requirements of a given type of linguistic data (these are referred to as offline approaches), and those adopting the linked data (LD) initiative and the semantic web technologies to support the interoperability of heterogeneous linguistic resources. For each paper, the type of linguistic resource exchanged, the framework/format used, the interoperability approach taken and the related projects were identified. Findings: The information gathered in the survey reflects an increase in recent years in approaches adopting the LD initiative. This is due to the fact that the structural and syntactic issues which arise when addressing the interoperability of linguistic resources can be solved by applying semantic web technologies. What remains an open issue in the field of computational linguistics is the development of knowledge artefacts and mechanisms to support the alignment of the different aspects of linguistic resources in order to guarantee semantic and conceptual interoperability in the linked open data (LOD) cloud. Ontologies have proved to be of great use in achieving this goal. Research limitations/implications: The research presented here is by no means a comprehensive or all-inclusive survey of all existing approaches to the exchange of linguistic resources. Rather, the aim was to highlight, analyze and categorize the most significant advances in the field. Practical implications: This survey has practical implications for computational linguists and for every application requiring new developments in natural language processing. In addition, multilingual issues can be better addressed when semantic interoperability of heterogeneous linguistic resources is achieved. Originality/value: The paper provides a survey of past and present research and developments addressing the interoperability of linguistic resources, including those where the linked data initiative has been adopted. © Emerald Group Publishing Limited.",Final,
Goldsack T.; Zhang Z.; Tang C.; Scarton C.; Lin C.,"Goldsack, Tomas (57222235208); Zhang, Zhihao (57864377300); Tang, Chen (57196025933); Scarton, Carolina (36442577500); Lin, Chenghua (35322970500)",57222235208; 57864377300; 57196025933; 36442577500; 35322970500,Enhancing Biomedical Lay Summarisation with External Knowledge Graphs,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184809727&partnerID=40&md5=ceeb43a0ece58fae8778c8bea4243038,"Previous approaches for automatic lay summarisation are exclusively reliant on the source article that, given it is written for a technical audience (e.g., researchers), is unlikely to explicitly define all technical concepts or state all of the background information that is relevant for a lay audience. We address this issue by augmenting eLife, an existing biomedical lay summarisation dataset, with article-specific knowledge graphs, each containing detailed information on relevant biomedical concepts. Using both automatic and human evaluations, we systematically investigate the effectiveness of three different approaches for incorporating knowledge graphs within lay summarisation models, with each method targeting a distinct area of the encoder-decoder model architecture. Our results confirm that integrating graph-based domain knowledge can significantly benefit lay summarisation by substantially increasing the readability of generated text and improving the explanation of technical concepts. © 2023 Association for Computational Linguistics.",Final,
Koner R.; Li H.; Hildebrandt M.; Das D.; Tresp V.; Günnemann S.,"Koner, Rajat (57219734248); Li, Hang (57221545932); Hildebrandt, Marcel (57202465286); Das, Deepan (57656533000); Tresp, Volker (6603805670); Günnemann, Stephan (35242528700)",57219734248; 57221545932; 57202465286; 57656533000; 6603805670; 35242528700,Graphhopper: Multi-hop Scene Graph Reasoning for Visual Question Answering,1,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116858375&doi=10.1007%2f978-3-030-88361-4_7&partnerID=40&md5=f0f5cc665dc9f46cc1c8a83af67176b1,"Visual Question Answering (VQA) is concerned with answering free-form questions about an image. Since it requires a deep semantic and linguistic understanding of the question and the ability to associate it with various objects that are present in the image, it is an ambitious task and requires multi-modal reasoning from both computer vision and natural language processing. We propose Graphhopper, a novel method that approaches the task by integrating knowledge graph reasoning; computer vision, and natural language processing techniques. Concretely, our method is based on performing context-driven, sequential reasoning based on the scene entities and their semantic and spatial relationships. As a first step, we derive a scene graph that describes the objects in the image, as well as their attributes and their mutual relationships. Subsequently, a reinforcement learning agent is trained to autonomously navigate in a multi-hop manner over the extracted scene graph to generate reasoning paths, which are the basis for deriving answers. We conduct an experimental study on the challenging dataset GQA, based on both manually curated and automatically generated scene graphs. Our results show that we keep up with human performance on manually curated scene graphs. Moreover, we find that Graphhopper outperforms another state-of-the-art scene graph reasoning model on both manually curated and automatically generated scene graphs by a significant margin. © 2021, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Qiao F.; Zhu X.,"Qiao, Fengfeng (57221648050); Zhu, Xinjuan (7406186403)",57221648050; 7406186403,Domain Intelligent QA user intention recognition based on keyword separation,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099694451&doi=10.1109%2fICCST50977.2020.00049&partnerID=40&md5=808a2d0906815dff59e6d367e744b377,"In view of the disadvantages of current intelligent QA user intention recognition technology, which can't make good use of the detailed features in user questions, this paper proposes a layered method to identify user intention. This method first identifies the keywords in the user problem as the user's first level intention, then distinguishes the sentence pattern of the user problem according to the number of keywords, and determines whether to identify the second level intention according to the sentence pattern of the problem. Then, the key word features are fused to identify the user's problem type, and the result of problem type recognition is regarded as the second layer of user's intention. Finally, the user's two layers of intentions are integrated and regarded as the user's overall intentions, and retrieved in the Knowledge Graph. Experiments show that the F1 value of user problem type recognition is increased by 6% after keyword features are added. The method of keyword separation is used to identify the user's intention in question and answer, which separates the two layers of user's intention. For the problem sentence pattern that is not necessary to recognize the second layer of user's intention, the judgment of user's intention is no longer performed, which reduces the complexity of user's intention recognition, and opens up space for the case that keywords need to be processed. In addition, keyword features are added to the second layer of user intention recognition model, which makes better use of the detailed features in user question statements and improves the effect of user intention recognition.  © 2020 IEEE.",Final,
Kilicoglu H.; Rosemblat G.; Fiszman M.; Shin D.,"Kilicoglu, Halil (8272303300); Rosemblat, Graciela (8443562100); Fiszman, Marcelo (8437484300); Shin, Dongwook (55449804300)",8272303300; 8443562100; 8437484300; 55449804300,Broad-coverage biomedical relation extraction with SemRep,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084825129&doi=10.1186%2fs12859-020-3517-7&partnerID=40&md5=b969041f5ce9b844abcf2a6eeade2b36,"Background: In the era of information overload, natural language processing (NLP) techniques are increasingly needed to support advanced biomedical information management and discovery applications. In this paper, we present an in-depth description of SemRep, an NLP system that extracts semantic relations from PubMed abstracts using linguistic principles and UMLS domain knowledge. We also evaluate SemRep on two datasets. In one evaluation, we use a manually annotated test collection and perform a comprehensive error analysis. In another evaluation, we assess SemRep's performance on the CDR dataset, a standard benchmark corpus annotated with causal chemical-disease relationships. Results: A strict evaluation of SemRep on our manually annotated dataset yields 0.55 precision, 0.34 recall, and 0.42 F 1 score. A relaxed evaluation, which more accurately characterizes SemRep performance, yields 0.69 precision, 0.42 recall, and 0.52 F 1 score. An error analysis reveals named entity recognition/normalization as the largest source of errors (26.9%), followed by argument identification (14%) and trigger detection errors (12.5%). The evaluation on the CDR corpus yields 0.90 precision, 0.24 recall, and 0.38 F 1 score. The recall and the F 1 score increase to 0.35 and 0.50, respectively, when the evaluation on this corpus is limited to sentence-bound relationships, which represents a fairer evaluation, as SemRep operates at the sentence level. Conclusions: SemRep is a broad-coverage, interpretable, strong baseline system for extracting semantic relations from biomedical text. It also underpins SemMedDB, a literature-scale knowledge graph based on semantic relations. Through SemMedDB, SemRep has had significant impact in the scientific community, supporting a variety of clinical and translational applications, including clinical decision making, medical diagnosis, drug repurposing, literature-based discovery and hypothesis generation, and contributing to improved health outcomes. In ongoing development, we are redesigning SemRep to increase its modularity and flexibility, and addressing weaknesses identified in the error analysis. © 2020 The Author(s).",Final,All Open Access; Gold Open Access; Green Open Access
Ferré S.; Cellier P.,"Ferré, Sébastien (8974579900); Cellier, Peggy (23388216000)",8974579900; 23388216000,Graph-FCA: An extension of formal concept analysis to knowledge graphs,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064636404&doi=10.1016%2fj.dam.2019.03.003&partnerID=40&md5=6162f1034398f67beb18f823e9251361,"Knowledge graphs offer a versatile knowledge representation, and have been studied under different forms, such as conceptual graphs or RDF graphs in the Semantic Web. A challenge is to discover conceptual structures in those graphs, in the same way as Formal Concept Analysis (FCA) discovers conceptual structures in tables. FCA has been successful for analysing, mining, learning, and exploring tabular data, and our aim is to help transpose those results to graph-based data. Previous several FCA approaches have already addressed relational data, hence graphs, but with various limits. We propose Graph-FCA as an extension of FCA where a dataset is a hypergraph instead of a binary table. We show that it can be formalized simply by replacing objects by tuples of objects. This leads to the notion of “n-ary concept”, whose extent is an n-ary relation of objects, and whose intent is a “projected graph pattern”. In this paper, we formally reconstruct the fundamental results of FCA for knowledge graphs. We describe in detail the representation of hypergraphs, and the operations on them, as they are much more complex than the sets of attributes that they extend. We also propose an algorithm based on a notion of “pattern basis” to generate and display n-ary concepts in a more efficient and more compact way. We explore a few use cases, in order to study the feasibility and usefulness of Graph-FCA. We consider two use cases: workflow patterns in cooking recipes and linguistic structures from parse trees. In addition, we report on experiments about quantitative aspects of the approach. © 2019",Final,All Open Access; Bronze Open Access; Green Open Access
Xing C.; Liu X.; Du D.; Hu W.; Zhang M.,"Xing, Chengli (57212190825); Liu, Xueyang (35746287900); Du, Dongdong (7202611255); Hu, Wenhui (7404359716); Zhang, Minghui (57212191422)",57212190825; 35746287900; 7202611255; 7404359716; 57212191422,Relation extraction using language model based on knowledge graph,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096414931&doi=10.1088%2f1742-6596%2f1624%2f2%2f022037&partnerID=40&md5=8dabd909fb79c05a8f685bdafcfba007,"Relation extraction is an important task in natural language processing (NLP). The existing methods generally pay more attention on extracting textual semantic information from text, but ignore the relation contextual information from existed relations in datasets, which is very important for the performance of relation extraction task. In this paper, we represent each individual entity as a embedding based on entities and relations knowledge graph, which encodes the relation contextual information between the given entity pairs and relations. Besides, inspired by the impressive performance of language models recently, we used the language model to leverage word semantic information, in which word semantic information can be better captured than word embedding. The experimental results on SemEval2010 Task 8 dataset showed that the F1-score of our proposed method improved nearly 3% compared with the previous methods. © 2020 Institute of Physics Publishing. All rights reserved.",Final,All Open Access; Bronze Open Access
Hulpus I.; Štajner S.; Stuckenschmidt H.,"Hulpus, Ioana (36188149800); Štajner, Sanja (55634787100); Stuckenschmidt, Heiner (6603168933)",36188149800; 55634787100; 6603168933,A spreading activation framework for tracking conceptual complexity of texts,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084068774&partnerID=40&md5=f03a787428be66767cfcf9de97df3a56,"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation. Using DBpedia knowledge graph as a proxy to long-term memory, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as semantic priming, sentence wrap-up, and forgetting. We show that our models capture various aspects of conceptual text complexity and significantly outperform current state of the art. © 2019 Association for Computational Linguistics",Final,
Perera R.; Nand P.; Klette G.,"Perera, Rivindu (56425389400); Nand, Parma (6506991350); Klette, Gisela (14045274000)",56425389400; 6506991350; 14045274000,RealTextlex: A lexicalization framework for linked open data,1,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955577860&partnerID=40&md5=f707be0930aa670704c7c320f95255ad,"Linked Open Data (LOD) is growing rapidly as a source of structured knowledge used in a variety of text processing applications. However, the applications using the LOD need to be able to mediate between the front end user interfaces and LOD. This often requires a natural language interpretation of this structured, linked data. We demonstrate a middle-tier framework that can generate patterns which can be used to transform LOD triples back into natural text. The framework utilizes preprocessed free text to extract a wide range of relations which are then aligned with triples to identify possible lexicalization patterns. These lexicalization patterns can then be used to transform a given triple into natural language sentence.",Final,
Dramé K.; Smits G.; Pivert O.,"Dramé, Khadim (55561880900); Smits, Grégory (35185786000); Pivert, Olivier (6701395936)",55561880900; 35185786000; 6701395936,Coarse to fine keyword queries with user interactions,1,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966908066&doi=10.1145%2f2837185.2837210&partnerID=40&md5=504912286990be062cfa1e9e4a3d1a6b,"A large amount of linked data is now available, but to retrieve knowledge from these data, queries have to be formulated using formal query languages. While expressive query languages are developed, their use by end users, generally not familiar with formal languages, is limited. Keywordbased search is considered as a convenient and intuitive way for users to express their information needs. Keyword search over structured data is thus an interesting alternative but which raises challenging issues. The main challenge is to determine the meaning of a keyword query in order to translate it into a target formal query language, SPARQL in our case. In this paper, we address this challenge and propose a novel approach that relies on user interactions to determine the correct interpretation of the keyword query. The principle is to first ask the user to define a coarse keyword query, then to suggest candidate interpretations expressed in an explicit, thus unambiguous, and human readable form. Once the correct interpretation has been selected, the query may be refined with aggregate functions and comparatives. Experiments conducted on a large knowledge base show the effectiveness and the effciency of the proposed approach. © 2015 ACM.",Final,
Lašek I.; Vojtáš P.,"Lašek, Ivo (53979840800); Vojtáš, Peter (57189205301)",53979840800; 57189205301,Various approaches to text representation for named entity disambiguation,1,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882991679&doi=10.1108%2fIJWIS-05-2013-0016&partnerID=40&md5=cbe1c40e4a5d696a54734d0baf2c6e3c,"Purpose - The purpose of this paper is to focus on the problem of named entity disambiguation. The paper disambiguates named entities on a very detailed level. To each entity is assigned a concrete identifier of a corresponding Wikipedia article describing the entity. Design/methodology/approach - For such a fine-grained disambiguation a correct representation of the context is crucial. The authors compare various context representations: bag of words representation, linguistic representation and structured co-occurrence representation. Models for each representation are described and evaluated. They also investigate the possibilities of multilingual named entity disambiguation. Findings - Based on this evaluation, the structured co-occurrence representation provides the best disambiguation results. It showed up that this method could be successfully applied also on other languages, not only on English. Research limitations/implications - Despite its good results the structured co-occurrence context representation has several limitations. It trades precision for recall, which might not be desirable in some use cases. Also it is not able to disambiguate two different types of entities, which are mentioned under the same name in the same text. These limitations can be overcome by combination with other described methods. Practical implications - The authors provide a ready-made web service, which can be directly plugged in existing applications using a REST interface. Originality/value - The paper proposes a new approach to named entity disambiguation exploiting various context representation models (bag of words, linguistic and structural representation). The authors constructed a comprehensive dataset based on all English Wikipedia articles for named entity disambiguation. They evaluated and compared the individual context representation models on this dataset. They evaluate the support of multiple languages. Copyright © 2013 Emerald Group Publishing Limited. All rights reserved.",Final,
Kumar S.; Ramaneswaran S.; Akhtar M.S.; Chakraborty T.,"Kumar, Shivani (58262492000); Ramaneswaran, S. (57211886141); Akhtar, Md Shad (57193850945); Chakraborty, Tanmoy (25723003500)",58262492000; 57211886141; 57193850945; 25723003500,From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184822341&partnerID=40&md5=14584b69691f8ab92b34cc16279846d8,"Understanding emotions during conversation is a fundamental aspect of human communication, driving NLP research for Emotion Recognition in Conversation (ERC). While considerable research has focused on discerning emotions of individual speakers in monolingual dialogues, understanding the emotional dynamics in code-mixed conversations has received relatively less attention. This motivates our undertaking of ERC for code-mixed conversations in this study. Recognizing that emotional intelligence encompasses a comprehension of worldly knowledge, we propose an innovative approach that integrates commonsense information with dialogue context to facilitate a deeper understanding of emotions. To achieve this, we devise an efficient pipeline that extracts relevant commonsense from existing knowledge graphs based on the code-mixed input. Subsequently, we develop an advanced fusion technique that seamlessly combines the acquired commonsense information with the dialogue representation obtained from a dedicated dialogue understanding module. Our comprehensive experimentation showcases the substantial performance improvement obtained through the systematic incorporation of commonsense in ERC. Both quantitative assessments and qualitative analyses further corroborate the validity of our hypothesis, reaffirming the pivotal role of commonsense integration in enhancing ERC. © 2023 Association for Computational Linguistics.",Final,
Joshi M.; Sawant U.; Chakrabarti S.,"Joshi, Mandar (57187691000); Sawant, Uma (26535080400); Chakrabarti, Soumen (58570163200)",57187691000; 26535080400; 58570163200,Knowledge graph and corpus driven segmentation and answer inference for telegraphic entity-seeking queries,1,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949831806&doi=10.3115%2fv1%2fd14-1117&partnerID=40&md5=1d7830f2fd1c75f92427a9941d39871b,"Much recent work focuses on formal interpretation of natural question utterances, with the goal of executing the resulting structured queries on knowledge graphs (KGs) such as Freebase. Here we address two limitations of this approach when applied to open-domain, entity-orientedWeb queries. First,Web queries are rarely wellformed questions. They are ""telegraphic"", with missing verbs, prepositions, clauses, case and phrase clues. Second, the KG is always incomplete, unable to directly answer many queries. We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment: A base entity e1, a relation type r, a target entity type t2, and contextual words s. The query seeks entity e2 ε t2 where r(e1, e2) holds, further evidenced by schema-agnostic words s. Query segmentation is integrated with the KG and an unstructured corpus where mentions of entities have been linked to the KG. We do not trust the best or any specific query segmentation. Instead, evidence in favor of candidate e2s are aggregated across several segmentations. Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG, using over a thousand telegraphic queries adapted from TREC, INEX, and Web- Questions, show the efficacy of our approach. For one benchmark, MAP improves from 0.2-0.29 (competitive baselines) to 0.42 (our system). NDCG@10 improves from 0.29-0.36 to 0.54. © 2014 Association for Computational Linguistics.",Final,All Open Access; Bronze Open Access; Green Open Access
Gu Y.; Yao S.; Gan C.; Tenenbaum J.B.; Yu M.,"Gu, Yi (57814227900); Yao, Shunyu (57221157014); Gan, Chuang (57141834200); Tenenbaum, Joshua B. (7006818404); Yu, Mo (35174012000)",57814227900; 57221157014; 57141834200; 7006818404; 35174012000,Revisiting the Roles of “Text” in Text Games,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149869084&partnerID=40&md5=88b6ea6528904927ca47c5e3df454db6,"Text games present opportunities for natural language understanding (NLU) methods to tackle reinforcement learning (RL) challenges. However, recent work has questioned the necessity of NLU by showing random text hashes could perform decently. In this paper, we pursue a fine-grained investigation into the roles of text in the face of different RL challenges, and reconcile that semantic and non-semantic language representations could be complementary rather than contrasting. Concretely, we propose a simple scheme to extract relevant contextual information into an approximate state hash as extra input for an RNN-based text agent. Such a lightweight plug-in achieves competitive performance with state-of-the-art text agents using advanced NLU techniques such as knowledge graph and passage retrieval, suggesting non-NLU methods might suffice to tackle the challenge of partial observability. However, if we remove RNN encoders and use approximate or even ground-truth state hash alone, the model performs miserably, which confirms the importance of semantic function approximation to tackle the challenge of combinatorially large observation and action spaces. Our findings and analysis provide new insights for designing better text game task setups and agents. © 2022 Association for Computational Linguistics.",Final,
Jin Z.; Guo Q.; Qiu X.; Zhang Z.,"Jin, Zhijing (57216691426); Guo, Qipeng (56106079600); Qiu, Xipeng (56291171900); Zhang, Zheng (58847371600)",57216691426; 56106079600; 56291171900; 58847371600,GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101451295&partnerID=40&md5=4daba04320f0ebc30eea37b5d49deacb,"Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Yadav S.; Pallagani V.; Sheth A.,"Yadav, Shweta (57214081426); Pallagani, Vishal (57202970472); Sheth, Amit (57200763252)",57214081426; 57202970472; 57200763252,Medical Knowledge-enriched Textual Entailment Framework,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149672544&partnerID=40&md5=2302894b2523d23035fce4a514c8102c,"One of the cardinal tasks in achieving robust medical question answering systems is textual entailment. The existing approaches make use of an ensemble of pre-trained language models or data augmentation, often to clock higher numbers on the validation metrics. However, two major shortcomings impede higher success in identifying entailment: (1) understanding the focus/intent of the question and (2) ability to utilize the real-world background knowledge to capture the context beyond the sentence. In this paper, we present a novel Medical Knowledge-Enriched Textual Entailment framework that allows the model to acquire a semantic and global representation of the input medical text with the help of a relevant domain-specific knowledge graph. We evaluate our framework on the benchmark MEDIQA-RQE dataset and manifest that the use of knowledge-enriched dual-encoding mechanism help in achieving an absolute improvement of 8.27% over SOTA language models. We have made the source code available here. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Zhao Y.; Zhang J.; Zhou Y.; Zong C.,"Zhao, Yang (57202271643); Zhang, Jiajun (51666026800); Zhou, Yu (57169094000); Zong, Chengqing (7005615574)",57202271643; 51666026800; 57169094000; 7005615574,Knowledge graphs enhanced neural machine translation,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097342403&partnerID=40&md5=0ae6d87f08dd49ee81d8742071255ca0,"Knowledge graphs (KGs) store much structured information on various entities, many of which are not covered by the parallel sentence pairs of neural machine translation (NMT). To improve the translation quality of these entities, in this paper we propose a novel KGs enhanced NMT method. Specifically, we first induce the new translation results of these entities by transforming the source and target KGs into a unified semantic space. We then generate adequate pseudo parallel sentence pairs that contain these induced entity pairs. Finally, NMT model is jointly trained by the original and pseudo sentence pairs. The extensive experiments on Chinese-to-English and English-to-Japanese translation tasks demonstrate that our method significantly outperforms the strong baseline models in translation quality, especially in handling the induced entities. © 2020 Inst. Sci. inf., Univ. Defence in Belgrade. All rights reserved.",Final,
Kundu S.; Khot T.; Sabharwal A.; Clark P.,"Kundu, Souvik (57189599225); Khot, Tushar (35173172400); Sabharwal, Ashish (14831740900); Clark, Peter (7402579556)",57189599225; 35173172400; 14831740900; 7402579556,Exploiting explicit paths for multi-hop reading comprehension,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084048724&partnerID=40&md5=fa88b2415cccb661045197a953ab39e4,"We propose a novel, path-based reasoning approach for the multi-hop reading comprehension task where a system needs to combine facts from multiple passages to answer a question. Although inspired by multi-hop reasoning over knowledge graphs, our proposed approach operates directly over unstructured text. It generates potential paths through passages and scores them without any direct path supervision. The proposed model, named PathNet, attempts to extract implicit relations from text through entity pair representations, and compose them to encode each path. To capture additional context, PathNet also composes the passage representations along each path to compute a passage-based representation. Unlike previous approaches, our model is then able to explain its reasoning via these explicit paths through the passages. We show that our approach outperforms prior models on the multi-hop Wikihop dataset, and also can be generalized to apply to the OpenBookQA dataset, matching state-of-the-art performance. © 2019 Association for Computational Linguistics.",Final,
Weber T.,"Weber, Tobias (57209530243)",57209530243,A Philological Perspective on Meta-scientific Knowledge Graphs,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090093271&doi=10.1007%2f978-3-030-55814-7_19&partnerID=40&md5=3f4d2aef0a3fc9fb6633180ad0c66968,"This paper discusses knowledge graphs and networks on the scientific process from a philological viewpoint. Relevant themes are: the smallest entities of scientific discourse; the treatment of documents or artefacts as texts and commentaries in discourse; and links between context, (co)text, and data points. As an illustration of the micro-level approach, version control of linguistic examples is discussed as a possible field of application in this discipline. This underlines the claim for data points to be treated like unique entities, which possess metadata of the datum and any text generating knowledge from it. © 2020, Springer Nature Switzerland AG.",Final,
Chen X.; Chen M.; Fan C.; Uppunda A.; Sun Y.; Zaniolo C.,"Chen, Xuelu (57202439053); Chen, Muhao (57077271100); Fan, Changjun (56419227300); Uppunda, Ankith (57219827390); Sun, Yizhou (25823970300); Zaniolo, Carlo (35610506100)",57202439053; 57077271100; 56419227300; 57219827390; 25823970300; 35610506100,Multilingual knowledge graph completion via ensemble knowledge transfer,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098414071&partnerID=40&md5=16c05b1bd715d103286c9b4c277dc12a,"Predicting missing facts in a knowledge graph (KG) is a crucial task in knowledge base construction and reasoning; and it has been the subject of much research in recent works using KG embeddings. While existing KG embedding approaches mainly learn and predict facts within a single KG, a more plausible solution would benefit from the knowledge in multiple language-specific KGs, considering that different KGs have their own strengths and limitations on data quality and coverage. This is quite challenging, since the transfer of knowledge among multiple independently maintained KGs is often hindered by the insufficiency of alignment information and the inconsistency of described facts. In this paper, we propose KEnS, a novel framework for embedding learning and ensemble knowledge transfer across a number of language-specific KGs. KEnS embeds all KGs in a shared embedding space, where the association of entities is captured based on self-learning. Then, KEnS performs ensemble inference to combine prediction results from embeddings of multiple language-specific KGs, for which multiple ensemble techniques are investigated. Experiments on five real-world language-specific KGs show that KEnS consistently improves state-of-the-art methods on KG completion, via effectively identifying and leveraging complementary knowledge. © 2020 Association for Computational Linguistics",Final,
Macketanz V.; Avramidis E.; Burchardt A.; Helcl J.; Srivastava A.,"Macketanz, Vivien (57205403777); Avramidis, Eleftherios (55191209800); Burchardt, Aljoscha (57190058377); Helcl, Jindrich (57200284230); Srivastava, Ankit (57191887611)",57205403777; 55191209800; 57190058377; 57200284230; 57191887611,"Machine translation: Phrase-based, rule-based and neural approaches with linguistic evaluation",1,1,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055563223&doi=10.1515%2fcait-2017-0014&partnerID=40&md5=b4fa85519fc7a94dca33c2c1b32423fd,"In this article we present a novel linguistically driven evaluation method and apply it to the main approaches of Machine Translation (Rule-based, Phrase-based, Neural) to gain insights into their strengths and weaknesses in much more detail than provided by current evaluation schemes. Translating between two languages requires substantial modelling of knowledge about the two languages, about translation, and about the world. Using English-German IT-domain translation as a case-study, we also enhance the Phrase-based system by exploiting parallel treebanks for syntax-aware phrase extraction and by interfacing with Linked Open Data (LOD) for extracting named entity translations in a post decoding framework.",Final,All Open Access; Gold Open Access; Green Open Access
Buchmann R.A.; Karagiannis D.,"Buchmann, Robert Andrei (16030647900); Karagiannis, Dimitris (35573472500)",16030647900; 35573472500,Modelling mobile app requirements for semantic traceability,1,1,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937826800&doi=10.1007%2fs00766-015-0235-1&partnerID=40&md5=9cde5f230420f803d22d454e1dd911e8,"The paper presents a modelling method aimed to support the definition and elicitation of requirements for mobile apps through an approach that enables semantic traceability for the requirements representation. Business process-centricity is employed in order to capture requirements in a knowledge structure that retains procedural knowledge from stakeholders and can be traversed by semantic queries in order to trace domain-specific contextual information for the modelled requirements. Consequently, instead of having requirements represented as natural language items that are documented by diagrammatic models, the communication channels are switched: semantically interlinked conceptual models become the requirements representation, while free text can be used for requirements annotations/metadata. Thus, the method establishes a knowledge externalization channel between business stakeholders and app developers, also tackling the Twin Peaks bridging challenge (between requirements and early designs). The method is presented using its modelling procedure as a guiding thread, with each step illustrated by case-based samples of the modelling language and auxiliary functionality. The design work is encompassed by an existing metamodelling framework and introduces a taxonomy for modelling relations, since the metamodel is the key enabler for the goal of semantic traceability. The research was driven by the ComVantage EU research project, concerned with mobile app support for collaborative business process execution. Therefore, the project provides context for the illustrating examples; however, generalization possibilities beyond the project scope will also be discussed, with respect to both motivation and outcome. © 2015, Springer-Verlag London.",Final,
Zadeh P.D.H.; D. Hossein Zadeh M.; Reformat M.Z.,"Zadeh, Parisa D. Hossein (51863965300); D. Hossein Zadeh, Mahsa (56580423200); Reformat, Marek Z. (6603618138)",51863965300; 56580423200; 6603618138,Feature-driven linguistic-based entity matching in linked data with application in pharmacy,1,1,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926221452&doi=10.1007%2fs00500-015-1632-6&partnerID=40&md5=c95fa81febc8406bc647518a8d9b384d,"The web becomes an overwhelmingly huge repository of data. At the same time, users demand access to the information on the web in a more natural way. In other words, users require interaction with the web using natural linguistic terms and expect human comprehensive answers. The introduction of Resource Description Framework (RDF) is a promising step towards significant changes how systems can utilize the web. The very nature of RDF format that ensures high interconnectivity of pieces of data creates an opportunity to process and analyse data in a different way. In this paper, we address the problem of processing web information using fuzzy-based technologies. In particular, we adopt a linguistic representation model to determining alternatives that match a given reference with the highest possible degree and satisfying some specific criteria. The process of comparing alternatives to the reference is feature-driven while an entity is described by its features. The proposed methodology is able to deal with features of different nature and utilize comparison mechanisms suitable for each type of features. The utilization of 2-tuple allows for comparing and aggregating linguistic-based descriptions of features, especially when the reference does not specify values of features explicitly. In experiments, we show the utilization of our approach in the domain of pharmacy. The obtained results show the advantage of using the feature-based comparison process and linguistic aggregation procedure over results obtained using the RDF query language SPARQL (SPARQL Protocol and RDF Query Language). © 2015, Springer-Verlag Berlin Heidelberg.",Final,
Van Aggelen A.; Hollink L.; Van Ossenbruggen J.,"Van Aggelen, Astrid (57192316244); Hollink, Laura (55949222600); Van Ossenbruggen, Jacco (55897905700)",57192316244; 55949222600; 55897905700,Combining distributional semantics and structured data to study lexical change,1,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016291410&partnerID=40&md5=c553b8279d1c93ff2cff33aba3370daa,"Statistical Natural Language Processing (NLP) techniques allow to quantify lexical semantic change using large text corpora. Word-level results of these methods can be hard to analyse in the context of sets of semantically or linguistically related words. On the other hand, structured knowledge sources represent such relationships explicitly, but ignore the problem of semantic change. We aim to address these limitations by combining the statistical and symbolic approach: we enrich WordNet, a structured lexical database, with quantitative lexical change scores provided by HistWords, a dataset produced by distributional NLP methods. We publish the result as Linked Open Data and demonstrate how queries on the combined dataset can provide new insights. © 2016, CEUR-WS. All rights reserved.",Final,
Tan Y.; Zhang X.; Chen Y.; Ali Z.; Hua Y.; Qi G.,"Tan, Yiming (57347010800); Zhang, Xinyu (58451949900); Chen, Yongrui (57205105178); Ali, Zafar (57220705145); Hua, Yuncheng (56900504700); Qi, Guilin (56393840100)",57347010800; 58451949900; 57205105178; 57220705145; 56900504700; 56393840100,CLRN: A reasoning network for multi-relation question answering over Cross-lingual Knowledge Graphs,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162144389&doi=10.1016%2fj.eswa.2023.120721&partnerID=40&md5=725cd1d23f8e203ad0f1238fbe3f76a0,"Cross-lingual Knowledge Graphs-based Question Answering (CLKGQA) requires the question answering (QA) system to combine the knowledge graphs (KGs) in different languages to obtain answers to input questions. In previous works, the common idea is to merge Cross-lingual Knowledge Graphs (CLKGs) into a single KG through aligned entity pairs and then treat it as a traditional KG-based QA. However, as demonstrated by Tan et al. (2023), existing Entity Alignment (EA) models cannot generate highly accurate aligned entity pairs for CLKGs. Therefore, two issues need to be addressed in the CLKGQA task: (1) Remove the dependency of the QA model on the fused KG; (2) Improve the performance of the EA model in obtaining aligned entity pairs from locally isomorphic CLKGs. To solve the above two issues, this paper presents Cross-lingual Reasoning Network (CLRN), a novel multi-hop QA model that allows switching knowledge graphs at any stage of the multi-hop reasoning. Furthermore, we establish an iterative framework that combines CLRN and EA model, in which CLRN is used for extracting potential alignment triple pairs from CLKGs during the QA process. The extracted triple pairs provide pseudo-aligned entities, and the additional aligned entity pairs are used to mine missing relations between entities in CLKGs. These pseudo-aligned entity pairs and relations improve the performance of the EA model, resulting in higher accuracy in QA. Extensive experiments demonstrate the effectiveness of the proposed model, which outperforms the baseline approaches. Through iterative enhancement, the performance of the EA model has also been improved by > 1.0 % in Hit@1 and Hit@10, and the improvement is statistically significant in the confidence interval of p<0.01. Moreover, our work discusses the correlation between QA and EA from the side of QA, which has reference value for the follow-up exploration of related communities. We have open-sourced our dataset and code, which is available at the URL https://github.com/tan92hl/Cross-lingual-Reasoning-Network-for-CLKGQA. © 2023 Elsevier Ltd",Final,
Varshney D.; Zafar A.; Behera N.K.; Ekbal A.,"Varshney, Deeksha (57217702734); Zafar, Aizan (58031569400); Behera, Niranshu Kumar (58119357000); Ekbal, Asif (23093674100)",57217702734; 58031569400; 58119357000; 23093674100,Knowledge graph assisted end-to-end medical dialog generation,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151685702&doi=10.1016%2fj.artmed.2023.102535&partnerID=40&md5=5d9b3d397a451b33d684afc4c3ddb30c,"Medical dialog systems have the potential to assist e-medicine in improving access to healthcare services, improving patient treatment quality, and lowering medical expenses. In this research, we describe a knowledge-grounded conversation generation model that demonstrates how large-scale medical information in the form of knowledge graphs can aid in language comprehension and generation in medical dialog systems. Generic responses are often produced by existing generative dialog systems, resulting in monotonous and uninteresting conversations. To solve this problem, we combine various pre-trained language models with a medical knowledge base (UMLS) to generate clinically correct and human-like medical conversations using the recently released MedDialog-EN dataset. The medical-specific knowledge graph contains broadly 3 types of medical-related information, including disease, symptom and laboratory test. We perform reasoning over the retrieved knowledge graph by reading the triples in each graph using MedFact attention, which allows us to use semantic information from the graphs for better response generation. In order to preserve medical information, we employ a policy network, which effectively injects relevant entities associated with each dialog into the response. We also study how transfer learning can significantly improve the performance by utilizing a relatively small corpus, created by extending the recently released CovidDialog dataset, containing the dialogs for diseases that are symptoms of Covid-19. Empirical results on the MedDialog corpus and the extended CovidDialog dataset demonstrate that our proposed model significantly outperforms the state-of-the-art methods in terms of both automatic evaluation and human judgment. © 2023 Elsevier B.V.",Final,
Srivastava N.; Perevalov A.; Kuchelev D.; Moussallem D.; Ngonga Ngomo A.-C.; Both A.,"Srivastava, Nikit (57204461756); Perevalov, Aleksandr (57207821935); Kuchelev, Denis (57219525151); Moussallem, Diego (57079181300); Ngonga Ngomo, Axel-Cyrille (23397850200); Both, Andreas (23966392700)",57204461756; 57207821935; 57219525151; 57079181300; 23397850200; 23966392700,Lingua Franca - Entity-Aware Machine Translation Approach for Question Answering over Knowledge Graphs,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180369135&doi=10.1145%2f3587259.3627567&partnerID=40&md5=65a582eb42da55e0bc56ce9e187cbe41,"This research paper proposes an approach called Lingua Franca that improves machine translation quality by utilizing information from a knowledge graph to translate named entities accurately. The accurate entity translation is crucial when applied to entity-oriented search including Knowledge Graph Question Answering systems. In a nutshell, the approach preserves recognized named entities with an entity-replacement technique during the translation process. It replaces the entities back with their labels found in a knowledge graph for the target language to ensure that questions are translated correctly before answering them using a Knowledge Graph Question Answering system. The paper also introduces an open-source modular framework that enables researchers to design their own named entity-aware machine translation pipelines. The presented experimental results demonstrate the effectiveness of the Lingua Franca approach in comparison to baseline Machine Translation models. The approach shows a statistically significant improvement in the quality provided by several Knowledge Graph Question Answering systems using Lingua Franca on different datasets. © 2023 ACM.",Final,
Casadei S.,"Casadei, Stefano (58759563200)",58759563200,Semiotic Knowledge Models for Personal Knowledge Repositories,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546774&doi=10.5220%2f0012209100003598&partnerID=40&md5=233ec7719a4b45185dcb5753aed35c4b,"Knowledge graphs have been used successfully to represent and acquire general knowledge and have also been proposed for personal knowledge representations. While general knowledge data can be modelled statistically as being a noisy projection of universal (and crisp) entities, categories, and relationships, personal knowledge data requires a more refined model: each user’s peculiarities and fluctuations in associating words with meanings and meanings with words should be tracked and analysed instead of being treated as noise and averaged out. This position paper describes a semiotic knowledge model whose primitives are the signification events which occur when symbols such as words and linguistic expressions are associated with an instantaneous meaning. Semiotic structures constructed from these primitives with users’ active participation, enable them to create, update, modify, organize, re-organize and curate detailed and comprehensive representations of their own personal knowledge by means of their own personal terminologies, taxonomies, and organizational schemes. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0).",Final,All Open Access; Hybrid Gold Open Access
Lenz M.; Bergmann R.,"Lenz, Mirko (57211170160); Bergmann, Ralph (57193551665)",57211170160; 57193551665,Case-Based Adaptation of Argument Graphs with WordNet and Large Language Models,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172236578&doi=10.1007%2f978-3-031-40177-0_17&partnerID=40&md5=16c053188e78a303828ea1b95c941983,"Finding information online is hard, even more so once you get into the domain of argumentation. There have been developments around the specialized argumentation machines that incorporate structural features of arguments, but all current approaches share one pitfall: They operate on a corpora of limited sizes. Consequently, it may happen that a user searches for a rather general term like cost increases, but the machine is only able to serve arguments concerned with rent increases. We aim to bridge this gap by introducing approaches to generalize/specialize a found argument using a combination of WordNet and Large Language Models. The techniques are evaluated on a new benchmark dataset with diverse queries using our fully featured implementation. Both the dataset and the code are publicly available on GitHub. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Sun W.; Li Y.; Yao J.; Wu Q.; Liu K.,"Sun, Wen (57614738400); Li, Yifan (58747481200); Yao, Junfeng (16644372400); Wu, Qingqiang (57212567708); Liu, Kunhong (34973260300)",57614738400; 58747481200; 16644372400; 57212567708; 34973260300,Combining Structure Embedding and Text Semantics for Efficient Knowledge Graph Completion,1,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170076831&doi=10.18293%2fSEKE2023-100&partnerID=40&md5=e19bfda0c4056eb1fb642c35ddeff2ce,"Knowledge graph completion plays a crucial role in downstream applications. However, existing methods tend to only rely on the structure or textual information, resulting in suboptimal model performance. Moreover, recent attempts to leverage pre-trained language models to complete knowledge graphs have proved unsatisfactory. To overcome these limitations, we propose a novel model that combines structural embedding and semantic information of the knowledge graph. Compared with previous works based on pre-trained language models, our model can better use the implicit knowledge of pre-trained language models by using relation templates, entity definitions, and learnable tokens. Furthermore, our model employs a multi-head attention mechanism to transform the embedding semantic space of entities and relations obtained from the knowledge graph embedding model, thereby enhancing their expressiveness and unifying the semantic space of both types of information. Finally, we utilize convolutional neural networks to extract features from the matrices created by combining these two types of information for link prediction and triplet classification tasks. Empirical evaluations on two knowledge graph completion datasets demonstrate that our model is effective for both tasks. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Final,All Open Access; Bronze Open Access
Boukkouri H.E.; Ferret O.; Lavergne T.; Zweigenbaum P.,"Boukkouri, Hicham El (58209526200); Ferret, Olivier (14832680800); Lavergne, Thomas (57215443055); Zweigenbaum, Pierre (6701325746)",58209526200; 14832680800; 57215443055; 6701325746,Specializing Static and Contextual Embeddings in the Medical Domain Using Knowledge Graphs: Let's Keep It Simple,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154614219&partnerID=40&md5=21a721dcab51423456aa000d55e80aaf,"Domain adaptation of word embeddings has mainly been explored in the context of retraining general models on large specialized corpora. While this usually yields good results, we argue that knowledge graphs, which are used less frequently, could also be utilized to enhance existing representations with specialized knowledge. In this work, we aim to shed some light on whether such knowledge injection could be achieved using a basic set of tools: graph-level embeddings and concatenation. To that end, we adopt an incremental approach where we first demonstrate that static embeddings can indeed be improved through concatenation with in-domain node2vec representations. Then, we validate this approach on contextual models and generalize it further by proposing a variant of BERT that incorporates knowledge embeddings within its hidden states through the same process of concatenation. We show that this variant outperforms plain retraining on several specialized tasks, then discuss how this simple approach could be improved further. Both our code and pre-trained models are open-sourced for future research. In this work, we conduct experiments that target the medical domain and the English language.  © 2022 Association for Computational Linguistics.",Final,
Păiş V.-F.; Mititelu V.B.,"Păiş, Vasile-Florian (16686767100); Mititelu, Verginica Barbu (14042533100)",16686767100; 14042533100,Linguistic linked open data for speech processing,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140660011&partnerID=40&md5=ff76df373fe23e6056d6db34aae6e4af,"Linguistic Linked Open Data is becoming an important format for language resources, due to its power to ensure resources' interoperability and integration, which makes them more easily findable, accessible, interoperable and retrievable (i.e., FAIR). Romanian has fragmentary support with respect to the development of language resources and processing tools. Thus, in an effort to promote the existing ones, their conversion to Linked Data is a natural step. We focus here on resources for speech processing and present the RoLEX lexicon and the RTASC corpus that are relevant for this task: the former is the largest lexicon with phonetic transcription for Romanian words and their inflected forms, while the latter is a bimodal corpus relevant for training a robot's speech component for a specifically designed microworld. Both are converted to the Linguistic Linked Open Data format, linked to other existing resources for Romanian and made available as downloadable files and for query by means of SPARQL language. Some scenarios for exploiting the power of Linked Data format of these resources are also described here. © 2022 Nova Science Publishers, Inc..",Final,
AlMousa M.; Benlamri R.; Khoury R.,"AlMousa, Mohannad (57203297062); Benlamri, Rachid (57203235506); Khoury, Richard (16021635100)",57203297062; 57203235506; 16021635100,A novel word sense disambiguation approach using WordNet knowledge graph,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122705398&doi=10.1016%2fj.csl.2021.101337&partnerID=40&md5=ac2d90607397c902c5eaef4ae5251b0c,"Various applications in computational linguistics and artificial intelligence rely on high-performing word sense disambiguation techniques to solve challenging tasks such as information retrieval, machine translation, question answering, and document clustering. While text comprehension is intuitive for humans, machines face tremendous challenges in processing and interpreting a human's natural language. This paper presents a novel knowledge-based word sense disambiguation algorithm, namely Sequential Contextual Similarity Matrix Multiplication (SCSMM). The SCSMM algorithm combines semantic similarity, heuristic knowledge, and document context to respectively exploit the merits of local sense-based context between consecutive terms, human knowledge about terms, and a document's main topic in disambiguating terms. Unlike other algorithms, the SCSMM algorithm guarantees the capture of the maximum sentence context while maintaining the terms’ order within the sentence. The proposed algorithm outperformed all other algorithms when disambiguating nouns on the combined gold standard datasets, while demonstrating comparable results to current state-of-the-art word sense disambiguation systems when dealing with each dataset separately. Furthermore, the paper discusses the impact of granularity level, ambiguity rate, sentence size, and part of speech distribution on the performance of the proposed algorithm. © 2022 Elsevier Ltd",Final,All Open Access; Green Open Access
Goel S.; Gracia J.; Forcada M.L.,"Goel, Shashwat (58711735300); Gracia, Jorge (55392626700); Forcada, Mikel L. (6603811993)",58711735300; 55392626700; 6603811993,Bilingual dictionary generation and enrichment via graph exploration,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140834359&doi=10.3233%2fSW-222899&partnerID=40&md5=dacaa9f99e46d8a0814518971cac32c2,"In recent years, we have witnessed a steady growth of linguistic information represented and exposed as linked data on the Web. Such linguistic linked data have stimulated the development and use of openly available linguistic knowledge graphs, as is the case with the Apertium RDF, a collection of interconnected bilingual dictionaries represented and accessible through Semantic Web standards. In this work, we explore techniques that exploit the graph nature of bilingual dictionaries to automatically infer new links (translations). We build upon a cycle density based method: partitioning the graph into biconnected components for a speed-up, and simplifying the pipeline through a careful structural analysis that reduces hyperparameter tuning requirements. We also analyse the shortcomings of traditional evaluation metrics used for translation inference and propose to complement them with new ones, both-word precision (BWP) and both-word recall (BWR), aimed at being more informative of algorithmic improvements. Over twenty-seven language pairs, our algorithm produces dictionaries about 70% the size of existing Apertium RDF dictionaries at a high BWP of 85% from scratch within a minute. Human evaluation shows that 78% of the additional translations generated for dictionary enrichment are correct as well. We further describe an interesting use-case: inferring synonyms within a single language, on which our initial human-based evaluation shows an average accuracy of 84%. We release our tool as free/open-source software which can not only be applied to RDF data and Apertium dictionaries, but is also easily usable for other formats and communities.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
Liu Y.; Li L.; Zhang B.; Huang Q.,"Liu, Yiting (58138325800); Li, Liang (56182887500); Zhang, Beichen (57219687889); Huang, Qingming (8435766200)",58138325800; 56182887500; 57219687889; 8435766200,Think Beyond Words: Exploring Context-Relevant Visual Commonsense for Diverse Dialogue Generation,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149885714&partnerID=40&md5=405a983b343341f586184d863d76d20b,"Commonsense knowledge has been widely considered for building intelligent open-domain dialogue agents, aiming to generate meaningful and diverse responses. Previous works in this field usually lack the ability to effectively obtain and utilize auxiliary commonsense from the external visual world. In this paper, we argue that exploiting logical information in images related to context can be effective to enrich and steer the generation process. In view of this, we propose VICTOR, a context-relevant VIsual Commonsense enhanced dialogue generaTOR for generating coherent and informative responses. To obtain the associated visual commonsense, we devise a novel approach that expands topic words on the knowledge graph and maps them into daily scenarios. During the generation, the model adopts multimodal fusion mechanism to integrate visual and textual information, and adaptively combine their decoding distributions for better response generation. The experimental results on two public datasets show that our proposed method outperforms the latest competitive methods in terms of coherence and diversity. © 2022 Association for Computational Linguistics.",Final,
Liu L.; Li X.; He R.; Bing L.; Joty S.; Si L.,"Liu, Linlin (57216692813); Li, Xin (57225160117); He, Ruidan (57200339803); Bing, Lidong (24314897600); Joty, Shafiq (24779447500); Si, Luo (7006717974)",57216692813; 57225160117; 57200339803; 24314897600; 24779447500; 7006717974,Enhancing Multilingual Language Model with Massive Multilingual Knowledge Triples,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143087240&partnerID=40&md5=23c56bd34f15c1847bdc19f5bba9c742,"Knowledge-enhanced language representation learning has shown promising results across various knowledge-intensive NLP tasks. However, prior methods are limited in efficient utilization of multilingual knowledge graph (KG) data for language model (LM) pretraining. They often train LMs with KGs in indirect ways, relying on extra entity/relation embeddings to facilitate knowledge injection. In this work, we explore methods to make better use of the multilingual annotation and language agnostic property of KG triples, and present novel knowledge based multilingual language models (KMLMs) trained directly on the knowledge triples. We first generate a large amount of multilingual synthetic sentences using the Wikidata KG triples. Then based on the intra- and inter-sentence structures of the generated data, we design pretraining tasks to enable the LMs to not only memorize the factual knowledge but also learn useful logical patterns. Our pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive crosslingual tasks, including named entity recognition (NER), factual knowledge retrieval, relation classification, and a newly designed logical reasoning task. © 2022 Association for Computational Linguistics.",Final,
Huang Z.; Li Z.; Jiang H.; Cao T.; Lu H.; Yin B.; Subbian K.; Sun Y.; Wang W.,"Huang, Zijie (57217167601); Li, Zheng (57196124633); Jiang, Haoming (57210643061); Cao, Tianyu (57225220598); Lu, Hanqing (57224593165); Yin, Bing (57210637479); Subbian, Karthik (24345164000); Sun, Yizhou (25823970300); Wang, Wei (55157954300)",57217167601; 57196124633; 57210643061; 57225220598; 57224593165; 57210637479; 24345164000; 25823970300; 55157954300,Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142893526&partnerID=40&md5=4ae7fe3d7d3b61eee6fea8f653a78a48,"Predicting missing facts in a knowledge graph (KG) is crucial as modern KGs are far from complete. Due to labor-intensive human labeling, this phenomenon deteriorates when handling knowledge represented in various languages. In this paper, we explore multilingual KG completion, which leverages limited seed alignment as a bridge, to embrace the collective knowledge from multiple languages. However, language alignment used in prior works is still not fully exploited: (1) alignment pairs are treated equally to maximally push parallel entities to be close, which ignores KG capacity inconsistency; (2) seed alignment is scarce and new alignment identification is usually in a noisily unsupervised manner. To tackle these issues, we propose a novel self-supervised adaptive graph alignment (SS-AGA) method. Specifically, SS-AGA fuses all KGs as a whole graph by regarding alignment as a new edge type. As such, information propagation and noise influence across KGs can be adaptively controlled via relation-aware attention weights. Meanwhile, SS-AGA features a new pair generator that dynamically captures potential alignment pairs in a self-supervised paradigm. Extensive experiments on both the public multilingual DBPedia KG and newly-created industrial multilingual E-commerce KG empirically demonstrate the effectiveness of SS-AGA. © 2022 Association for Computational Linguistics.",Final,
Tian J.; Li X.; Qiang C.,"Tian, Junpeng (57402164900); Li, Xiaoge (56050500900); Qiang, Chengyu (57402327000)",57402164900; 56050500900; 57402327000,Cross-lingual Knowledge Graph Alignment via Neighborhood Reconstruction Network,1,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125856136&doi=10.1145%2f3488933.3489028&partnerID=40&md5=d5074a6db72a845fcb4d264e1948128d,"Structural heterogeneity between knowledge graphs is an outstanding challenge for entity alignment. Most of the previous cross-lingual knowledge graph alignment studies rely on entity information only from monolingual mapping information, which may fail at matching entities that have different structure information in two KGs. In this paper, we propose the Neighborhood Reconstruction Network (NRNet), a novel entity alignment framework for tackling the structural heterogeneity challenge. NRNet first expand their one-hop neighbors based on other KGs to reduce the difference between neighbor structures. Next, it calculates the mutual information between entities to capture both the topological structure and the neighborhood difference. We further used a solution based on graph attention to obtain graph-level matching vectors. Experiments on the benchmark dataset show that the effectiveness of NRNet by detailed ablation studies and analysis.  © 2021 ACM.",Final,
Augenstein I.; Gentile A.L.; Norton B.; Zhang Z.; Ciravegna F.,"Augenstein, Isabelle (55236320300); Gentile, Anna Lisa (23392611200); Norton, Barry (15136545600); Zhang, Ziqi (14326468700); Ciravegna, Fabio (8957737400)",55236320300; 23392611200; 15136545600; 14326468700; 8957737400,Mapping keywords to Linked Data resources for automatic query expansion,1,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922580693&partnerID=40&md5=8965215840be6c3d4d6bbd95e2170a49,"Linked Data is a gigantic, constantly growing and extremely valuable resource, but its usage is still heavily dependent on (i) the familiarity of end users with RDF's graph data model and its query language, SPARQL, and (ii) knowledge about available datasets and their contents. Intelligent keyword search over Linked Data is currently being investigated as a means to overcome these barriers to entry in a number of different approaches, including semantic search engines and the automatic conversion of natural language questions into structured queries. Our work addresses the specific challenge of mapping keywords to Linked Data resources, and proposes a novel method for this task. By exploiting the graph structure within Linked Data we determine which properties between resources are useful to discover, or directly express, semantic similarity. We also propose a novel scoring function to rank results. Experiments on a publicly available dataset show a 17% improvement in Mean Reciprocal Rank over the state of the art.",Final,
Nebhi K.,"Nebhi, Kamel (55443274100)",55443274100,A rule-based relation extraction system using DBpedia and syntactic parsing,1,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102494696&partnerID=40&md5=2235e2f8d78d98c9ae8145a9d119736c,"In this paper, we present a rule-based relation extraction approach which uses DBpedia and linguistic information provided by the syntactic parser Fips. Our goal is twofold: (i) the morpho-syntactic patterns are defined using the syntactic parser Fips to identify relations between named entities (ii) the RDF triples extracted from DBpedia are used to improve RE task by creating gazetteer relations.",Final,
Liwicki M.; Forcher B.; Jaeger P.; Dengel A.,"Liwicki, Marcus (14021418000); Forcher, Björn (36678783000); Jaeger, Philipp (55247741800); Dengel, Andreas (6603764314)",14021418000; 36678783000; 55247741800; 6603764314,Koios++: A query-answering system for handwritten input,1,1,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862081741&doi=10.1109%2fDAS.2012.48&partnerID=40&md5=2ad0680782e09a36ac8fabe870d374a3,"In this paper we propose KOIOS++, which automatically processes natural language queries provided by handwritten input. The system integrates several recent achievements in the area of handwriting recognition, natural language processing, information retrieval, and human computer interaction. It uses a knowledge base described by the resource description framework (RDF). Our generic approach first generates a lexicon as background information for the handwritten text recognition. After recognizing a handwritten query, several output hypotheses are sent to a natural language processing system in order to generate a structured query (SPARQL query). Subsequently, the query is applied to the given knowledge base and a result graph visualizes the retrieved information. At all stages, the user can easily adjust the intermediate results if there is any undesired outcome. The system is implemented as a web-service and therefore works for handwritten input on digital paper as well as on input on Pen-enabled interactive surfaces. Furthermore, we build on the generic RDF-representation of semantic knowledge which is also used by the linked open data (LOD) initiative. As such, our system works well in various scenarios. We have implemented prototypes for querying company knowledge bases, the DBPedia1, the DBLP computer science bibliography2, and a knowledge base of the DAS 2012. © 2012 IEEE.",Final,
Menéndez A.A.; Gayo J.E.L.,"Menéndez, Alejandro Álvarez (55338453100); Gayo, José Emilio Labra (8374489000)",55338453100; 8374489000,SCOWT: Semantic competencies for worker training,1,1,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865102309&partnerID=40&md5=e68ca7aacefedfb898dc17d43287f4af,"Organizations globalization is becoming more and more usual in IT sector. Currently, teams composed by members from different countries and collaborating with other foreign teams is a growing tendency. However, this multicultural working environment carries remarkable problems due to linguistic and cultural issues. These problems arise not only in software development stages but also in information exchange between organization departments. The Human Resources (HR) department is one of those departments that suffer from ambiguous vocabulary while understanding concepts like, e.g, ""competence"" or ""skill"". We propose a Competence Management Ontology (calledSCOWT), inspired by Semantic Web technologies, Linked Data principles and the European e-Competence Framework for ICT professional competencies definition. This ontology has been designed as the key component for the development of a Competence Management System. Using ontologies will raise the current level of semantic interoperability of data exchange between HR departments and could improve efficiency of HR activities, specifically the training activities design in a global IT organization. © 2011 IADIS.",Final,
Melnyk I.; Dognin P.; Das P.,"Melnyk, Igor (57057398500); Dognin, Pierre (55967126700); Das, Payel (58194251700)",57057398500; 55967126700; 58194251700,Knowledge Graph Generation From Text,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149903796&partnerID=40&md5=56beffdd18ab7b82da1a15471af9dea5,"In this work we propose a novel end-to-end multi-stage Knowledge Graph (KG) generation system from textual inputs, separating the overall process into two stages. The graph nodes are generated first using pretrained language model, followed by a simple edge construction head, enabling efficient KG extraction from the text. For each stage we consider several architectural choices that can be used depending on the available training resources. We evaluated the model on a recent WebNLG 2020 Challenge dataset, matching the state-of-the-art performance on text-to-RDF generation task, as well as on New York Times (NYT) and a large-scale TEKGEN datasets, showing strong overall performance, outperforming the existing baselines. We believe that the proposed system can serve as a viable KG construction alternative to the existing linearization or sampling-based graph generation approaches. © 2022 Association for Computational Linguistics.",Final,
Stanković R.; Krstev C.; Todorović B.Š.; Vitas D.; Škorić M.; Nešić M.I.,"Stanković, Ranka (56443795400); Krstev, Cvetana (7801364908); Todorović, Branislava Šandrih (57394596900); Vitas, Duško (6506362231); Škorić, Mihailo (57220089897); Nešić, Milica Ikonić (57429235100)",56443795400; 7801364908; 57394596900; 6506362231; 57220089897; 57429235100,Distant Reading in Digital Humanities: Case Study on the Serbian Part of the ELTeC Collection,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144424875&partnerID=40&md5=20e877c23a939d7ac524675188fe815d,"In this paper we present the Serbian part of the ELTeC multilingual corpus of novels written in the time period 1840-1920. The corpus is being built in order to test various distant reading methods and tools with the aim of re-thinking the European literary history. We present the various steps that led to the production of the Serbian sub-collection: the novel selection and retrieval, text preparation, structural annotation, POS-tagging, lemmatization and named entity recognition. The Serbian sub-collection was published on different platforms in order to make it freely available to various users. Several use examples show that this sub-collection is useful for both close and distant reading approaches. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Markowitz E.; Balasubramanian K.; Mirtaheri M.; Annavaram M.; Galstyan A.; Steeg G.V.,"Markowitz, Elan (57130686500); Balasubramanian, Keshav (57216085554); Mirtaheri, Mehrnoosh (57197876200); Annavaram, Murali (57195496128); Galstyan, Aram (7003679856); Steeg, Greg Ver (26326519600)",57130686500; 57216085554; 57197876200; 57195496128; 7003679856; 26326519600,StATIK: Structure and Text for Inductive Knowledge Graph Completion,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137336754&partnerID=40&md5=dcd256325a283a1ebc2179470216ec6a,"Knowledge graphs (KGs) often represent knowledge bases that are incomplete. Machine learning models can alleviate this by helping automate graph completion. Recently, there has been growing interest in completing knowledge bases that are dynamic, where previously unseen entities may be added to the KG with many missing links. In this paper, we present StATIK-Structure And Text for Inductive Knowledge Completion. StATIK uses Language Models to extract the semantic information from text descriptions, while using Message Passing Neural Networks to capture the structural information. StATIK achieves state of the art results on three challenging inductive baselines. We further analyze our hybrid model through detailed ablation studies. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Niklaus C.,"Niklaus, Christina (57204292696)",57204292696,From Complex Sentences to a Formal Semantic Representation using Syntactic Text Simplification and Open Information Extraction,1,-1,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131573085&doi=10.1007%2f978-3-658-38697-9&partnerID=40&md5=181a2ca4adf4f0737db88ef317301321,"This work presents a discourse-aware Text Simplification approach that splits and rephrases complex English sentences within the semantic context in which they occur. Based on a linguistically grounded transformation stage, complex sentences are transformed into shorter utterances with a simple canonical structure that can be easily analyzed by downstream applications. To avoid breaking down the input into a disjointed sequence of statements that is difficult to interpret, the author incorporates the semantic context between the split propositions in the form of hierarchical structures and semantic relationships, thus generating a novel representation of complex assertions that puts a semantic layer on top of the simplified sentences. In a second step, she leverages the semantic hierarchy of minimal propositions to improve the performance of Open IE frameworks. She shows that such systems benefit in two dimensions. First, the canonical structure of the simplified sentences facilitates the extraction of relational tuples, leading to an improved precision and recall of the extracted relations. Second, the semantic hierarchy can be leveraged to enrich the output of existing Open IE approaches with additional meta-information, resulting in a novel lightweight semantic representation for complex text data in the form of normalized and context-preserving relational tuples. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Fachmedien Wiesbaden GmbH, part of Springer Nature 2022.",Final,All Open Access; Green Open Access
Zhao Y.; Cai X.; Wu Y.; Zhang H.; Zhang Y.; Zhao G.; Jiang N.,"Zhao, Yu (57909140900); Cai, Xiangrui (55954059800); Wu, Yike (57210586635); Zhang, Haiwei (35118347900); Zhang, Ying (55954386400); Zhao, Guoqing (57928752500); Jiang, Ning (57264662700)",57909140900; 55954059800; 57210586635; 35118347900; 55954386400; 57928752500; 57264662700,MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph Completion,1,1,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441752&partnerID=40&md5=d8b426357d0ebabc4b4a88ab9dbda59d,"Multimodal knowledge graph completion (MKGC) aims to predict missing entities in MKGs. Previous works usually share relation representation across modalities. This results in mutual interference between modalities during training, since for a pair of entities, the relation from one modality probably contradicts that from another modality. Furthermore, making a unified prediction based on the shared relation representation treats the input in different modalities equally, while their importance to the MKGC task should be different. In this paper, we propose MoSE, a Modality Split representation learning and Ensemble inference framework for MKGC. Specifically, in the training phase, we learn modality-split relation embeddings for each modality instead of a single modality-shared one, which alleviates the modality interference. Based on these embeddings, in the inference phase, we first make modality-split predictions and then exploit various ensemble methods to combine the predictions with different weights, which models the modality importance dynamically. Experimental results on three KG datasets show that MoSE outperforms state-of-the-art MKGC methods. Codes are available at https://github.com/OreOZhao/MoSE4MKGC. © 2022 Association for Computational Linguistics.",Final,
Ge T.; Wang Y.; De Melo G.; Li H.; Chen B.,"Ge, Tong (57193773310); Wang, Yafang (57189491283); De Melo, Gerard (23088528100); Li, Haofeng (57193778770); Chen, Baoquan (7408533850)",57193773310; 57189491283; 23088528100; 57193778770; 7408533850,Visualizing and curating knowledge graphs over time and space,1,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016486947&doi=10.18653%2fv1%2fp16-4005&partnerID=40&md5=3dd121ce08e7cc4d531c210d79fe08b2,"Publicly available knowledge repositories, such as Wikipedia and Freebase, benefit significantly from volunteers, whose contributions ensure that the knowledge keeps expanding and is kept up-to-date and accurate. User interactions are often limited to hypertext, tabular, or graph visualization interfaces. For spatio-temporal information, however, other interaction paradigms may be better-suited. We present an integrated system that combines crowdsourcing, automatic or semi-automatic knowledge harvesting from text, and visual analytics. It enables users to analyze large quantities of structured data and unstructured textual data from a spatio-temporal perspective and gain deep insights that are not easily observed in individual facts. © 2016 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
Laek I.; Vojtá P.,"Laek, Ivo (53979840800); Vojtá, Peter (55578990700)",53979840800; 55578990700,Various approaches to text representation for named entity disambiguation,1,1,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873378914&doi=10.1145%2f2428736.2428776&partnerID=40&md5=ea55476c124f7e55d72c6fe00422ff40,"In this paper, we focus on the problem of named entity disambiguation. We disambiguate named entities on a very detailed level. To each entity is assigned a concrete identifier of a corresponding Wikipedia article describing the entity. For such a fine grained disambiguation a correct representation of a context is crucial. We compare various context representations: bag of words representation, linguistic representation and structured co-occurrence representation of the context. Models for each representation are described and evaluated. © 2012 ACM.",Final,
Gillis-Webber F.; Tittel S.,"Gillis-Webber, Frances (57204543421); Tittel, Sabine (36165030000)",57204543421; 36165030000,A framework for shared agreement of language tags beyond ISO 639,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512485&partnerID=40&md5=e44ab9b4c0659408b02cf0f00d949ed5,"The identification and annotation of languages in an unambiguous and standardized way is essential for the description of linguistic data. It is the prerequisite for machine-based interpretation, aggregation, and re-use of the data with respect to different languages. This makes it a key aspect especially for Linked Data and the multilingual Semantic Web. The standard for language tags is defined by IETF's BCP 47 and ISO 639 provides the language codes that are the tags' main constituents. However, for the identification of lesser-known languages, endangered languages, regional varieties or historical stages of a language, the ISO 639 codes are insufficient. Also, the optional language sub-tags compliant with BCP 47 do not offer a possibility fine-grained enough to represent linguistic variation. We propose a versatile pattern that extends the BCP 47 sub-tag privateuse and is, thus, able to overcome the limits of BCP 47 and ISO 639. Sufficient coverage of the pattern is demonstrated with the use case of linguistic Linked Data of the endangered Gascon language. We show how to use a URI shortcode for the extended sub-tag, making the length compliant with BCP 47. We achieve this with a web application and API developed to encode and decode the language tag. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
Vaisman A.,"Vaisman, Alejandro (7006229550)",7006229550,Publishing OLAP cubes on the semantic web,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978761828&doi=10.1007%2f978-3-319-39243-1_2&partnerID=40&md5=42e4e5d9ac8a2fdf6954962636b65709,"The availability of large repositories of semantically annotated data on the web is opening new opportunities for enhancing Decision-Support Systems. In addition, the advent of initiatives such as Open Data and Open Government, together with the Linked Open Data paradigm, are promoting publication and sharing of multidimensional data (MD) on the web. In this paper we address the problem of representing MD data using Semantic Web (SW) standards. We discuss how MD data can be represented and queried directly over the SW, without the need to download data sets into local data warehouses. We first comment on the RDF Data Cube Vocabulary (QB), the current W3C recommendation, and show that it is not enough to appropriately represent and query MD data on the web. In order to be able to support useful Online Analytical Process (OLAP) analysis, extension to QB, denoted QB4OLAP, has been proposed. We provide an in-depth comparison between these two proposals, and show that extending QB with QB4OLAP can be done without re-writing the observations, (the largest part of a QB data set). We provide extensive examples of the QB4OLAP representation, using a portion of the Eurostat data set and the wellknown Northwind database. Finally, we present a high-level query language, called QL, that allows OLAP users not familiar with SW concepts or languages, to write and execute OLAP operators without any knowledge of RDF or SPARQL, the standard data model and query language, respectively, for the SW. QL queries are automatically translated into SPARQL (using the QB4OLAP metadata) and executed over an endpoint. © Springer International Publishing Switzerland 2016.",Final,
Baisa V.; El Maarouf I.; Rychlý P.; Rambousek A.,"Baisa, Vít (36602193200); El Maarouf, Ismaïl (35302194200); Rychlý, Pavel (56879210000); Rambousek, Adam (24605427800)",36602193200; 35302194200; 56879210000; 24605427800,Software and data for Corpus Pattern Analysis,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013663967&partnerID=40&md5=06de7a846fc4e6389fdf3f462d911d91,"This report describes the tools and resources developed to support Corpus Pattern Analysis (CPA)-a corpus-based method for building patterns dictionaries. The tools are an annotation of concordance in Sketch Engine, a special CPA editor for editing Pattern Dictionary of English Verbs (PDEV), dedicated servlets based on the Dictionary Editing and Browsing platform and a public interface for browsing the PDEV. The resources are SemEval 2015 Task 15 dataset and LEMON API. © Tribun EU 2015.",Final,
Zeng Z.; Cheng K.T.; Nanniyur S.V.; Zhou J.; Bhat S.,"Zeng, Ziheng (57207569351); Cheng, Kellen Tan (58773022200); Nanniyur, Srihari Venkat (57224972744); Zhou, Jianing (57222732494); Bhat, Suma (34879366000)",57207569351; 58773022200; 57224972744; 57222732494; 34879366000,IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184812286&partnerID=40&md5=23c4bc18fa4642ce63ebca5720985705,"Idiomatic expression (IE) processing and comprehension have challenged pre-trained language models (PTLMs) because their meanings are non-compositional. Unlike prior works that enable IE comprehension through fine-tuning PTLMs with sentences containing IEs, in this work, we construct IEKG, a commonsense knowledge graph for figurative interpretations of IEs. This extends the established ATOMIC2020 (Hwang et al., 2021) graph, converting PTLMs into knowledge models (KMs) that encode and infer commonsense knowledge related to IE use. Experiments show that various PTLMs can be converted into KMs with IEKG. We verify the quality of IEKG and the ability of the trained KMs with automatic and human evaluation. Through applications in natural language understanding, we show that a PTLM injected with knowledge from IEKG exhibits improved IE comprehension ability and can generalize to IEs unseen during training. ©2023 Association for Computational Linguistics.",Final,
Conia S.; Minhas U.F.; Li M.; Ilyas I.; Lee D.; Li Y.,"Conia, Simone (57216690786); Minhas, Umar Farooq (24725343600); Li, Min (58754420200); Ilyas, Ihab (6603960193); Lee, Daniel (58754550000); Li, Yunyao (10739396100)",57216690786; 24725343600; 58754420200; 6603960193; 58754550000; 10739396100,Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824790&partnerID=40&md5=d35b9b6be4c24654571ed83b5f9fc1ef,"Recent work in Natural Language Processing and Computer Vision has been using textual information - e.g., entity names and descriptions - available in knowledge graphs to ground neural models to high-quality structured data. However, when it comes to non-English languages, the quantity and quality of textual information are comparatively scarce. To address this issue, we introduce the novel task of automatic Knowledge Graph Enhancement (KGE) and perform a thorough investigation on bridging the gap in both the quantity and quality of textual information between English and non-English languages. More specifically, we: i) bring to light the problem of increasing multilingual coverage and precision of entity names and descriptions in Wikidata; ii) demonstrate that state-of-the-art methods, namely, Machine Translation (MT), Web Search (WS), and Large Language Models (LLMs), struggle with this task; iii) present M-NTA, a novel unsupervised approach that combines MT, WS, and LLMs to generate high-quality textual information; and, iv) study the impact of increasing multilingual coverage and precision of non-English textual information in Entity Linking, Knowledge Graph Completion, and Question Answering. As part of our effort towards better multilingual knowledge graphs, we also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE approaches in 10 languages across 7 language families. ©2023 Association for Computational Linguistics.",Final,
Zhang Z.; Yufan; Li B.; Zeng Z.Z.,"Zhang, Zilin (58876603600); Yufan (58876496400); Li, BaiHong (58876658200); Zeng, Zhi Zhong (55265071800)",58876603600; 58876496400; 58876658200; 55265071800,Review of research on synonym equivalence relation mining,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184654616&doi=10.1109%2fIEIR59294.2023.10391221&partnerID=40&md5=735bdf0bdadc4ce4bb4cd8d5135bb05d,"Synonym discovery, also known as synonym relation mining or synonym extraction, aims to identify and establish synonymous relationships between words, phrases, or sentences. The primary objective of this relationship mining is to enhance the performance of natural language processing (NLP) tasks, such as information retrieval, question-answering systems, text summarization, and machine translation. Considering that there are still numerous areas and issues awaiting further research in synonym relation mining, this paper provides a comprehensive review of the research methods employed in this field over the past two decades. The review is organized into four main categories. The first category explores the u e of language models for synonym extraction, including techniques such as word embeddings and the recent BERT model. The second category focuses on computing semantic similarity in synonym semantic spaces. The third category examines neural network-based approaches for synonym relation mining. Lastly, the fourth category delves into constructing synonym relationships based on knowledge graphs. Additionally, this paper provides an outlook and summary of potential future developments in this direction, with the aim of offering valuable guidance for future research in the field.  © 2023 IEEE.",Final,
Zhu J.; Zhang M.; Yang H.; Peng S.; Wu Z.; Jiang Y.; Qiu X.; Pan W.; Zhu M.; Ma M.; Zhang W.,"Zhu, Junhao (58021038000); Zhang, Min (57282022500); Yang, Hao (57208745952); Peng, Song (57226320078); Wu, Zhanglin (57387088200); Jiang, Yanfei (58101632700); Qiu, Xijun (58889796200); Pan, Weiqiang (58889796300); Zhu, Ming (58021037900); Ma, Miaomiao (57821122700); Zhang, Weidong (58890066800)",58021038000; 57282022500; 57208745952; 57226320078; 57387088200; 58101632700; 58889796200; 58889796300; 58021037900; 57821122700; 58890066800,KG-IQES: An Interpretable Quality Estimation System for Machine Translation Based on Knowledge Graph,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185221581&partnerID=40&md5=3fa50e9d20769a445bfe42de12d15f64,"The widespread use of machine translation (MT) has driven the need for effective automatic quality estimation (AQE) methods. How to enhance the interpretability of MT output quality estimation is well worth exploring in the industry. From the perspective of the alignment of named entities (NEs) in the source and translated sentences, we construct a multilingual knowledge graph (KG) consisting of domain-specific NEs, and design a KG-based interpretable quality estimation (QE) system for machine translations (KG-IQES). KG-IQES effectively estimates the translation quality without relying on reference translations. Its effectiveness has been verified in our business scenarios. © 2023 The authors. This article is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0)",Final,
Wang Z.; Zhang Z.; Qin J.; Iwaihara M.,"Wang, Zhaoyi (58645635500); Zhang, Zhenyang (58645579200); Qin, Jiaxin (58645613300); Iwaihara, Mizuho (6603237123)",58645635500; 58645579200; 58645613300; 6603237123,"SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features",,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180152462&doi=10.1007%2f978-981-99-8085-7_12&partnerID=40&md5=ec7d49a1dfe28d59acefc0e72f577ade,"Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity typing. 2) Finetuning and prompt-tuning of the pre-trained language model BERT are carried out over the training data, to capture semantic and syntactic properties of class names. Our model SLHCat is evaluated over a benchmark dataset constructed by annotating 3000 fine-grained CaLiGraph-DBpedia mapping pairs. SLHCat is outperforming the baseline model by a large margin of 25% in accuracy, offering a practical solution for large-scale ontology mapping. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,All Open Access; Green Open Access
Wang C.; Guo S.; He Z.; Xue Z.; Chen Y.; Liu K.; Zhao J.,"Wang, Chenhao (57214862680); Guo, Shaoru (57192306453); He, Zhitao (58121980600); Xue, Zhipeng (57222420705); Chen, Yubo (57935192700); Liu, Kang (55729555700); Zhao, Jun (57190004147)",57214862680; 57192306453; 58121980600; 57222420705; 57935192700; 55729555700; 57190004147,"CogNet2: A Multi-Level Frame Organized Knowledge Base Integrating Linguistic, World and Commonsense Knowledge",,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184369774&partnerID=40&md5=2d9e69dc3544c90879a226ce0a69ddf2,"In this paper, we present CogNet2, an extension of the CogNet knowledge base, which combines the significant events form Wikidata, entities from YAGO4 and commonsense assertions from ATOMIC. It aims to unify knowledge of multiple levels of granularity. To efficiently integrate significant event and entity knowledge into CogNet, we construct significant event- and entity-centric frames, and then link them to the CogNet by automated labeling and crowd-sourced annotation. To enrich CogNet with more commonsense knowledge in social interaction, we construct frames with element restriction for fine-grained typical situations and integrate commonsense assertions about them. As a result, in comparison with CogNet1, CogNet2 increases 800+ new frames of significant events and entities, 30000+ new fine-grained frames with element restrictions, more than 204K new commonsense assertions. The scale of frame instances is up to 33.4M in total. © 2023 Copyright for this paper by its authors.",Final,
Lee J.; Chung C.; Lee H.; Jo S.; Whang J.J.,"Lee, Jaejun (57826216200); Chung, Chanyoung (57226460829); Lee, Hochang (57222088269); Jo, Sungho (36922784600); Whang, Joyce Jiyoung (58306607700)",57826216200; 57226460829; 57222088269; 36922784600; 58306607700,VISTA: Visual-Textual Knowledge Graph Representation Learning,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183298983&partnerID=40&md5=dba38781f8c9640990b6a0cbaf387666,"Knowledge graphs represent human knowledge using triplets composed of entities and relations. While most existing knowledge graph embedding methods only consider the structure of a knowledge graph, a few recently proposed multimodal methods utilize images or text descriptions of entities in a knowledge graph. In this paper, we propose visual-textual knowledge graphs (VTKGs), where not only entities but also triplets can be explained using images, and both entities and relations can accompany text descriptions. By compiling visually expressible commonsense knowledge, we construct new benchmark datasets where triplets themselves are explained by images, and the meanings of entities and relations are described using text. We propose VISTA, a knowledge graph representation learning method for VTKGs, which incorporates the visual and textual representations of entities and relations using entity encoding, relation encoding, and triplet decoding transformers. Experiments show that VISTA outperforms state-of-the-art knowledge graph completion methods in real-world VTKGs. © 2023 Association for Computational Linguistics.",Final,
Mihindukulasooriya N.; Dash S.; Bagchi S.; Chowdhury F.; Gliozzo A.; Farkash A.; Glass M.; Gokhman I.; Hassanzadeh O.; Pham N.; Rossiello G.; Rozenberg B.; Sagron Y.; Subramanian D.; Takahashi T.; Tateishi T.; Vu L.,"Mihindukulasooriya, Nandana (56406504100); Dash, Sarthak (57196468028); Bagchi, Sugato (7102840811); Chowdhury, Faisal (57219462528); Gliozzo, Alfio (55893529800); Farkash, Ariel (6602940398); Glass, Michael (57210396534); Gokhman, Igor (57188566277); Hassanzadeh, Oktie (22937276200); Pham, Nhan (57217524254); Rossiello, Gaetano (57190124913); Rozenberg, Boris (36936865900); Sagron, Yehoshua (58869778800); Subramanian, Dharmashankar (14046006900); Takahashi, Toshihiro (55722260300); Tateishi, Takaaki (58852196700); Vu, Long (58119457200)",56406504100; 57196468028; 7102840811; 57219462528; 55893529800; 6602940398; 57210396534; 57188566277; 22937276200; 57217524254; 57190124913; 36936865900; 58869778800; 14046006900; 55722260300; 58852196700; 58119457200,Unleashing the Potential of Data Lakes with Semantic Enrichment Using Foundation Models,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184379489&partnerID=40&md5=3575ea110a78ffde7449db418c24400b,"Nowadays most organizations are managing data lakes containing heterogeneous data from various sources. However, the lack of adequate metadata often transforms these data lakes into data swamps, making it challenging to locate relevant data for critical organizational tasks and consequently limiting their utility. Recent advancements in large language models and foundation models have enabled the automation of metadata generation using generative AI models and the use of generated metadata for mapping tabular data into semantically richer glossaries, taxonomies, or ontologies. In this talk, we will present a semantic enrichment process that generates table metadata such as descriptive table captions, tags, expanded column names, and column descriptions and then uses that information to map table columns to concepts in a given business glossary or an ontology. Furthermore, during this process, we represent both table metadata and business glossaries as knowledge graphs and connect them by mapping columns to business concepts. As a result, the enrichment process makes the data in data lakes more meaningful to the organization and enhances downstream tasks, including improved table search and discovery, efficient table joins, and advanced business analytics. © 2023 Copyright for this paper by its authors.",Final,
Verlinden S.; Zaporojets K.; Deleu J.; Demeester T.; Develder C.,"Verlinden, Severine (57226332652); Zaporojets, Klim (57221141248); Deleu, Johannes (24331318000); Demeester, Thomas (35415697600); Develder, Chris (6602998454)",57226332652; 57221141248; 24331318000; 35415697600; 6602998454,Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Coreference Resolution,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118062880&partnerID=40&md5=431b08e936cac6de3ccf9b884a2d115d,"We consider a joint information extraction (IE) model, solving named entity recognition, coreference resolution and relation extraction jointly over the whole document. In particular, we study how to inject information from a knowledge base (KB) in such IE model, based on unsupervised entity linking. The used KB entity representations are learned from either (i) hyperlinked text documents (Wikipedia), or (ii) a knowledge graph (Wikidata), and appear complementary in raising IE performance. Representations of corresponding entity linking (EL) candidates are added to text span representations of the input document, and we experiment with (i) taking a weighted average of the EL candidate representations based on their prior (in Wikipedia), and (ii) using an attention scheme over the EL candidate list. Results demonstrate an increase of up to 5% F1-score for the evaluated IE tasks on two datasets. Despite a strong performance of the prior-based model, our quantitative and qualitative analysis reveals the advantage of using the attention-based approach. © 2021 Association for Computational Linguistics",Final,
Zhou Y.; Geng X.; Shen T.; Zhang W.; Jiang D.,"Zhou, Yucheng (57262453900); Geng, Xiubo (57216694637); Shen, Tao (57210531549); Zhang, Wenqiang (56593812000); Jiang, Daxin (57226177359)",57262453900; 57216694637; 57210531549; 56593812000; 57226177359,Improving Zero-Shot Cross-lingual Transfer for Multilingual Question Answering over Knowledge Graph,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113823264&partnerID=40&md5=927041cb034315cb207fa63a6422b3d5,"Multilingual question answering over knowledge graph (KGQA) aims to derive answers from a knowledge graph (KG) for questions in multiple languages. To be widely applicable, we focus on its zero-shot transfer setting. That is, we can only access training data in a high-resource language, while need to answer multilingual questions without any labeled data in target languages. A straightforward approach is resorting to pre-trained multilingual models (e.g., mBERT) for cross-lingual transfer, but there is a still significant gap of KGQA performance between source and target languages. In this paper, we exploit unsupervised bilingual lexicon induction (BLI) to map training questions in source language into those in target language as augmented training data, which circumvents language inconsistency between training and inference. Furthermore, we propose an adversarial learning strategy to alleviate syntax-disorder of the augmented data, making the model incline to both language- and syntax-independence. Consequently, our model narrows the gap in zero-shot cross-lingual transfer. Experiments on two multilingual KGQA datasets with 11 zero-resource languages verify its effectiveness. © 2021 Association for Computational Linguistics.",Final,
Su Y.; Han X.; Zhang Z.; Lin Y.; Li P.; Liu Z.; Zhou J.; Sun M.,"Su, Yusheng (57221148212); Han, Xu (57205548124); Zhang, Zhengyan (57196122281); Lin, Yankai (57155321900); Li, Peng (57211755481); Liu, Zhiyuan (57191691341); Zhou, Jie (57211746430); Sun, Maosong (7403180987)",57221148212; 57205548124; 57196122281; 57155321900; 57211755481; 57191691341; 57211746430; 7403180987,CokeBERT: Contextual knowledge selection and embedding towards enhanced pre-trained language models,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115923209&doi=10.1016%2fj.aiopen.2021.06.004&partnerID=40&md5=ed03d32aeb98fe97751bf6a6ad2a6cf0,"Several recent efforts have been devoted to enhancing pre-trained language models (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs (KGs), and achieved consistent improvements on various knowledge-driven NLP tasks. However, most of these knowledge-enhanced PLMs embed static sub-graphs of KGs (“knowledge context”), regardless of that the knowledge required by PLMs may change dynamically according to specific text (“textual context”). In this paper, we propose a novel framework named Coke to dynamically select contextual knowledge and embed knowledge context according to textual context for PLMs, which can avoid the effect of redundant and ambiguous knowledge in KGs that cannot match the input text. Our experimental results show that Coke outperforms various baselines on typical knowledge-driven NLP tasks, indicating the effectiveness of utilizing dynamic knowledge context for language understanding. Besides the performance improvements, the dynamically selected knowledge in Coke can describe the semantics of text-related knowledge in a more interpretable form than the conventional PLMs. Our implementation and datasets are publicly available. © 2021 The Authors",Final,All Open Access; Gold Open Access; Green Open Access
El-Khoury J.; Ekelin C.; Ekholm C.,"El-Khoury, Jad (8122105900); Ekelin, Cecilia (8848825900); Ekholm, Christian (57190123741)",8122105900; 8848825900; 57190123741,Supporting the linked data approach to maintain coherence across rich EMF models,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977471007&doi=10.1007%2f978-3-319-42061-5_3&partnerID=40&md5=6f6915d15c1fd3d2a87b86e02a4db69e,"In many development environments, Model-Driven Engineering (MDE) may well be limited to parts of the complete product development process due to the lack of interoperability mechanisms that connect the product data across the model-based engineering tools being used. This is especially the case if the tools are not designed to work tightly together, and/or if they do not share a common technological basis. In this paper, we investigate the use of the OASIS OSLC interoperability standard to facilitate the integration of models from different languages into a single coherent view. We evaluate a fully-automated code generator that provides OSLC interfaces for EMF-based modelling tools, allowing the exposure of modelling elements from any rich modelling language. We argue that such a generator is a critical component for reducing the cost of providing rich and specialized tool interfaces, generally needed when integrating modelling tools. The study is based on a case study that addresses the development process – and the corresponding integrated software engineering environment - at Volvo Trucks used when developing a new electronic architecture including heavy vehicle functions. © Springer International Publishing Switzerland 2016.",Final,
Oramas S.; Sordo M.; Espinosa-Anke L.,"Oramas, Sergio (55582112200); Sordo, Mohamed (43462170300); Espinosa-Anke, Luis (56242866900)",55582112200; 43462170300; 56242866900,A rule-based approach to extracting relations from music tidbits,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968563052&doi=10.1145%2f2740908.2741709&partnerID=40&md5=b04597175eefe1cff3dc5ba56630c779,"This paper presents a rule based approach to extracting re- lations from unstructured music text sources. The proposed approach identifies and disambiguates musical entities in text, such as songs, bands, persons, albums and music gen- res. Candidate relations are then obtained by traversing the dependency parsing tree of each sentence in the text with at least two identified entities. A set of syntactic rules based on part of speech tags are defined to filter out spurious and irrel- evant relations. The extracted entities and relations are - nally represented as a knowledge graph. We test our method on texts from songfacts.com, a website that provides tidbits with facts and stories about songs. The extracted relations are evaluated intrinsically by assessing their linguistic qual- ity, as well as extrinsically by assessing the extent to which they map an existing music knowledge base. Our system produces a vast percentage of linguistically correct relations between entities, and is able to replicate a significant part of the knowledge base.",Final,All Open Access; Green Open Access
Pedretti I.; Del Grosso A.; Giovannetti E.; Mancini L.; Piccini S.; Abrate M.; Lo Duca A.; Marchetti A.,"Pedretti, Irene (57128390200); Del Grosso, Angelo (56319538600); Giovannetti, Emiliano (55604835100); Mancini, Lorenzo (57127680400); Piccini, Silvia (57128335600); Abrate, Matteo (56287311800); Lo Duca, Angelica (57808966400); Marchetti, Andrea (23397813500)",57128390200; 56319538600; 55604835100; 57127680400; 57128335600; 56287311800; 57808966400; 23397813500,"The clavius on the web project: Digitization, annotation and visualization of early modern manuscripts",,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958691991&doi=10.1145%2f2802612.2802636&partnerID=40&md5=62dee99529fbb39587a182d59688ec41,"This paper describes the full procedure adopted in the context of the Clavius on the Web project, which aims to help Web users to appraise the importance of specific manuscripts by going beyond their digital reproduction. The proposed approach is based on the multilayered explication of linguistic, lexical and semantic data representing the innermost nature of the analyzed manuscripts. The final purpose of the project is to gather and display the results of the three layers of analysis through interactive visualization techniques and export them as Linked Data. All the analyses rely on the XML/TEI encoding of the text, followed by a CTS-based tokenization. As a working example for this paper, the analysis of a portion of a manuscript provided by Historical Archives of the Pontifical Gregorian University will be illustrated. The text is a letter written in Latin and sent by Botvitus Nericius to Christophorus Clavius in 1598 from Madrid. © 2014 ACM.",Final,
Li Y.; Clark P.,"Li, Yang (57192521738); Clark, Peter (7402579556)",57192521738; 7402579556,Answering elementary science questions by constructing coherent scenes using background knowledge,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959867303&doi=10.18653%2fv1%2fd15-1236&partnerID=40&md5=ca35d2968fd72770c7eabd9c013c4b46,"Much of what we understand from text is not explicitly stated. Rather, the reader uses his/her knowledge to fill in gaps and create a coherent, mental picture or ""scene"" depicting what text appears to convey. The scene constitutes an understanding of the text, and can be used to answer questions that go beyond the text. Our goal is to answer elementary science questions, where this requirement is pervasive; A question will often give a partial description of a scene and ask the student about implicit information. We show that by using a simple ""knowledge graph"" representation of the question, we can leverage several large-scale linguistic resources to provide missing background knowledge, somewhat alleviating the knowledge bottleneck in previous approaches. The coherence of the best resulting scene, built from a question/answer-candidate pair, reflects the confidence that the answer candidate is correct, and thus can be used to answer multiple choice questions. Our experiments show that this approach outperforms competitive algorithms on several datasets tested. The significance of this work is thus to show that a simple ""knowledge graph"" representation allows a version of ""interpretation as scene construction"" to be made viable. © 2015 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Wendt M.; Gerlach M.; Düwiger H.,"Wendt, Matthias (56022755600); Gerlach, Martin (57196529674); Düwiger, Holger (55654868400)",56022755600; 57196529674; 55654868400,Linguistic modeling of linked open data for question answering,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942694222&doi=10.1007%2f978-3-662-46641-4_8&partnerID=40&md5=5d225bae902853fe2896daa11926a55a,"With the evolution of linked open data sources, question answering regains importance as a way to make data accessible and explorable to the public. The triple structure of RDF-data at the same time seems to predetermine question answering for being devised in its native subject-verb-object form. The devices of natural language, however, often exceed this trFiple-centered model. But RDF does not preclude this point of view. Rather, it depends on the modeling. As part of a government funded research project named Alexandria, we implemented an approach to question answering that enables the user to ask questions in ways that may involve more than binary relations. © Springer-Verlag Berlin Heidelberg 2015.",Final,All Open Access; Green Open Access
Both A.; Avdiyenko L.; Lemke C.,"Both, Andreas (23966392700); Avdiyenko, Liliya (55913379700); Lemke, Christiane (34972920300)",23966392700; 55913379700; 34972920300,Computing geo-spatial motives from linked data for search-driven applications,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930741546&partnerID=40&md5=e4aa5bd0e9147f3d5414941f8b97af45,"The Web of Data puts a vast and ever-increasing amount of information at the disposal of its users. In the era of big data, interpreting and exploiting these information is both a highly active research area and a key issue for users in industry trying to gain a competitive edge. One current problem in industry with many potential application areas is finding a common theme for varying features by generating higher level summaries. We introduce the notion of motives to describe these common themes. Motives can be identified for all sorts of entities such as geo-spatial regions (e.g., ""cultural regions"") or holidays (e.g., ""win- ter holidays"", ""activity holidays""). These motives are closer to common language and human conversations than ordinary keywords. Since users prefer formulating their information needs using everyday language, which expresses their understanding of the world, the poten- tial for a strong industrial impact for search applications can be de- rived. However, capturing the users' often vaguely formulated intentions and matching them to appropriate retrieval operations on the available knowledge bases is a challenging issue. Yet, it is an important step on the way of providing the best possible search experience to users. This paper presents our work in progress on computing motives for geo- spatial regions. Following a long term agenda, we are evaluating the requirements for identifying such motives in large data sets. At this point, we can show that out-of-the-box machine learning methods can be used on Linked Data to train a model for computation of geo-spatial motives with good accuracy. Copyright © 2015 for the individual papers by the papers' authors.",Final,
Rettinger A.; Schumilin A.; Thoma S.; Ell B.,"Rettinger, Achim (23092350400); Schumilin, Artem (56728804700); Thoma, Steffen (56727815200); Ell, Basil (36720533800)",23092350400; 56728804700; 56727815200; 36720533800,Learning a cross-lingual semantic representation of relations expressed in text,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937406143&doi=10.1007%2f978-3-319-18818-8_21&partnerID=40&md5=19640ca2dd0bc2e31d2fae09b2b784c1,"Learning cross-lingual semantic representations of relations from textual data is useful for tasks like cross-lingual information retrieval and question answering. So far, research has been mainly focused on cross-lingual entity linking, which is confined to linking between phrases in a text document and their corresponding entities in a knowledge base but cannot link to relations. In this paper, we present an approach for inducing clusters of semantically related relations expressed in text, where relation clusters (i) can be extracted from text of different languages, (ii) are embedded in a semantic representation of the context, and (iii) can be linked across languages to properties in a knowledge base. This is achieved by combining multi-lingual semantic role labeling (SRL) with cross-lingual entity linking followed by spectral clustering of the annotated SRL graphs. With our initial implementation we learned a cross-lingual lexicon of relation expressions from English and Spanish Wikipedia articles. To demonstrate its usefulness we apply it to crosslingual question answering over linked data. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Bronze Open Access
Franco-Salvador M.; Gupta P.; Rosso P.,"Franco-Salvador, Marc (55533434300); Gupta, Parth (57199836973); Rosso, Paolo (8960238100)",55533434300; 57199836973; 8960238100,Knowledge graphs as context models: Improving the detection of cross-language plagiarism with paraphrasing,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901341490&doi=10.1007%2f978-3-642-54798-0_12&partnerID=40&md5=38f36f4e100941b64bcdc632b5e709fd,"Cross-language plagiarism detection attempts to identify and extract automatically plagiarism among documents in different languages. Plagiarized fragments can be translated verbatim copies or may alter their structure to hide the copying, which is known as paraphrasing and is more difficult to detect. In order to improve the paraphrasing detection, we use a knowledge graph-based approach to obtain and compare context models of document fragments in different languages. Experimental results in German-English and Spanish-English cross-language plagiarism detection indicate that our knowledge graph-based approach offers a better performance compared to other state-of-the-art models. © 2014 Springer-Verlag.",Final,All Open Access; Green Open Access
Meehan A.; Brennan R.; Lewis D.; O'Sullivan D.,"Meehan, Alan (56556339100); Brennan, Rob (36447456700); Lewis, Dave (57035492800); O'Sullivan, Declan (57202521703)",56556339100; 36447456700; 57035492800; 57202521703,Mapping representation based on meta-data and spin for localization workflows,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924955908&partnerID=40&md5=9a58986dd708238421d6fecbd9d2576e,"The localization industry currently deploys language translation workflows based on heterogeneous tool-chains. Standardized tool interchange formats such as XLIFF (XML Localization Interchange File Format) have had some impact on enabling more agile translation workflows. However the rise of new tools based on machine translation technology and the growing demand for enterprise linked data applications has created new interoperability challenges as workflows need to encompass a broader range of tools. In this paper we present an approach of representing mappings between RDF-based representations of multilingual content and meta-data. To represent the mappings, we use a combination of SPARQL Inferencing Notation (SPIN) and meta-data. Our approach allows the mapping representation to be published as Linked Data. In contrast to other frameworks such as R2R, the mappings are executed via a standard SPARQL processor. The objective is to provide a more agile approach to translation workflows and greater interoperability between software tools by leveraging the ongoing innovation in the Multilingual Web field. Our use case is a Language Technology retraining workflow where publishing mappings leads to new opportunities for interoperability and end-to-end tool-chain analytics. We present the results from an initial experiment which compared our approach of executing and representing mappings to that of a similar approach - The R2R Framework.",Final,
Li X.; Tur G.; Hakkani-Tur D.; Li Q.,"Li, Xiang (55968579800); Tur, Gokhan (15060858000); Hakkani-Tur, Dilek (6603261445); Li, Qi (58462550400)",55968579800; 15060858000; 6603261445; 58462550400,Personal knowledge graph population from user utterances in conversational understanding,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983195590&doi=10.1109%2fSLT.2014.7078578&partnerID=40&md5=1cdb2929b884ab85366b7f988ad9290f,"Knowledge graphs provide a powerful representation of entities and the relationships between them, but automatically constructing such graphs from spoken language utterances presents the novelty and numerous challenges. In this paper, we introduce a statistical language understanding approach to automatically construct personal (user-centric) knowledge graphs in conversational dialogs. Such information has the potential to better understand the users' requests, fulfilling them, and enabling other technologies such as developing better inferences or proactive interactions. Knowledge encoded in semantic graphs such as Freebase has been shown to benefit semantic parsing and interpretation of natural language utterances. Hence, as a first step, we exploit the personal factual relation triples from Freebase to mine natural language snippets with a search engine, and the resulting snippets containing pairs of related entities to create the training data. This data is then used to build three key language understanding components: (1) Personal Assertion Classification identifies the user utterances that are relevant with personal facts, e.g., 'my mother's name is Rosa'; (2) Relation Detection classifies the personal assertion utterance into one of the predefined relation classes, e.g., 'parents'; and (3) Slot Filling labels the attributes or arguments of relations, e.g., 'name(parents): Rosa'. Our experiments using the Microsoft conversational understanding system demonstrate the performance of this proposed approach on the population of personal knowledge graphs. © 2014 IEEE.",Final,
Sánchez-Rada J.F.; Vulcu G.; Iglesias C.A.; Buitelaar P.,"Sánchez-Rada, J. Fernando (56426347900); Vulcu, Gabriela (36176660600); Iglesias, Carlos A. (56357213400); Buitelaar, Paul (14041096000)",56426347900; 36176660600; 56357213400; 14041096000,EUROSENTIMENT: Linked data sentiment analysis,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921887944&partnerID=40&md5=b70ae9f6fb7a8e6419d701bd746999c8,"Sentiment and Emotion Analysis strongly depend on quality language resources, especially sentiment dictionaries. These resources are usually scattered, heterogeneous and limited to specific domains of application by simple algorithms. The EUROSENTIMENT project addresses these issues by 1) developing a common language resource representation model for sentiment analysis, and APIs for sentiment analysis services based on established Linked Data formats (lemon, Marl, NIF and ONYX) 2) by creating a Language Resource Pool (a.k.a. LRP) that makes available to the community existing scattered language resources and services for sentiment analysis in an interoperable way. In this paper we describe the available language resources and services in the LRP and some sample applications that can be developed on top of the EUROSENTIMENT LRP.",Final,
Park S.; Shim H.; Lee G.G.,"Park, Seonyeong (56428130300); Shim, Hyosup (56501371500); Lee, Gary Geunbae (7404853194)",56428130300; 56501371500; 7404853194,ISOFT at QALD-4: Semantic similarity-based question answering system over linked data,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961289185&partnerID=40&md5=c383cd424bb80b9855cb185024e51f2a,"We present a question answering system over linked data. We use natural language processing tools to extract slots and SPARQL templates from the question. Then, we use semantic similarity to map a natural language question to a SPARQL query. We combine important words to avoid loss of meaning, and compare combined words with uniform resource identifiers (URIs) from a knowledgebase (KB). This process is more powerful than comparing each word individually. Using our method, the problem of mapping a phrase of a user question to URIs from a KB can be more easily solved than without our method; this method improves the F-measure of the system.",Final,
Recupero D.R.; Consoli S.; Gangemi A.; Nuzzolese A.G.; Presutti V.; Spampinato D.,"Recupero, Diego Reforgiato (57206674454); Consoli, Sergio (24168054400); Gangemi, Aldo (55605133800); Nuzzolese, Andrea Giovanni (42862074000); Presutti, Valentina (55885160000); Spampinato, Daria (55976373100)",57206674454; 24168054400; 55605133800; 42862074000; 55885160000; 55976373100,Semantic web-based sentiment analysis,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926391179&partnerID=40&md5=2348848a14158c7f8c3ec2bdd1146d5a,"The introduction of semantics in Sentiment Analysis research has proved to bring several benefits for what performances are concerned and has allowed to identify new challenging tasks to be accomplished. Semantics helps structuring the plain natural language text with formal representation. The current system we are developing performs sentiment analysis by hybridizing natural language processing techniques with Semantic Web technologies. Our system, called Sentilo, is able to recognize the holder of an opinion, to detect the topics and sub-topics in its scope, and to measure the sentiment expressed by them. This information is formally represented by means of RDF graphs according to an OWL opinion ontology, while holders and topics identity is resolved on the Linked Open Data cloud.",Final,
Liu X.; Chen M.; Qin J.,"Liu, Xiaozhong (55218252500); Chen, Miao (55733221800); Qin, Jian (16023002400)",55218252500; 55733221800; 16023002400,Interlinking cross language metadata using heterogeneous graphs and wikipedia,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013648969&partnerID=40&md5=adb01bcdabcb11bcbb9c5891ee9c07d2,"Cross-language metadata are essential in helping users overcome language barriers in information discovery and recommendation. The construction of cross-language vocabulary, however, is usually costly and intellectually laborious. This paper addresses these problems by proposing a Cross-Language Metadata Network (CLMN) approach, which uses Wikipedia as the intermediary for cross-language metadata linking. We conducted a proof-of-concept experiment with key metadata in two digital libraries and in two different languages without using machine translation. The experiment result is encouraging and suggests that the CLMN approach has the potential not only to interlink metadata in different languages with reasonable rate of precision and quality but also to construct cross-language metadata vocabulary. Limitations and further research are also discussed. © 2014, Dublin Core metadata initiative. All rights reserved.",Final,
Mimouni N.,"Mimouni, Nada (7801571016)",7801571016,Modeling legal documents as typed linked data for relational querying,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911941699&partnerID=40&md5=88489de0390e051945943395fa93f41c,"Access to legal knowledge is particularly challenging to information retrieval systems. Not only is legal knowledge usually expressed in linguistically complex forms, but it is also structurally sophisticated (e.g pieces of legislation applicable to a case, version in force of a legal document, other related sources). Modeling the collection of documents in such complex domains requires taking into account the semantic content of the documents as well as their relational structure since documents are usually related to each other by various types of links. In this paper we describe two approaches for modeling and querying a collection of interlinked legal documents. The first approach is based on Formal Concept Analysis and Relational Concept Analysis to model and query the collection of documents. The second approach uses semantic web techniques (RDF, OWL and SPARQL). Different types of relational queries are discussed.",Final,
Draicchio F.; Gangemi A.; Presutti V.; Nuzzolese A.G.,"Draicchio, Francesco (58332583000); Gangemi, Aldo (55605133800); Presutti, Valentina (55885160000); Nuzzolese, Andrea Giovanni (42862074000)",58332583000; 55605133800; 55885160000; 42862074000,FRED: From natural language text to RDF and OWL in one click,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893803453&doi=10.1007%2f978-3-642-41242-4_36&partnerID=40&md5=3e70d41fd698f9811e5b8d19df26b6a8,"FRED is an online tool for converting text into internally well-connected and quality linked-data-ready ontologies in web-service-acceptable time. It implements a novel approach for ontology design from natural language sentences. In this paper we present a demonstration of such tool combining Discourse Representation Theory (DRT), linguistic frame semantics, and Ontology Design Patterns (ODP). The tool is based on Boxer which implements a DRT-compliant deep parser. The logical output of Boxer enriched with semantic data from Verbnet or FrameNet frames is transformed into RDF/OWL by means of a mapping model and a set of heuristics following ODP best-practice [5] of OWL ontologies and RDF data design. © Springer-Verlag 2013.",Final,All Open Access; Bronze Open Access
Gamba F.; Passarotti M.C.; Ruffolo P.,"Gamba, Federica (58024445100); Passarotti, Marco C. (56957111300); Ruffolo, Paolo (57195437110)",58024445100; 56957111300; 57195437110,Linking the Dictionary of Medieval Latin in the Czech Lands to the LiLa Knowledge Base,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181170485&partnerID=40&md5=aff1f6c290235155b182138c4e61c2f6,"The paper presents the process of linking the Dictionary of Medieval Latin in the Czech Lands to the LiLa Knowledge Base, which adopts the Linked Data paradigm to make linguistic resources for Latin interoperable. An overview of the Dictionary and of the architecture of the LiLa Knowledge Base is first provided; then, the stages of the process of linking the Dictionary to LiLa's collection of lemmas are described. In conclusion, a query illustrates how interoperability allows for full exploitation of Latin resources. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Alexander R.J.; Bartocci M.; Persico O.; Vetere G.,"Alexander, Robert J. (58789455900); Bartocci, Matteo (58789588200); Persico, Oriana (55371953900); Vetere, Guido (22434365100)",58789455900; 58789588200; 55371953900; 22434365100,Harnessing Il Manifesto Newspaper Archive for Knowledge Base Creation: Techniques and Findings in the MeMa Project,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181166938&partnerID=40&md5=afe1b1cd50fecba10a70c4af0fde3629,"The historical archive of the newspaper “il Manifesto” is a valuable asset protected by the Italian Ministry of Cultural Heritage. The MeMa project aims to create an “intelligent archive” using AI principles, fostering collaboration and transparency. The platform, built around Apache Jena and open linguistic technologies, addresses the newspaper community's specific needs. This paper presents the platform's architecture, knowledge base construction process, and future directions, emphasizing journalism enhancements through AI while respecting “Il Manifesto”'s principles. Italiano.L'archivio storico del quotidiano “il Manifesto” è tutelato dal Ministero dei Beni Culturali. Il progetto MeMa mira a creare un “archivio intelligente” basato su una intelligenza artificiale che favorisce la collaborazione e la trasparenza. La piattaforma, costruita attorno ad Apache Jena e tecnologie linguistiche aperte, risponde alle esigenze specifiche della comunità del giornale. Questo contributo presenta l'architettura della piattaforma, il processo di costruzione della base di conoscenza e le direzioni future, discutendo il potenziamento del giornalismo attraverso l'intelligenza artificiale nel rispetto dei principi de “Il Manifesto”. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Biswas D.; Linzbach S.; Dimitrov D.; Jabeen H.; Dietze S.,"Biswas, Debanjali (57225007407); Linzbach, Stephan (58258749400); Dimitrov, Dimitar (57194824143); Jabeen, Hajira (36005417500); Dietze, Stefan (19638604400)",57225007407; 58258749400; 57194824143; 36005417500; 19638604400,Broadening BERT vocabulary for Knowledge Graph Construction using Wikipedia2Vec,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179557571&partnerID=40&md5=1609abf8ea196ad7f449e16ff3bd92f7,"Recent advancements in natural language processing (NLP) have been driven by the utilization of large language models like BERT. These models, pre-trained on extensive textual data, capture linguistic and relational knowledge. Therefore, cloze-style prompts, which involve filling in missing words in a sentence, can be used to solve knowledge-intensive NLP tasks with the help of a language model. The ""Knowledge Base Construction from Pre-trained Language Models (LM-KBC 2023)"" challenge aims to harness language models’ potential for knowledge graph construction through prompts. In particular, contestants are challenged to infer the correct Wikidata ID of objects, given a prompt used to link subject, relation, and object. Automatically inferring the correct objects would help in reducing the need for an expensive manual graph population. Our proposed approach in Track 1 focuses on expanding BERT’s vocabulary with a task-specific one (i.e., Wikipedia2Vec) and facilitating its usage through prompt tuning with OPTIPROMPT. © 2023 CEUR-WS. All rights reserved.",Final,
Zhang M.; Liu L.; Zhao Y.; Qiao X.; Su C.; Zhao X.; Zhu J.; Zhu M.; Peng S.; Li Y.; Liu Y.; Ma W.; Piao M.; Tao S.; Yang H.; Jiang Y.,"Zhang, Min (57282022500); Liu, Limin (58889967000); Zhao, Yanqing (58037311400); Qiao, Xiaosong (57878511600); Su, Chang (57231364700); Zhao, Xiaofeng (58294176000); Zhu, Junhao (58021038000); Zhu, Ming (58021037900); Peng, Song (57226320078); Li, Yinglu (57386898100); Liu, Yilun (58037446700); Ma, Wenbing (58546579100); Piao, Mengyao (58644939100); Tao, Shimin (57191988840); Yang, Hao (57208745952); Jiang, Yanfei (58101632700)",57282022500; 58889967000; 58037311400; 57878511600; 57231364700; 58294176000; 58021038000; 58021037900; 57226320078; 57386898100; 58037446700; 58546579100; 58644939100; 57191988840; 57208745952; 58101632700,Leveraging Multilingual Knowledge Graph to Boost Domain-specific Entity Translation of ChatGPT,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185220903&partnerID=40&md5=7a909295f31a1c5a3def5daf8b247840,"Recently, ChatGPT has shown promising results for Machine Translation (MT) in general domains and is becoming a new paradigm for translation. In this paper, we focus on how to apply ChatGPT to domain-specific translation and propose to leverage Multilingual Knowledge Graph (MKG) to help ChatGPT improve the domain entity translation quality. To achieve this, we extract the bilingual entity pairs from MKG for the domain entities that are recognized from source sentences. We then introduce these pairs into translation prompts, instructing ChatGPT to use the correct translations of the domain entities. To evaluate this novel MKG method for ChatGPT, we conduct comparative experiments on three Chinese-English (zh-en) test datasets constructed from three specific domains, of which one domain is from biomedical science, and the other two are from the Information and Communications Technology (ICT) industry - Visible Light Communication (VLC) and wireless domains. Experimental results show that both the overall translation quality of ChatGPT (+6.21, +3.13 and +11.25 in BLEU scores) and the translation accuracy of domain entities (+43.2%, +30.2% and +37.9% absolute points) are significantly improved with MKG on the three test datasets. © 2023 The authors. This article is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0)",Final,
Yu X.,"Yu, Xiaodan (58864932400)",58864932400,Design of Modern English-Chinese Bilingual Interactive AI Teaching Platform for International Shipping Based on Structured Data Sources,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184134659&doi=10.1109%2fECICE59523.2023.10383057&partnerID=40&md5=0827aadb1f1dc3ebefe971b6aea5f077,"Along with the rapid growth of the modern economy, China has emerged as the most influential shipping power in the world. In international shipping, English is the standard language and a key component of international trade and logistics activities. It is important to use modern technological tools that assist learners and practitioners in improving and mastering English in trading. The efficiency and quality of trade business strengthen international cooperation and competitiveness [1]. Computational linguistics, as a cross-disciplinary academic, needs to flourish and progress in the rapid development of information technology and globalization. However, due to the specificity of language, there is no institution to collect English and related words for the industry on a large scale and construct a knowledge base for efficient organizational learning and training. The interaction between the knowledge bases makes the industry's language information disclosed and circulated efficiently. This study was carried out to collect and analyze the semantics of the industry and provide shared retrieval through the construction of patterns of knowledge graphs and the use of modern artificial intelligence (AI) techniques. Relevant theories and technologies were integrated using computational linguistics for knowledge bases for trade and were constructed on an interactive teaching platform to provide a solid foundation for effective language learning.  © 2023 IEEE.",Final,
He Z.; Wang H.; Zhang X.,"He, Zhu (58098551300); Wang, Honglei (57196429392); Zhang, Xiaoping (57298457800)",58098551300; 57196429392; 57298457800,Multi-Task Learning Model Based on BERT and Knowledge Graph for Aspect-Based Sentiment Analysis,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147807407&doi=10.3390%2felectronics12030737&partnerID=40&md5=2f299618c05df364f0255a10194383d2,"Aspect-based sentiment analysis (ABSA) aims to identify the sentiment of an aspect in a given sentence and thus can provide people with comprehensive information. However, many conventional methods need help to discover the linguistic knowledge implicit in sentences. Additionally, they are susceptible to unrelated words. To improve the performance of the model in the ABSA task, a multi-task sentiment analysis model based on Bidirectional Encoder Representation from Transformers (BERT) and a Knowledge Graph (SABKG) is proposed in this paper. Expressly, part-of-speech information is incorporated into the output representation of BERT, thereby obtaining textual semantic information through linguistic knowledge. It also enhances the textual representation to identify the aspect terms. Moreover, this paper constructs a knowledge graph of aspect and sentiment words. It uses a graph neural network to learn the embeddings in the triplet of “aspect word, sentiment polarity, sentiment word”. The constructed graph improves the contextual relationship between the text’s aspect and sentiment words. The experimental results on three open datasets show that the proposed model can achieve the most advanced performance compared with previous models. © 2023 by the authors.",Final,All Open Access; Gold Open Access
De Felice I.; Tamponi L.; Iurescia F.; Passarotti M.,"De Felice, Irene (57198816847); Tamponi, Lucia (57204663005); Iurescia, Federica (57212510921); Passarotti, Marco (56957111300)",57198816847; 57204663005; 57212510921; 56957111300,Linking the Corpus CLaSSES to the LiLa Knowledge Base of Interoperable Linguistic Resources for Latin,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181169574&partnerID=40&md5=cc655c13e1148a60682c1136d1905bcf,"In this paper, we describe the process of linking the corpus CLaSSES (which collects non-literary Latin texts of different periods and places) to the LiLa Knowledge Base of linguistic resources for Latin made interoperable through their publication as Linked Data. The paper details the RDF modeling of the (meta)data provided by CLaSSES and presents three queries on data from different resources that interact in LiLa. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Boano V.I.; Mambrini F.; Passarotti M.; Ginevra R.,"Boano, Valeria Irene (58789550100); Mambrini, Francesco (57190293497); Passarotti, Marco (56957111300); Ginevra, Riccardo (57226578631)",58789550100; 57190293497; 56957111300; 57226578631,Modelling and Publishing the “Lexicon der indogermanischen Verben” as Linked Open Data,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181173280&partnerID=40&md5=1eae48af781f7c0327c8a9776a5ad990,"This paper describes the modelling and publication of part of the etymological information in the Lexicon der indogermanischen Verben, an etymological dictionary of verbs attested in ancient Indo-European languages, as Linguistic Linked Open Data. The lexicon has been made interoperable with a set of lexical and textual linguistic resources for Latin in the Lila Knowledge Base. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Reformat M.Z.; Tan L.; D'Aniello G.; Gaeta M.,"Reformat, Marek Z. (6603618138); Tan, Liang (57221976944); D'Aniello, Giuseppe (56487957100); Gaeta, Matteo (8659094300)",6603618138; 57221976944; 56487957100; 8659094300,Emotion-based Analysis of Reviews using Knowledge Graph,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182523199&doi=10.1109%2fWI-IAT59888.2023.00017&partnerID=40&md5=6657adddcf2169d3ec099ce179ce29d6,"This study introduces a novel approach to sentiment analysis, combining the finesse of Knowledge Graphs with the unique perspective offered by the SenticNet and the Hourglass Model of Emotions. We aim to interpret, quantify, and categorize emotional responses in various reviews and offer, at the same time, a more nuanced understanding of user emotions than traditional sentiment analysis methods. Our process begins with extracting emotional indicators from reviews by linking their descriptive words with states of different emotions and further expressing them using terms and phrases defined in the Hourglass Model of Emotions. All the data is incorporated into a Knowledge Graph, where each review is connected to all its related aspects, description words, and their synonyms and emotions. We enhance the results with linguistic terms describing emotions of identified aspects to learn more about the justification behind the determined sentiments of the reviews.  © 2023 IEEE.",Final,
Peng Y.; Alam M.; Bonald T.,"Peng, Yiwen (58784055300); Alam, Mehwish (57201532578); Bonald, Thomas (6603808064)",58784055300; 57201532578; 6603808064,Ontology Matching using Textual Class Descriptions,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180776271&partnerID=40&md5=5115bca4fda57f89bac2412fb02a8506,"In this paper, we propose TEXTO, a TEXT-based Ontology matching system. This matcher leverages the rich semantic information of classes available in most ontologies by a combination of a pre-trained word embedding model and a pre-trained language model. Its performance is evaluated on the datasets of the OAEI Common Knowledge Graphs Track, augmented with the description of each class, and a new dataset based on the refreshed alignment of Schema.org and Wikidata. Our results demonstrate that TEXTO outperforms all state-of-art matchers in terms of precision, recall and F1 score. In particular, we show that almost perfect class alignment can be achieved using textual content only, excluding any structural information like the graph of classes or the instances of each class. © 2023 Copyright for this paper by its authors.",Final,
Kumar N.; Schockaert S.,"Kumar, Nitesh (57224558840); Schockaert, Steven (8886625200)",57224558840; 8886625200,Solving Hard Analogy Questions with Relation Embedding Chains,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824370&partnerID=40&md5=e392314f6085d80c88e944f2001a7480,"Modelling how concepts are related is a central topic in Lexical Semantics. A common strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to model the relation between two concepts as a set of paths. However, KGs are limited to a fixed set of relation types, and they are incomplete and often noisy. Another strategy is to distill relation embeddings from a fine-tuned language model. However, this is less suitable for words that are only indirectly related and it does not readily allow us to incorporate structured domain knowledge. In this paper, we aim to combine the best of both worlds. We model relations as paths but associate their edges with relation embeddings. The paths are obtained by first identifying suitable intermediate words and then selecting those words for which informative relation embeddings can be obtained. We empirically show that our proposed representations are useful for solving hard analogy questions. © 2023 Association for Computational Linguistics.",Final,
Zugarini A.; Röthenbacher T.; Klede K.; Ernandes M.; Eskofier B.M.; Zanca D.,"Zugarini, Andrea (57203924178); Röthenbacher, Thomas (57986101400); Klede, Kai (58307112200); Ernandes, Marco (10240012800); Eskofier, Bjoern M. (26428080900); Zanca, Dario (57202056859)",57203924178; 57986101400; 58307112200; 10240012800; 26428080900; 57202056859,Die Rätselrevolution: Automated German Crossword Solving,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181170035&partnerID=40&md5=e1a37ea17994eb346966d1a80adfd77c,"Crossword puzzles are popular word games played in various languages around the world, with diverse styles across different countries. For this reason, automated crossword solvers designed for a language, may not work well on others. In this paper, we extend Webcrow, an automatic crossword solver, to German, making it the first program for crossword solving in the German language. To address the lack of large clue-answer crossword pairs data, Webcrow combines multiple modules, known as experts, which retrieve potential answers from various resources, including the web, knowledge graphs, and linguistic rules. The system is evaluated on a collection of crosswords from variegate sources, where it is able to solve perfectly 67% of them. Additional analysis reveals that while our solver achieved commendable results, puzzles with poorly constrained schemas and original clues still presented significant hurdles. These findings shed light on the complexity of the crossword-solving problem and emphasize the need for future research to address and overcome these particular challenges effectively. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Cirillo N.; Vellutino D.,"Cirillo, Nicola (57211683506); Vellutino, Daniela (43661852300)",57211683506; 43661852300,Towards a Multi-Level Annotation Format for the Interoperability of Automatic Term Extraction Corpora,,1,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181171880&partnerID=40&md5=228c822d822adb2b51f3dce7eaa952fb,"The main corpora used as benchmarks in Automatic Term Extraction are represented in different formats. Unfortunately, none of these formats covers the wide range of linguistic phenomena related to terminology. To address this issue, we propose to encode Automatic Term Extraction corpora in RDF using the OntoLex-Lemon and the NLP Interchange Format ontologies. Furthermore, we developed a small Italian corpus on waste management legislation to provide an example of the proposed formalization. Italiano. I corpora principali impiegati nella valutazione degli algoritmi di Estrazione Automatica di Termini sono codificati in formati diversi. Purtroppo, nessuno di questi formati permette di rappresentare l'ampia gamma di fenomeni linguistici legati alla terminologia. Per affrontare la questione, proponiamo di codificare i corpora di Estrazione Automatica di Termini in RDF usando le ontologie OntoLex-Lemon e NLP Interchange Format. Inoltre, abbiamo sviluppato un piccolo corpus italiano riguardante la legislazione della gestione dei rifiuti per fornire un esempio della formalizzazione proposta. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Pavithra C.P.; Mandal S.,"Pavithra, C.P. (57205437872); Mandal, Supriya (57215287412)",57205437872; 57215287412,An Overview of Relevant Literature on Different Approaches to Word Sense Disambiguation,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123448034&doi=10.1109%2fICECCT52121.2021.9616677&partnerID=40&md5=362966991d677e643d37bcc41ddb99cc,"WSD (Word Sense Disambiguation) is a common issue in Natural Language Processing (NLP) and Machine Learning technology. In NLP, word sense disambiguation is described as the capacity to detect which meaning of a word is activated by its use in a specific context. WSD is a solution to the uncertainty that occurs when words have different meanings in different contexts. Contextual word meaning plays an important role in various applications such as sentiment analysis, search engine, information extraction, machine translation etc. It is a challenge for these systems to detect and overcome the uncertainty that emerges from the lexical ambiguity. Many studies have been conducted over the decades to propose various approaches to the WSD problem. In this manuscript, a comparative study of three approaches namely LESK algorithm, embedding techniques, and Neural Network techniques based on the text collected from children's story books is performed. We explored an approach that combines Bi-LSTM neural network with Knowledge Graph to predict contextual word meaning. Our study shows that the combined approach accuracy is 80.34approaches  © 2021 IEEE.",Final,
Aspillaga C.; Mendoza M.; Soto A.,"Aspillaga, Carlos (57219587280); Mendoza, Marcelo (7101729849); Soto, Alvaro (56207577200)",57219587280; 7101729849; 56207577200,Inspecting the concept knowledge graph encoded by modern language models,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115697837&partnerID=40&md5=b3da3ae1bde188fa9f14b21fb13d8bec,"The field of natural language understanding has experienced exponential progress in the last few years, with impressive results in several tasks. This success has motivated researchers to study the underlying knowledge encoded by these models. Despite this, attempts to understand their semantic capabilities have not been successful, often leading to non-conclusive, or contradictory conclusions among different works. Via a probing classifier, we extract the underlying knowledge graph of nine of the most influential language models of the last years, including word embeddings, text generators, and context encoders. This probe is based on concept relatedness, grounded on WordNet. Our results reveal that all the models encode this knowledge, but suffer from several inaccuracies. Furthermore, we show that the different architectures and training strategies lead to different model biases. We conduct a systematic evaluation to discover specific factors that explain why some concepts are challenging. We hope our insights will motivate the development of models that capture concepts more precisely. © 2021 Association for Computational Linguistics",Final,
Zloch M.; Acosta M.; Hienert D.; Conrad S.; Dietze S.,"Zloch, Matthäus (55582536100); Acosta, Maribel (36699349400); Hienert, Daniel (49963420600); Conrad, Stefan (7102956675); Dietze, Stefan (19638604400)",55582536100; 36699349400; 49963420600; 7102956675; 19638604400,Charaterizing RDF graphs through graph-based measures - Framework and assessment,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113925797&doi=10.3233%2fSW-200409&partnerID=40&md5=8a539180b654048818b928276b1d1bca,"The topological structure of RDF graphs inherently differs from other types of graphs, like social graphs, due to the pervasive existence of hierarchical relations (TBox), which complement transversal relations (ABox). Graph measures capture such particularities through descriptive statistics. Besides the classical set of measures established in the field of network analysis, such as size and volume of the graph or the type of degree distribution of its vertices, there has been some effort to define measures that capture some of the aforementioned particularities RDF graphs adhere to. However, some of them are redundant, computationally expensive, and not meaningful enough to describe RDF graphs. In particular, it is not clear which of them are efficient metrics to capture specific distinguishing characteristics of datasets in different knowledge domains (e.g., Cross Domain vs. Linguistics). In this work, we address the problem of identifying a minimal set of measures that is efficient, essential (non-redundant), and meaningful. Based on 54 measures and a sample of 280 graphs of nine knowledge domains from the Linked Open Data Cloud, we identify an essential set of 13 measures, having the capacity to describe graphs concisely. These measures have the capacity to present the topological structures and differences of datasets in established knowledge domains. © 2021 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
MurugesanI K.; Atzeni M.; Kapanipathi P.; Talamadupula K.; Sachan M.; Campbell M.,"MurugesanI, Keerthiram (57395300500); Atzeni, Mattia (57195407967); Kapanipathi, Pavan (36623952200); Talamadupula, Kartik (25960433100); Sachan, Mrinmaya (36094978300); Campbell, Murray (7403371273)",57395300500; 57195407967; 36623952200; 25960433100; 36094978300; 7403371273,Efficient Text-based Reinforcement Learning by Jointly Leveraging State and Commonsense Graph Representations,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118069672&partnerID=40&md5=8346294343e5d54db8862a4e75b05652,"Text-based games (TBGs) have emerged as useful benchmarks for evaluating progress at the intersection of grounded language understanding and reinforcement learning (RL). Recent work has proposed the use of external knowledge to improve the efficiency of RL agents for TBGs. In this paper, we posit that to act efficiently in TBGs, an agent must be able to track the state of the game while retrieving and using relevant commonsense knowledge. Thus, we propose an agent for TBGs that induces a graph representation of the game state and jointly grounds it with a graph of commonsense knowledge from ConceptNet. This combination is achieved through bidirectional knowledge graph attention between the two symbolic representations. We show that agents that incorporate commonsense into the game state graph outperform baseline agents. © 2021 Association for Computational Linguistics.",Final,
Klimek B.; Ackermann M.; Brümmer M.; Hellmann S.,"Klimek, Bettina (57194613467); Ackermann, Markus (57188714998); Brümmer, Martin (55995213500); Hellmann, Sebastian (35199882400)",57194613467; 57188714998; 55995213500; 35199882400,MMoOn Core - The Multilingual Morpheme Ontology,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113951709&doi=10.3233%2fSW-200412&partnerID=40&md5=61b6d9164fe4de93cdd02d74fa6a8a54,"In the last years a rapid emergence of lexical resources has evolved in the Semantic Web. Whereas most of the linguistic information is already machine-readable, we found that morphological information is mostly absent or only contained in semi-structured strings. An integration of morphemic data has not yet been undertaken due to the lack of existing domain-specific ontologies and explicit morphemic data. In this paper, we present the Multilingual Morpheme Ontology called MMoOn Core which can be regarded as the first comprehensive ontology for the linguistic domain of morphological language data. It will be described how crucial concepts like morphs, morphemes, word forms and meanings are represented and interrelated and how language-specific morpheme inventories can be created as a new possibility of morphological datasets. The aim of the MMoOn Core ontology is to serve as a shared semantic model for linguists and NLP researchers alike to enable the creation, conversion, exchange, reuse and enrichment of morphological language data across different data-dependent language sciences. Therefore, various use cases are illustrated to draw attention to the cross-disciplinary potential which can be realized with the MMoOn Core ontology in the context of the existing Linguistic Linked Data research landscape. © 2021 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
Xia P.; Qin G.; Vashishtha S.; Chen Y.; Chen T.; May C.; Harman C.; Rawlins K.; White A.S.; van Durme B.,"Xia, Patrick (57205398560); Qin, Guanghui (57211207303); Vashishtha, Siddharth (57216614046); Chen, Yunmo (57219737313); Chen, Tongfei (57194696781); May, Chandler (56349959300); Harman, Craig (56349681300); Rawlins, Kyle (22986136400); White, Aaron Steven (56743808400); van Durme, Benjamin (26425343200)",57205398560; 57211207303; 57216614046; 57219737313; 57194696781; 56349959300; 56349681300; 22986136400; 56743808400; 26425343200,Lome: Large ontology multilingual extraction,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282328&partnerID=40&md5=0d2242fdaff90b4f240f8baae701e87a,"We present Lome, a system for performing multilingual information extraction. Given a text document as input, our core system identifies spans of textual entity and event mentions with a FrameNet (Baker et al., 1998) parser. It subsequently performs coreference resolution, fine-grained entity typing, and temporal relation prediction between events. By doing so, the system constructs an event and entity focused knowledge graph. We can further apply third-party modules for other types of annotation, like relation extraction. Our (multilingual) first-party modules either outperform or are competitive with the (monolingual) state-of-the-art. We achieve this through the use of multilingual encoders like XLM-R (Conneau et al., 2020) and leveraging multilingual training data. Lome is available as a Docker container on Docker Hub. In addition, a lightweight version of the system is accessible as a web demo. © 2021 Association for Computational Linguistics",Final,
Becker M.; Korfhage K.; Frank A.,"Becker, Maria (57194699697); Korfhage, Katharina (57219584541); Frank, Anette (56254159500)",57194699697; 57219584541; 56254159500,COCO-EX: A tool for linking concepts from texts to conceptnet,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282443&partnerID=40&md5=bf9c125f24319e7264ffc336123d4791,"In this paper we present COCO-EX, a tool for Extracting Concepts from texts and linking them to the ConceptNet knowledge graph. COCO-EX extracts meaningful concepts from natural language texts and maps them to conjunct concept nodes in ConceptNet, utilizing the maximum of relational information stored in the ConceptNet knowledge graph. COCO-EX takes into account the challenging characteristics of ConceptNet, namely that - unlike conventional knowledge graphs - nodes are represented as non-canonicalized, free-form text. This means that i) concepts are not normalized; ii) they often consist of several different, nested phrase types; and iii) many of them are uninformative, over-specific, or misspelled. A commonly used shortcut to circumvent these problems is to apply string matching. We compare COCO-EX to this method and show that COCO-EX enables the extraction of meaningful, important rather than overspecific or uninformative concepts, and allows to assess more relational information stored in the knowledge graph. © 2021 Association for Computational Linguistics",Final,
Harrando I.; Troncy R.,"Harrando, Ismail (57219181682); Troncy, Raphaël (23986650400)",57219181682; 23986650400,Named Entity Recognition as Graph Classification,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115834933&doi=10.1007%2f978-3-030-80418-3_19&partnerID=40&md5=2f4be5d087d96ac2c7cbfa9dcf3601d6,"Injecting real-world information (typically contained in Knowledge Graphs) and human expertise into an end-to-end training pipeline for Natural Language Processing models is an open challenge. In this preliminary work, we propose to approach the task of Named Entity Recognition, which is traditionally viewed as a Sequence Labeling problem, as a Graph Classification problem, where every word is represented as a node in a graph. This allows to embed contextual information as well as other external knowledge relevant to each token, such as gazetteer mentions, morphological form, and linguistic tags. We experiment with a variety of graph modeling techniques to represent words, their contexts, and external knowledge, and we evaluate our approach on the standard CoNLL-2003 dataset. We obtained promising results when integrating external knowledge through the use of graph representation in comparison to the dominant end-to-end training paradigm. © 2021, Springer Nature Switzerland AG.",Final,
Chen M.; Shi W.; Zhou B.; Roth D.,"Chen, Muhao (57077271100); Shi, Weijia (57216177199); Zhou, Ben (57205400110); Roth, Dan (7401669040)",57077271100; 57216177199; 57205400110; 7401669040,Cross-lingual entity alignment with incidental supervision,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106367685&partnerID=40&md5=6ce87ce9d8dab67a1d80ecba9685f668,"Much research effort has been put to multilingual knowledge graph (KG) embedding methods to address the entity alignment task, which seeks to match entities in different language-specific KGs that refer to the same real-world object. Such methods are often hindered by the insufficiency of seed alignment provided between KGs. Therefore, we propose an incidentally supervised model, JEANS, which jointly represents multilingual KGs and text corpora in a shared embedding scheme, and seeks to improve entity alignment with incidental supervision signals from text. JEANS first deploys an entity grounding process to combine each KG with the monolingual text corpus. Then, two learning processes are conducted: (i) an embedding learning process to encode the KG and text of each language in one embedding space, and (ii) a self-learning based alignment learning process to iteratively induce the matching of entities and that of lexemes between embeddings. Experiments on benchmark datasets show that JEANS leads to promising improvement on entity alignment with incidental supervision, and significantly outperforms state-of-the-art methods that solely rely on internal information of KGs. © 2021 Association for Computational Linguistics",Final,
Zhou P.; Gopalakrishnan K.; Hedayatnia B.; Kim S.; Pujara J.; Ren X.; Liu Y.; Hakkani-Tu D.,"Zhou, Pei (57207759495); Gopalakrishnan, Karthik (57219690784); Hedayatnia, Behnam (57193226690); Kim, Seokhwan (24724364000); Pujara, Jay (52664421900); Ren, Xiang (58619993600); Liu, Yang (57218455754); Hakkani-Tu, Dilek (57903796500)",57207759495; 57219690784; 57193226690; 24724364000; 52664421900; 58619993600; 57218455754; 57903796500,Commonsense-Focused Dialogues for Response Generation: An Empirical Study,,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117308108&partnerID=40&md5=303ec9ab3fd4f438ba19544878e2e34c,"Smooth and effective communication requires the ability to perform latent or explicit commonsense inference. Prior commonsense reasoning benchmarks (such as SocialIQA and CommonsenseQA) mainly focus on the discriminative task of choosing the right answer from a set of candidates, and do not involve interactive language generation as in dialogue. Moreover, existing dialogue datasets do not explicitly focus on exhibiting commonsense as a facet. In this paper, we present an empirical study of commonsense in dialogue response generation. We first auto-extract commonsensical dialogues from existing dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph. Furthermore, building on social contexts/situations in SocialIQA, we collect a new dialogue dataset with 25K dialogues aimed at exhibiting social commonsense in an interactive setting. We evaluate response generation models trained using these datasets and find that models trained on both extracted and our collected data produce responses that consistently exhibit more commonsense than baselines. Finally we propose an approach for automatic evaluation of commonsense that relies on features derived from ConceptNet and pretrained language and dialog models, and show reasonable correlation with human evaluation of responses' commonsense quality.  ©2021 Association for Computational Linguistics.",Final,
Bauer L.; Bansal M.,"Bauer, Lisa (57215723859); Bansal, Mohit (16466939600)",57215723859; 16466939600,"Identify, align, and integrate: Matching knowledge graphs to commonsense reasoning tasks",,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107268857&partnerID=40&md5=1a3d30a6d333c1d466373512665e1c17,"Integrating external knowledge into commonsense reasoning tasks has shown progress in resolving some, but not all, knowledge gaps in these tasks. For knowledge integration to yield peak performance, it is critical to select a knowledge graph (KG) that is well-aligned with the given task's objective. We present an approach to assess how well a candidate KG can correctly identify and accurately fill in gaps of reasoning for a task, which we call KG-to-task match. We show this KG-to-task match in 3 phases: knowledge-task identification, knowledge-task alignment, and knowledge-task integration. We also analyze our transformer-based KG-to-task models via commonsense probes to measure how much knowledge is captured in these models before and after KG integration. Empirically, we investigate KG matches for the SocialIQA (SIQA) (Sap et al., 2019b), Physical IQA (PIQA) (Bisk et al., 2020), and MCScript2.0 (Ostermann et al., 2019) datasets with 3 diverse KGs: ATOMIC (Sap et al., 2019a), ConceptNet (Speer et al., 2017), and an automatically constructed instructional KG based on WikiHow (Koupaee and Wang, 2018). With our methods we are able to demonstrate that ATOMIC, an event-inference focused KG, is the best match for SIQA and MCScript2.0, and that the taxonomic ConceptNet and WikiHow-based KGs are the best matches for PIQA across all 3 analysis phases. We verify our methods and findings with human evaluation. © 2021 Association for Computational Linguistics",Final,
Szakács B.B.; Mészáros T.,"Szakács, Béla Benedek (57222082196); Mészáros, Tamás (35318287000)",57222082196; 35318287000,"Hybrid distance-based, CNN and Bi-LSTM system for dictionary expansion",,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101382998&doi=10.36244%2fICJ.2020.4.2&partnerID=40&md5=20a966a3a01dc875d6c918a94b90d59f,"Dictionaries like WordNet can help in a variety of Natural Language Processing applications by providing additional morphological data. They can be used in Digital Humanities research, building knowledge graphs and other applications. Creating dictionaries from large corpora of texts written in a natural language is a task that has not been a primary focus of research, as other tasks have dominated the field (such as chat-bots), but it can be a very useful tool in analysing texts. Even in the case of contemporary texts, categorizing the words according to their dictionary entry is a complex task, and for less conventional texts (in old or less researched languages) it is even harder to solve this problem automatically. Our task was to create a software that helps in expanding a dictionary containing word forms and tagging unprocessed text. We used a manually created corpus for training and testing the model. We created a combination of Bidirectional Long-Short Term Memory networks, convolutional networks and a distance-based solution that outperformed other existing solutions. While manual post-processing for the tagged text is still needed, it significantly reduces the amount of it. © 2020 Scientific Association for Infocommunications. All rights reserved.",Final,All Open Access; Bronze Open Access; Green Open Access
Gupta D.; Berberich K.,"Gupta, Dhruv (56729790600); Berberich, Klaus (55953919200)",56729790600; 55953919200,Weaving Text into Tables,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095863899&doi=10.1145%2f3340531.3417442&partnerID=40&md5=fbf6df476c38a720c7cc8d20b25a044a,"In this paper, we showcase JIGSAW, a system that is able to shape unstructured text into structured tables for user-defined schemas. In short, to structure text into tables, JIGSAW leverages the lexico-syntactic structure imposed by linguistic annotations (e.g., part-of-speech, named entities, temporal and numerical expressions) on natural language text. We describe how challenging knowledge-centric tasks such as question answering, summarization, and analytics can be greatly simplified with the help of JIGSAW. © 2020 Owner/Author.",Final,All Open Access; Bronze Open Access
Wang D.; Fan H.; Liu J.,"Wang, Dongsheng (57211761419); Fan, Hongjie (57188877078); Liu, Junfei (55576492600)",57211761419; 57188877078; 55576492600,Towards Bootstrapping Biomedical Named Entity Recognition using Reinforcement Learning,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100352914&doi=10.1109%2fBIBM49941.2020.9313571&partnerID=40&md5=110fb7c7180f1b8670bb70e9679f03f4,"Named entity recognition is one of the most fundamental problems in knowledge graph. In biomedical field, labeling high-quality biomedical entities requires plenty of linguistic knowledge due to abbreviation and specificity. Using dictionary is the simplest way for labeling, but it is difficult to obtain a versatile dictionary and usually a dictionary for one corpus is not suitable for another corpus due to bad transferability. Current mainstream recognition methods require lots of manpower, which is time-consuming and laborious. To handle this challenge, we present a novel approach to automatically recognize new biomedical entities. First, we use a small number of manually labeled biomedical entities as seeds to label some biomedical texts and learn their features autonomously. Then by using a tagger based on supervised learning and an instance selector based on reinforcement learning, we iteratively generate new biomedical entities. Experiment results demonstrate that our method can deal with biomedical named entity recognition and obtain significant performances in both English and Chinese biomedical datasets. © 2020 IEEE.",Final,
Edelstein E.; Pan J.Z.; Soares R.; Wyner A.,"Edelstein, Elspeth (57204806756); Pan, Jeff Z. (8856621200); Soares, Ricardo (57204808269); Wyner, Adam (7006211789)",57204806756; 8856621200; 57204808269; 7006211789,Knowledge-Driven Intelligent Survey Systems Towards Open Science,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081887293&doi=10.1007%2fs00354-020-00087-y&partnerID=40&md5=7ae25110f5bd1e32da7860ca861f339d,"In this paper, we propose Knowledge Graph (KG), an articulated underlying semantic structure, as a semantic bridge between humans, systems, and scientific knowledge. To illustrate our proposal, we focus on KG-based intelligent survey systems. In state-of-the-art systems, information is hard-coded or implicit, making it hard for researchers to reuse, customise, link, or transmit structured knowledge. Furthermore, such systems do not facilitate dynamic interaction based on semantic structure. We design and implement a knowledge-driven intelligent survey system which is based on knowledge graph, a widely used technology that facilitates sharing and querying hypotheses, survey content, results, and analyses. The approach is developed, implemented, and tested in the field of Linguistics. Syntacticians and morphologists develop theories of grammar of natural languages. To evaluate theories, they seek intuitive grammaticality (well-formedness) judgments from native speakers, which either support hypotheses or provide counter-evidence. Our preliminary experiments show that a knowledge graph-based linguistic survey can provide more nuanced results than the traditional document-based grammaticality judgment surveys by allowing for tagging and manipulation of specific linguistic variables. © 2020, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Chen Y.-H.; Lu E.J.-L.; Lin S.-C.,"Chen, Yi-Hui (36138698800); Lu, Eric Jui-Lin (7102537079); Lin, Sheng-Chia (57218835049)",36138698800; 7102537079; 57218835049,Ontology-based Dynamic Semantic Annotation for Social Image Retrieval,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090381498&doi=10.1109%2fMDM48529.2020.00074&partnerID=40&md5=0f913291ac5297a8ef08dcb0c1851b52,"To mitigate the semantic gap between a visual feature and linguistic representation in social image retrieval, researchers have proposed an automatic image annotation approach, which employs multiple visual features and text matching to label images. This paper used a linked open data approach and ontology to construct a model, an automatic semantic image annotation model for social image retrieval. These models enable users to label images through automatic semantic annotation and to identify the underlying intents of semantics, thereby fulfilling user needs and enhancing the retrieval accuracy. © 2020 IEEE.",Final,
Bouziane A.; Bouchiha D.; Doumi N.,"Bouziane, Abdelghani (57188738097); Bouchiha, Djelloul (6504442016); Doumi, Noureddine (55308795600)",57188738097; 6504442016; 55308795600,Annotating Arabic Texts with Linked Data,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106857950&doi=10.1109%2fISIA51297.2020.9416543&partnerID=40&md5=ffe754a542a65be0b0f0ada6d5e53302,"The evolution of the traditional Web towards the semantic Web allows the machine to be a first-order citizen on the Web and increases discoverability of and accessibility to the unstructured data on the Web. This evolution enables the Linked Data technology to be used as background knowledge bases for unstructured data, notably the texts, available nowadays on the Web. For the Arabic language, the current situation is less brightness; the content of the Arabic language on the Web doesn't reflect the importance of this language. Given the fact that Arabic is one of the most important languages in the Web, and unfortunately it is under-resourced, so creating linguistic resources for it now is a necessity. Thus, we developed a linguistic approach for annotating Arabic textual corpus with Linked Data, especially DBpedia, which is Linked Open Data (LOD) extracted from Wikipedia. This approach uses natural language techniques to shedding light on Arabic text with Linked Open Data. The evaluation results of this approach are encouraging, despite the high complexity of our independent-domain knowledge base and the reduced resources in Arabic natural language processing.  © 2020 IEEE.",Final,
Wang J.; Ouyang Z.; Gan J.,"Wang, Jun (57216678092); Ouyang, Zhaoxiang (57215332308); Gan, Jianhou (25652691700)",57216678092; 57215332308; 25652691700,A method for constructing knowledge graph of ethnic cultural information resources,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092440802&doi=10.1109%2fCSEI50228.2020.9142525&partnerID=40&md5=2a9e0087a7f5396719a8e0e63e51501e,"In order to construct the knowledge graph of ethnic cultural information resources, we first use the Chinese word segmentation system and user-defined thesaurus to segment and part-of-speech tagging the data of ethnic cultural dictionary, and remove the punctuation. Then the text data is detected. If the number of continuous word segmentation is not less than the set threshold, then to perform manual word segmentation operation, and to add the result of manual word segmentation to the user-defined thesaurus of Chinese word segmentation system until there is no new word. Then we extract the attributes of the text data after the correct segmentation to build the domain knowledge graph. We detect the repeatability of the domain knowledge graph, delete the duplicate data, and store the knowledge graph. Finally, we link the stored domain knowledge graph with resources.  © 2020 IEEE.",Final,
Ahmadnia B.,"Ahmadnia, Benyamin (57201687028)",57201687028,Linked data effectiveness in neural machine translation,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123041684&doi=10.1145%2f3440084.3441214&partnerID=40&md5=8033e1fc47d630da29cdc4e58617f1f8,"Quality of data-driven Machine Translation (MT) systems depends on large volumes of data from which models can be constructed to leverage patterns and knowledge from these datasets. In corpus-based MT systems, Out-Of-Vocabulary (OOV) words and ambiguous translations are the most common sources of error. In this paper, JRC-Names and DBpedia have been employed as Linked Data (LD) to minimize the aforementioned types of errors on top of a Neural MT (NMT) model. Three strategies have been evaluated for exploiting knowledge from LD in translating named entities; 1) Dictionaries, 2) Pre-decoding, and 3) Post-editing. Based on the experimental results, these strategies optimize the benefit of the multilingual LD to NMT application. The experiments on English-Spanish translation as well as English-French translation evaluate the validity of the proposed idea. © 2020 ACM.",Final,
Mehler A.; Hemati W.; Welke P.; Konca M.; Uslu T.,"Mehler, Alexander (13907942400); Hemati, Wahed (57194692173); Welke, Pascal (55416297100); Konca, Maxim (57219797170); Uslu, Tolga (57194689342)",13907942400; 57194692173; 55416297100; 57219797170; 57194689342,Multiple Texts as a Limiting Factor in Online Learning: Quantifying (Dis-)similarities of Knowledge Networks,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095556372&doi=10.3389%2ffeduc.2020.562670&partnerID=40&md5=b555be9c0f7d792286387c3c944df84a,"We test the hypothesis that the extent to which one obtains information on a given topic through Wikipedia depends on the language in which it is consulted. Controlling the size factor, we investigate this hypothesis for a number of 25 subject areas. Since Wikipedia is a central part of the web-based information landscape, this indicates a language-related, linguistic bias. The article therefore deals with the question of whether Wikipedia exhibits this kind of linguistic relativity or not. From the perspective of educational science, the article develops a computational model of the information landscape from which multiple texts are drawn as typical input of web-based reading. For this purpose, it develops a hybrid model of intra- and intertextual similarity of different parts of the information landscape and tests this model on the example of 35 languages and corresponding Wikipedias. In the way it measures the similarities of hypertexts, the article goes beyond existing approaches by examining their structural and semantic aspects intra- and intertextually. In this way it builds a bridge between reading research, educational science, Wikipedia research and computational linguistics. © Copyright © 2020 Mehler, Hemati, Welke, Konca and Uslu.",Final,All Open Access; Gold Open Access; Green Open Access
Kancheva Z.; Radev I.,"Kancheva, Z. (57215965215); Radev, I. (57215965292)",57215965215; 57215965292,Linguistic vs Encyclopaedic Knowledge. Classification of MWEs from Wikipedia Articles,,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098103687&doi=10.2478%2fcait-2020-0051&partnerID=40&md5=a78ab248628da4eb3d98a025ca7a4b6d,"This paper reports on the first steps in the creation of linked data through the mapping between the synsets of BTB-WordNet and the articles in Bulgarian Wikipedia. The task of expanding the BTB-WordNet with encyclopaedic knowledge is done by mapping its synsets to Wikipedia articles with many MWEs found in the articles and subjected to further analysis. We look for a way to filter the Wikipedia MWEs in the effort of selecting the ones most beneficial to the enrichment of BTB-WN. © 2020 Z. Kancheva et al., published by Sciendo 2020.",Final,All Open Access; Gold Open Access
Navigli R.,"Navigli, Roberto (6507102454)",6507102454,BabelNet 3.0: A core for linguistic linked data and NLP,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964048415&partnerID=40&md5=1196f8a7acc89a7ad22c70dc11844dbb,"This tutorial will introduce BabelNet 3.0, the largest multilingual encyclopedic dictionary and semantic network, which covers 271 languages. BabelNet is a core component of the Linked Open Data cloud and a powerful engine for virtually any Natural Language Processing task in desperate need of wide-coverage lexical semantics in arbitrary languages. © Springer International Publishing Switzerland 2016.",Final,
Sánchez-Rada J.F.; Iglesias C.A.,"Sánchez-Rada, J. Fernando (56426347900); Iglesias, Carlos A. (56357213400)",56426347900; 56357213400,Onyx: A Linked Data approach to emotion representation,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928027547&doi=10.1016%2fj.ipm.2015.03.007&partnerID=40&md5=107c96b0046793fd47e9000173a7f6d1,"Extracting opinions and emotions from text is becoming increasingly important, especially since the advent of micro-blogging and social networking. Opinion mining is particularly popular and now gathers many public services, datasets and lexical resources. Unfortunately, there are few available lexical and semantic resources for emotion recognition that could foster the development of new emotion aware services and applications. The diversity of theories of emotion and the absence of a common vocabulary are two of the main barriers to the development of such resources. This situation motivated the creation of Onyx, a semantic vocabulary of emotions with a focus on lexical resources and emotion analysis services. It follows a linguistic Linked Data approach, it is aligned with the Provenance Ontology, and it has been integrated with the Lexicon Model for Ontologies (lemon), a popular RDF model for representing lexical entries. This approach also means a new and interesting way to work with different theories of emotion. As part of this work, Onyx has been aligned with EmotionML and WordNet-Affect. © 2015 Elsevier Ltd. All rights reserved.",Final,All Open Access; Green Open Access
Chiarcos C.,"Chiarcos, Christian (22333764800)",22333764800,Annotation interoperability (Invited tutorial),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964065872&partnerID=40&md5=4ebc8818a0899557b1124e4425712525,"The tutorial addressed the problem of heterogeneous representations for language resources, in particular annotated corpora. Heterogeneity exists on multiple levels, the most important being the levels of physical representation, and annotation vocabulary. Establishing interoperability between and among corpora, dictionaries and NLP tools thus involves two dimensions, as well, namely structural interoperability (defining how to access the data, i.e., common formats and protocols) and conceptual interoperability (defining how to interpret the data, i.e., by reference to a common vocabulary). In this tutorial, both aspects were addressed with a focus on linguistic annotations and the Ontologies of Linguistic Annotation (OLiA). As a means to solve the problem of conceptual interoperability for annotations, the OLiA ontologies represent a major hub of linguistic terminology in the Linguistic Linked Open Data (LLOD) cloud. Finally, use cases from natural language processing and corpus querying were described. © Springer International Publishing Switzerland 2016.",Final,
Gómez A.,"Gómez, Asunción (6603934482)",6603934482,Linguistic linked data: Paving the way towards maximising (Re)usability of linguistic resources,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964890766&partnerID=40&md5=71922cbb60c25db3c4e8974f2fa79e41,[No abstract available],Final,
Patraşcu M.I.; Haja G.; Clim M.R.; Tamba E.,"Patraşcu, Mădălin Ionel (57188870500); Haja, Gabriela (57188881472); Clim, Marius Radu (57188880449); Tamba, Elena (57188880007)",57188870500; 57188881472; 57188880449; 57188880007,Romanian dictionaries. Projects of digitization and linked data,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964022185&doi=10.1007%2f978-3-319-32942-0_8&partnerID=40&md5=d71a3288cb1a1ad09ac93a40a080908f,"In the context of globalization and of interest for linked data, Romanian lexicography tries to harmonize to this trends by aligning its resources and adapting to the necessities of a diversity of users. The lexicographic tradition of the Romanian language passed through various periods, from glosses and small bilingual dictionaries, written in Slavonic alphabet (17th–19th century), to scholar dictionaries from the 20th century, written in Latin alphabet. This tradition was highlighted by different projects, some of them presented in this article, and these projects will continue to emphasize the Romanian language features in order to make accessible the Romanian language for the users and to offer the public research materials and resources of the Romanian culture. © Springer International Publishing Switzerland 2016.",Final,
McCrae J.P.,"McCrae, John P. (36666801700)",36666801700,Linked data for lexicons (Invited tutorial),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964039339&partnerID=40&md5=6d8a146e51470caa340c92d862028118,"Lexicons form a crucial part of how we build natural language systems that allow humans to interact with machines and to build web applications that can use web standards such as OWL but express them in natural language, we developed a vocabulary called lemon (Lexicon Model for Ontologies). This tutorial details the model and enables participants to apply it in line with common patterns of usage. © Springer International Publishing Switzerland 2016.",Final,
Strobin L.; Niewiadomski A.,"Strobin, Lukasz (56209036500); Niewiadomski, Adam (8853881300)",56209036500; 8853881300,Integration of multiple graph datasets and their linguistic summaries: An application to linked data,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976632384&doi=10.1007%2f978-3-319-39378-0_29&partnerID=40&md5=ebfbd84b45f6a78f961d2d2942a121dd,"This paper presents a novel method of generating and evaluating linguistic summaries of content stored in distributed graph datasets, like Linked Data. Linguistic summarization is a well known data mining technique, aimed to discover patterns in data and present them in natural language. So far, this method has been researched only for relational databases. In our recent paper we have presented how to adapt this method for graph datasets. We have solved the problems of subject definition (further extended in this paper), retrieval of the attributes for summarization, generalization of summarizers and qualifiers. In this paper we extend that research by adapting proposed method to distributed interlinked graph datasets, which results in obtaining new summaries, and therefore new knowledge. We discuss how to follow different types of equivalence links that may exists between graph datasets. In order to measure characteristics specific for summaries of distributed graph data we propose new truth values (degree of subject appropriateness, degree of summarizer order and degree of linkage), and adapt existing ones (degree of covering). We run several experiments on Linked Data and discuss the results. © Springer International Publishing Switzerland 2016.",Final,
Ide N.,"Ide, Nancy (36943380900)",36943380900,Annotations as linked data – interoperability (Invited tutorial),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964053076&partnerID=40&md5=74680de0ee792fbfba39187bbf2fb86e,"This tutorial considers Semantic Web representations of linguistically-annotated corpora and related resources — in particular, ontological data — specifically from the perspective of interoperability. © Springer International Publishing Switzerland 2016.",Final,
Presutti V.; Nuzzolese A.G.; Consoli S.; Gangemi A.; Recupero D.R.,"Presutti, Valentina (55885160000); Nuzzolese, Andrea Giovanni (42862074000); Consoli, Sergio (24168054400); Gangemi, Aldo (55605133800); Recupero, Diego Reforgiato (57206674454)",55885160000; 42862074000; 24168054400; 55605133800; 57206674454,From hyperlinks to Semantic Web properties using Open Knowledge Extraction,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971554079&doi=10.3233%2fSW-160221&partnerID=40&md5=ac1d14b2b6bd082d9df1734161891fb7,"Open information extraction approaches are useful but insufficient alone for populating the Web with machine readable information as their results are not directly linkable to, and immediately reusable from, other Linked Data sources. This work proposes a novel paradigm, named Open Knowledge Extraction, and its implementation (Legalo) that performs unsupervised, open domain, and abstractive knowledge extraction from text for producing machine readable information. The implemented method is based on the hypothesis that hyperlinks (either created by humans or knowledge extraction tools) provide a pragmatic trace of semantic relations between two entities, and that such semantic relations, their subjects and objects, can be revealed by processing their linguistic traces (i.e. the sentences that embed the hyperlinks) and formalised as Semantic Web triples and ontology axioms. Experimental evaluations conducted on validated text extracted from Wikipedia pages, with the help of crowdsourcing, confirm this hypothesis showing high performances. © 2016 - IOS Press and the authors.",Final,All Open Access; Green Open Access
Gómez-Pérez A.; Gracia J.; Vila-Suero D.,"Gómez-Pérez, Asunción (6603934482); Gracia, Jorge (55392626700); Vila-Suero, Daniel (55532057700)",6603934482; 55392626700; 55532057700,Multilingual linked data generation from language resources (Invited tutorial),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964060201&partnerID=40&md5=b961de65722066ee7137d3df1d5140e0,"This document briefly describes the tutorial on multilingual linked data generation from language resources imparted at EUROLAN’15. In such course, a theoretical overview of linguistic linked data was given, followed by a hands-on session that covered the main steps and aspects in the lifecycle of linguistic linked data generation and publication. The focus was very practical and the participants had the opportunity of generating linked data of some sample resources by themselves. © Springer International Publishing Switzerland 2016.",Final,
Declerck T.,"Declerck, Thierry (22333556000)",22333556000,Building ontolex resources using protégé (Invited tutorial),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964066428&partnerID=40&md5=1d49d491a980db0772d8944ef46cb064,"In this tutorial the aim was to introduce both to the use of the Protégé ontology editor and to the building of lexical resources on the basis of an ontological model for such resources, the Ontolex model, which has been developed in the context of a W3C Community Group. The overall goal was to show how lexical data can be encoded in such a way that they can be published in the emerging Linguistic Linked (Open) Data. © Springer International Publishing Switzerland 2016.",Final,
Verhagen M.; Suderman K.; Wang D.; Ide N.; Shi C.; Wright J.; Pustejovsky J.,"Verhagen, Marc (57205965624); Suderman, Keith (6506579989); Wang, Di (58362268700); Ide, Nancy (36943380900); Shi, Chunqi (57220974267); Wright, Jonathan (57188571779); Pustejovsky, James (6602448845)",57205965624; 6506579989; 58362268700; 36943380900; 57220974267; 57188571779; 6602448845,The LAPPS interchange format,,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961700378&doi=10.1007%2f978-3-319-31468-6_3&partnerID=40&md5=2034b6e99f0c6bf9a1666548be35cf0f,"We describe and motivate the LAPPS Interchange Format, a JSON-LD format that is used for data transfer between language services in the Language Application Grid. The LAPPS Interchange Format enables syntactic and semantic interoperability of language services by providing a uniform syntax for common linguistic data and by using the Linked Data aspect of JSON-LD to refer to external definitions of linguistic categories. It is tightly integrated with the Web Services Exchange Vocabulary, which specifies a terminology for a core of linguistic objects and features exchanged by services. © Springer International Publishing Switzerland 2016.",Final,
Nagvenkar A.; Pawar J.; Bhattacharyya P.,"Nagvenkar, Apurva (56286796000); Pawar, Jyoti (23668496400); Bhattacharyya, Pushpak (7101803108)",56286796000; 23668496400; 7101803108,IndoWordNet conversion to web ontology language (OWL),,1,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962799579&partnerID=40&md5=5551ce812d53615f1172cff07c66db34,"WordNet plays a significant role in Linked Open Data (LOD) cloud. It has numerous application ranging from ontology annotation to ontology mapping. IndoWord-Net is a linked WordNet connecting 18 Indian language WordNets with Hindi as a source WordNet. The Hindi WordNet was initially developed by linking it to English WordNet. In this paper, we present a data representation of IndoWordNet in Web Ontology Language (OWL). The schema of Princeton WordNet has been enhanced to support the representation of IndoWordNet. This IndoWordNet representation in OWL format is now available to link other web resources. This representation is implemented for eight Indian languages.",Final,
Chiarcos C.; Sukhareva M.,"Chiarcos, Christian (22333764800); Sukhareva, Maria (56644499500)",22333764800; 56644499500,OLiA - Ontologies of Linguistic Annotation,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929329936&doi=10.3233%2fSW-140167&partnerID=40&md5=f770d89e6ffb85c9b28c8ddb2dea89d3,"This paper describes the Ontologies of Linguistic Annotation (OLiA) as one of the data sets currently available as part of Linguistic Linked Open Data (LLOD) cloud. Within the LLOD cloud, the OLiA ontologies serve as a reference hub for annotation terminology for linguistic phenomena on a great band-width of languages, they have been used to facilitate interoperability and information integration of linguistic annotations in corpora, NLP pipelines, and lexical-semantic resources and mediate their linking with multiple community-maintained terminology repositories. © 2015 - IOS Press and the authors. All rights reserved.",Final,
Çağdaş V.; Stubkjær E.,"Çağdaş, Volkan (25722968900); Stubkjær, Erik (6507482968)",25722968900; 6507482968,A SKOS vocabulary for Linked Land Administration: Cadastre and Land Administration Thesaurus,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948985186&doi=10.1016%2fj.landusepol.2014.12.017&partnerID=40&md5=fc7d3a37a9ebc9d1f9b18c1e74b1db38,"Intensification of international communication calls for multilingual terminology databases and other linguistic tools. The World Wide Web Consortium framed the further specification of the Simple Knowledge Organization System (SKOS), which is a formal language designed for standardized representation of structured vocabularies, as well as the Linked Data methodology of publishing structured data in a machine-readable and interlinked way, that they become more useful. Applying the Linked Data approach, the European Commission recently established e-Government Core Vocabularies. This paper describes the development of a Knowledge Organization System (KOS) in terms of a thesaurus for the domain of cadastre and land administration. The main purpose is to contribute towards the development of 'Linked Land Administration' that adopts Linked Data technologies for semantic management of datasets kept in public registries, and scholarly and legislative resources kept in libraries. The proposed controlled vocabulary in SKOS format may be used for specifying metadata records of scholarly and legislative resources, as well as enrichment of these resources through semantic annotations. It also provides a base for further ontology development initiatives. The thesaurus is mainly derived from terms of the standard ISO 19152:2012 Land Administration Domain Model, which represents the static aspect of the domain. Reports of the project Property Formation in the Nordic countries (Kort og Matrikelstyrelsen, 2006) provide the basis for the temporal or activity aspect of the domain, while the ANSI/NISO, 2005 Guidelines for the Construction, Format, and Management of Monolingual Controlled Vocabularies provided methodological advice. The thesaurus consists of 143 terms, the relations of which are recorded according to the mentioned SKOS standard. About one fourth of the terms are adopted from existing thesauri, including the AGROVOC multilingual agricultural vocabulary, the GEMET Thesaurus with INSPIRE Spatial Data Themes, and the STW Thesaurus for Economics. © 2015 Elsevier Ltd.",Final,
Montiel-Ponsoda E.; Bosque-Gil J.; Gracia J.; Aguado-De-Cea G.; Vila-Suero D.,"Montiel-Ponsoda, Elena (25654093800); Bosque-Gil, Julia (57031866000); Gracia, Jorge (55392626700); Aguado-De-Cea, Guadalupe (6507619884); Vila-Suero, Daniel (55532057700)",25654093800; 57031866000; 55392626700; 6507619884; 55532057700,Towards the integration of multilingual terminologies: An example of a linked data prototype,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955270336&partnerID=40&md5=0c93f08a0480b4fa64875dc53df9a78c,"Many language resources are nowadays available in machine readable formats, but still contained in isolated silos. Current Semantic Web-based techniques enable the transformation and linking of those resources to become a navigable graph of linked language resources, which can be directly consumed by third-party applications. The prototype we have developed builds on a web user interface and SPARQL endpoint initially developed to query a single terminological database (Terminesp), now extended to navigate a set of multilingual terminologies. The vocabulary used to represent these terminologies into the linked data format is lemon-ontolex, a de facto standard for representing lexical information relative to ontologies and for linking lexicons and machine-readable dictionaries to the Semantic Web.",Final,
Winiwarter W.,"Winiwarter, Werner (57224438042)",57224438042,JAMRED - A Japanese abstract meaning representation EDitor,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967225539&doi=10.1145%2f2837185.2837246&partnerID=40&md5=eae858b0144bbc20b9a769a5da793aa3,"Meaning Representation (AMR) has emerged recently as one of the most influential formalisms for the semantic representation of natural language. In this paper, we present a Web-based environment for the annotation of Japanese Web pages using augmented browsing and logic programming as the two key enabling technologies. We have developed a visual AMR editor strongly integrated into our Web-based Japanese language learning environment, which hides most of the complexities of AMR syntax from the user and extends it by grounding concepts through links to WordNet synsets and DBpedia resources. The resulting tool can be used meaningfully for several language engineering tasks, in particular, language learning, corpus annotation, and translation. © 2015 ACM.",Final,
Wang C.; Gao M.; He X.; Zhang R.,"Wang, Chengyu (55926354300); Gao, Ming (7201511612); He, Xiaofeng (55641972700); Zhang, Rong (55522967300)",55926354300; 7201511612; 55641972700; 55522967300,Challenges in Chinese knowledge graph construction,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944313968&doi=10.1109%2fICDEW.2015.7129545&partnerID=40&md5=00015070afabe392d68409a6f4b2bd71,"The automatic construction of large-scale knowledge graphs has received much attention from both academia and industry in the past few years. Notable knowledge graph systems include Google Knowledge Graph, DBPedia, YAGO, NELL, Probase and many others. Knowledge graph organizes the information in a structured way by explicitly describing the relations among entities. Since entity identification and relation extraction are highly depending on language itself, data sources largely determine the way the data are processed, relations are extracted, and ultimately how knowledge graphs are formed, which deeply involves the analysis of lexicon, syntax and semantics of the content. Currently, much progress has been made for knowledge graphs in English language. In this paper, we discuss the challenges facing Chinese knowledge graph construction because Chinese is significantly different from English in various linguistic perspectives. Specifically, we analyze the challenges from three aspects: data sources, taxonomy derivation and knowledge extraction. We also present our insights in addressing these challenges. © 2015 IEEE.",Final,
Winiwarter W.,"Winiwarter, Werner (57224438042)",57224438042,JILL - Japanese incidental language learning,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967145274&doi=10.1145%2f2837185.2837191&partnerID=40&md5=57f44e22da2b1e839b9e93bfae6dced2,"We present aWeb-based environment for incidental learning of Japanese. As the two key enabling technologies we use augmented browsing at the client and logic programming at the server. This way we can create a learning experience which blends foreign language acquisition with the user's everyday browsing activities. Main features presented in this paper are an intuitive visual presentation of sentence structures, comprehensive support at the word level by integrating several lexical resources including DBpedia, and multiple customization options. © 2015 ACM.",Final,
Krause S.; Hennig L.; Gabryszak A.; Xu F.; Uszkoreit H.,"Krause, Sebastian (52164089400); Hennig, Leonhard (26430879400); Gabryszak, Aleksandra (57194692891); Xu, Feiyu (7401695091); Uszkoreit, Hans (13007575400)",52164089400; 26430879400; 57194692891; 7401695091; 13007575400,Sar-graphs: A Linked Linguistic Knowledge Resource Connecting Facts with Language,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120063260&partnerID=40&md5=a16d1a7609391717447bfb96366186ec,"We present sar-graphs, a knowledge resource that links semantic relations from factual knowledge graphs to the linguistic patterns with which a language can express instances of these relations. Sar-graphs expand upon existing lexicosemantic resources by modeling syntactic and semantic information at the level of relations, and are hence useful for tasks such as knowledge base population and relation extraction. We present a languageindependent method to automatically construct sar-graph instances that is based on distantly supervised relation extraction. We link sar-graphs at the lexical level to BabelNet, WordNet and UBY, and present our ongoing work on pattern- and relationlevel linking to FrameNet. An initial dataset of English sar-graphs for 25 relations is made publicly available, together with a Java-based API. © 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing.",Final,
McCrae J.P.; Cimiano P.,"McCrae, John P. (36666801700); Cimiano, Philipp (15838793700)",36666801700; 15838793700,Linghub: A linked data based portal supporting the discovery of language resources,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954569919&partnerID=40&md5=7ed5f6e247231bc3636337434087b8ff,"Language resources are an essential component of any natural language processing system and such systems can only be applied to new languages and domains if appropriate resources can be found. Currently the task of finding new language resources for a particular task or application is complicated by the fact that records about such resources are stored in different repositories with different models, different quality and search mechanisms. To remedy this situation, we present Linghub, a new portal that aggregates and indexes data from a range of sources and repositories and applied the Linked Data Principles to expose all the metadata under a common interface. Furthermore, we use faceted browsing and SPARQL queries to show how this can help to answer real user problems extracted from a mailing list for linguists. © Copyright 2015 for the individual papers by the papers' authors.",Final,
Carvalho S.; Roche C.; Costa R.,"Carvalho, Sara (58064085700); Roche, Christophe (7103052641); Costa, Rute (55958196000)",58064085700; 7103052641; 55958196000,Ontologies for terminological purposes: The EndoTerm project,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955246750&partnerID=40&md5=22484d2fa7c52b510c2786ba83f281b8,"In today's digital society, characterized by the Semantic Web and by Linked Data, ontologies, in the sense of Knowledge Engineering, have paved the way for new perspectives for Terminology, namely in what concerns the operationalization of terminological products. The collaborative work involving Terminology and ontologies has led to the emergence of new theoretical perspectives, one of which being Ontoterminology. This approach aims to reconcile Terminology's linguistic and conceptual dimensions whilst maintaining their fundamental differences and, in addition, enables the construction of a computer-readable representation of a given conceptualization. Bearing this in mind, this paper presents the EndoTerm project, a multilingual resource within the medical domain - with <Endometriosis> as the core concept - that comprises both verbal and nonverbal representations and that can be computationally represented and manipulated. The presentation of micro-concept systems based on these verbal and non-verbal representations will support a reflection upon the role of the latter in terminology work.",Final,
McCrae J.P.; Cimiano P.; Matteis L.; Navigli R.; Doncel V.R.; Vila-Suero D.; Gracia J.; Abele A.; Vulcu G.; Buitelaar P.,"McCrae, John P. (36666801700); Cimiano, Philipp (15838793700); Matteis, Luca (55362600300); Navigli, Roberto (6507102454); Doncel, Victor Rodríguez (18037048500); Vila-Suero, Daniel (55532057700); Gracia, Jorge (55392626700); Abele, Andrejs (57194614158); Vulcu, Gabriela (36176660600); Buitelaar, Paul (14041096000)",36666801700; 15838793700; 55362600300; 6507102454; 18037048500; 55532057700; 55392626700; 57194614158; 36176660600; 14041096000,Reconciling Heterogeneous Descriptions of Language Resources,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037062941&partnerID=40&md5=ed7fb332868691d899ab1410be3ce03d,"Language resources are a cornerstone of linguistic research and for the development of natural language processing tools, but the discovery of relevant resources remains a challenging task. This is due to the fact that relevant metadata records are spread among different repositories and it is currently impossible to query all these repositories in an integrated fashion, as they use different data models and vocabularies. In this paper we present a first attempt to collect and harmonize the metadata of different repositories, thus making them queriable and browsable in an integrated way. We make use of RDF and linked data technologies for this and provide a first level of harmonization of the vocabularies used in the different resources by mapping them to standard RDF vocabularies including Dublin Core and DCAT. Further, we present an approach that relies on NLP and in particular word sense disambiguation techniques to harmonize resources by mapping values of attributes - such as the type, license or intended use of a resource - into normalized values. Finally, as there are duplicate entries within the same repository as well as across different repositories, we also report results of detection of these duplicates. © 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing.",Final,
Lee C.-Y.; Hsieh S.-K.,"Lee, Chih-Yao (55837874900); Hsieh, Shu-Kai (23397094300)",55837874900; 23397094300,Linguistic Linked Data in Chinese: The Case of ChineseWordNet,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031283009&partnerID=40&md5=c25ab3bedbba36373c64117925801a98,"The present study describes recent developments of Chinese WordNet, which has been reformatted using the lemon model and published as part of the Linguistic Linked Open Data Cloud. While lemon suffices for modeling most of the structures in Chinese WordNet at the lexical level, the model does not allow for finergrained distinction of a word sense, or meaning facets, a linguistic feature also attended to in Chinese WordNet. As for the representation of synsets, we use the WordNet RDF ontology for integration's sake. Also, we use another ontology proposed by the Global WordNet Association to show how Chinese WordNet as Linked Data can be integrated into the Global WordNet Grid. © 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing.",Final,
Villegas M.; Bel N.,"Villegas, Marta (57197393787); Bel, Núria (55369471300)",57197393787; 55369471300,PAROLE/SIMPLE 'lemon' ontology and lexicons,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929303692&doi=10.3233%2fSW-140148&partnerID=40&md5=6f9894bba1bf28153bb538a863672ff5,"The PAROLE/SIMPLE 'lemon' Ontology and Lexicon are the OWL/RDF version of the PAROLE/SIMPLE lexicons (defined during the PAROLE (LE2-4017) and SIMPLE (LE4-8346) IV FP EU projects) once mapped onto lemon model and LexInfo ontology. Original PAROLE/SIMPLE lexicons contain morphological, syntactic and semantic information, organized according to a common model and to common linguistic specifications for 12 European languages. The data set we describe includes the PAROLE/SIMPLE model mapped to lemon and LexInfo ontology and the Spanish & Catalan lexicons. All data are published in the Data Hub and are distributed under CC Attribution 3.0 Unported license. The Spanish lexicon contains 199466 triples and 7572 lexical entries fully annotated with syntactic and semantic information. The Catalan lexicon contains 343714 triples and 20545 lexical entries annotated with syntactic information half of which are also annotated with semantic information. In this paper we describe the resulting data, the mapping process and the benefits obtained. We demonstrate that the Linked Open Data principles prove essential for datasets such as original PAROLE/SIMPLE lexicons where harmonization and interoperability were crucial. The resulting data is lighter and better suited for exploitation. In addition, it facilitates further extensions and linking to external resources such as WordNet, lemonUby, DBpedia etc. © 2015 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Green Open Access
Wang C.; Song Y.; El-Kishky A.; Roth D.; Zhang M.; Han J.,"Wang, Chenguang (56367840700); Song, Yangqiu (14039604300); El-Kishky, Ahmed (55452293400); Roth, Dan (7401669040); Zhang, Ming (57853084000); Han, Jiawei (24325399900)",56367840700; 14039604300; 55452293400; 7401669040; 57853084000; 24325399900,Incorporating world knowledge to document clustering via heterogeneous information networks,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954104008&doi=10.1145%2f2783258.2783374&partnerID=40&md5=5c28b32026aa7202d6b17bfb9cb64535,"One of the key obstacles in making learning protocols realistic in applications is the need to supervise them, a costly process that often requires hiring domain experts. We consider the framework to use the world knowledge as indirect supervision. World knowledge is general-purpose knowledge, which is not designed for any specific domain. Then the key challenges are how to adapt the world knowledge to domains and how to represent it for learning. In this paper, we provide an example of using world knowledge for domain dependent document clustering. We provide three ways to specify the world knowledge to domains by resolving the ambiguity of the entities and their types, and represent the data with world knowledge as a heterogeneous information network. Then we propose a clustering algorithm that can cluster multiple types and incorporate the sub-type information as constraints. In the experiments, we use two existing knowledge bases as our sources of world knowledge. One is Freebase, which is collaboratively collected knowledge about entities and their organizations. The other is YAGO2, a knowledge base automatically extracted from Wikipedia and maps knowledge to the linguistic knowledge base, WordNet. Experimental results on two text benchmark datasets (20news-groups and RCV1) show that incorporating world knowledge as indirect supervision can significantly outperform the state-of-the-art clustering algorithms as well as clustering algorithms enhanced with world knowledge features.",Final,All Open Access; Green Open Access
Cheniki N.; Belkhir A.; Atif Y.,"Cheniki, Nasredine (57156487100); Belkhir, Abdelkader (25929012700); Atif, Yacine (6602094384)",57156487100; 25929012700; 6602094384,Supporting multilingual semantic Web services discovery by consuming data from DBpedia knowledge base,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959933874&doi=10.1145%2f2816839.2816862&partnerID=40&md5=a79701a17e143e5939ac809da64d1d98,"The Web is becoming a truly multilingual hub in which speakers from different languages and cultures are producing, interacting and consuming information. Web services are an essential part of the Web which nowadays attract more and more people around the world. So, supporting multilingual Web services discovery is a crucial goal to achieve, so that providers and users publish or consume Web services independently from their culture and native language. In this paper, we propose to overcome language barrier by supporting multilingual Web services discovery using DB-pedia, which is a cross-domain multilingual knowledge base. DBpedia is used to annotate services with semantic entities called resources as well as their categories and types. We take advantage of semantic and multilingual information provided by DBpedia to enable cross-language semantic Web services discovery. Implementation shows that DBpedia offers a valuable information source to achieve our goal. © 2015 ACM.",Final,
Mohamed R.; El-Makky N.M.; Nagi K.,"Mohamed, Reham (57197175008); El-Makky, Nagwa M. (14051767000); Nagi, Khaled (8531093900)",57197175008; 14051767000; 8531093900,ArabRelat: Arabic relation extraction using distant supervision,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961176131&doi=10.5220%2f0005636604100417&partnerID=40&md5=2dd482bce31d0abcd1362f835dce4eb3,"Relation Extraction is an important preprocessing task for a number of text mining applications, including: Information Retrieval, Question Answering, Ontology building, among others. In this paper, we propose a novel Arabic relation extraction method that leverages linguistic features of the Arabic language in Web data to infer relations between entities. Due to the lack of labeled Arabic corpora, we adopt the idea of distant supervision, where DBpedia, a large database of semantic relations extracted from Wikipedia, is used along with a large unlabeled text corpus to build the training data. We extract the sentences from the unlabeled text corpus, and tag them using the corresponding DBpedia relations. Finally, we build a relation classifier using this data which predicts the relation type of new instances. Our experimental results show that the system reaches 70% for the F-measure in detecting relations. Copyright © 2015 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Final,
Westphal P.; Stadler C.; Pool J.,"Westphal, Patrick (56406316700); Stadler, Claus (36705275300); Pool, Jonathan (53564209400)",56406316700; 36705275300; 53564209400,Countering language attrition with PanLex and the Web of Data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929329731&doi=10.3233%2fSW-140138&partnerID=40&md5=57e748dd4fa77890501020cad958f43b,"The world is losing some of its 7,000 languages. Hypothesizing that language attrition might subside if all languages were intertranslatable, the PanLex project supports panlingual lexical translation by integrating all known lexical translations. Semantic Web technologies can flexibly represent and reason with the content of its database and interlink it with linguistic and other resources and annotations. Conversely, PanLex, with its collection of translation links between more than a billion pairs of lexemes from more than 9,000 language varieties, can improve the coverage of the Linguistic Web of Data. We detail how we transformed the content of the PanLex database to RDF, established conformance with the lemon and GOLD data models, interlinked it with Lexvo and DBpedia, and published it as Linked Data and via SPARQL. © 2015 - IOS Press and the authors. All rights reserved.",Final,
Declerck T.; Wandl-Vogt E.; Krek S.; Tiberius C.,"Declerck, Thierry (22333556000); Wandl-Vogt, Eveline (24336963100); Krek, Simon (55581031400); Tiberius, Carole (26632410700)",22333556000; 24336963100; 55581031400; 26632410700,Towards multilingual elexicography by means of linked (Open) Data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962264489&partnerID=40&md5=88d3e39003b509bd4dc9ad338b93ef2b,"In this short paper, we document the current state of work consisting in mapping various lexicographic resources onto the OntoLex model, which is an OWL and RDF(s) based representation format. This model has been designed in the context of a W3C Community Group effort for supporting the publication of linguistic data in the Linked (Open) Data cloud. The deployment of OntoLex is currently being tested within the ISCH COST Action IS1305 European Network of e-Lexicography (ENeL), which is adapting to the field of digital lexicography guidelines that have been suggested by the LIDER FP7 Support Action.",Final,
Dragoni M.; Tettamanzi A.G.B.; da Costa Pereira C.,"Dragoni, Mauro (19638448200); Tettamanzi, Andrea G. B. (56343725100); da Costa Pereira, Célia (55893690200)",19638448200; 56343725100; 55893690200,Propagating and Aggregating Fuzzy Polarities for Concept-Level Sentiment Analysis,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926322258&doi=10.1007%2fs12559-014-9308-6&partnerID=40&md5=76b58e9064aa0df3998923e453fa0fa6,"An emerging field within sentiment analysis concerns the investigation about how sentiment polarities associated with concepts have to be adapted with respect to the different domains in which they are used. In this paper, we explore the use of fuzzy logic for modeling concept polarities, and the uncertainty associated with them, with respect to different domains. The approach is based on the use of a knowledge graph built by combining two linguistic resources, namely WordNet and SenticNet. Such a knowledge graph is then exploited by a graph-propagation algorithm that propagates sentiment information learned from labeled datasets. The system implementing the proposed approach has been evaluated on the Blitzer dataset. The results demonstrate its viability in real-world cases. © 2014, Springer Science+Business Media New York.",Final,All Open Access; Green Open Access
Álvarez A.A.,"Álvarez, Aitor Arronte (57219495648)",57219495648,"Enriching Digitized Medieval Manuscripts: Linking Image, Text and Lexical Knowledge",,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122503695&partnerID=40&md5=a7452c56d9465f76100490ec9185d749,"This paper describes an on-going project of transcribing and annotating digitized manuscripts of medieval Spanish with paleographic and lexical information. We link lexical units from the manuscripts with the Multilingual Central Repository (MCR), making terms retrievable by any of the languages that integrate MCR. The goal of the project is twofold: creating a paleographic knowledge base from digitized medieval facsimiles, that will allow paleographers, philologist, historical linguist, and humanities scholars in general, to analyze and retrieve graphemic, lexical and textual information from historical documents; and on the other hand, developing machine readable documents that will link image representations of graphemic and lexical units in a facsimile with Linked Open Data resources. This paper concentrates on the encoding and cross-linking procedures. c 2015 Association for Computational Linguistics and The Asian Federation of Natural Language Processing. © 2015 Proceedings of the Annual Meeting of the Association for Computational Linguistics.",Final,
Ruseti S.; Mirea A.; Rebedea T.; Trausan-Matu S.,"Ruseti, Stefan (57188672704); Mirea, Alexandru (57190740323); Rebedea, Traian (24338916400); Trausan-Matu, Stefan (16318248100)",57188672704; 57190740323; 24338916400; 16318248100,QAnswer - Enhanced entity matching for question answering over linked data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982843402&partnerID=40&md5=1f37b2483f4710ea1f8a2f3238080c2e,"QAnswer is a question answering system that uses DBpedia as a knowledge base and converts natural language questions into a SPARQL query. In order to improve the match between entities and relations and natural language text, we make use of Wikipedia to extract lexicalizations of the DBpedia entities and then match them with the question. These entities are validated on the ontology, while missing ones can be inferred. The proposed system was tested in the QALD-5 challenge and it obtained a F1 score of 0.30, which placed QAnswer in the second position in the challenge, despite the fact that the system used only a small subset of the properties in DBpedia, due to the long extraction process.",Final,
Celikyilmaz A.; Hakkani-Tiir D.; Pasupat P.; Sarikaya R.,"Celikyilmaz, Asli (35614300300); Hakkani-Tiir, Dilek (57191155900); Pasupat, Panupong (55756364000); Sarikaya, Ruhi (6602907269)",35614300300; 57191155900; 55756364000; 6602907269,Enriching word embeddings using knowledge graph for semantic tagging in conversational dialog systems,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987629985&partnerID=40&md5=deb001215138bdab456b70f41603852e,"Unsupervised word embeddings provide rich linguistic and conceptual information about words. However, they may provide weak information about domain specific semantic relations for certain tasks such as semantic parsing of natural language queries, where such information about words can be valuable. To encode the prior know ledge about the semantic word relations, we present new method as follows: we extend the neural network based lexical word embedding objective function (Mikolov et al. 2013) by incorporating the information about relationship between entities that we extract from knowledge bases. Our model can jointly learn lexical word representations from free text enriched by the relational word embeddings from relational data (e.g. Freebase) for each type of entity relations. We empirically show on the task of semantic tagging of natural language queries that our enriched embeddings can provide information about not only short-range syntactic dependencies but also long-range semantic dependencies between words. Using the enriched embeddings, we obtain an average of 2% improvement in F-score compared to the previous baselines. Copyright © 2015. Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
McCrae J.P.; Moran S.; Hellmann S.; Brümmer M.,"McCrae, John P. (36666801700); Moran, Steven (55901459600); Hellmann, Sebastian (35199882400); Brümmer, Martin (55995213500)",36666801700; 55901459600; 35199882400; 55995213500,Multilingual linked data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929314245&doi=10.3233%2fSW-150178&partnerID=40&md5=09615eb60517073ee3e7a2dadd1b178a,"The interaction of natural language processing and the Semantic Web have lead to the creation of a new paradigm known as Linguistic Linked Open Data (LLOD), whereby traditional language resources are made available as linked data. Conversely, the publication of corpora, machine-readable dictionaries as linked data has opened new resources to Semantic Web researchers and allowed new tools to be developed. In this special issue, we present recent development of tools and resources for creating and publishing language resources as linked data and tools to exploit this data to enable a multilingual Semantic Web. © 2015 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Bronze Open Access
De Melo G.,"De Melo, Gerard (23088528100)",23088528100,Lexvo.org: Language-related information for the Linguistic Linked Data cloud,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929309290&doi=10.3233%2fSW-150171&partnerID=40&md5=f37c88e076c88f5831122a3041ca8ed0,"Lexvo.org brings information about languages, words, and other linguistic entities to the Web of Linked Data. It defines URIs for terms, languages, scripts, and characters, which are not only highly interconnected but also linked to a variety of resources on the Web. Additionally, new datasets are being published to contribute to the emerging Linked Data Cloud of Language-Related information. © 2015 - IOS Press and the authors. All rights reserved.",Final,
Siemoneit B.; McCrae J.P.; Cimiano P.,"Siemoneit, Benjamin (57414991200); McCrae, John P. (36666801700); Cimiano, Philipp (15838793700)",57414991200; 36666801700; 15838793700,Linking four heterogeneous language resources as linked data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009269613&partnerID=40&md5=dfbe34f7414893e5c07f0c81c0ec3ccb,"The interest in publishing language resources as linked data is increasing, as clearly corroborated by the recent growth of the Linguistic Linked Data cloud. However, the actual value of data published as linked data is the fact that it is linked across datasets, supporting integration and discovery of data. As the manual creation of links between datasets is costly and therefore does not scale well, automatic linking approaches are of great importance to increase the quality and degree of linking of the Linguistic Linked Data cloud. In this paper we examine an automatic approach to link four different datasets to each other: Two terminologies, the European Migration Network (EMN) glossary as well as the Interactive Terminology for Europe (IATE), BabelNet, and the Manually Annotated Subcorpus (MASC) of the American National Corpus. We describe our methodology, present some results on the quality of the links and summarize our experiences with this small linking exercise We will make sure that the resources are added to the linguistic linked data cloud. © 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing.",Final,
Lesnikova T.; David J.; Euzenat J.,"Lesnikova, Tatiana (55872927200); David, Jérôme (7401663885); Euzenat, Jérôme (6602400029)",55872927200; 7401663885; 6602400029,Interlinking English and Chinese RDF data using BabelNet,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959182734&doi=10.1145%2f2682571.2797089&partnerID=40&md5=14dd737f9c6e954599d219a883a53ab9,"Linked data technologies make it possible to publish and link structured data on the Web. Although RDF is not about text, many RDF data providers publish their data in their own language. Cross-lingual interlinking aims at discovering links between identical resources across knowledge bases in different languages. In this paper, we present a method for interlinking RDF resources described in English and Chinese using the BabelNet multilingual lexicon. Resources are represented as vectors of identifiers and then similarity between these resources is computed. The method achieves an F-measure of 88%. The results are also compared to a translation-based method. © 2015 ACM.",Final,All Open Access; Green Open Access
A. Hassan I.; Ojo A.; Porwol L.,"A. Hassan, Islam (56406088500); Ojo, Adegboyega (55800630300); Porwol, Lukasz (55322222200)",56406088500; 55800630300; 55322222200,A lexical resource for identifying public services names on the social web,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960414008&doi=10.1007%2f978-3-319-27237-5_14&partnerID=40&md5=347831e00599e9a27681c492d9aef37d,"Discovery of government-related resources on the social web through mentions of government-related terms requires domain-specific lexical resources. This chapter describes an approach for developing a Lexical Resource for Public Services Names and how it could be exploited. Central to our technical approach is the development of a Semantic Alignment Algorithm, which organizes a set of public service names automatically captured from government websites in a semantic network based on a semantic relatedness measure (Explicit Semantic Analysis—ESA). To demonstrate the use of the developed lexicon, we: (1) clustered the United Kingdom and Irish Government public services catalogue for easier access to related services on citizens portals and (2) developed a Named Entity Recognizer (NER) to identify mentions of public service related information in a twitter stream. Evaluation of the semantic relations in the developed lexical resource computed by our semantic alignment algorithm showed the accuracy (specifically the F-Score ranged from 0.65 to 0.93. © Springer International Publishing Switzerland 2015.",Final,
Sasaki F.; Gornostay T.; Dojchinovski M.; Osella M.; Mannens E.; Stoitsis G.; Ritchie P.; Koidl K.,"Sasaki, Felix (8938640000); Gornostay, Tatiana (36602652700); Dojchinovski, Milan (55453114000); Osella, Michele (54991462500); Mannens, Erik (24464045700); Stoitsis, Giannis (55256347000); Ritchie, Phil (57188680776); Koidl, Kevin (25031643800)",8938640000; 36602652700; 55453114000; 54991462500; 24464045700; 55256347000; 57188680776; 25031643800,Introducing FREME: Deploying linguistic linked data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962281732&partnerID=40&md5=5e4040102e2f6f4b16843b81622ecc55,"This paper introduces the FREME project, a new Horizon 2020 innovation action. It aims at building an open framework of e-Services for multilingual and semantic enrichment of digital content, based on a reusable set of open Application Programme Interfaces and Graphical User Interfaces to FREME enrichment services. In addition, the paper discusses how the project deploys Linguistic Linked Data (LLD), especially existing LLD resources, LLD best practices and the LLD reference architecture.",Final,
Chen Y.-N.; Wang W.Y.; Rudnicky A.I.,"Chen, Yun-Nung (47061006000); Wang, William Yang (57233559700); Rudnicky, Alexander I. (6602574360)",47061006000; 57233559700; 6602574360,Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959178594&doi=10.3115%2fv1%2fn15-1064&partnerID=40&md5=063c7e0df5060b318024b813d9264f66,"A key challenge of designing coherent semantic ontology for spoken language understanding is to consider inter-slot relations. In practice, however, it is difficult for domain experts and professional annotators to define a coherent slot set, while considering various lexical, syntactic, and semantic dependencies. In this paper, we exploit the typed syntactic dependency theory for unsupervised induction and filling of semantics slots in spoken dialogue systems. More specifically, we build two knowledge graphs: a slot-based semantic graph, and a word-based lexical graph. To jointly consider word-to-word, word-toslot, and slot-to-slot relations, we use a random walk inference algorithm to combine the two knowledge graphs, guided by dependency grammars. The experiments show that considering inter-slot relations is crucial for generating a more coherent and compete slot set, resulting in a better spoken language understanding model, while enhancing the interpretability of semantic slots. © 2015 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Eckle-Kohler J.; McCrae J.P.; Chiarcos C.,"Eckle-Kohler, Judith (24168347000); McCrae, John Philip (36666801700); Chiarcos, Christian (22333764800)",24168347000; 36666801700; 22333764800,"LemonUby - A large, interlinked, syntactically-rich lexical resource for ontologies",,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929333600&doi=10.3233%2fSW-140159&partnerID=40&md5=9810242a0d59db7a8d89f50f37462b9f,"We introduce lemonUby, a new lexical resource integrated in the Semantic Web which is the result of converting data extracted from the existing large-scale linked lexical resource UBY to the lemon lexicon model. The following data from UBY were converted: WordNet, FrameNet, VerbNet, English and German Wiktionary, the English and German entries of OmegaWiki, as well as links between pairs of these lexicons at the word sense level (links between VerbNet and FrameNet, VerbNet and WordNet, WordNet and FrameNet, WordNet and Wiktionary, WordNet and German OmegaWiki). We linked lemonUby to other lexical resources and linguistic terminology repositories in the Linguistic Linked Open Data cloud and outline possible applications of this new dataset. © 2015 - IOS Press and the authors. All rights reserved.",Final,
Sérasset G.,"Sérasset, Gilles (8897914400)",8897914400,DBnary: Wiktionary as a Lemon-based multilingual lexical resource in RDF,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929331267&doi=10.3233%2fSW-140147&partnerID=40&md5=88747477c7725eef8b8640fb49224648,"Contributive resources, such as Wikipedia, have proved to be valuable to Natural Language Processing or multilingual Information Retrieval applications. This work focusses on Wiktionary, the dictionary part of the resources sponsored by the Wikimedia foundation. In this article, we present our extraction of multilingual lexical data from Wiktionary data and to provide it to the community as a Multilingual Lexical Linked Open Data (MLLOD). This lexical resource is structured using the LEMON Model. This data, called DBnary, is registered at http://thedatahub.org/dataset/dbnary. © 2015 - IOS Press and the authors. All rights reserved.",Final,
Beyene M.; Portier P.-E.; Atnafu S.; Calabretto S.,"Beyene, Melkamu (57208699535); Portier, Pierre-Edouard (36979110100); Atnafu, Solomon (6507393366); Calabretto, Sylvie (7801625208)",57208699535; 36979110100; 6507393366; 7801625208,Tensor Factorization for cross lingual entity co-reference resolution in the linked open data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962739480&doi=10.1145%2f2857218.2857221&partnerID=40&md5=72043c8051e7adb679e1200263c74644,"The main objective of this research was to identify co-referent entities located in several linked open data (LOD) sources that are described in various natural languages. The problem is approached from two perspectives. First, we do a multi-scale analysis of the RDF graph to discover structural similarities of entities. This was implemented as a tensor decomposition of the RDF graph with each predicate corresponding to a horizontal slide of the tensor. Hereafter, we used the term ""structural evidence"" to refer to the result of this analysis. Second, for each entity, we associated textual data coming from the Web of documents. Thus, after some preprocessing (viz. removing empty words, applying a weighting scheme such as tf-idf, ⋯), we represented each entity in a high dimensional space with each dimension corresponding to a term. Next, through a Singular Value Decomposition (SVD), we find a subspace such that the sum of squared distances from the original space to the sub space is minimized. This dimensionality reduction allows us to find language independent similarities between entities. Hereafter, we use the term ""textual evidence"" to refer to the result of this analysis. Since the similarity information coming from the structural and the textual evidence are complementary to each other, a global similarity score is computed by aggregating the two evidences. We adopt a linear opinion pool, an approach which is commonly used in belief aggregation as an aggregation mechanism. In the end, for any given entity, we obtained a global similarity vector. The higher component values of this vector correspond to potential co-referent entities. All algorithms are implemented in Python. According to the experiment result conducted on the French and English DBpedia, our approach can bring high results. © 2015 ACM.",Final,
Li J.; Wang C.; He X.; Zhang R.; Gao M.,"Li, Jinyang (57008282900); Wang, Chengyu (55926354300); He, Xiaofeng (55641972700); Zhang, Rong (55522967300); Gao, Ming (7201511612)",57008282900; 55926354300; 55641972700; 55522967300; 7201511612,User generated content oriented Chinese taxonomy construction,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950238015&doi=10.1007%2f978-3-319-25255-1_51&partnerID=40&md5=810c7d0fdc664a6192eb1e6b6993dd03,"The taxonomy is one of the basic components in knowledge graphs as it establishes types of classes and semantic relations among the classes. Taxonomies are normally constructed either manually, or by language-dependent rules or patterns for type and relation extraction or inference. Existing work on building taxonomies for knowledge graphs is mostly in English language environment. In this paper, we propose a novel approach for large-scale Chinese taxonomy construction based on user generated content. We take Chinese Wikipedia as the data source, develop methods to extract classes and their relations mined from user tagged categories, and build up the taxonomy using a bottom-up strategy. The algorithms can be easily applied to other Wiki-style data sources. The experiments show that the constructed Chinese taxonomy achieves better results in both quality and quantity. © Springer International Publishing Switzerland 2015.",Final,
Rouces J.; De Melo G.; Hose K.,"Rouces, Jacobo (55871390700); De Melo, Gerard (23088528100); Hose, Katja (23388785300)",55871390700; 23088528100; 23388785300,Framebase: Representing N-ary relations using semantic frames,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937485067&doi=10.1007%2f978-3-319-18818-8_31&partnerID=40&md5=91c42249bc74eb30360db366db046087,"Large-scale knowledge graphs such as those in the Linked Data cloud are typically represented as subject-predicate-object triples. However, many facts about the world involve more than two entities. While n-ary relations can be converted to triples in a number of ways, unfortunately, the structurally different choices made in different knowledge sources significantly impede our ability to connect them. They also make it impossible to query the data concisely and without prior knowledge of each individual source. We present FrameBase, a wide-coverage knowledge-base schema that uses linguistic frames to seamlessly represent and query n-ary relations from other knowledge bases, at different levels of granularity connected by logical entailment. It also opens possibilities to draw on natural language processing techniques for querying and data mining. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Bronze Open Access
Arcan M.; Turchi M.; Buitelaar P.,"Arcan, Mihael (55453083200); Turchi, Marco (55907504700); Buitelaar, Paul (14041096000)",55453083200; 55907504700; 14041096000,Knowledge portability with semantic expansion of ontology labels,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943746735&doi=10.3115%2fv1%2fp15-1069&partnerID=40&md5=cb59323a8b2b76877cf4445da028a55e,"Our research focuses on the multilingual enhancement of ontologies that, often represented only in English, need to be translated in different languages to enable knowledge access across languages. Ontology translation is a rather different task then the classic document translation, because ontologies contain highly specific vocabulary and they lack contextual information. For these reasons, to improve automatic ontology translations, we first focus on identifying relevant unambiguous and domain-specific sentences from a large set of generic parallel corpora. Then, we leverage Linked Open Data resources, such as DBPedia, to isolate ontologyspecific bilingual lexical knowledge. In both cases, we take advantage of the semantic information of the labels to select relevant bilingual data with the aim of building an ontology-specific statistical machine translation system. We evaluate our approach on the translation of a medical ontology, translating from English into German. Our experiment shows a significant improvement of around 3 BLEU points compared to a generic as well as a domain-specific translation approach. © 2015 Association for Computationl Linguisticss.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Hauck P.; Braga R.; Campos F.; Torrent T.; Matos E.; David J.M.N.,"Hauck, Paulo (56903993200); Braga, Regina (7006111233); Campos, Fernanda (35319797200); Torrent, Tiago (56338314300); Matos, Ely (32868078100); David, José Maria N. (18433696900)",56903993200; 7006111233; 35319797200; 56338314300; 32868078100; 18433696900,Supporting FrameNet Project with Semantic Web technologies,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944338891&partnerID=40&md5=55195632f450d4c300e56691024dd0c5,"FrameNet Project is being developed by ICSI at Berkeley, with the goal of documenting the English language lexicon based on Frame Semantics. For Brazilian Portuguese, the FrameNet-Br Project, hosted at UFJF, follows the same theoretical and methodological perspective. This work presents a service-based infrastructure that combines Semantic Web technologies with FrameNet-like databases, by considering the hypothesis that the application of technologies such as ontologies, linked data, and web services can contribute to build and reuse lexical resources based on Frame Semantics. The contributions are related to enriched semantics, data reliability and natural language processing.",Final,
Perera R.; Nand P.,"Perera, Rivindu (56425389400); Nand, Parma (6506991350)",56425389400; 6506991350,A multi-strategy approach for lexicalizing linked open data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942510700&doi=10.1007%2f978-3-319-18117-2_26&partnerID=40&md5=377178b92a49433985cfee371f267073,"This paper aims at exploiting Linked Data for generating natural text, often referred to as lexicalization. We propose a framework that can generate patterns which can be used to lexicalize Linked Data triples. Linked Data is structured knowledge organized in the form of triples consisting of a subject, a predicate and an object. We use DBpedia as the Linked Data source which is not only free but is currently the fastest growing data source organized as Linked Data. The proposed framework utilizes the Open Information Extraction (OpenIE) to extract relations from natural text and these relations are then aligned with triples to identify lexicalization patterns. We also exploit lexical semantic resources which encode knowledge on lexical, semantic and syntactic information about entities. Our framework uses VerbNet and WordNet as semantic resources. The extracted patterns are ranked and categorized based on the DBpedia ontology class hierarchy. The pattern collection is then sorted based on the score assigned and stored in an index embedded database for use in the framework as well as for future lexical resource. The framework was evaluated for syntactic accuracy and validity by measuring the Mean Reciprocal Rank (MRR) of the first correct pattern. The results indicated that framework can achieve 70.36% accuracy and a MRR value of 0.72 for five DBpedia ontology classes generating 101 accurate lexicalization patterns. © Springer International Publishing Switzerland 2015.",Final,
Li Q.; Liu S.; Lin R.; Li M.; Zhou M.,"Li, Qinglin (57015720200); Liu, Shujie (56181265100); Lin, Rui (57015992100); Li, Mu (35110581300); Zhou, Ming (55587890800)",57015720200; 56181265100; 57015992100; 35110581300; 55587890800,Entity translation with collective inference in knowledge graph,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951275676&doi=10.1007%2f978-3-319-25207-0_5&partnerID=40&md5=5981a3d872977177e02b88848fe0a77c,"Nowadays knowledge base (KB) has been viewed as one of the important infrastructures for many web search applications and NLP tasks. However, in practice the availability of KB data varies from language to language, which greatly limits potential usage of knowledge base. In this paper, we propose a novel method to construct or enrich a knowledge base by entity translation with help of another KB but compiled in a different language. In our work, we concentrate on two key tasks: 1) collecting translation candidates with as good coverage as possible from various sources such as web or lexicon; 2) building an effective disambiguation algorithm based on collective inference approach over knowledge graph to find correct translation for entities in the source knowledge base. We conduct experiments on movie domain of our inhouse knowledge base from English to Chinese, and the results show the proposed method can achieve very high translation precision compared with classical translation methods, and significantly increase the volume of Chinese knowledge base in this domain. © Springer International Publishing Switzerland 2015.",Final,
Bretschneider C.; Oberkampf H.; Zillner S.,"Bretschneider, Claudia (55967679400); Oberkampf, Heiner (55819780100); Zillner, Sonja (22037213700)",55967679400; 55819780100; 22037213700,UIMA2LOD: Integrating UIMA text annotations into the linked open data cloud,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951828238&doi=10.1007%2f978-3-319-24543-0_2&partnerID=40&md5=1d1ffe005801345da14770b89aedfb6e,"The LOD cloud is becoming the de-facto standard for sharing and connecting pieces of data, information and knowledge on the Web. As of today, means for the seamless integration of structured data into the LOD cloud are available. However, algorithms for integrating information enclosed in unstructured text sources are missing. In order to foster the (re)use of the high percentage of unstructured text, automatic means for the integration of their content are needed. We address this issue by proposing an approach for conceptual representation of textual annotations which distinguishes linguistic from semantic annotations and their integration. Additionally, we implement a generic UIMA pipeline that automatically creates a LOD graph from texts that (1) implements the proposed conceptual representation, (2) extracts semantically classified entities, (3) links to existing LOD datasets and (4) generates RDF graphs from the extracted information. We show the application and benefits of the approach in a case study on a medical corpus. © Springer International Publishing Switzerland 2015.",Final,
Hakimov S.; Unger C.; Walter S.; Cimiano P.,"Hakimov, Sherzod (55293616500); Unger, Christina (42862497400); Walter, Sebastian (55452669100); Cimiano, Philipp (15838793700)",55293616500; 42862497400; 55452669100; 15838793700,Applying semantic parsing to question answering over linked data: Addressing the lexical gap,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948799577&doi=10.1007%2f978-3-319-19581-0_8&partnerID=40&md5=016d37f8a56437dea5c4290f9ffdfbdd,"Question answering over linked data has emerged in the past years as an important topic of research in order to provide natural language access to a growing body of linked open data on the Web. In this paper we focus on analyzing the lexical gap that arises as a challenge for any such question answering system. The lexical gap refers to the mismatch between the vocabulary used in a user question and the vocabulary used in the relevant dataset. We implement a semantic parsing approach and evaluate it on the QALD-4 benchmark, showing that the performance of such an approach suffers from training data sparseness. Its performance can, however, be substantially improved if the right lexical knowledge is available. To show this, we model a set of lexical entries by hand to quantify the number of entries that would be needed. Further, we analyze if a state-of-the-art tool for inducing ontology lexica from corpora can derive these lexical entries automatically. We conclude that further research and investments are needed to derive such lexical knowledge automatically or semi-automatically. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
Costa T.; Leal J.P.,"Costa, Teresa (56023132400); Leal, José Paulo (56238063100)",56023132400; 56238063100,Reducing large semantic graphs to improve semantic relatedness,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952662774&doi=10.1007%2f978-3-319-27653-3_23&partnerID=40&md5=0781900743552cc4a1a615c5f31f4226,"In the previous research the authors developed a family of semantic measures that are adaptable to any semantic graph, being automatically tuned with a set of parameters. The research presented in this paper extends this approach by also tuning the graph. This graph reduction procedure starts with a disconnected graph and incrementally adds edge types, until the quality of the semantic measure cannot be further improved. The validation performed used the three most recent versions of WordNet and, in most cases, this approach improves the quality of the semantic measure. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
Bennacer N.; Vioulès M.J.; López M.A.; Quercini G.,"Bennacer, Nacéra (22333719100); Vioulès, Mia Johnson (57004791400); López, Maximiliano Ariel (57004156900); Quercini, Gianluca (17435434700)",22333719100; 57004791400; 57004156900; 17435434700,A multilingual approach to discover cross-language links in wikipedia,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949963735&doi=10.1007%2f978-3-319-26190-4_36&partnerID=40&md5=c82c2a83d3eec7745f518d9a128b6b1e,"Wikipedia is a well-known public and collaborative encyclopaedia consisting of millions of articles. Initially in English, the popular website has grown to include versions in over 288 languages. These versions and their articles are interconnected via cross-language links, which not only facilitate navigation and understanding of concepts in multiple languages, but have been used in natural language processing applications, developments in linked open data, and expansion of minor Wikipedia language versions. These applications are the motivation for an automatic, robust, and accurate technique to identify cross-language links. In this paper, we present a multilingual approach called EurekaCL to automatically identify missing cross-language links in Wikipedia. More precisely, given a Wikipedia article (the source) EurekaCL uses the multilingual and semantic features of BabelNet 2.0 in order to efficiently identify a set of candidate articles in a target language that are likely to cover the same topic as the source. The Wikipedia graph structure is then exploited both to prune and to rank the candidates. Our evaluation carried out on 42,000 pairs of articles in eight language versions of Wikipedia shows that our candidate selection and pruning procedures allow an effective selection of candidates which significantly helps the determination of the correct article in the target language version. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
Tran P.N.; Nguyen D.T.,"Tran, Phong Nguyen (57195215573); Nguyen, Dang Tuan (56914958600)",57195215573; 56914958600,Mapping expansion of natural language entities to DBpedia's components for querying linked data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926200010&doi=10.1145%2f2701126.2701212&partnerID=40&md5=ee141ba8e35f1f40de6dd5df5c8c2faa,This paper introduces the MEQLD method (Mapping Expansion of Natural Language Entities to DBpedia's Components for Querying Linked Data) that we propose to perform a part of the Task 1 (Multilingual Question Answering) [15] of CLEF 2013 lab QALD-3 (Multilingual Question Answering over Linked Data) [14]. MEQLD investigates to improve the mapping extension of (lexical) entities of English questions into DBpedia's components for creating query in SPARQL Query Language [12]. This paper will focus on resolving the most difficult testing questions of QALD-3 [18] that all their submitted systems have no good evaluation.,Final,
Gracia J.; Vila-Suero D.; McCrae J.P.; Flati T.; Baron C.; Dojchinovski M.,"Gracia, Jorge (55392626700); Vila-Suero, Daniel (55532057700); McCrae, John P. (36666801700); Flati, Tiziano (55258481300); Baron, Ciro (57078048100); Dojchinovski, Milan (55453114000)",55392626700; 55532057700; 36666801700; 55258481300; 57078048100; 55453114000,Language resources and linked data: A practical perspective,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928557666&doi=10.1007%2f978-3-319-17966-7_1&partnerID=40&md5=090f916d8a33c0466d970b75c8caa41d,"Recently, experts and practitioners in language resources have started recognizing the benefits of the linked data (LD) paradigm for the representation and exploitation of linguistic data on the Web. The adoption of the LD principles is leading to an emerging ecosystem of multilingual open resources that conform to the Linguistic Linked Open Data Cloud, in which datasets of linguistic data are interconnected and represented following common vocabularies, which facilitates linguistic information discovery, integration and access. In order to contribute to this initiative, this paper summarizes several key aspects of the representation of linguistic information as linked data from a practical perspective. The main goal of this document is to provide the basic ideas and tools for migrating language resources (lexicons, corpora, etc.) as LD on the Web and to develop some useful NLP tasks with them (e.g., word sense disambiguation). Such material was the basis of a tutorial imparted at the EKAW’14 conference, which is also reported in the paper. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
Ustalov D.A.,"Ustalov, D.A. (55968856600)",55968856600,Russian thesauri as linked open data,,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952764996&partnerID=40&md5=96d23c7a151c13f0d982a031ae398084,"Open linguistic data is a good recently established trend allowing both researchers and developers in the field of natural language processing to create their own applications using high-quality dictionaries, thesauri, corpora, etc. At the same time, the published open data are stored in different formats making them difficult to be used in an efficient way without falling within vendor lock-in. This paper is devoted to the problem of representing popular lexical resources of the Russian language in the form of Linked Open Data. It summarizes the recent work in the field of thesauri representation formats and approaches to converting such formats to those of Linked Data. It also proposes an approach to converting popular Russian thesauri to the vocabularies that are the essential parts of the Linguistic Linked Open Data Cloud. The proposed approach has been implemented in open source software and the resulted dataset has been made publicly available on NLPub in the Turtle format under the terms of a Creative Commons license.",Final,
Ehrmann M.; Cecconi F.; Vannella D.; McCrae J.; Cimiano P.; Navigli R.,"Ehrmann, Maud (55237793100); Cecconi, Francesco (7005947086); Vannella, Daniele (56350024800); McCrae, John (36666801700); Cimiano, Philipp (15838793700); Navigli, Roberto (6507102454)",55237793100; 7005947086; 56350024800; 36666801700; 15838793700; 6507102454,Representing multilingual data as linked data: The case of BabelNet 2.0,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988951977&partnerID=40&md5=34d7ad7dfd105e42f06a0441c1f7051a,"Recent years have witnessed a surge in the amount of semantic information published on the Web. Indeed, the Web of Data, a subset of the Semantic Web, has been increasing steadily in both volume and variety, transforming the Web into a 'global database' in which resources are linked across sites. Linguistic fields - in a broad sense - have not been left behind, and we observe a similar trend with the growth of linguistic data collections on the so-called 'Linguistic Linked Open Data (LLOD) cloud'. While both Semantic Web and Natural Language Processing communities can obviously take advantage of this growing and distributed linguistic knowledge base, they are today faced with a new challenge, i.e., that of facilitating multilingual access to the Web of data. In this paper we present the publication of BabelNet 2.0, a wide-coverage multilingual encyclopedic dictionary and ontology, as Linked Data. The conversion made use of lemon, a lexicon model for ontologies particularly well-suited for this enterprise. The result is an interlinked multilingual (lexical) resource which can not only be accessed on the LOD, but also be used to enrich existing datasets with linguistic information, or to support the process of mapping datasets across languages.",Final,
Chiarcos C.; Sukhareva M.; Mittmann R.; Price T.; Chobotsky J.; Detmold G.,"Chiarcos, Christian (22333764800); Sukhareva, Maria (56644499500); Mittmann, Roland (57343539900); Price, Timothy (57343980300); Chobotsky, Jens (57344126900); Detmold, Gaye (57343112600)",22333764800; 56644499500; 57343539900; 57343980300; 57344126900; 57343112600,New technologies for old Germanic. Resources and research on parallel bibles in older continental western Germanic,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964029453&partnerID=40&md5=1b0b40cff472a8438b40b1e0b5bb83c7,"We provide an overview of on-going efforts to facilitate the study of older Germanic languages currently pursued at the Goethe-University Frankfurt, Germany. We describe created resources, such as a parallel corpus of Germanic Bibles and a morphosyntactically annotated corpus of Old High German (OHG) and Old Saxon, a lexicon of OHG in XML and a multilingual etymological database. We discuss NLP algorithms operating on this data, and their relevance for research in the Humanities. RDF and Linked Data represent new and promising aspects in our research, currently applied to establish cross-references between etymological dictionaries, infer new information from their symmetric closure and to formalize linguistic annotations in a corpus and grammatical categories in a lexicon in an interoperable way. © 2014 Association for Computational Linguistics.",Final,
Declerck T.,"Declerck, Thierry (22333556000)",22333556000,Harmonizing Lexical Data for their Linking to Knowledge Objects in the Linked Data Framework,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123847447&partnerID=40&md5=391046e533952cd6d855ec4aa1fa2120,"In this position paper we discuss some of the experiences we made in describing lexical data using representation formalisms that are compatible for the publication of such data in the Linked Data framework. While we see a huge potential in the emerging Linguistic Linked Open Data, also supporting the publication of less-resourced language data on the same platform as for mainstream languages, we are wondering if, parallel to the widening of linking language data to both other language data and encyclopaedic knowledge present in the Linked Data cloud, it would not be beneficial to give more focus more on harmonization and merging of RDF encoded lexical data, instead of establishing links between such resources in the Linked Data. © COLING 2014. All rights reserved.",Final,
Chen Y.; Skiena S.,"Chen, Yanqing (56350069900); Skiena, Steven (7003825841)",56350069900; 7003825841,Building sentiment lexicons for all major languages,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906927782&doi=10.3115%2fv1%2fp14-2063&partnerID=40&md5=21feca95c076bbfb9e61213e4383cbf7,"Sentiment analysis in a multilingual world remains a challenging problem, because developing language-specific sentiment lexicons is an extremely resourceintensive process. Such lexicons remain a scarce resource for most languages. In this paper, we address this lexicon gap by building high-quality sentiment lexicons for 136 major languages. We integrate a variety of linguistic resources to produce an immense knowledge graph. By appropriately propagating from seed words, we construct sentiment lexicons for each component language of our graph. Our lexicons have a polarity agreement of 95.7% with published lexicons, while achieving an overall coverage of 45.2%. We demonstrate the performance of our lexicons in an extrinsic analysis of 2,000 distinct historical figures' Wikipedia articles on 30 languages. Despite cultural difference and the intended neutrality of Wikipedia articles, our lexicons show an average sentiment correlation of 0.28 across all language pairs. © 2014 Association for Computational Linguistics.",Final,All Open Access; Bronze Open Access; Green Open Access
Dima C.,"Dima, Corina (35185949800)",35185949800,Answering natural language questions with Intui3,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981172784&partnerID=40&md5=6588b24ece46e909c89bbacbf6b7a499,"Intui3 is one of the participating systems at the fourth evaluation campaign on multilingual question answering over linked data, QALD4. The system accepts as input a question formulated in natural language (in English), and uses syntactic and semantic information to construct its interpretation with respect to a given database of RDF triples (in this case DBpedia 3.9). The interpretation is mapped to the corresponding SPARQL query, which is then run against a SPARQL endpoint to retrieve the answers to the initial question. Intui3 competed in the challenge called Task 1: Multilingual question answering over linked data, which offered 200 training questions and 50 test questions in 7 different languages. It obtained an F-measure of 0.24 by providing a correct answer to 10 of the test questions and a partial answer to 4 of them.",Final,
Kríž V.; Hladká B.; Nečaský M.; Knap T.,"Kríž, Vincent (55667832100); Hladká, Barbora (57193792766); Nečaský, Martin (24723160000); Knap, Tomáš (26664625500)",55667832100; 57193792766; 24723160000; 26664625500,Data extraction using NLP techniques and its transformation to linked data,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944543658&doi=10.1007%2f978-3-319-13647-9_13&partnerID=40&md5=e5639512518db37019fb671eb487f863,"We present a system that extracts a knowledge base from raw unstructured texts that is designed as a set of entities and their relations and represented in an ontological framework. The extraction pipeline processes input texts by linguistically-aware tools and extracts entities and relations from their syntactic representation. Consequently, the extracted data is represented according to the Linked Data principles. The system is designed both domain and language independent and provides users with data for more intelligent search than full-text search. We present our first case study on processing Czech legal texts. © Springer International Publishing Switzerland 2014.",Final,
Borin L.; Dannélls D.; Forsberg M.; McCrae J.P.,"Borin, Lars (22033397600); Dannélls, Dana (27567480800); Forsberg, Markus (55345935300); McCrae, John P. (36666801700)",22033397600; 27567480800; 55345935300; 36666801700,Representing Swedish lexical resources in RDF with lemon,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921893669&partnerID=40&md5=5561a53363080f9e2f6a3b75923329c3,"The paper presents an ongoing project which aims to publish Swedish lexical-semantic resources using Semantic Web and Linked Data technologies. In this article, we highlight the practical conversion methods and challenges of converting three of the Swedish language resources in RDF with lemon.",Final,
Narducci F.; Palmonari M.; Semeraro G.,"Narducci, Fedelucio (35107856400); Palmonari, Matteo (8835755600); Semeraro, Giovanni (57108777800)",35107856400; 8835755600; 57108777800,CroSeR: Cross-language semantic retrieval of open government data,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899928218&doi=10.1007%2f978-3-319-06028-6_98&partnerID=40&md5=4f1821db1a3c7a6fe02d240734e8ca19,"CroSer (Cross-language Semantic Retrieval) is an ir system able to discover links between e-gov services described in different languages. CroSeR supports public administrators to link their own source catalogs of e-gov services described in any language to a target catalog whose services are described in English and are available in the Linked Open Data (lod) cloud. Our system is based on a cross-language semantic matching method that i) translates service labels in English using a machine translation tool, ii) extracts a Wikipedia-based semantic representation from the translated service labels using Explicit Semantic Analysis (esa), iii) evaluates the similarity between two services using their Wikipedia-based representations. The user selects a service in a source catalog and exploits the ranked list of matches suggested by CroSeR to establish a relation (of type narrower, equivalent, or broader match) with other services in the English catalog. The method is independent from the language adopted in the source catalog and it does not assume the availability of information about the services other than very short text descriptions used as service labels. CroSeR is a web application accessible via http://siti-rack.siti.disco.unimib.it:8080/croser/. © 2014 Springer International Publishing Switzerland.",Final,
Huang H.-H.; Yu C.-S.; Chen H.-Y.; Chen H.-H.; Lee P.-C.; Chen C.-H.,"Huang, Hen-Hsen (56138799600); Yu, Chang-Sheng (56242045200); Chen, Huan-Yuan (56242847900); Chen, Hsin-Hsi (7501614471); Lee, Po-Ching (56241079100); Chen, Chun-Hsun (56241894900)",56138799600; 56242045200; 56242847900; 7501614471; 56241079100; 56241894900,Integrating linguistic and world knowledge for domain-adaptable natural language interfaces,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958524555&doi=10.1007%2f978-3-319-07983-7_33&partnerID=40&md5=a63bfc3e7b5f63e273fa104310821b3b,"Nowadays, natural language interfaces (NLIs) show strong demands on various smart devices from wearable devices, cell phones, televisions, to vehicles. Domain adaptation becomes one of the major challenging issues to support the applications on different domains. In this paper, we propose a framework of domain-adaptable NLIs to integrate linguistic knowledge and world knowledge. Given a knowledge base of a target domain and the function definition of a target smart device, the corresponding NLI system is developed under the framework. In the experiments, we demonstrate a Chinese NLI system for a video on demand (VOD) service. © Springer International Publishing Switzerland 2014.",Final,
Walter S.; Unger C.; Cimiano P.,"Walter, Sebastian (55452669100); Unger, Christina (42862497400); Cimiano, Philipp (15838793700)",55452669100; 42862497400; 15838793700,ATOLL - A framework for the automatic induction of ontology lexica,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915732154&doi=10.1016%2fj.datak.2014.09.003&partnerID=40&md5=2c0fe477f12c272f5d6455236f1ac341,"There is a range of large knowledge bases, such as Freebase and DBpedia, as well as linked data sets available on the web, but they typically lack lexical information stating how the properties and classes they comprise are realized lexically. Often only one label is attached, if at all, thus lacking rich linguistic information, e.g. about morphological forms, syntactic arguments or possible lexical variants and paraphrases. While ontology lexicon models like lemon allow for defining such linguistic information with respect to a given ontology, the cost involved in creating and maintaining such lexica is substantial, requiring a high manual effort. Towards lowering this effort we present ATOLL, a framework for the automatic induction of ontology lexica, based both on existing labels and on dependency paths extracted from a text corpus. We instantiate ATOLL with respect to DBpedia as dataset and Wikipedia as corresponding corpus, and evaluate it by comparing the automatically generated lexicon with a manually constructed one. Our results clearly corroborate that our approach shows a high potential to be applied in a semi-automatic fashion in which a lexicon engineer can validate, reject or refine the automatically generated lexical entries, thus having a clear potential to contributing to the reduction of the overall cost of creating ontology lexica. © 2014 Elsevier B.V. All rights reserved.",Final,All Open Access; Green Open Access
Di Buccio E.; Di Nunzio G.M.; Silvello G.,"Di Buccio, Emanuele (36019969000); Di Nunzio, Giorgio Maria (57210368958); Silvello, Gianmaria (23398794400)",36019969000; 57210368958; 23398794400,A linked open data approach for geolinguistics applications,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893913189&doi=10.1504%2fIJMSO.2014.059125&partnerID=40&md5=b6c25d8bb032118d163144e76c46502a,"Geolinguistic systems explore the relationship between language and cultural adaptation and change and they can be used as instructional tools, presenting complex data and relationships in a way accessible to all educational levels. However, the heterogeneity of geolinguistic projects has been recognised as a key problem limiting the reusability of linguistic tools and data collections. We propose an approach based on LOD, which moves the focus from the systems handling the data to the data themselves with the main goal of increasing the level of interoperability of geolinguistic applications and the reuse of the data. We defined an extensible ontology for geolinguistic resources based on the common ground defined by current European linguistic projects. We provide a Geolinguistic Linked Open Dataset based on the data case study of a linguistic project named ASIt. Finally, we show a geolinguistic application, which exploits this dataset for dynamically generating linguistic maps. Copyright © 2014 Inderscience Enterprises Ltd.",Final,
Zhang Y.; Mangeot M.; Bellynck V.; Boitet C.,"Zhang, Ying (57391892300); Mangeot, Mathieu (35146481700); Bellynck, Valérie (8539869300); Boitet, Christian (14044531300)",57391892300; 35146481700; 8539869300; 14044531300,Jibiki-LINKS: a Tool between Traditional Dictionaries and Lexical Networks for Modelling Lexical Resources,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122040960&partnerID=40&md5=b3db9332575ae130fd7b3f1a1af2855c,"Between simple electronic dictionaries such as the TLFi (computerized French Language Treasure)1 and lexical networks like WordNet2 (Diller et al., 1990; Vossen, 1998), the lexical databases are growing at high speed. Our work is about the addition of rich links to lexical databases, in the context of the parallel development of lexical networks. Current research on management tools for lexical databases is strongly influenced by the field of massive data (""big data"") and by the Web of data (""linked data""). In lexical networks, one can build and use arbitrary links, but possible queries cannot model all the usual interactions with lexicographers-developers and users, that are needed, and derive from the paper world. Our work aims to find a solution that allows for the main advantages of lexical networks, while providing the equivalent of paper dictionaries by doing the lexicographic work in lexical DBs. © 2014 Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, CogALex 2014 at the 25th International Conference on Computational Linguistics, COLING 2014. All rights reserved.",Final,
Declerck T.; Krieger H.-U.,"Declerck, Thierry (22333556000); Krieger, Hans-Ulrich (8955135000)",22333556000; 8955135000,Harmonization of German lexical resources for opinion mining,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037104633&partnerID=40&md5=abd2c1bb4f96fefe866d0c647843b35d,"We present on-going work on the harmonization of existing German lexical resources in the field of opinion and sentiment mining. The input of our harmonization effort consisted in four distinct lexicons of German word forms, encoded either as lemmas or as full forms, marked up with polarity features, at distinct granularity levels. We describe how the lexical resources have been mapped onto each other, generating a unique list of entries, with unified Part-of-Speech information and basic polarity features. Future work will be dedicated to the comparison of the harmonized lexicon with German corpora annotated with polarity information. We are further aiming at both linking the harmonized German lexical resources with similar resources in other languages and publishing the resulting set of lexical data in the context of the Linguistic Linked Open Data cloud.",Final,
Di Buono M.P.; Monteleone M.; Elia A.,"Di Buono, Maria Pia (55968435900); Monteleone, Mario (43661222900); Elia, Annibale (43660911700)",55968435900; 43661222900; 43660911700,Terminology and Knowledge Representation Italian Linguistic Resources for the Archaeological Domain,,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978822095&partnerID=40&md5=ef7bef62c8826d6dc79abd7bef319b80,"Knowledge representation is heavily based on using terminology, due to the fact that many terms have precise meanings in a specific domain but not in others. As a consequence, terms becomes unambiguous and clear, and at last, being useful for conceptualizations, are used as a starting point for formalizations. Starting from an analysis of problems in existing dictionaries, in this paper we present formalized Italian Linguistic Resources (LRs) for the Archaeological domain, in which we integrate/couple formal ontology classes and properties into/to electronic dictionary entries, using a standardized conceptual reference model. We also add Linguistic Linked Open Data (LLOD) references in order to guarantee the interoperability between linguistic and language resources, and therefore to represent knowledge. © COLING 2014. All rights reserved.",Final,
Walter S.; Unger C.; Cimiano P.,"Walter, Sebastian (55452669100); Unger, Christina (42862497400); Cimiano, Philipp (15838793700)",55452669100; 42862497400; 15838793700,A corpus-based approach for the induction of ontology lexica,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884933747&doi=10.1007%2f978-3-642-38824-8_9&partnerID=40&md5=6d5dbc4fbc39c798ec928d0de77de5d1,"While there are many large knowledge bases (e.g. Freebase, Yago, DBpedia) as well as linked data sets available on the web, they typically lack lexical information stating how the properties and classes are realized lexically. If at all, typically only one label is attached to these properties, thus lacking any deeper syntactic information, e.g. about syntactic arguments and how these map to the semantic arguments of the property as well as about possible lexical variants or paraphrases. While there are lexicon models such as lemon allowing to define a lexicon for a given ontology, the cost involved in creating and maintaining such lexica is substantial, requiring a high manual effort. Towards lowering this effort, in this paper we present a semi-automatic approach that exploits a corpus to find occurrences in which a given property is expressed, and generalizing over these occurrences by extracting dependency paths that can be used as a basis to create lemon lexicon entries. We evaluate the resulting automatically generated lexica with respect to DBpedia as dataset and Wikipedia as corresponding corpus, both in an automatic mode, by comparing to a manually created lexicon, and in a semi-automatic mode in which a lexicon engineer inspected the results of the corpus-based approach, adding them to the existing lexicon if appropriate. © 2013 Springer-Verlag Berlin Heidelberg.",Final,All Open Access; Green Open Access
Calì A.; Capuzzi S.; Dimartino M.M.; Frosini R.,"Calì, Andrea (57204263871); Capuzzi, Stefano (57193494527); Dimartino, Mirko Michele (56031178200); Frosini, Riccardo (55556910000)",57204263871; 57193494527; 56031178200; 55556910000,Recommendation of text tags in social applications using linked data,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893742773&doi=10.1007%2f978-3-319-04244-2_17&partnerID=40&md5=45ad37b0010cf876305de854d418aa6f,We present a recommender system that suggests geo-located text tags by using linguistic information extracted from Linked Data sets available on the Web. The recommender system performs tag matching by measuring the semantic similarity of natural language texts. Our approach evaluates similarity using a technique that compares sentences taking into account their grammatical structure. © Springer International Publishing 2013.,Final,All Open Access; Bronze Open Access
Narducci F.; Palmonari M.; Semeraro G.,"Narducci, Fedelucio (35107856400); Palmonari, Matteo (8835755600); Semeraro, Giovanni (57108777800)",35107856400; 8835755600; 57108777800,Cross-language semantic retrieval and linking of e-gov services,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891943734&doi=10.1007%2f978-3-642-41338-4_9&partnerID=40&md5=62d2a3605eddce6d96e8da09fd427fc9,"Public administrations are aware of the advantages of sharing Open Government Data in terms of transparency, development of improved services, collaboration between stakeholders, and spurring new economic activities. Initiatives for the publication and interlinking of government service catalogs as Linked Open Data (lod) support the interoperability among European administrations and improve the capability of foreign citizens to access services across Europe. However, linking service catalogs to reference lod catalogs requires a significant effort from local administrations, preventing the uptake of interoperable solutions at a large scale. The web application presented in this paper is named CroSeR (Cross-language Service Retriever) and supports public bodies in the process of linking their own service catalogs to the lod cloud. CroSeR supports different European languages and adopts a semantic representation of e-gov services based on Wikipedia. CroSeR tries to overcome problems related to the short textual descriptions associated to a service by embodying a semantic annotation algorithm that enriches service labels with emerging Wikipedia concepts related to the service. An experimental evaluation carried-out on e-gov service catalogs in five different languages shows the effectiveness of our model. © 2013 Springer-Verlag.",Final,All Open Access; Bronze Open Access; Green Open Access
O'Riain S.; Coughlan B.; Buitelaar P.; Declerk T.; Krieger U.; Marie-Thomas S.,"O'Riain, Seán (56878816000); Coughlan, Barry (56031948600); Buitelaar, Paul (14041096000); Declerk, Thierry (22333556000); Krieger, Uli (56032462200); Marie-Thomas, Susan (55456103600)",56878816000; 56031948600; 14041096000; 22333556000; 56032462200; 55456103600,Cross-lingual querying and comparison of linked financial and business data,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893767862&doi=10.1007%2f978-3-642-41242-4_32&partnerID=40&md5=5a2d88e4cf1487605ff1a9af578f3dd9,"Cross lingual querying of financial and business data from multi-lingual sources requires that inherent challenges posed by the diversity of financial concepts and languages used in different jurisdictions be addressed. Ontologies can be used to semantically align financial concepts and integrate financial facts with other company information from multilingual, semi-structured and unstructured Open Data sources. Availability as Linked Data then allows cross-lingual interrogation of the interlinked multi-lingual data set. This paper presents how the use of semantics and Linked Data enables the alignment and integration of business and financial facts provided by the different European Business Registers. The demonstrator allows business users to query multilingual data, perform comparisons, and review generated financial metrics. © Springer-Verlag 2013.",Final,All Open Access; Bronze Open Access
Shekarpour S.; Hoffner K.; Lehmann J.; Auer S.,"Shekarpour, Saeedeh (55298471100); Hoffner, Konrad (55453670900); Lehmann, Jens (35229806900); Auer, Soren (23391879500)",55298471100; 55453670900; 35229806900; 23391879500,Keyword query expansion on linked data using linguistic and semantic features,,1,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893945883&doi=10.1109%2fICSC.2013.41&partnerID=40&md5=94c1ad1d9cc5ca064669c3adc183737e,"Effective search in structured information based on textual user input is of high importance in thousands of applications. Query expansion methods augment the original query of a user with alternative query elements with similar meaning to increase the chance of retrieving appropriate resources. In this work, we introduce a number of new query expansion features based on semantic and linguistic inferencing over Linked Open Data. We evaluate the effectiveness of each feature individually as well as their combinations employing several machine learning approaches. The evaluation is carried out on a training dataset extracted from the QALD question answering benchmark. Furthermore, we propose an optimized linear combination of linguistic and lightweight semantic features in order to predict the usefulness of each expansion candidate. Our experimental study shows a considerable improvement in precision and recall over baseline approaches. © 2013 IEEE.",Final,All Open Access; Green Open Access
Schoene A.M.; Dethlefs N.; Ananiadou S.,"Schoene, Annika M. (57203546877); Dethlefs, Nina (36241145800); Ananiadou, Sophia (6602788919)",57203546877; 36241145800; 6602788919,RELATE: Generating a linguistically inspired Knowledge Graph for fine-grained emotion classification,1,Maria Angela PELLEGRINO,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143651259&partnerID=40&md5=6572091fcd5d64ecee27f933bf8ed3e5,"Several existing resources are available for sentiment analysis (SA) tasks that are used for learning sentiment specific embedding (SSE) representations. These resources are either large, common-sense knowledge graphs (KG) that cover a limited amount of polarities/emotions or they are smaller in size (e.g.: lexicons), which require costly human annotation and cover fine-grained emotions. Therefore using knowledge resources to learn SSE representations is either limited by the low coverage of polarities/emotions or the overall size of a resource. In this paper, we first introduce a new directed KG called 'RELATE', which is built to overcome both the issue of low coverage of emotions and the issue of scalability. RELATE is the first KG of its size to cover Ekman's six basic emotions that are directed towards entities. It is based on linguistic rules to incorporate the benefit of semantics without relying on costly human annotation. The performance of 'RELATE' is evaluated by learning SSE representations using a Graph Convolutional Neural Network (GCN). © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Ding X.; Zhang Y.; Liu T.; Duan J.,"Ding, Xiao (56375894000); Zhang, Yue (56066648800); Liu, Ting (57199476645); Duan, Junwen (56403918600)",56375894000; 56066648800; 57199476645; 56403918600,Knowledge-driven event embedding for stock prediction,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051146159&partnerID=40&md5=b392aa1f2bf3a29ea48ad7df6175ff10,"Representing structured events as vectors in continuous space offers a new way for defining dense features for natural language processing (NLP) applications. Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as event-driven stock prediction. On the other hand, events extracted from raw texts do not contain background knowledge on entities and relations that they are mentioned. To address this issue, this paper proposes to leverage extra information from knowledge graph, which provides ground truth such as attributes and properties of entities and encodes valuable relations between entities. Specifically, we propose a joint model to combine knowledge graph information into the objective function of an event embedding learning model. Experiments on event similarity and stock market prediction show that our model is more capable of obtaining better event embeddings and making more accurate prediction on stock market volatilities. © 1963-2018 ACL.",Final,
Ciroku F.; De Giorgis S.; Gangemi A.; Martinez-Pandiani D.S.; Presutti V.,"Ciroku, Fiorela (57871703700); De Giorgis, Stefano (57194034894); Gangemi, Aldo (55605133800); Martinez-Pandiani, Delfina S. (58027700800); Presutti, Valentina (55885160000)",57871703700; 57194034894; 55605133800; 58027700800; 55885160000,Automated multimodal sensemaking: Ontology-based integration of linguistic frames and visual data,1,,1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174832331&doi=10.1016%2fj.chb.2023.107997&partnerID=40&md5=aa66d8255e2636105d6d877f8ee1fcf1,"Frame evocation from visual data is an essential process for multimodal sensemaking, due to the multimodal abstraction provided by frame semantics. However, there is a scarcity of data-driven approaches and tools to automate it. We propose a novel approach for explainable automated multimodal sensemaking by linking linguistic frames to their physical visual occurrences, using ontology-based knowledge engineering techniques. We pair the evocation of linguistic frames from text to visual data as “framal visual manifestations”. We present a deep ontological analysis of the implicit data model of the Visual Genome image dataset, and its formalization in the novel Visual Sense Ontology (VSO). To enhance the multimodal data from this dataset, we introduce a framal knowledge expansion pipeline that extracts and connects linguistic frames – including values and emotions – to images, using multiple linguistic resources for disambiguation. It then introduces the Visual Sense Knowledge Graph (VSKG), a novel resource. VSKG is a queryable knowledge graph that enhances the accessibility and comprehensibility of Visual Genome's multimodal data, based on SPARQL queries. VSKG includes frame visual evocation data, enabling more advanced forms of explicit reasoning; analysis and sensemaking. Our work represents a significant advancement in the automation of frame evocation and multimodal sense-making, performed in a fully interpretable and transparent way, with potential applications in various fields, including the fields of knowledge representation, computer vision, and natural language processing. © 2023",Final,
Lewandowska-Tomaszczyk B.; Baczkowska A.; Dontcheva-Navrátilová O.; Liebeskind C.; Valūnaitė Oleškevičienė G.; Zitnik S.; Trojszczak M.; Povolná R.; Selmistraitis L.; Utka A.; Gudelis D.,"Lewandowska-Tomaszczyk, Barbara (6506927380); Baczkowska, Anna (57197523089); Dontcheva-Navrátilová, Olga (55745658100); Liebeskind, Chaya (55761687500); Valūnaitė Oleškevičienė, Giedrė (57194015310); Zitnik, Slavko (55386991900); Trojszczak, Marcin (57193529665); Povolná, Renata (55745348600); Selmistraitis, Linas (57209136234); Utka, Andrius (26632661300); Gudelis, Dangis (36625135100)",6506927380; 57197523089; 55745658100; 55761687500; 57194015310; 55386991900; 57193529665; 55745348600; 57209136234; 26632661300; 36625135100,LLOD schema for Simplified Offensive Language Taxonomy in multilingual detection and applications,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180448082&doi=10.1515%2flpp-2023-0016&partnerID=40&md5=2f971e23337d5b3cbf581098de640309,"The goal of the paper is to present a Simplified Offensive Language (SOL) Taxonomy, its application and testing in the Second Annotation Campaign conducted between March-May 2023 on four languages: English, Czech, Lithuanian, and Polish to be verified and located in LLOD. Making reference to the previous Offensive Language taxonomic models proposed mostly by the same COST Action Nexus Linguarum WG 4.1.1 team, the number and variety of the categories underwent the definitional revision, and the present typology was tested in the annotation on the publicly available offensive language datasets of each of the four languages. The results of the annotation are presented and as they are contained within the accepted statistical values on the inter-annotator agreement in the SOL categories and their aspects, we propose this taxonomy as a core ontology which represents the encoding of the supported offensive languages and justify its use on new data in terms of a more universal Linguistic Linked Open Data (LLOD) schema.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",Final,All Open Access; Bronze Open Access
Zhang S.; Gao Y.; Yang S.,"Zhang, Shijie (58153715600); Gao, Yongbin (56510441200); Yang, Shuqun (57214721720)",58153715600; 56510441200; 57214721720,Multilingual Knowledge Graph Completion Based on Structure Features of the Dual-Branch,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150708413&doi=10.1051%2fwujns%2f2023281045&partnerID=40&md5=0243693989e4259de111b7e1a109b8a7,"With the development of information fusion, knowledge graph completion tasks have received a lot of attention. some studies investigate the broader underlying problems of linguistics, while embedding learning has a narrow focus. This poses significant challenges due to the heterogeneity of coarse-graining patterns. Then, to settle the whole matter, a framework for completion is designed, named Triple Encoder-Scoring Module (TEsm). The model employs an alternating two-branch structure that fuses local features into the interaction pattern of the triplet itself by perfectly combining distance and structure models. Moreover, it is mapped to a uniform shared space. Upon completion, an ensemble inference method is proposed to query multiple predictions from different graphs using a weight classifier. Experiments show that the experimental dataset used for the completion task is DBpedia, which contains five different linguistic subsets.. Our extensive experimental results demonstrate that TEsm can efficiently and smoothly solve the optimal completion task, validating the performance of the proposed model. © 2023 Wuhan University.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Bellandi A.; Piccini S.,"Bellandi, Andrea (36023165400); Piccini, Silvia (57128335600)",36023165400; 57128335600,Creating specialised dictionaries using LexO,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178137448&doi=10.1515%2flex-2023-0012&partnerID=40&md5=00f7a48155843f344c3dba39b211f452,"Although the contribution of linguistics to terminology is widely recognized today, there remains a lack of tools allowing the construction of specialized dictionaries that deal with both the conceptual and the linguistic dimension of the terms. In this paper we present LexO, a collaborative web editor that was built with the aim of filling this gap. The guiding principles of LexO are the following: i) to allow terminologists to define the morphological, syntactic and semantic features of a term, w.r.t. the traditional onomasiological perspective; ii) to adhere to the open science philosophy and to the FAIR principles, so to create specialized dictionaries that can be shared and reused within the scientific community. © 2023 Walter de Gruyter GmbH, Berlin/Boston.",Final,
Costa R.; Salgado A.; Ramos M.; Almeida B.; Silva R.; Carvalho S.; Khan F.; Tasovac T.; Khemakhem M.; Romary L.,"Costa, Rute (55958196000); Salgado, Ana (57198203815); Ramos, Margarida (57453307500); Almeida, Bruno (57222163016); Silva, Raquel (57225746331); Carvalho, Sara (58064085700); Khan, Fahad (56643810600); Tasovac, Toma (57217845814); Khemakhem, Mohamed (57211914770); Romary, Laurent (22942401100)",55958196000; 57198203815; 57453307500; 57222163016; 57225746331; 58064085700; 56643810600; 57217845814; 57211914770; 22942401100,A crossroad between lexicography and terminology work: Knowledge organization and domain labelling,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163993265&doi=10.1093%2fllc%2ffqad022&partnerID=40&md5=cc9504aff414986d41021c39fa0ed7b7,"MORDigital project aims to encode the selected editions of Diccionario de Lingua Portugueza by António de Morais Silva, first published in 1789. Our ultimate goals are, on the one hand, to promote accessibility to cultural heritage while fostering reusability and, on the other hand, to contribute towards a more significant presence of lexicographic digital content in Portuguese through open tools and standards. The Morais dictionary represents a significant legacy, since it marks the beginning of Portuguese dictionaries, having served as a model for all subsequent lexicographic production. The team follows a new paradigm in lexicography, which results from the convergence between lexicography, terminology, computational linguistics, and ontologies as an integral part of digital humanities and linked (open) data. In the Portuguese context, this research fills a gap concerning searchable online retrodigitized dictionaries, built on current standards and methodologies which promote data sharing and harmonization, namely TEI Lex-0. The team will further ensure the connection to other existing systems and lexical resources, particularly in the Portuguese-speaking world.  © 2023 The Author(s).",Final,
Zhang H.; Jiang C.,"Zhang, Haiyang (14030743100); Jiang, Chao (57211626755)",14030743100; 57211626755,Verb-driven machine reading comprehension with dual-graph neural network,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177181063&doi=10.1016%2fj.patrec.2023.11.008&partnerID=40&md5=5c86f6f33010e859a8a8bc157d66fe9d,"Logical reasoning of context is vital for reading comprehension, which requires to explore the logical relationship through sentence structure. However, previous methods of logical symbols and graph-based models do not make full explore the relationships among entities. In this paper, we present a verb-driven dual-graph network (VDGN) that utilizes core verbs of sentences to model the inter-sentence relationship by the ability of verbs to express linguistic context and the shortest dependency path to model the relationship between entities of intra-sentence. We construct a context graph and a query graph respectively through the above method. In order to predict the answer correctly, our framework fuses information from the context graph and the query graph applying a bi-directional attention mechanism on graph data. We evaluate our approach on two public logical reasoning machine reading comprehension(MRC) datasets: ReClor and LogiQA. Experiments on representative benchmark datasets demonstrate the effectiveness of our approach. © 2023 Elsevier B.V.",Final,
Valūnaitė-Oleškevičienė G.; Selmistraitis L.; Utka A.; Gudelis D.,"Valūnaitė-Oleškevičienė, Giedrė (57194015310); Selmistraitis, Linas (57209136234); Utka, Andrius (26632661300); Gudelis, Dangis (36625135100)",57194015310; 57209136234; 26632661300; 36625135100,Offensive language in user-generated comments in Lithuanian,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180496544&doi=10.1515%2flpp-2023-0013&partnerID=40&md5=554a84b8d150bb2c5a8e633d1c765d97,"The aim of the current research is to investigate the feasibility of identifying offensive language in Lithuanian by utilising the Simplified Offensive Language Taxonomy (SOLT). The key principle behind this taxonomy is its ability to complement existing offensive language ontologies and tagset systems, with the ultimate goal of integrating it into publicly accessible Linguistic Linked Open Data (LLOD) resources. The dataset used in the current study is a publicly available corpus of user-generated comments collected from a Lithuanian portal (Amilevičius et al. 2016). The study identified that offensive language predominantly focuses on collective derogatory language rather than individuals. The most common category of offensive language is related to physical and mental disabilities, followed by ideological offenses, xenophobic and sexist remarks, and less frequent categories like ageism, classism, homophobia, and religious discrimination. These results highlight the diverse range of offensive language online and underscore the need to combat discrimination and promote respectful discourse, particularly concerning marginalised groups.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",Final,
Aranovich R.,"Aranovich, Raúl (22984050100)",22984050100,Modeling Grammars with Knowledge Representation Methods: Subcategorization as a Test Case,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175976004&doi=10.1007%2f978-3-031-43458-7_21&partnerID=40&md5=1e0d292b9e033ed32009481d911107dc,"An OWL ontology is used to model a grammar that accounts for subcategorization, showing that ontologies are able to generate (mildly) context-sensitive languages. Semantic Web knowledge representation methods offer a useful way to model the implicit knowledge that defines human linguistic abilities. When a grammar is modeled as a set of ontological constraints (i.e. classes with restrictions on their properties), ungrammatical sentences are defined as facts that lead to inconsistencies which can be discovered by a reasoner. Property chains are used to “pass on” the category of a syntactic complement as the value of a head’s subcategorization feature, modeling the concept of structure sharing that is central to constraint-based theories of syntax like HPSG. By treating utterances as instances and syntactic constraints as axioms, this approach offers points of contact with efforts to model grammars as Linguistic Linked Open Data in the Semantic Web. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
Wu Y.; Wu X.; Li J.; Zhang Y.; Wang H.; Du W.; He Z.; Liu J.; Ruan T.,"Wu, Yinan (58741068500); Wu, Xiaowei (57769794900); Li, Junwen (58704352500); Zhang, Yue (58610776300); Wang, Haofen (23399118800); Du, Wen (57208669801); He, Zhidong (58704504700); Liu, Jingping (57208656857); Ruan, Tong (35240657900)",58741068500; 57769794900; 58704352500; 58610776300; 23399118800; 57208669801; 58704504700; 57208656857; 35240657900,MMpedia: A Large-Scale Multi-modal Knowledge Graph,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177439074&doi=10.1007%2f978-3-031-47243-5_2&partnerID=40&md5=d97d33de6b765a990acb315b64c495f3,"Knowledge graphs serve as crucial resources for various applications. However, most existing knowledge graphs present symbolic knowledge in the form of natural language, lacking other modal information, e.g., images. Previous multi-modal knowledge graphs have encountered challenges with scaling and image quality. Therefore, this paper proposes a highly-scalable and high-quality multi-modal knowledge graph using a novel pipeline method. Summarily, we first retrieve images from a search engine and build a new Recurrent Gate Multi-modal model to filter out the non-visual entities. Then, we utilize entities’ textual and type information to remove noisy images of the remaining entities. Through this method, we construct a large-scale multi-modal knowledge graph named MMpedia, containing 2,661,941 entity nodes and 19,489,074 images. As we know, MMpedia has the largest collection of images among existing multi-modal knowledge graphs. Furthermore, we employ human evaluation and downstream tasks to verify the usefulness of images in MMpedia. The experimental result shows that both the state-of-the-art method and multi-modal large language model (e.g., VisualChatGPT) achieve about a 4% improvement on Hit@1 in the entity prediction task by incorporating our collected images. We also find that the multi-modal large language model is hard to ground entities to images. The dataset (https://zenodo.org/record/7816711 ) and source code of this paper are available at https://github.com/Delicate2000/MMpedia. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Final,
Gatiatullin A.; Kubedinova L.; Prokopyev N.; Suleymanov D.,"Gatiatullin, Ayrat (56500678000); Kubedinova, Lenara (57200283057); Prokopyev, Nikolai (57206891311); Suleymanov, Dzavdet (55874224600)",56500678000; 57200283057; 57206891311; 55874224600,Linguistic Knowledge Graphs of the 'Turkic Morpheme' Portal,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177550341&doi=10.1109%2fUBMK59864.2023.10286723&partnerID=40&md5=5e7cf92cafa6ddd41f0a97562b21eb76,"This paper presents a description of linguistic knowledge graphs, which form the basis of knowledge base of the portal 'Turkic morpheme'. Peculiarity of these knowledge graphs is that ontological models that form the basis are developed using pragmatically oriented approach to linguistic models' development and are focused on the most complete description of structural and functional features of the Turkic languages. These knowledge graphs are a useful resource, both for creating information and reference systems for Turkic languages, and application programs for computer processing. © 2023 IEEE.",Final,
Mambrini F.; Passarotti M.C.,"Mambrini, Francesco (57190293497); Passarotti, Marco Carlo (56957111300)",57190293497; 56957111300,The LiLa Lemma Bank: A Knowledge Base of Latin Canonical Forms,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179106255&doi=10.5334%2fjohd.145&partnerID=40&md5=c7bca225d7d3e40141a1883995b62a53,"The dataset contains a list of 215,102 Latin dictionary forms (known as canonical forms or lemmas). The dataset is a set of 1,699,687 Resource Description Framework (RDF) triples that describe, using a series of Web Ontology Language (OWL) ontologies for Linguistic Linked Data, the morphological properties of these forms. The dataset is used to link together a series of corpora and dictionaries in the interoperable network of language resources published by the LiLa: Linking Latin project. © 2023 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.",Final,All Open Access; Gold Open Access
Zhang Z.; Yuan P.; Jin H.,"Zhang, Zhaobo (57228034800); Yuan, Pingpeng (12762118900); Jin, Hai (56434989100)",57228034800; 12762118900; 56434989100,Exploring Word-Sememe Graph-Centric Chinese Antonym Detection,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174442827&doi=10.1007%2f978-3-031-43418-1_35&partnerID=40&md5=e3895e1353ef188f5be4ea162c5ca49e,"Antonym detection is a vital task in NLP systems. Pattern-based methods, typical solutions for this, recognize semantic relationships between words using given patterns but have limited performance. Distributed word embeddings often struggle to distinguish antonyms from synonyms because their representations rely on local co-occurrences in similar contexts. Combining the ambiguity of Chinese and the contradictory nature of antonyms, antonym detection faces unique challenges. In this paper, we propose a word-sememe graph to integrate relationships between sememes and Chinese words, organized as a 4-partite graph. We design a heuristic sememe relevance computation as a supplementary measure and develop a relation inference scheme using related sememes as taxonomic information to leverage the relational transitivity. The 4-partite graph can be extended based on this scheme. We introduce the R elation D iscriminated L earning based on S ememe A ttention (RDLSA) model, employing three attention strategies on sememes to learn flexible entity representations. Antonym relations are detected using a Link Prediction approach with these embeddings. Our method demonstrates superior performance in Triple Classification and Chinese Antonym Detection compared to the baselines. Experimental results show reduced ambiguity and improved antonym detection using linguistic sememes. A quantitative ablation analysis further confirms our scheme’s effectiveness in capturing antonyms. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Iurescia F.; Litta E.; Passarotti M.; Pellegrini M.; Moretti G.; Ruffolo P.,"Iurescia, Federica (57212510921); Litta, Eleonora (57192942633); Passarotti, Marco (56957111300); Pellegrini, Matteo (57220703991); Moretti, Giovanni (57190677309); Ruffolo, Paolo (57195437110)",57212510921; 57192942633; 56957111300; 57220703991; 57190677309; 57195437110,Linking the Neulateinische Wortliste to the LiLa Knowledge Base of Interoperable Resources for Latin,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175477239&partnerID=40&md5=68f42614eab37b7bd59f7101634a6985,"This paper describes the process of interlinking a lexical resource consisting of a list of more than 20,000 Neo-Latin words with other resources for Latin. The resources are made interoperable thanks to their linking to the LiLa Knowledge Base, which applies Linguistic Linked Open Data practices and data categories to describe and publish on the Web both textual and lexical resources for the Latin language. © 2023 Association for Computational Linguistics.",Final,
Faulhaber C.B.; Rodríguez Ó.P.,"Faulhaber, Charles B. (8082307500); Rodríguez, Óscar Perea (57207796944)",8082307500; 57207796944,PHILOBIBLON AS A DIGITAL TOOL FOR HISTORIANS OF MEDIEVAL IBERIA,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172665109&doi=10.21001%2fitma.2023.16.15&partnerID=40&md5=7c0c4d10eed7b65ccf47e98c535a97d7,"This article provides a succinct review of the history and technological development of PhiloBiblon, one of the pioneer Digital Humanities projects for the study of the primary sources of the medieval and early modern literatures of the Iberian Peninsula. The warp and weft of its history are the four bibliographies that comprise it: BETA (Bibliografía Española de Textos Antiguos), BITECA (Bibliografia de Textos Antics Catalans, Valencians i Balears), BITAGAP (Bibliografia de Textos Antigos Galegos e Portugueses), and BIPA (Bibliografía de la Poesía Áurea). We describe how the program functions on the web, paying particular attention to the use of PhiloBiblon's key identifiers. Then we explain the proposed evolution of the project from siloed databases to Linked Open Data via FactGrid, a Database for Historians. Precisely because of this pending change, we wish to show medievalists other than literary and linguistic specialists, especially historians, how to make good use of PhiloBiblon. © 2023 Consolidated Medieval Studies Research Group. All rights reserved.",Final,All Open Access; Green Open Access
Declerck T.; Bajčetić L.; Sérasset G.,"Declerck, Thierry (22333556000); Bajčetić, Lenka (57203989889); Sérasset, Gilles (8897914400)",22333556000; 57203989889; 8897914400,Adding Information to Multiword Terms in Wiktionary,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171336522&partnerID=40&md5=65b77c44f06749bd27262b5f9bd5eec9,"We describe ongoing work dealing with the potential “auto-enrichment” of “Multiword terms” (MWTs) that are included in the English edition of Wiktionary. The idea is to use and combine information contained in the lexical components of the MWTs and to propagate this extracted and filtered information into the lexical description of the MWTs, as those are typically equipped with less lexical information as it is the case for their lexical components. We started our work with the generation of pronunciation information for such MWTs, on the base of the pronunciation information available for their components. We present in this paper first achievements but also issues we encountered. Addressing those issues lead us to consider additional resources for supporting our approach, like DBnary and WikiPron. This step was ultimately leading to suggestions of adaptations for those additional resources, which, in the case of DBnary, are already implemented. We are currently extending our approach to a morphosyntactic and semantic enrichment of the English MWTs in Wiktionary. © 2023 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Huaman E.; Huaman J.L.; Huaman W.,"Huaman, Elwin (57219734797); Huaman, Jorge Luis (57873514400); Huaman, Wendi (57873514500)",57219734797; 57873514400; 57873514500,Getting Quechua Closer to Final Users Through Knowledge Graphs,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164270030&doi=10.1007%2f978-3-031-35445-8_5&partnerID=40&md5=4e17f9c08ab107992111f7a599bbcff2,"Quechua language and Quechua knowledge gather millions of people around the world, especially in several countries in South America. Unfortunately, there are only a few resources available to Quechua communities, and they are mainly stored in unstructured format. In this paper, the Quechua Knowledge Graph is envisioned and generated as an effort to get Quechua language and knowledge closer to the Quechua communities, researchers, and technology developers. The process model for building the Quechua Knowledge Graph involved its creation, hosting, curation, and deployment phases. Currently, there are 553,636 triples stored in the Quechua Knowledge Graph, which is accessible on the Web, retrievable by machines, and curated by users. To showcase the deployment of the Quechua Knowledge Graph, use cases and future work are described. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Tittel S.,"Tittel, Sabine (36165030000)",36165030000,Ceci n’est pas un dictionnaire. Adding and Extending Lexicographical Data of Medieval Romance Languages to and through a Multilingual Lexico-Ontological Project,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171336702&partnerID=40&md5=8f67bb4534bf2f7dd8fc87f8fc942f23,"Historical lexicography of the Romance languages currently finds itself in a difficult place since the funding of some important dictionaries ended. The newly launched project ALMA will contribute to the future of these dictionaries’ content. ALMA combines methods of historical lexicography, text philology, corpus linguistics, and the history of sciences with a Linked Data approach and ontology development. It adopts a Pan-Romance perspective focusing on medieval Italian, French, and Occitan / Gascon within two knowledge domains, ‘medicine’ and ‘law’. ALMA’s goals include re-using, extending, further processing, and disseminating lexicographical data by integrating it into its work pipeline. This makes for benefits on both sides: Pivotal for the ALMA project is the anchoring of its philological and lexicological work within the framework of the entire languages examined by the dictionaries. The dictionaries, most notably those whose funding ended, profit by seeing their linguistic, textual, and historico-cultural knowledge put into new formats—e.g., Linked Data—, contexts—e.g., Pan-Romance—, and correlations—e.g., through linking to the historicized domain ontologies ALMA will develop. This introduces the valuable dictionary contents to a knowledge circulation that goes beyond their original scope and ensures its long-term re-use in a somewhat concealed way. © 2023 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Asprino L.; Presutti V.,"Asprino, Luigi (57191745706); Presutti, Valentina (55885160000)",57191745706; 55885160000,Observing LOD: Its Knowledge Domains and the Varying Behavior of Ontologies Across Them,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149402038&doi=10.1109%2fACCESS.2023.3250105&partnerID=40&md5=67157753284e85cc6828165806c03600,"Linked Open Data (LOD) is the largest, collaborative, distributed, and publicly-accessible Knowledge Graph (KG) uniformly encoded in the Resource Description Framework (RDF) and formally represented according to the semantics of the Web Ontology Language (OWL). LOD provides researchers with a unique opportunity to study knowledge engineering as an empirical science: to observe existing modelling practices and possibly understanding how to improve knowledge engineering methodologies and knowledge representation formalisms. Following this perspective, several studies have analysed LOD to identify (mis-)use of OWL constructs or other modelling phenomena e.g. class or property usage, their alignment, the average depth of taxonomies. A question that remains open is whether there is a relation between observed modelling practices and knowledge domains (natural science, linguistics, etc.): do certain practices or phenomena change as the knowledge domain varies? Answering this question requires an assessment of the domains covered by LOD as well as a classification of its datasets. Existing approaches to classify LOD datasets provide partial and unaligned views, posing additional challenges. In this paper, we introduce a classification of knowledge domains, and a method for classifying LOD datasets and ontologies based on it. We classify a large portion of LOD and investigate whether a set of observed phenomena have a domain-specific character. © 2013 IEEE.",Final,All Open Access; Gold Open Access; Green Open Access
Jia Z.,"Jia, Zhibai (58502793500)",58502793500,Multi-Dialectal Representation Learning of Sinitic Phonology,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173499956&partnerID=40&md5=be64a07e43f9a2d7c48b238346d6db2f,"Machine learning techniques have shown their competence for representing and reasoning in symbolic systems such as language and phonology. In Sinitic Historical Phonology, notable tasks that could benefit from machine learning include the comparison of dialects and reconstruction of proto-languages systems. Motivated by this, this paper provides an approach for obtaining multi-dialectal representations of Sinitic syllables, by constructing a knowledge graph from structured phonological data, then applying the BoxE technique from knowledge base learning. We applied unsupervised clustering techniques to the obtained representations to observe that the representations capture phonemic contrast from the input dialects. Furthermore, we trained classifiers to perform inference of unobserved Middle Chinese labels, showing the representations' potential for indicating archaic, proto-language features. The representations can be used for performing completion of fragmented Sinitic phonological knowledge bases, estimating divergences between different characters, or aiding the exploration and reconstruction of archaic features. © 2023 Association for Computational Linguistics.",Final,
Lymperaiou M.; Stamou G.,"Lymperaiou, Maria (57900314700); Stamou, Giorgos (7004137698)",57900314700; 7004137698,The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166465476&partnerID=40&md5=8fb195719401d3640ea348259374011d,"Recent advancements in visiolinguistic (VL) learning have allowed the development of multiple models and techniques that offer several impressive implementations, able to currently resolve a variety of tasks that require the collaboration of vision and language. Current datasets used for VL pre-training only contain a limited amount of visual and linguistic knowledge, thus significantly limiting the generalization capabilities of many VL models. External knowledge sources such as knowledge graphs (KGs) and Large Language Models (LLMs) are able to cover such generalization gaps by filling in missing knowledge, resulting in the emergence of hybrid architectures. In the current survey, we analyze tasks that have benefited from such hybrid approaches. Moreover, we categorize existing knowledge sources and types, proceeding to discussion regarding the KG vs LLM dilemma and its potential impact to future hybrid approaches.  © 2023 Copyright for this paper by its authors.",Final,
Vasilevich A.; Wetzel M.,"Vasilevich, Alena (57224534828); Wetzel, Michael (57214890582)",57224534828; 57214890582,Multilingual Knowledge Systems as Linguistic Linked Open Data,1,,1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141866894&doi=10.1007%2f978-3-031-17258-8_23&partnerID=40&md5=c5ad1b639c47006e962ade964c538329,"Creation and re-usability of language resources in accordance with Linked Data principles is a valuable asset in the modern data world. We describe the contributions made to extend the Linguistic Linked Open Data (LLOD) stack with a new resource, Coreon MKS, bringing together concept-oriented, language-agnostic terminology management and graph-based knowledge organisation. We dwell on our approach to mirroring of Coreon’s original data structure to RDF and supplying it with a SPARQL endpoint. We integrate MKS into the existing ELG infrastructure, using it as a platform for making the published MKS discoverable and retrievable via a industry-standard interface. While we apply this approach to LLOD-ify Coreon MKS, it can also provide relevant input for standardisation bodies and interoperability communities, acting as a blueprint for similar integration activities. © 2023, The Author(s).",Final,All Open Access; Hybrid Gold Open Access
Liu W.; Tuo J.; Xue J.,"Liu, Weihang (57742372400); Tuo, Jiawei (57742862300); Xue, Jianwu (36603606000)",57742372400; 57742862300; 36603606000,A Study on the Connotation Remodeling of Science and Technology Vocabulary Based on the Application of Knowledge Graphs,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132024163&doi=10.1088%2f1742-6596%2f2278%2f1%2f012015&partnerID=40&md5=07779c19cb45e5ed16f352dff78ac2fa,"Disruptive Technology is also often translated as disruptive technology or breakthrough technology, which was first proposed by Professor Christensen of Harvard Business School in 1990s. Nowadays, the competition among countries is increasingly fierce, especially in the field of science and technology, which often leads to the backwardness and impoverishment of the whole industry due to the technological gap. Today, with the rapid consumption of social resources, social and economic development urgently needs disruptive technologies to promote industrial transformation, optimize economic structure and improve people's quality of life. Countries that master disruptive technologies can open up new industrial development paths and lay a foundation for unique technological advantages, thus bringing huge technological dividends to national economic development. Visuwords is a knowledge graph application platform, through which the meaning and semantic association of words can be visualized. This study takes the word ""famished""as an example to analyze the relationship between its new connotation and original meaning to verify its feasibility at the communication level. Today's social science knowledge in the general public needs to be disseminated from the original relatively obscure and academic to an easily acceptable form. This study applies the idea of scientific popularization to a knowledge graph visualization tool, while using the connotation of linguistic ideas to analyze and deconstruct specific wordsThe study combines the connotation concept of linguistics with the disciplinary tools in the field of knowledge graph, and specifically analyzes the role of scientific terms, especially some abbreviations, in the mass science communication.  © Published under licence by IOP Publishing Ltd.",Final,All Open Access; Bronze Open Access
Giovannetti E.; Albanesi D.; Bellandi A.; Dattilo D.; Del Grosso A.M.; Marchi S.,"Giovannetti, Emiliano (55604835100); Albanesi, Davide (57195557333); Bellandi, Andrea (36023165400); Dattilo, David (57198886665); Del Grosso, Angelo Mario (56319538600); Marchi, Simone (27567818000)",55604835100; 57195557333; 36023165400; 57198886665; 56319538600; 27567818000,An ontology of masters of the Babylonian Talmud,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141278876&doi=10.1093%2fllc%2ffqab043&partnerID=40&md5=24971102523111e6ca94b38cde2f25ec,"The purpose of this research is to build an ontology of the masters appearing in the Babylonian Talmud (BT). The ontology built so far has been shared as a Linked Open Data and it will be linked to existing vocabularies. This work has been developed in the context of the Babylonian Talmud Translation Project, where more than eighty Talmudists are working together, since 2012, at the translation (comprehensive of explicative notes and glossaries) of the Talmud into Italian. The construction of the resource has involved the application of tools leveraging on computational linguistics approaches. The ontology, already describing more than 500 masters, constitutes the first portion of a more comprehensive Talmudic Knowledge Base where the text itself, the terminology, the entities, and the concepts constituting the BT will be formalized and linked to each other.  © 2022 The Author(s) 2021. Published by Oxford University Press on behalf of EADH. All rights reserved.",Final,
Harrando I.; Troncy R.,"Harrando, Ismail (57219181682); Troncy, Raphael (23986650400)",57219181682; 23986650400,Combining semantic and linguistic representations for media recommendation,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134315539&doi=10.1007%2fs00530-022-00968-w&partnerID=40&md5=019ec48399117519fc140f2a5a02b8b8,"Content-based recommendation systems offer the possibility of promoting media (e.g., posts, videos, podcasts) to users based solely on a representation of the content (i.e., without using any user-related data such as views or interactions between users and items). In this work, we study the potential of using different textual representations (based on the content of the media) and semantic representations (created from a knowledge graph of media metadata). We also show that using off-the-shelf automatic annotation tools from the Information Extraction literature, we can improve recommendation performance, without any extra cost of training, data collection or annotation. We first evaluate multiple textual content representations on two tasks of recommendation: user-specific, which is performed by suggesting new items to the user given a history of interactions, and item-based, which is based solely on content relatedness, and is rarely investigated in the literature of recommender systems. We compare how using automatically extracted content (via ASR) compares to using human-written summaries. We then derive a semantic content representation by combining manually created metadata and automatically extracted annotations and we show that Knowledge Graphs, through their embeddings, constitute a great modality to seamlessly integrate extracted knowledge to legacy metadata and can be used to provide good content recommendations. We finally study how combining both semantic and textual representations can lead to superior performance on both recommendation tasks. Our code is available at https://github.com/D2KLab/ka-recsys to support experiment reproducibility. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Final,All Open Access; Green Open Access
Armaselu F.; Apostol E.-S.; Khan A.F.; Liebeskind C.; Mcgillivray B.; Truicǎ C.-O.; Utka A.; Oleškevičiene G.V.; Van Erp M.,"Armaselu, Florentina (57191504666); Apostol, Elena-Simona (55365937600); Khan, Anas Fahad (57205198244); Liebeskind, Chaya (55761687500); Mcgillivray, Barbara (14325441100); Truicǎ, Ciprian-Octavian (56331462000); Utka, Andrius (26632661300); Oleškevičiene, Giedre Valunaite (57194015310); Van Erp, Marieke (56458465100)",57191504666; 55365937600; 57205198244; 55761687500; 14325441100; 56331462000; 26632661300; 57194015310; 56458465100,LL(O)D and NLP perspectives on semantic change for humanities research,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136245558&doi=10.3233%2fSW-222848&partnerID=40&md5=415e770a0e93459f7177187911a839f3,"This paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with its main application in humanities research. The paper's aim is to provide the starting point for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action Nexus Linguarum, European network for Web-centred linguistic data science, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
Martín-Chozas P.; Vázquez-Flores K.; Calleja P.; Montiel-Ponsoda E.; Rodríguez-Doncel V.,"Martín-Chozas, Patricia (57210581382); Vázquez-Flores, Karen (57946168600); Calleja, Pablo (57200278655); Montiel-Ponsoda, Elena (25654093800); Rodríguez-Doncel, Víctor (35204031900)",57210581382; 57946168600; 57200278655; 25654093800; 35204031900,TermitUp: Generation and enrichment of linked terminologies,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140849135&doi=10.3233%2fSW-222885&partnerID=40&md5=508d8e226d64fbe8278dee83c0ce83bb,"Domain-specific terminologies play a central role in many language technology solutions. Substantial manual effort is still involved in the creation of such resources, and many of them are published in proprietary formats that cannot be easily reused in other applications. Automatic term extraction tools help alleviate this cumbersome task. However, their results are usually in the form of plain lists of terms or as unstructured data with limited linguistic information. Initiatives such as the Linguistic Linked Open Data cloud (LLOD) foster the publication of language resources in open structured formats, specifically RDF, and their linking to other resources on the Web of Data. In order to leverage the wealth of linguistic data in the LLOD and speed up the creation of linked terminological resources, we propose TermitUp, a service that generates enriched domain specific terminologies directly from corpora, and publishes them in open and structured formats. TermitUp is composed of five modules performing terminology extraction, terminology post-processing, terminology enrichment, term relation validation and RDF publication. As part of the pipeline implemented by this service, existing resources in the LLOD are linked with the resulting terminologies, contributing in this way to the population of the LLOD cloud. TermitUp has been used in the framework of European projects tackling different fields, such as the legal domain, with promising results. Different alternatives on how to model enriched terminologies are considered and good practices illustrated with examples are proposed.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access
Zhu Y.; Hu L.; Ning N.; Zhang W.; Wu B.,"Zhu, Yangfu (57716193300); Hu, Linmei (56181376700); Ning, Nianwen (57203246323); Zhang, Wei (57775503700); Wu, Bin (56449782000)",57716193300; 56181376700; 57203246323; 57775503700; 56449782000,A lexical psycholinguistic knowledge-guided graph neural network for interpretable personality detection,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130979428&doi=10.1016%2fj.knosys.2022.108952&partnerID=40&md5=7f0c12a4f159aa56486489a050c7c5cf,"With the blossoming of online social media, personality detection based on user-generated content has a significant impact on information scientific and industrial applications. Most existing approaches rely heavily on semantic features or superficial psycholinguistic statistical features calculated by existing tools and fail to effectively exploit psycholinguistic knowledge that can help determine and interpret peoples personality traits. In this paper, we propose a novel lexical psycholinguistic knowledge-guided graph neural model for interpretable personality detection, which leverages the personality lexicons as a bridge for injecting relevant external knowledge to enrich the semantics of a document. Specifically, we learn a kind of personality-aware word embedding, that encodes psycholinguistic information in the continuous representations of words. Then, a Heterogeneous Personality word graph is constructed by aligning the personality lexicons with the personality knowledge graph, which is fed into a Message-passing graph Network (HPMN) to extract explicit lexicon and knowledge relations through the interactions among heterogeneous graph nodes. Finally, through a carefully designed readout function, all heterogeneous nodes are selectively incorporated as knowledge-guided document embeddings for user-generated text personality understanding and interpretation. Experiments show that our model effectively detects personality traits. Moreover, it provides a certain level of support for lexical hypotheses in psycholinguistic research from a computational linguistics perspective. © 2022",Final,
Zhang F.; Zhang Z.; Ao X.; Gao D.; Zhuang F.; Wei Y.; He Q.,"Zhang, Fuwei (57394025800); Zhang, Zhao (57202848584); Ao, Xiang (57197191379); Gao, Dehong (48761170500); Zhuang, Fuzhen (23391452500); Wei, Yi (57215052564); He, Qing (26643590900)",57394025800; 57202848584; 57197191379; 48761170500; 23391452500; 57215052564; 26643590900,Mind the Gap: Cross-Lingual Information Retrieval with Hierarchical Knowledge Enhancement,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140824664&partnerID=40&md5=4f9beece0f00a07c1ac016c832300531,"Cross-Lingual Information Retrieval (CLIR) aims to rank the documents written in a language different from the user's query. The intrinsic gap between different languages is an essential challenge for CLIR. In this paper, we introduce the multilingual knowledge graph (KG) to the CLIR task due to the sufficient information of entities in multiple languages. It is regarded as a “silver bullet” to simultaneously perform explicit alignment between queries and documents and also broaden the representations of queries. And we propose a model named CLIR with hierarchical knowledge enhancement (HIKE) for our task. The proposed model encodes the textual information in queries, documents and the KG with multilingual BERT, and incorporates the KG information in the query-document matching process with a hierarchical information fusion mechanism. Particularly, HIKE first integrates the entities and their neighborhood in KG into query representations with a knowledge-level fusion, then combines the knowledge from both source and target languages to further mitigate the linguistic gap with a language-level fusion. Finally, experimental results demonstrate that HIKE achieves substantial improvements over state-of-the-art competitors. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Forkel R.; Hammarström H.,"Forkel, Robert (57195331057); Hammarström, Harald (15074045500)",57195331057; 15074045500,"Glottocodes: Identifiers linking families, languages and dialects to comprehensive reference information",1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140853767&doi=10.3233%2fSW-212843&partnerID=40&md5=558639b9e88deeea1855087cfe435372,"Glottocodes constitute the backbone identification system for the language, dialect and family inventory Glottolog (https://glottolog.org). In this paper, we summarize the motivation and history behind the system of glottocodes and describe the principles and practices of data curation, technical infrastructure and update/version-tracking systematics. Since our understanding of the target domain - the dialects, languages and language families of the entire world - is continually evolving, changes and updates are relatively common. The resulting data is assessed in terms of the FAIR (Findable, Accessible, Interoperable, Reusable) Guiding Principles for scientific data management and stewardship. As such the glottocode-system responds to an important challenge in the realm of Linguistic Linked Data with numerous NLP applications.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access
Khan A.F.; Chiarcos C.; Declerck T.; Gifu D.; García E.G.-B.; Gracia J.; Ionov M.; Labropoulou P.; Mambrini F.; Mccrae J.P.; Pagé-Perron É.; Passarotti M.; Muñoz S.R.; Truica C.-O.,"Khan, Anas Fahad (57205198244); Chiarcos, Christian (22333764800); Declerck, Thierry (22333556000); Gifu, Daniela (42661254500); García, Elena González-Blanco (57945852700); Gracia, Jorge (55392626700); Ionov, Maxim (57194612761); Labropoulou, Penny (57031820700); Mambrini, Francesco (57190293497); Mccrae, John P. (36666801700); Pagé-Perron, Émilie (57203468297); Passarotti, Marco (56957111300); Muñoz, Salvador Ros (57202375507); Truica, Ciprian-Octavian (56331462000)",57205198244; 22333764800; 22333556000; 42661254500; 57945852700; 55392626700; 57194612761; 57031820700; 57190293497; 36666801700; 57203468297; 56957111300; 57202375507; 56331462000,When linguistics meets web technologies. Recent advances in modelling linguistic linked data,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140849273&doi=10.3233%2fSW-222859&partnerID=40&md5=60240ef879df5b5e8305eddddd7f9621,"This article provides a comprehensive and up-to-date survey of models and vocabularies for creating linguistic linked data (LLD) focusing on the latest developments in the area and both building upon and complementing previous works covering similar territory. The article begins with an overview of some recent trends which have had a significant impact on linked data models and vocabularies. Next, we give a general overview of existing vocabularies and models for different categories of LLD resource. After which we look at some of the latest developments in community standards and initiatives including descriptions of recent work on the OntoLex-Lemon model, a survey of recent initiatives in linguistic annotation and LLD, and a discussion of the LLD metadata vocabularies META-SHARE and lime. In the next part of the paper, we focus on the influence of projects on LLD models and vocabularies, starting with a general survey of relevant projects, before dedicating individual sections to a number of recent projects and their impact on LLD vocabularies and models. Finally, in the conclusion, we look ahead at some future challenges for LLD models and vocabularies. The appendix to the paper consists of a brief introduction to the OntoLex-Lemon model.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
Hosseini H.; Mansouri M.; Bagheri E.,"Hosseini, Hawre (57204815218); Mansouri, Mehran (57225218245); Bagheri, Ebrahim (20435297000)",57204815218; 57225218245; 20435297000,A systemic functional linguistics approach to implicit entity recognition in tweets,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130179375&doi=10.1016%2fj.ipm.2022.102957&partnerID=40&md5=5c39a8d58f6495316fd81056929b8b92,"The identification of knowledge graph entity mentions in textual content has already attracted much attention. The major assumption of existing work is that entities are explicitly mentioned in text and would only need to be disambiguated and linked. However, this assumption does not necessarily hold for social content where a significant portion of information is implied. The focus of our work in this paper is to identify whether textual social content include implicit mentions of knowledge graph entities or not, hence forming a two-class classification problem. To this end, we adopt the systemic functional linguistic framework that allows for capturing meaning expressed through language. Based on this theoretical framework we systematically introduce two classes of features, namely syntagmatic and paradigmatic features, for implicit entity recognition. In our experiments, we show the utility of these features for the task, report on ablation studies, measure the impact of each feature subset on each other and also provide a detailed error analysis of our technique. © 2022 Elsevier Ltd",Final,
Bosque-Gil J.; Cimiano P.; Dojchinovski M.,"Bosque-Gil, Julia (57031866000); Cimiano, Philipp (15838793700); Dojchinovski, Milan (55453114000)",57031866000; 15838793700; 55453114000,Editorial of the Special Issue on Latest Advancements in Linguistic Linked Data,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140851009&doi=10.3233%2fSW-223251&partnerID=40&md5=9939198c383a2828a82cfb1436f7133e,"Since the inception of the Open Linguistics Working Group in 2010, there have been numerous efforts in transforming language resources into Linked Data. The research field of Linguistic Linked Data (LLD) has gained in importance, visibility and impact, with the Linguistic Linked Open Data (LLOD) cloud gathering nowadays over 200 resources. With this increasing growth, new challenges have emerged concerning particular domain and task applications, quality dimensions, and linguistic features to take into account. This special issue aims to review and summarize the progress and status of LLD research in recent years, as well as to offer an understanding of the challenges ahead of the field for the years to come. The papers in this issue indicate that there are still aspects to address for a wider community adoption of LLD, as well as a lack of resources for specific tasks and (interdisciplinary) domains. Likewise, the integration of LLD resources into Natural Language Processing (NLP) architectures and the search for long-term infrastructure solutions to host LLD resources continue to be essential points to which to attend in the foreseeable future of the research line.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access; Green Open Access
Schneidermann N.S.; Pedersen B.S.,"Schneidermann, Nina Skovgaard (57220027911); Pedersen, Bolette Sandford (7201713480)",57220027911; 7201713480,"Evaluating a New Danish Sentiment Resource: the Danish Sentiment Lexicon, DSL",1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146225959&partnerID=40&md5=f56055c8d4bfb8efa5e69f27e218c159,"In this paper, we evaluate a new sentiment lexicon for Danish, the Danish Sentiment Lexicon (DSL), to gain input regarding how to carry out the final adjustments of the lexicon. A feature of the lexicon that differentiates it from other sentiment resources for Danish is that it is linked to a large number of other Danish lexical resources via the DDO lemma and sense inventory and the LLOD via the Danish WordNet, DanNet. We perform our evaluation on four datasets labeled with sentiments. In addition, we compare the lexicon against two existing benchmarks for Danish: the Afinn and the Sentida resources. We observe that DSL performs mostly comparably to the existing resources, but that more fine-grained explorations need to be done in order to fully exploit its possibilities given its linking properties. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Ponciano C.; Schaffert M.; Würriehausen F.; Ponciano J.-J.,"Ponciano, Claire (58062817200); Schaffert, Markus (46761574700); Würriehausen, Falk (55176768100); Ponciano, Jean-Jacques (57189220493)",58062817200; 46761574700; 55176768100; 57189220493,Publish and Enrich Geospatial Data as Linked Open Data,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146197990&partnerID=40&md5=fb8bb4d5a9bcf3c330d4fddedd2e0038,"The rapid growth of geospatial data (at least 20% every year) makes spatial data increasingly heterogeneous. With the emergence of Semantic Web technologies, more and more approaches are trying to group these data in knowledge graphs, allowing to link data together and to facilitate their sharing, use and maintenance. These approaches face the problem of homogenisation of these data which are not unified in the structure of the data on the one hand and on the other hand have a vocabulary that varies greatly depending on the application domain for which the data are dedicated and the language in which they are described. In order to solve this problem of homogenisation, we present in this paper the foundations of a framework allowing to group efficiently heterogeneous spatial data in a knowledge base. This knowledge base is based on an ontology linked to Schema.org and DCAT-AP, and provides a data structure compatible with GeoSPARQL. This framework allows the integration of geospatial data independently of their original language by translating them using Neural Machine Translation. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Final,
Stranisci M.A.; Frenda S.; Lai M.; Araque O.; Cignarella A.T.; Basile V.; Patti V.; Bosco C.,"Stranisci, Marco A. (57198815487); Frenda, Simona (57192937088); Lai, Mirko (56611219700); Araque, Oscar (56002164800); Cignarella, Alessandra T. (57195403666); Basile, Valerio (57191892846); Patti, Viviana (6506947801); Bosco, Cristina (7004550793)",57198815487; 57192937088; 56611219700; 56002164800; 57195403666; 57191892846; 6506947801; 7004550793,O-Dang! The Ontology of Dangerous Speech Messages,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146216572&partnerID=40&md5=fef0ade8584f337d1191ead5ebacfbc8,"Inside the NLP community there is a considerable amount of language resources created, annotated and released every day with the aim of studying specific linguistic phenomena. Despite a variety of attempts in order to organize such resources has been carried on, a lack of systematic methods and of possible interoperability between resources are still present. Furthermore, when storing linguistic information, still nowadays, the most common practice is the concept of “gold standard”, which is in contrast with recent trends in NLP that aim at stressing the importance of different subjectivities and points of view when training machine learning and deep learning methods. In this paper we present O-Dang!: The Ontology of Dangerous Speech Messages, a systematic and interoperable Knowledge Graph (KG) for the collection of linguistic annotated data. O-Dang! is designed to gather and organize Italian datasets into a structured KG, according to the principles shared within the Linguistic Linked Open Data community. The ontology has also been designed to account a perspectivist approach, since it provides a model for encoding both gold standard and single-annotator labels in the KG. The paper is structured as follows. In Section 1. the motivations of our work are outlined. Section 2. describes the O-Dang! Ontology, that provides a common semantic model for the integration of datasets in the KG. The Ontology Population stage with information about corpora, users, and annotations is presented in Section 3.. Finally, in Section 4. an analysis of offensiveness across corpora is provided as a first case study for the resource. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Declerck T.,"Declerck, Thierry (22333556000)",22333556000,Towards a new Ontology for Sign Languages,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140453253&partnerID=40&md5=66408d93e4a95af9feb947fc4ac977c4,"We present the current status of a new ontology for representing constitutive elements of Sign Languages (SL). This development emerged from investigations on how to represent multimodal lexical data in the OntoLex-Lemon framework, with the goal to publish such data in the Linguistic Linked Open Data (LLOD) cloud. While studying the literature and various sites dealing with sign languages, we saw the need to harmonise all the data categories (or features) defined and used in those sources, and to organise them in an ontology to which lexical descriptions in OntoLex-Lemon could be linked. We make the code of the first version of this ontology available, so that it can be further developed collaboratively by both the Linked Data and the SL communities. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Sun Y.; Shi Q.; Qi L.; Zhang Y.,"Sun, Yueqing (57374949300); Shi, Qi (57275062500); Qi, Le (57204179688); Zhang, Yu (55949765600)",57374949300; 57275062500; 57204179688; 55949765600,JointLK: Joint Reasoning with Language Models and Knowledge Graphs for Commonsense Question Answering,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138372259&partnerID=40&md5=5e07a3b2313a072bb3f369edb054dac8,"Existing KG-augmented models for commonsense question answering primarily focus on designing elaborate Graph Neural Networks (GNNs) to model knowledge graphs (KGs). However, they ignore (i) the effectively fusing and reasoning over question context representations and the KG representations, and (ii) automatically selecting relevant nodes from the noisy KGs during reasoning. In this paper, we propose a novel model, JointLK, which solves the above limitations through the joint reasoning of LM and GNN and the dynamic KGs pruning mechanism. Specifically, JointLK performs joint reasoning between LM and GNN through a novel dense bidirectional attention module, in which each question token attends on KG nodes and each KG node attends on question tokens, and the two modal representations fuse and update mutually by multi-step interactions. Then, the dynamic pruning module uses the attention weights generated by joint reasoning to prune irrelevant KG nodes recursively. We evaluate JointLK on the CommonsenseQA and OpenBookQA datasets, and demonstrate its improvements to the existing LM and LM+KG models, as well as its capability to perform interpretable reasoning. © 2022 Association for Computational Linguistics.",Final,
Chiarcos C.; Fäth C.; Ionov M.,"Chiarcos, Christian (22333764800); Fäth, Christian (57194612424); Ionov, Maxim (57194612761)",22333764800; 57194612424; 57194612761,Querying a Dozen Corpora and a Thousand Years with Fintan,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144449882&partnerID=40&md5=796cde76de97360b5cf4c16f50ccbf12,"Large-scale diachronic corpus studies covering longer time periods are difficult if more than one corpus are to be consulted and, as a result, different formats and annotation schemas need to be processed and queried in a uniform, comparable and replicable manner. We describes the application of the Flexible Integrated Transformation and Annotation eNgineering (Fintan) platform for studying word order in German using syntactically annotated corpora that represent its entire written history. Focusing on nominal dative and accusative arguments, this study hints at two major phases in the development of scrambling in modern German. Against more recent assumptions, it supports the traditional view that word order flexibility decreased over time, but it also indicates that this was a relatively sharp transition in Early New High German. The successful case study demonstrates the potential of Fintan and the underlying LLOD technology for historical linguistics, linguistic typology and corpus linguistics. The technological contribution of this paper is to demonstrate the applicability of Fintan for querying across heterogeneously annotated corpora, as previously, it had only been applied for transformation tasks. With its focus on quantitative analysis, Fintan is a natural complement for existing multi-layer technologies that focus on query and exploration. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Kirillovich A.; Nikolaev K.,"Kirillovich, Alexander (55994716700); Nikolaev, Konstantin (57205380412)",55994716700; 57205380412,Adapting the LodView RDF Browser for Navigation over the Multilingual Linguistic Linked Open Data Cloud,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138990992&doi=10.1109%2fSETIT54465.2022.9875628&partnerID=40&md5=6ad70bd7390e781408048147b270f432,"This paper is dedicated to using of LodView RDF browser for navigation over the multilingual Linguistic Linked Open Data cloud. We reveal several limitations of LodView that impede its use for this purpose, and propose improvements to be made for fixing these limitations. These improvements are: 1) resolution of Cyrillic URIs; 2) decoding Cyrillic URIs in Turtle representations of resources; 3) support of Cyrillic literals; 4) user-friendly URLs for RDF representations of resources; 5) support of hash URIs; 6) expanding nested resources; 7) support of RDF collections; 8) support of LATEX math notation; and 9) pagination of resource property values. We implement several of the proposed improvements.  © 2022 IEEE.",Final,All Open Access; Green Open Access
Bansal R.; Aggarwal M.; Bhatia S.; Kaur J.N.; Krishnamurthy B.,"Bansal, Rachit (57222270975); Aggarwal, Milan (57202719175); Bhatia, Sumit (35316725900); Kaur, Jivat Neet (57680104300); Krishnamurthy, Balaji (57196672802)",57222270975; 57202719175; 35316725900; 57680104300; 57196672802,CoSe-Co: Text Conditioned Generative CommonSense Contextualizer,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138416742&partnerID=40&md5=ec59166b5a37455e8796a5a2cdd887c8,"Pre-trained Language Models (PTLMs) have been shown to perform well on natural language tasks. Many prior works have leveraged structured commonsense present in the form of entities linked through labeled relations in Knowledge Graphs (KGs) to assist PTLMs. Retrieval approaches use KG as a separate static module which limits coverage since KGs contain finite knowledge. Generative methods train PTLMs on KG triples to improve the scale at which knowledge can be obtained. However, training on symbolic KG entities limits their applicability in tasks involving natural language text where they ignore overall context. To mitigate this, we propose a CommonSense Contextualizer (CoSeCo) conditioned on sentences as input to make it generically usable in tasks for generating knowledge relevant to the overall context of input text. To train CoSe-Co, we propose a novel dataset comprising of sentence and commonsense knowledge pairs. The knowledge inferred by CoSe-Co is diverse and contain novel entities not present in the underlying KG. We augment generated knowledge in Multi-Choice QA and Open-ended CommonSense Reasoning tasks leading to improvements over current best methods on CSQA, ARC, QASC and OBQA datasets. We also demonstrate its applicability in improving performance of a baseline model for paraphrase generation task. © 2022 Association for Computational Linguistics.",Final,
Porzel R.; Pomarlan M.; Spillner L.; Bateman J.; Mildner T.; Santagiustina C.,"Porzel, Robert (21741148500); Pomarlan, Mihai (35410087600); Spillner, Laura (57299173600); Bateman, John (7202065408); Mildner, Thomas (57194284434); Santagiustina, Carlo (57219757849)",21741148500; 35410087600; 57299173600; 7202065408; 57194284434; 57219757849,Narrativizing Knowledge Graphs,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142493609&partnerID=40&md5=97e9b0544dd52d6554863b5fbd4e8177,"Any natural language expression of a set of facts - that can be represented as a knowledge graph - will more or less overtly assume a specific perspective on these facts. In this paper we see the conversion of a given knowledge graph into natural language as the construction of a narrative about the assertions made by the knowledge graph. We, therefore, propose a specific pipeline that can be applied to produce linguistic narratives from knowledge graphs using an ontological layer and corresponding rules that turn a knowledge graph into a semantic specification for natural language generation. Critically, narratives are seen as necessarily committing to specific perspectives taken on the facts presented. We show how this most commonly neglected facet of producing summaries of facts can be brought under control. © 2021 Copyright for this paper by its authors.",Final,
Robin C.; Suresh G.V.; Doncel V.R.; McCrae J.; Buitelaar P.,"Robin, Cécile (57200367411); Suresh, Gautham Vadakkekara (57446650900); Doncel, Víctor Rodríguez (18037048500); McCrae, John (36666801700); Buitelaar, Paul (14041096000)",57200367411; 57446650900; 18037048500; 36666801700; 14041096000,Linghub2: Language Resource Discovery Tool for Language Technologies,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144395636&partnerID=40&md5=95b25678ee51855168f23c5b460f39cf,"Language resources are an essential component of natural language processing, as well as related research and applications. Users of language resources have different needs in terms of format, language, topics, etc. for the data they need to use. Linghub (McCrae and Cimiano, 2015) was first developed for this purpose, using the capabilities of linked data to represent metadata, and tackling the heterogeneous metadata issue. Linghub is aimed at helping language resources and technology users to easily find and retrieve relevant data, and identify important information on access, topics, etc. This work describes a rejuvenation and modernisation of the 2015 platform into using a popular open source data management system, DSpace, as foundation. The new platform, Linghub2, contains updated and extended resources, more languages, and continues the work towards the homogenisation of metadata through conversions, through linkage to standardisation strategies and community groups, such as the Open Digital Rights Language (ODRL) community group. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Deshpande A.; Ruiter D.; Mosbach M.; Klakow D.,"Deshpande, Awantee (57733401700); Ruiter, Dana (57212503586); Mosbach, Marius (57212346738); Klakow, Dietrich (23392812900)",57733401700; 57212503586; 57212346738; 23392812900,StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139104669&partnerID=40&md5=7440e0daa331119fc6732f0e01996c97,"Analyzing ethnic or religious bias is important for improving fairness, accountability, and transparency of natural language processing models. However, many techniques rely on human-compiled lists of bias terms, which are expensive to create and are limited in coverage. In this study, we present a fully data-driven pipeline for generating a knowledge graph (KG) of cultural knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5 nationalities and can easily be extended to include more entities. Our human evaluation shows that the majority (59.2%) of non-singleton entries are coherent and complete stereotypes. We further show that performing intermediate masked language model training on the verbalized KG leads to a higher level of cultural awareness in the model and has the potential to increase classification performance on knowledge-crucial samples on a related task, i.e., hate speech detection. © 2022 Association for Computational Linguistics.",Final,
Martín-Chozas P.; Montiel-Ponsoda E.; Carvalho S.; Costa R.,"Martín-Chozas, Patricia (57210581382); Montiel-Ponsoda, Elena (25654093800); Carvalho, Sara (58064085700); Costa, Rute (55958196000)",57210581382; 25654093800; 58064085700; 55958196000,TermTrends: Trends in Terminology Generation and Modelling,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142452288&partnerID=40&md5=2d89c78c1d8f85671b0041affd5343a1,"This document presents the objectives, content and organisation of the TermTrends tutorial within EKAW 2022. The tutorial intends to give an overview of current techniques and tools for terminology generation, as well as of standardisation approaches for terminological data. Thus, the first part of the tutorial is a theoretical block that includes an introduction to the terminological work, current standards for terminology modelling and two use cases on legal and medical terminology. The second part is a hands-on block that deals with terminological resources and tools. The tutorial is linked to the conference through a series of topics, such as knowledge acquisition and ontology engineering; and it is suitable for both an expert and non-expert audience. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)",Final,
Krause L.; Sommerauer P.; Vossen P.,"Krause, Lea (57224852907); Sommerauer, Pia (57215968995); Vossen, Piek (57204791557)",57224852907; 57215968995; 57204791557,Towards More Informative List Verbalisations,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142540592&partnerID=40&md5=4754d7f294b8fb873fdcde3c9cbc6b46,"In this paper we propose the task of list verbalisation within a Knowledge Graph Question Answering system. Inspired by the Gricean Maxims of Quantity, Relation, and Manner we show a proof of concept ranking answer candidates through graph-based and language model-based measurements for on the one hand popularity and on the other hand a more pragmatically informed context. Our finding show that in our current set-up graph-based measures work best, while language model-based systems need further refinement and may benefit from approaches such as fine-tuning or prompting. We evaluate our approach with a user study and give insights into promising future directions of the task. © 2022 Copyright for this paper by its authors.",Final,
Vasilogamvrakis N.,"Vasilogamvrakis, Nikos (57581705600)",57581705600,The Ontological Approach of Modern Greek Morphology (short paper),1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140894096&partnerID=40&md5=b4f7f5075f57b7a58b0c5fb0c4dce941,"This article comprises a brief overview of my PhD research proposal investigating the ontological approach of Modern Greek (MG) morphology. Its main objective is to study contemporary onto-linguistic models in order to form an onto-morphological tool for MG morphological analysis. The research was motivated by the lack of an ontologically holistic approach based on the Semantic Web (SW) paradigm to represent MG morphology. After a brief review on the current ontological setting within the Semantic Web, the respective morphological framework is determined and placed into the Strong Lexicalist theory justified by MG morpheme-based nature. Following this, main research questions are defined and the methodology of the research is presented as an itinerary process between ontological development, theory and lexical data testing. Finally, the article concludes with some preliminary research results based on a morpheme-based analysis of indicative MG lexical data in the MMoOn ontological model. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)",Final,
Basile P.; Cassotti P.; Ferilli S.; McGillivray B.,"Basile, Pierpaolo (23392182500); Cassotti, Pierluigi (57198883659); Ferilli, Stefano (35502407200); McGillivray, Barbara (14325441100)",23392182500; 57198883659; 35502407200; 14325441100,A New Time-sensitive Model of Linguistic Knowledge for Graph Databases,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143434825&partnerID=40&md5=784409e837cc93283825123be1e091e6,"Graph databases are a straightforward technology for storing knowledge graphs. However, they are schema-less. We apply the GraphBRAIN Schema (GBS) format to describe Time-sensitive Linguistic Knowledge in a graph database (Neo4j). Our schema can model relations between concepts and words, information about word occurrences, and diachronic information about concepts and words. This paper introduces GraphBRAIN technology and describes our model for time-sensitive linguistic data. Moreover, we provide an example of usage and show the potential of this model for humanities and cultural heritage research. © 2022 Copyright for this paper by its authors.",Final,
Chiarcos C.; Fäth C.; Ionov M.,"Chiarcos, Christian (22333764800); Fäth, Christian (57194612424); Ionov, Maxim (57194612761)",22333764800; 57194612424; 57194612761,Unifying Morphology Resources with OntoLex-Morph. A Case Study in German,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144442932&partnerID=40&md5=b2279530bc4eb58858921bff9b066447,"The OntoLex vocabulary has become a widely used community standard for machine-readable lexical resources on the web. The primary motivation to use OntoLex in favor of tool- or application-specific formalisms is to facilitate interoperability and information integration across different resources. One of its extension that is currently being developed is a module for representing morphology, OntoLex-Morph. In this paper, we show how OntoLex-Morph can be used for the encoding and integration of different types of morphological resources on a unified basis. With German as the example, we demonstrate it for (a) a full-form dictionary with inflection information (Unimorph), (b) a dictionary of base forms and their derivations (UDer), (c) a dictionary of compounds (from GermaNet), and (d) lexicon and inflection rules of a finite-state parser/generator (SMOR/Morphisto). These data are converted to OntoLex-Morph, their linguistic information is consolidated and corresponding lexical entries are linked with each other. The main contribution of this paper is the discussion of the current state of OntoLex-Morph and its validation on different types of real-world resources for a single language. In the longer term, the successful application of OntoLex-Morph to such diverse data, along with the adjustments to the vocabulary observed in the process, will be a means to establish interoperability among morphological resources as well as between them and classical lexical data such as dictionaries, WordNets, or thesauri. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Leenoi D.; Alongkornchai A.; Takhom A.; Boonkwan P.; Sunnithi T.,"Leenoi, Dhanon (35793690200); Alongkornchai, Alongkorn (58010024200); Takhom, Akkharawoot (35231260200); Boonkwan, Prachya (36917795200); Sunnithi, Thenchai (58009927100)",35793690200; 58010024200; 35231260200; 36917795200; 58009927100,A Construction of Thai WordNet through Translation Equivalence,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143991392&doi=10.1109%2fiSAI-NLP56921.2022.9960263&partnerID=40&md5=e6162d7666ef392af33ee0d71a3e3858,"WordNet is a crucial language resource associated with artificial intelligence activities, for instance, constructing building models for advancement of computational linguistics and natural language processing, or representing statistical insights through knowledge graphs that emulate cognition and human understanding. Thai WordNet has been developed in many approaches, e.g., a merge approach in gold standard, and semi-auto construction with a bilingual dictionary. However, existing Thai WordNet is not easy to find words fit with the definition of synsets; and cover cultural gaps between the different languages of which needed to be aware. This paper presents a methodology of Translation Equivalence in order to construct Thai language resource, called LST22 Thai WordNet.  © 2022 IEEE.",Final,
Guo M.; Chen Y.; Xu J.; Zhang Y.,"Guo, Mengfei (57918274000); Chen, Yufeng (57114607100); Xu, Jinan (54796280200); Zhang, Yujie (45261676700)",57918274000; 57114607100; 54796280200; 45261676700,Dynamic Knowledge Integration for Natural Language Inference,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139414930&doi=10.1109%2fICNLP55136.2022.00066&partnerID=40&md5=0bedbd55d6413eaf9aaa331f6cc6d90c,"Natural language inference (NLI) aims to determine the entailment relationship between the premise and the hypothesis. It is a fundamental but difficult problem, since there may exists serious semantic and logistic gap between the premise and the hypothesis. Despite using strong pre-trained language model (PLM), previous work performs poorly on complicated reasoning for knowledge-sensitive cases ignoring the integration of external knowledge. We propose a dynamic knowledge integration strategy for NLI, where knowledge from multiple knowledge graphs (KGs) can be dynamically integrated. For each KG, it transforms input tokens into a graph according to the connectivity of the related entities. All the graphs are encoded by a group of parallel graph neural networks (GNNs), and after each layer the intermediate results are integrated dynamically by being conditioned on the input text. This strategy also facilitates the incorporation of PLM, simply by treating the input tokens as a fully connected graph and adapting the PLM outputs as the node embeddings. Experiments on SNLI, MNLI and SciTail show that, the dynamic integration of knowledge from WordNet and ConceptNet achieves significant improvements over the strongest baseline built upon RoBERTa.  © 2022 IEEE.",Final,
Hakami H.; Hakami M.; Mandya A.; Bollegala D.,"Hakami, Huda (57003240000); Hakami, Mona (56938495500); Mandya, Angrosh (57201251006); Bollegala, Danushka (13006618600)",57003240000; 56938495500; 57201251006; 13006618600,Learning to Borrow - Relation Representation for Without-Mention Entity-Pairs for Knowledge Graph Completion,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138356689&partnerID=40&md5=23259f3097e7310ea1f1a2b64e45e41e,"Prior work on integrating text corpora with knowledge graphs (KGs) to improve Knowledge Graph Embedding (KGE) have obtained good performance for entities that co-occur in sentences in text corpora. Such sentences (textual mentions of entity-pairs) are represented as Lexicalised Dependency Paths (LDPs) between two entities. However, it is not possible to represent relations between entities that do not co-occur in a single sentence using LDPs. In this paper, we propose and evaluate several methods to address this problem, where we borrow LDPs from the entity pairs that co-occur in sentences in the corpus (i.e. with mention entity pairs) to represent entity pairs that do not co-occur in any sentence in the corpus (i.e. without mention entity pairs). We propose a supervised borrowing method, SuperBorrow, that learns to score the suitability of an LDP to represent a without-mention entity pair using pre-trained entity embeddings and contextualised LDP representations. Experimental results show that SuperBorrow improves the link prediction performance of multiple widely-used prior KGE methods such as TransE, DistMult, ComplEx and RotatE. © 2022 Association for Computational Linguistics.",Final,
Mambrini F.; Passarotti M.; Moretti G.; Pellegrini M.,"Mambrini, Francesco (57190293497); Passarotti, Marco (56957111300); Moretti, Giovanni (57190677309); Pellegrini, Matteo (57220703991)",57190293497; 56957111300; 57190677309; 57220703991,The Index Thomisticus Treebank as Linked Data in the LiLa Knowledge Base,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144353382&partnerID=40&md5=c82f76ce1252ae5ed16ed2cd7a990f7f,"Although the Universal Dependencies initiative today allows for cross-linguistically consistent annotation of morphology and syntax in treebanks for several languages, syntactically annotated corpora are not yet interoperable with many lexical resources that describe properties of the words that occur therein. In order to cope with such limitation, we propose to adopt the principles of the Linguistic Linked Open Data community, to describe and publish dependency treebanks as LLOD. In particular, this paper illustrates the approach pursued in the LiLa Knowledge Base, which enables interoperability between corpora and lexical resources for Latin, to publish as Linguistic Linked Open Data the annotation layers of two versions of a Medieval Latin treebank (the Index Thomisticus Treebank). © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Zahera H.M.; Vollmers D.; Sherif M.A.; Ngomo A.-C.N.,"Zahera, Hamada M. (56901204500); Vollmers, Daniel (57212210737); Sherif, Mohamed Ahmed (55901643100); Ngomo, Axel-Cyrille Ngonga (23397850200)",56901204500; 57212210737; 55901643100; 23397850200,MultPAX: Keyphrase Extraction Using Language Models and Knowledge Graphs,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141678744&doi=10.1007%2f978-3-031-19433-7_18&partnerID=40&md5=5b3b91928f79921283b3ebdb9ea8ed4e,"Keyphrase extraction aims to identify a small set of phrases that best describe the content of text. The automatic generation of keyphrases has become essential for many natural language applications such as text categorization, indexing, and summarization. In this paper, we propose MultPAX, a multitask framework for extracting present and absent keyphrases using pre-trained language models and knowledge graphs. In particular, our framework contains three components: first, MultPAX identifies present keyphrases from an input document. Then, MultPAX links with external knowledge graphs to get more relevant phrases. Finally, MultPAX ranks the extracted phrases based on their semantic relatedness to the input document and return top-k phrases as a final output. We conducted several experiments on four benchmark datasets to evaluate the performance of MultPAX against different state-of-the-art baselines. The evaluation results demonstrate that our approach significantly outperforms the state-of-the-art baselines, with a significance t-test p&lt; 0.041. Our source code and datasets are public available at https://github.com/dice-group/MultPAX. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Yu S.; Zhang S.; Zhang J.; Zhou J.; Sun Y.; Li B.; Xuan Q.,"Yu, Shanqing (7405728956); Zhang, Shihan (57218472854); Zhang, Jianlin (57694755100); Zhou, Jiajun (57219502264); Sun, Yun (58037336700); Li, Bing (57780139300); Xuan, Qi (12766572500)",7405728956; 57218472854; 57694755100; 57219502264; 58037336700; 57780139300; 12766572500,SubGraph Networks Based Entity Alignment for Cross-Lingual Knowledge Graph,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145259786&doi=10.1007%2f978-981-19-7532-5_7&partnerID=40&md5=a0c5880675341497b46dd740c0c3054c,"Entity alignment is the task of discovering entities representing the equal real-world object in two knowledge graphs (KGs). Cross-lingual knowledge graph entity alignment aims to discover the cross-lingual links in the multi-language KGs, which is of wonderful value to solve the NLP problems and integrate multi-language KGs. In the task of aligning cross-language knowledge graphs, the structures of the two graphs are very similar, and the equivalent entities often have the same subgraph structure characteristics. The traditional GCN method neglects to obtain structural features through representative parts of the original graph and the use of adjacency matrix is not enough to effectively represent the structural features of the graph. In this paper, we introduce the subgraph network (SGN) method into the GCN-based cross-lingual KG entity alignment method. In the method, we extracted the first-order subgraphs of the KGs to expand the structural features of the original graph to enhance the representation ability of the entity embedding and improve the alignment accuracy. Experiments show that the proposed method is advanced in the task of entity alignment. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,All Open Access; Green Open Access
Kumar A.; Bharadwaj A.G.; Starly B.; Lynch C.,"Kumar, Aman (57203874891); Bharadwaj, Akshay G. (57784655300); Starly, Binil (6506856773); Lynch, Collin (14048865700)",57203874891; 57784655300; 6506856773; 14048865700,FabKG: A Knowledge graph of Manufacturing Science domain utilizing structured and unconventional unstructured knowledge source,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139121316&partnerID=40&md5=ce94bba41046abcba74ebfd11efa5a66,"As the demands for large-scale information processing have grown, knowledge graph-based approaches have gained prominence for representing general and domain knowledge. The development of such general representations is essential, particularly in domains such as manufacturing which intelligent processes and adaptive education can enhance. Despite the continuous accumulation of text in these domains, the lack of structured data has created information extraction and knowledge transfer barriers. In this paper, we report on work towards developing robust knowledge graphs based upon entity and relation data for both commercial and educational uses. To create the FabKG (Manufacturing knowledge graph), we have utilized textbook index words, research paper keywords, FabNER (manufacturing NER), to extract a sub knowledge base contained within Wikidata. Moreover, we propose a novel crowdsourcing method for KG creation by leveraging student notes, which contain invaluable information but are not captured as meaningful information, excluding their use in personal preparation for learning and written exams. We have created a knowledge graph containing 65000+ triples using all data sources. We have also shown the use case of domain-specific question answering and expression/formula-based question answering for educational purposes. © 2022 Association for Computational Linguistics.",Final,
Vasilogamvrakis N.; Sfakakis M.,"Vasilogamvrakis, Nikos (57581705600); Sfakakis, Michalis (6506370379)",57581705600; 6506370379,A Morpheme-Based Paradigm for the Ontological Analysis of Modern Greek Derivational Morphology,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128491291&doi=10.1007%2f978-3-030-98876-0_34&partnerID=40&md5=6620014278811c1edae91d13371b3856,"Morphology is the linguistic field that investigates the minimal meaningful units within words and their interactive processes. In coping with the ontological representation of Modern Greek (MG) derivational morphology the morpheme-based or lexicalist paradigm was tested due to the highly productive concatenative nature of the language. Following this, a specific domain ontological model, the MMoOn was chosen to assess MG morpheme-based morphological representation while being prepared to incorporate other formation approaches when required by the lexical data. Among others, MMoOn was chosen because of its targeted morphological character, its conceptual granularity, the covering of derivational aspects of morphology, its elasticity of embedding different inflectional language data models and its reference to previous frameworks. Accordingly, the model was appropriately extended for the MG language schema and tested towards a very productive MG derivational pattern revealing its high dynamics of representation and usability as a computed lexical inventory that semantically interlinks its entries. © 2022, Springer Nature Switzerland AG.",Final,
Linares-Sánchez J.J.; Sánchez-Cuadrado S.; Morato J.,"Linares-Sánchez, Jorge Juan (57456187400); Sánchez-Cuadrado, Sonia (23393875600); Morato, Jorge (57219289030)",57456187400; 23393875600; 57219289030,Linked data for the Greek and Latin literatura analysis; [Datos enlazados para el análisis de la literatura grecolatina],1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124721799&doi=10.3989%2fredc.2022.1.1842&partnerID=40&md5=eb0ae79c3e1f596e81ddf6e2275563fe,"The development of a domain ontology for the Greek and Latin literature representation in the form of linked data is described. The principles of the Semantic Web and the semantic diffusion of contents applied to classical Greek-Latin literature are analyzed. The essence of the Methontology methodology has been adapted for the construction of ontologies and a formalized linguistic resource has been implemented. The result of this research has been the development of a pilot project of linked data based on the principles and technologies of Linked Open Data (LOD) in the field of comparative literature, in which the Litcomp ontology has been developed to improve the study of the influence and preservation of Greek and Latin literature. © 2022 CSIC. All Rights Reserved.",Final,All Open Access; Gold Open Access; Green Open Access
Alcina A.,"Alcina, Amparo (24437633900)",24437633900,Using a Linguistic Approach to Represent Terminology in an Ontology,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134236644&partnerID=40&md5=53f41bec8389b984b9092912a8c42c77,"Ontology models of lexical and terminological resources need to include the linguistic dimension in a more coherent and adequate way. In general, ontologies describe objects, but the linguistic approach consist of describe terms as words, not as codes or labels. In this work, we will present our ontology model, where terms are the 'individuals' that are the object of classification and linguistic concepts (whether grammatical, as a noun or verb, or morphological, as a full or derived form) constitute the 'classes' into which the terms are classified. This model of lexical representation can enhance the use of ontologies to make dictionaries and contribute to the Web Semantic and Linked Data Linguistics.  © 2022 Copyright for this paper by its authors.",Final,
Montiel-Ponsoda E.,"Montiel-Ponsoda, Elena (25654093800)",25654093800,Terminology and ontologies,1,,1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132126845&doi=10.1075%2ftlrp.23.07mon&partnerID=40&md5=11fc6f6ec22c63556237819fdc71f354,"This chapter revisits the relation between terminologies and ontologies, focusing on those aspects that lie at the intersection of the two worlds. Terminological resources, methods and tools that follow the conceptual paradigm are analyzed to explain how close they are to ontologies. Then, current methodologies in Ontology Engineering are reviewed from a terminological perspective to highlight those aspects of terminological practice that are becoming increasingly relevant in an ontology development process. Finally, current trends and models in Ontology Engineering whose aim is to enrich ontologies with linguistic (terminological) descriptions are examined in the light of their use in Artificial Intelligence and Natural Language Processing tools, pointing to a renewed convergence of these two worlds. © 2022 Terminology and Lexicography Research and Practice. All rights reserved.",Final,
Chiarcos C.,"Chiarcos, Christian (22333764800)",22333764800,Get! Mimetypes! Right!,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115075174&doi=10.4230%2fOASIcs.LDK.2021.5&partnerID=40&md5=07f2f8c24f0ace3cceefe7e36dbf53ad,"This paper identifies three technical requirements - availability of data, sustainable hosting and resolvable URIs for hosted data - as minimal pre-conditions for Linguistic Linked Open Data technology to develop towards a mature technological ecosystem that third party applications can build upon. While a critical amount of data is available (and it continues to grow), there does not seem to exist a hosting solution that combines the prospects of long-term availability with an unrestricted capability to support resolvable URIs. In particular, data hosting services do currently not allow data to be declared as RDF content by means of their media type (mime type), so that the capability of clients to recognize formats and to resolve URIs on that basis is severely limited. © Christian Chiarcos; licensed under Creative Commons License CC-BY 4.0",Final,
Ramnath K.; Sari L.; Hasegawa-Johnson M.; Yoo C.,"Ramnath, Kiran (57191861427); Sari, Leda (56462674400); Hasegawa-Johnson, Mark (6602106855); Yoo, Chang (7201746384)",57191861427; 56462674400; 6602106855; 7201746384,Worldly Wise (WoW) - Cross-Lingual Knowledge Fusion for Fact-based Visual Spoken-Question Answering,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137712266&partnerID=40&md5=cef852d346571919b08d1629b1e076ba,"Although Question-Answering has long been of research interest, its accessibility to users through a speech interface and its support to multiple languages have not been addressed in prior studies. Towards these ends, we present a new task and a synthetically-generated dataset to do Fact-based Visual Spoken-Question Answering (FVSQA). FVSQA is based on the FVQA dataset, which requires a system to retrieve an entity from Knowledge Graphs (KGs) to answer a question about an image. In FVSQA, the question is spoken rather than typed. Three sub-tasks are proposed: (1) speech-to-text based, (2) end-to-end, without speech-to-text as an intermediate component, and (3) cross-lingual, in which the question is spoken in a language different from that in which the KG is recorded. The end-to-end and cross-lingual tasks are the first to require world knowledge from a multi-relational KG as a differentiable layer in an end-to-end spoken language understanding task, hence the proposed reference implementation is called Worldly-Wise (WoW). WoW is shown to perform end-to-end cross-lingual FVSQA at same levels of accuracy across 3 languages - English, Hindi, and Turkish. © 2021 Association for Computational Linguistics.",Final,
Fang T.; Zhang H.; Wang W.; Song Y.; He B.,"Fang, Tianqing (57222014949); Zhang, Hongming (57202439109); Wang, Weiqi (57222025650); Song, Yangqiu (14039604300); He, Bin (57221014343)",57222014949; 57202439109; 57222025650; 14039604300; 57221014343,DISCOS: Bridging the gap between discourse knowledge and commonsense knowledge,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106111969&doi=10.1145%2f3442381.3450117&partnerID=40&md5=7cd003556dcc8efcff823d16b9c256dd,"Commonsense knowledge is crucial for artificial intelligence systems to understand natural language. Previous commonsense knowledge acquisition approaches typically rely on human annotations (for example, ATOMIC) or text generation models (for example, COMET.) Human annotation could provide high-quality commonsense knowledge, yet its high cost often results in relatively small scale and low coverage. On the other hand, generation models have the potential to automatically generate more knowledge. Nonetheless, machine learning models often fit the training data well and thus struggle to generate high-quality novel knowledge. To address the limitations of previous approaches, in this paper, we propose an alternative commonsense knowledge acquisition framework DISCOS (from DIScourse to COmmonSense), which automatically populates expensive complex commonsense knowledge to more affordable linguistic knowledge resources. Experiments demonstrate that we can successfully convert discourse knowledge about eventualities from ASER, a large-scale discourse knowledge graph, into if-then commonsense knowledge defined in ATOMIC without any additional annotation effort. Further study suggests that DISCOS significantly outperforms previous supervised approaches in terms of novelty and diversity with comparable quality. In total, we can acquire 3.4M ATOMIC-like inferential commonsense knowledge by populating ATOMIC on the core part of ASER. Codes and data are available at https://github.com/HKUST-KnowComp/DISCOS-commonsense.  Â© 2021 ACM.",Final,All Open Access; Green Open Access
Racioppa S.; Declerck T.,"Racioppa, Stefania (24725676000); Declerck, Thierry (22333556000)",24725676000; 22333556000,Porting the Latin WordNet onto OntoLex-Lemon,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137094300&partnerID=40&md5=60cb170f433be37564195d5135fe8da8,"In this paper we describe the porting of the Latin WordNet data available at the University of Exeter onto the OntoLex-Lemon model, focusing on the representation of both morphological and conceptual information. In the longer term, we aim at integrating the resulting data set in the Linguistic Linked Open Data (LLOD) infrastructure, linking (or even merging) it to the Latin data sets already published in the LOD framework by the ERC “Linking Latin” (LILA) project. We discuss some lessons learned, as it turned out that such a transformation and linking exercise can lead to an improved consistency and accuracy of the original data. © 2021 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Semedo D.,"Semedo, David (57194266630)",57194266630,Towards Open-domain Vision and Language Understanding with Wikimedia,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107652202&doi=10.1145%2f3442442.3452346&partnerID=40&md5=797b040c8eb054bed1ec67608ea6b968,"Current state-of-The-Art task-Agnostic visio-linguistic approaches, such as ViLBERT [2], are limited to domains in which texts have a visual materialization (e.g. a person running). This work describes a project towards achieving the next generation of models, that can deal with open-domain media, and learn visio-linguistic representations that reflect data's context, by jointly reasoning over media, a domain knowledge-graph and temporal context. This ambition will be leveraged by a Wikimedia data framework, comprised by comprehensive and high-quality data, covering a wide range of social, cultural, political and other type of events. Towards this goal, we propose a research setup comprised by an open-domain data framework and a set of novel independent research tasks. © 2021 ACM.",Final,All Open Access; Bronze Open Access
Sharma A.; Jain S.,"Sharma, Abhisek (57217481852); Jain, Sarika (57203018058)",57217481852; 57203018058,Multilingual semantic representation of smart connected world data,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118413534&doi=10.1007%2f978-3-030-76387-9_7&partnerID=40&md5=25a100b762c9c451c01a5681d3518a62,"IoT devices now come in all shapes and forms. IoT is everywhere, from our mobile devices to cars. These devices help to perform various tasks from providing locations for navigation purposes, to detecting a heartbeat inside a locked car to notify parents or pet owners that they have left their child or pet inside the car and need attention. The latter example is not possible only with IoT devices; they need algorithms and systems to detect these heartbeats, and this is facilitated by Artificial Intelligence (AI). We will be working with Artificial Intelligence of Things (AIoT), a combination of Artificial Intelligence and IoT. We can't ignore the fact that our world is multilingual, with a wide variety of cultures and ethnic and racial groups. One of the AIoT system tasks is hearing a sentence from a user, interpreting what it means, and performing tasks accordingly. But this task is not so easy because of all the existing languages and cultural variations. Understanding cultural variations is crucial because it affects how a language is formed and used. This chapter covers just that, from the use and working of AIoT to how a computer can store and understand language-specific information and work with it. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021. All rights reserved.",Final,
Stokes P.A.,"Stokes, Peter A. (56846903200)",56846903200,Holistically Modelling the Medieval Book: Towards a Digital Contribution,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104341916&doi=10.1515%2fang-2021-0002&partnerID=40&md5=4f1956a8f0699764341ad4e5f950bf71,"The book has long played an important role in medieval and indeed modern culture, being at thesame time a carrier of texts and images, a sign potentially of wealth and/or education, a site of enquiry for modern scholarship for literature, history, linguistics, palaeography, codicology, art history, and more. The 'archaeology of the book' can tell us about its history (or biography) as well as the cultures that produced and used it, right up to its present ownership. This multidimensionality of the object has long been known, but it has also proven a challenge to digital approaches which (like all representations) are by their nature models that involve conscious or unconscious selection of particular aspects, and that have been more successful in some aspects than others. Thisthen raises the question to what degree these different viewpoints can be brought together into something approaching a holistic view, while always allowing for the tension between standardisation and innovation, and while remembering that a 'complete model' is a tautology, neither possible nor desirable.  © 2021 Walter de Gruyter GmbH, Berlin/Boston.",Final,
Rackevičienė S.; Utka A.; Mockienė L.; Rokas A.,"Rackevičienė, Sigita (56717770300); Utka, Andrius (26632661300); Mockienė, Liudmila (57215660702); Rokas, Aivaras (57219504131)",56717770300; 26632661300; 57215660702; 57219504131,Methodological Framework for the Development of an English-Lithuanian Cybersecurity Termbase; [Anglų-lietuvių kalbų kibernetinio saugumo terminų bazės kūrimo metodikos modelis],1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121922199&doi=10.5755%2fj01.sal.1.39.29156&partnerID=40&md5=6f901adc6b6422983b5c7aa9b9c25531,"The aim of the paper is to present a methodological framework for the development of an Abstract English-Lithuanian bilingual termbase in the cybersecurity domain, which can be applied as a model for other language pairs and other specialised domains. It is argued that the presented methodological approach can ensure creation of high-quality bilingual termbases even with limited available resources. The paper touches upon the methods and problems of dataset (corpora) compilation, terminology annotation, automatic bilingual term extraction (BiTE) and alignment, knowledge-rich context extraction, and linguistic linked open data (LLOD) technologies. The paper presents theoretical considerations as well as the arguments on the effectiveness of the described methods. The theoretical analysis and a pilot study allow arguing that: 1) a combination of parallel and comparable corpora enable to considerably expand the amount and variety of data sources that can be used for terminology extraction; this methodology is especially important for less-resourced languages which often lack parallel data; 2) deep learning systems trained by using gold standard corpora (manually annotated data) allow effective automatization of extraction of terminological data and metadata, which enables to regularly update termbases with minimised manual input; 3) LLOD technologies enable to integrate the terminological data into the global linguistic data ecosystem and make it reusable, searchable and discoverable across the Web. © 2021 Kaunas University of Technology. All rights reserved.",Final,All Open Access; Gold Open Access; Green Open Access
Garcia-Silva A.; Denaux R.; Gomez-Perez J.M.,"Garcia-Silva, Andres (36718996900); Denaux, Ronald (8958242500); Gomez-Perez, Jose Manuel (23485087500)",36718996900; 8958242500; 23485087500,On the impact of knowledge-based linguistic annotations in the quality of scientific embeddings,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101797141&doi=10.1016%2fj.future.2021.02.019&partnerID=40&md5=7dd8c6f926c093f01ef4e7e542687152,"In essence, embedding algorithms work by optimizing the distance between a word and its usual context in order to generate an embedding space that encodes the distributional representation of words. In addition to single words or word pieces, other features which result from the linguistic analysis of text, including lexical, grammatical and semantic information, can be used to improve the quality of embedding spaces. However, until now we did not have a precise understanding of the impact that such individual annotations and their possible combinations may have in the quality of the embeddings. In this paper, we conduct a comprehensive study on the use of explicit linguistic annotations to generate embeddings from a scientific corpus and quantify their impact in the resulting representations. Our results show how the effect of such annotations in the embeddings varies depending on the evaluation task. In general, we observe that learning embeddings using linguistic annotations contributes to achieve better evaluation results. © 2021 Elsevier B.V.",Final,All Open Access; Green Open Access
Wang L.; Li Y.; Aslan O.; Vinyals O.,"Wang, Luyu (57219763879); Li, Yujia (55924890500); Aslan, Ozlem (57226329096); Vinyals, Oriol (24342311100)",57219763879; 55924890500; 57226329096; 24342311100,WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130644669&partnerID=40&md5=4895d13adc9319199642b638967d2d1e,"We present a new dataset ofWikipedia articles each paired with a knowledge graph, to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new datasetWikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph → text generation, graph → text retrieval and text → graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement.  © 2021 Association for Computational Linguistics.",Final,
Huang H.; Lei M.; Feng C.,"Huang, Heyan (7405614195); Lei, Ming (57210962697); Feng, Chong (35182844100)",7405614195; 57210962697; 35182844100,Graph-based reasoning model for multiple relation extraction,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092253997&doi=10.1016%2fj.neucom.2020.09.025&partnerID=40&md5=9f9d541afc98a60e2a8c0c34dd11f21d,"Linguistic knowledge is useful for various NLP tasks, but the difficulty lies in the representation and application. We consider that linguistic knowledge is implied in a large-scale corpus, while classification knowledge, the knowledge related to the definitions of entity and relation types, is implied in the labeled training data. Therefore, a corpus subgraph is proposed to mine more linguistic knowledge from the easily accessible unlabeled data, and sentence subgraphs are used to acquire classification knowledge. They jointly constitute a relation knowledge graph (RKG) to extract relations from sentences in this paper. On RKG, entity recognition can be regarded as a property value filling problem and relation classification can be regarded as a link prediction problem. Thus, the multiple relation extraction can be treated as a reasoning process for knowledge completion. We combine statistical reasoning and neural network reasoning to segment sentences into entity chunks and non-entity chunks, then propose a novel Chunk Graph LSTM network to learn the representations of entity chunks and infer the relations among them. The experiments on two standard datasets demonstrate our model outperforms the previous models for multiple relation extraction. © 2020 Elsevier B.V.",Final,
AlMousa M.; Benlamri R.; Khoury R.,"AlMousa, Mohannad (57203297062); Benlamri, Rachid (57203235506); Khoury, Richard (16021635100)",57203297062; 57203235506; 16021635100,Exploiting non-taxonomic relations for measuring semantic similarity and relatedness in WordNet,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095852763&doi=10.1016%2fj.knosys.2020.106565&partnerID=40&md5=5573a5a128dd93ea1e4d6a4101770633,"Various applications in computational linguistics and artificial intelligence employ semantic similarity to solve challenging tasks, such as word sense disambiguation, text classification, information retrieval, machine translation, and document clustering. To our knowledge, research to date rely solely on the taxonomic relation “ISA” to evaluate semantic similarity and relatedness between terms. This paper explores the benefits of using all types of non-taxonomic relations in large linked data, such as WordNet knowledge graph, to enhance existing semantic similarity and relatedness measures. We propose a holistic poly-relational approach based on a new relation-based information content and non-taxonomic-based weighted paths to devise a comprehensive semantic similarity and relatedness measure. To demonstrate the benefits of exploiting non-taxonomic relations in a knowledge graph, we used three strategies to deploy non-taxonomic relations at different granularity levels. We conduct experiments on four well-known gold standard datasets. The results of our proposed method demonstrate an improvement over the benchmark semantic similarity methods, including the state-of-the-art knowledge graph embedding techniques, that ranged from 3.8%–23.8%, 1.3%–18.3%, 31.8%–117.2%, and 19.1%–111.1%, on all gold standard datasets MC, RG, WordSim, and Mturk, respectively. These results demonstrate the robustness and scalability of the proposed semantic similarity and relatedness measure, significantly improving existing similarity measures. © 2020 Elsevier B.V.",Final,All Open Access; Green Open Access
Anand V.; Ramesh R.; Jin B.; Wang Z.; Lei X.; Lin C.-Y.,"Anand, Vishal (57221473560); Ramesh, Raksha (57221472545); Jin, Boshen (57345722700); Wang, Ziyin (57221477628); Lei, Xiaoxiao (57344957800); Lin, Ching-Yung (34768522800)",57221473560; 57221472545; 57345722700; 57221477628; 57344957800; 34768522800,MultiModal Language Modelling on Knowledge Graphs for Deep Video Understanding,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119362395&doi=10.1145%2f3474085.3479220&partnerID=40&md5=0f6c2c4ebc8eb5060ace30f8ebd1967a,"The natural language processing community has had a major interest in auto-regressive [4, 13] and span-prediction based language models [7] recently, while knowledge graphs are often referenced for common-sense based reasoning and fact-checking models. In this paper, we present an equivalence representation of span-prediction based language models and knowledge-graphs to better leverage recent developments of language modelling for multi-modal problem statements. Our method performed well, especially with sentiment understanding for multi-modal inputs, and discovered potential bias in naturally occurring videos when compared with movie-data interaction-understanding. We also release a dataset of an auto-generated questionnaire with ground-truths consisting of labels spanning across 120 relationships, 99 sentiments, and 116 interactions, among other labels for finer-grained analysis of model comparisons in the community. © 2021 ACM.",Final,
Wood I.D.; Wan S.; Johnson M.,"Wood, Ian David (56564912800); Wan, Stephen (35088889600); Johnson, Mark (55574223118)",56564912800; 35088889600; 55574223118,Integrating Lexical Information into Entity Neighbourhood Representations for Relation Prediction,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137727793&partnerID=40&md5=9aa09388b06ff0f26271296d2d15a2ea,"Relation prediction informed from a combination of text corpora and curated knowledge bases, combining knowledge graph completion with relation extraction, is a relatively little studied task. A system that can perform this task has the ability to extend an arbitrary set of relational database tables with information extracted from a document corpus. OpenKi (Zhang et al., 2019) addresses this task through extraction of named entities and predicates via OpenIE tools then learning relation embeddings from the resulting entity-relation graph for relation prediction, outperforming previous approaches. We present an extension of OpenKi that incorporates embeddings of text-based representations of the entities and the relations. We demonstrate that this results in a substantial performance increase over a system without this information. https://github.com/drevicko/OpenKI. © 2021 Association for Computational Linguistics.",Final,
Armaselu F.; Apostol E.-S.; Khan A.F.; Liebeskind C.; McGillivray B.; Truică C.-O.; Oleškevičiene G.V.,"Armaselu, Florentina (57191504666); Apostol, Elena-Simona (55365937600); Khan, Anas Fahad (57205198244); Liebeskind, Chaya (55761687500); McGillivray, Barbara (14325441100); Truică, Ciprian-Octavian (56331462000); Oleškevičiene, Giedre Valūnaite (57194015310)",57191504666; 55365937600; 57205198244; 55761687500; 14325441100; 56331462000; 57194015310,"HISTORIAE, history of socio-cultural transformation as linguistic data science. A humanities use case",1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115084095&doi=10.4230%2fOASIcs.LDK.2021.34&partnerID=40&md5=890dcdc8d00c64cac8be48579dfddd0d,"The paper proposes an interdisciplinary approach including methods from disciplines such as history of concepts, linguistics, natural language processing (NLP) and Semantic Web, to create a comparative framework for detecting semantic change in multilingual historical corpora and generating diachronic ontologies as linguistic linked open data (LLOD). Initiated as a use case (UC4.2.1) within the COST Action Nexus Linguarum, European network for Web-centred linguistic data science, the study will explore emerging trends in knowledge extraction, analysis and representation from linguistic data science, and apply the devised methodology to datasets in the humanities to trace the evolution of concepts from the domain of socio-cultural transformation. The paper will describe the main elements of the methodological framework and preliminary planning of the intended workflow. © Florentina Armaselu, Elena-Simona Apostol, Anas Fahad Khan, Chaya Liebeskind, Barbara McGillivray, Ciprian-Octavian Truică, and Giedre Valūnaite Oleškevičien e; licensed under Creative Commons License CC-BY 4.0",Final,
Ionov M.,"Ionov, Maxim (57194612761)",57194612761,APiCS-ligt: Towards semantic enrichment of interlinear glossed text,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115061858&doi=10.4230%2fOASIcs.LDK.2021.27&partnerID=40&md5=8b0740db12112bbd97074f3fc27d3c10,"This paper presents APiCS-Ligt, an LLOD version of a collection of interlinear glossed linguistic examples from APiCS, the Atlas of Pidgin and Creole Language Structures. Interlinear glossed text (IGT) plays an important role in typological and theoretical linguistic research, especially with understudied and endangered languages: It provides a way to understand linguistic phenomena without necessarily knowing the source language which is crucial for these languages since native speakers are not always easily accessible. Previously, we presented Ligt, RDF vocabulary created for representing interlinear glosses in text segments. In this paper, we present our conversion of the APiCS IGT dataset into this model and describe our efforts in linking linguistic annotations to an external ontology to add semantic representation. © Maxim Ionov; licensed under Creative Commons License CC-BY 4.0",Final,
Pan J.Z.; Edelstein E.; Bansky P.; Wyner A.,"Pan, Jeff Z. (8856621200); Edelstein, Elspeth (57204806756); Bansky, Patrik (57215414288); Wyner, Adam (7006211789)",8856621200; 57204806756; 57215414288; 7006211789,A knowledge graph based approach to social science surveys,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118212118&doi=10.1162%2fdint_a_00107&partnerID=40&md5=5cbe3b4320d6fbe1437bfd2b7caa966c,"Recent success of knowledge graphs has spurred interest in applying them in open science, such as on intelligent survey systems for scientists. However, efforts to understand the quality of candidate survey questions provided by these methods have been limited. Indeed, existing methods do not consider the type of on-the-fly content planning that is possible for face-to-face surveys and hence do not guarantee that selection of subsequent questions is based on response to previous questions in a survey. To address this limitation, we propose a dynamic and informative solution for an intelligent survey system that is based on knowledge graphs. To illustrate our proposal, we look into social science surveys, focusing on ordering the questions of a questionnaire component by their level of acceptance, along with conditional triggers that further customise participants’ experience. Our main findings are: (i) evaluation of the proposed approach shows that the dynamic component can be beneficial in terms of lowering the number of questions asked per variable, thus allowing more informative data to be collected in a survey of equivalent length; and (ii) a primary advantage of the proposed approach is that it enables grouping of participants according to their responses, so that participants are not only served appropriate follow-up questions, but their responses to these questions may be analysed in the context of some initial categorisation. We believe that the proposed approach can easily be applied to other social science surveys based on grouping definitions in their contexts. The knowledge-graph-based intelligent survey approach proposed in our work allows online questionnaires to approach face-to-face interaction in their level of informativity and responsiveness, as well as duplicating certain advantages of interview-based data collection. © 2021 Chinese Academy of Sciences.",Final,All Open Access; Gold Open Access; Green Open Access
Chiarcos C.; Ionov M.,"Chiarcos, Christian (22333764800); Ionov, Maxim (57194612761)",22333764800; 57194612761,Linking discourse marker inventories,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115090315&doi=10.4230%2fOASIcs.LDK.2021.40&partnerID=40&md5=8ce3d81f124faee294626d7eb577c118,"The paper describes the first comprehensive edition of machine-readable discourse marker lexicons. Discourse markers such as and, because, but, though or thereafter are essential communicative signals in human conversation, as they indicate how an utterance relates to its communicative context. As much of this information is implicit or expressed differently in different languages, discourse parsing, context-adequate natural language generation and machine translation are considered particularly challenging aspects of Natural Language Processing. Providing this data in machine-readable, standard-compliant form will thus facilitate such technical tasks, and moreover, allow to explore techniques for translation inference to be applied to this particular group of lexical resources that was previously largely neglected in the context of Linguistic Linked (Open) Data. © Christian Chiarcos and Maxim Ionov; licensed under Creative Commons License CC-BY 4.0",Final,
Alberts H.; Huang N.; Deshpande Y.R.; Liu Y.; Cho K.; Vania C.; Calixto I.,"Alberts, Houda (57197778831); Huang, Ningyuan (57221251237); Deshpande, Yash R. (57219793541); Liu, Yibo (57219796995); Cho, Kyunghyun (55722769200); Vania, Clara (55008384600); Calixto, Iacer (55754926900)",57197778831; 57221251237; 57219793541; 57219796995; 55722769200; 55008384600; 55754926900,VisualSem: A High-quality Knowledge Graph for Vision & Language,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133780792&partnerID=40&md5=6ba1f09f115e5471cdc85c0285f0b3e2,"An exciting frontier in natural language understanding (NLU) and generation (NLG) calls for (vision-and-) language models that can efficiently access external structured knowledge repositories. However, many existing knowledge bases only cover limited domains, or suffer from noisy data, and most of all are typically hard to integrate into neural language pipelines. To fill this gap, we release VisualSem: a high-quality knowledge graph (KG) which includes nodes with multilingual glosses, multiple illustrative images, and visually relevant relations. We also release a neural multi-modal retrieval model that can use images or sentences as inputs and retrieves entities in the KG. This multi-modal retrieval model can be integrated into any (neural network) model pipeline. We encourage the research community to use VisualSem for data augmentation and/or as a source of grounding, among other possible uses. VisualSem as well as the multi-modal retrieval models are publicly available and can be downloaded in this URL: https://github.com/iacercalixto/visualsem. © 2021 Association for Computational Linguistics.",Final,
Kirillovich A.; Shaekhov M.; Galieva A.; Nevzorova O.; Ilvovsky D.; Loukachevitch N.,"Kirillovich, Alexander (55994716700); Shaekhov, Marat (57218311256); Galieva, Alfiya (56500587700); Nevzorova, Olga (6506234633); Ilvovsky, Dmitry (55967196200); Loukachevitch, Natalia (6504197092)",55994716700; 57218311256; 56500587700; 6506234633; 55967196200; 6504197092,TatWordNet: A linguistic linked open data-integrated WordNet resource for tatar,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115081049&doi=10.4230%2fOASIcs.LDK.2021.16&partnerID=40&md5=2eed9fc4b40da810c25e9844c161869c,"We present the first release of TatWordNet (http://WordNet.tatar), a WordNet resource for Tatar. TatWordNet has been constructed by the combination of the expand and the merge approaches. The synsets of TatWordNet have been compiled by: (i) the automatic conversion of concepts of TatThes, a socio-political Tatar; (ii) semi-automatic translation of synsets of RuWordNet, a WordNet resource for Russian with the followed manual verification and correction; (iii) manual translation of base RuWordNet synsets; (iv) and manual translation of the all hypernyms of the previously translated RuWordNet synsets. The currents version of TatWordNet contains 18,583 synsets, 36,540 lexical entries and 49,525 senses. The resource has been published to the Linguistic Linked Open Data cloud and interlinked with the Global WordNet Grid. © Alexander Kirillovich, Marat Shaekhov, Alfiya Galieva, Olga Nevzorova, Dmitry Ilvovsky, and Natalia Loukachevitch; licensed under Creative Commons License CC-BY 4.0",Final,
Liu C.; Cohn T.; Frermann L.,"Liu, Chunhua (57275269700); Cohn, Trevor (15043872200); Frermann, Lea (55747365100)",57275269700; 15043872200; 55747365100,Commonsense Knowledge in Word Associations and ConceptNet,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128898257&partnerID=40&md5=d8f3fcbf1d0993a84a8fef0833f0525b,"Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This commonsense knowledge is rarely communicated explicitly, however, understanding how commonsense knowledge is represented in different paradigms is important for both deeper understanding of human cognition and for augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge: ConceptNet, an engineered relational database, and SWOW a knowledge graph derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two graphs, as well as the extent to which they encode situational commonsense knowledge. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs. © 2021 Association for Computational Linguistics.",Final,
Pellegrini M.; Litta E.; Passarotti M.; Sprugnoli R.; Mambrini F.; Moretti G.,"Pellegrini, Matteo (57220703991); Litta, Eleonora (57192942633); Passarotti, Marco (56957111300); Sprugnoli, Rachele (15077007200); Mambrini, Francesco (57190293497); Moretti, Giovanni (57190677309)",57220703991; 57192942633; 56957111300; 15077007200; 57190293497; 57190677309,LiLa Linking Latin Tutorial,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126045333&partnerID=40&md5=4631fe94637a8a089afa3248a70ac2cb,"By applying Linked Data and FAIR principles, the LiLa: Linking Latin project makes linguistic resources (e.g. textual corpora, lexica, dictionaries) for Latin interact on the web via a lexical basis made of a collection of lemmas known as the LiLa Lemma Bank. In this hands-on tutorial, participants learned how to link a Latin text to the LiLa Knowledge Base of linguistic resources. By the end of the tutorial participants should have a better understanding of the benefits of linking a Latin text to the LiLa Knowledge Base, and of the work required to help machines process linguistic data and produce quality resources. © 2021 Copyright for this paper by its authors",Final,
Sprugnoli R.; Passarotti M.; Testori M.; Moretti G.,"Sprugnoli, Rachele (15077007200); Passarotti, Marco (56957111300); Testori, Marinella (57204895887); Moretti, Giovanni (57190677309)",15077007200; 56957111300; 57204895887; 57190677309,Extending and Using a Sentiment Lexicon for Latin in a Linked Data Framework,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126062402&partnerID=40&md5=9b41dc7547f84161c3b88dc7d0c48d59,"In this paper we present the methodology followed to extend a Latin sentiment lexicon (called LatinAffectus), the process of inclusion of the lexicon in a knowledge base of interoperable linguistic resources for Latin and one use case performed on the treebank of Dante Alighieri's Latin works annotated following the Universal Dependencies guidelines. In addition, we report on our first attempt at linking the polarity scores of SentiWordNet 3.0 to a manually revised version of Latin WordNet. © 2021 Copyright for this paper by its authors",Final,
Liang Z.; Yang J.; Liu H.; Huang K.,"Liang, Zongwei (57204164042); Yang, Junan (57223825387); Liu, Hui (56125442700); Huang, Keju (57201999317)",57204164042; 57223825387; 56125442700; 57201999317,A Semantic Filter Based on Relations for Knowledge Graph Completion,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127045685&partnerID=40&md5=52d36181394c61b12bcc1d67dedb2105,"Knowledge graph embedding, representing entities and relations in the knowledge graphs with high-dimensional vectors, has made significant progress in link prediction. More researchers have explored the representational capabilities of models in recent years. That is, they investigate better representational models to fit symmetry/antisymmetry and combination relationships. The current embedding models are more inclined to utilize the identical vector for the same entity in various triples to measure the matching performance. The observation that measuring the rationality of specific triples means comparing the matching degree of the specific attributes associated with the relations is well-known. Inspired by this fact, this paper designs Semantic Filter Based on Relations(SFBR) to extract the required attributes of the entities. Then the rationality of triples is compared under these extracted attributes through the traditional embedding models. The semantic filter module can be added to most geometric and tensor decomposition models with minimal additional memory. Experiments on the benchmark datasets show that the semantic filter based on relations can suppress the impact of other attribute dimensions and improve link prediction performance. The tensor decomposition models with SFBR have achieved state-of-the-art. © 2021 Association for Computational Linguistics",Final,
Postiglione M.,"Postiglione, Marco (57219928964)",57219928964,Towards an Italian Healthcare Knowledge Graph,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118970715&doi=10.1007%2f978-3-030-89657-7_29&partnerID=40&md5=943210e16e59138126728bf8aa3fd786,"Electronic Health Records (EHRs), Big Data, Knowledge Graphs (KGs) and machine learning can potentially be a great step towards the technological shift from the one-size-fit-all medicine, where treatments are based on an equal protocol for all the patients, to the precision medicine, which takes count of all their individual information: lifestyle, preferences, health history, genomics, and so on. However, the lack of data which characterizes low-resource languages is a huge limitation for the application of the above-mentioned technologies. In this work, we will try to fill this gap by means of transformer language models and few-shot approaches and we will apply similarity-based deep learning techniques on the constructed KG for downstream applications. The proposed architecture is general and thus applicable to any low-resource language. © 2021, Springer Nature Switzerland AG.",Final,
Vasilevich A.; Wetzel M.,"Vasilevich, Alena (57224534828); Wetzel, Michael (57214890582)",57224534828; 57214890582,Multilingual Knowledge Systems as Linguistic Linked Open Data for European Language Grid,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125997399&partnerID=40&md5=a5ab353907b44cacfc1c709258748574,"Creation and re-usability of language resources in accordance with Linked Data principles is a valuable asset in the modern data world. In this paper we describe the contributions made to extend the LLOD stack with a new resource, Coreon MKS, bringing together concept-oriented, language-agnostic terminology management and graph-based knowledge organization. We dwell on our approach to mirroring of Coreon's original data structure to RDF and supplying it with a real-time SPARQL endpoint. We integrate MKS into the existing ELG infrastructure, using it as a platform for making the published MKS discoverable and retrievable via a industry-standard interface. While we apply this approach to LLOD-ify Coreon MKS, it can provide a relevant input for standardisation bodies and interoperability communities, acting as a blueprint for similar integration activities. © 2021 Copyright for this paper by its authors",Final,
Chen W.; Chen X.; Xiong S.,"Chen, Wei (57231617800); Chen, Xiaoying (57208188277); Xiong, Shengwu (57203905556)",57231617800; 57208188277; 57203905556,Global entity alignment with Gated Latent Space Neighborhood Aggregation,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123405548&partnerID=40&md5=ba6adc99e7640ec0f7cc1975e13b3747,"Existing entity alignment models mainly use the topology structure of the original knowledge graph and have achieved promising performance. However, they are still challenged by the heterogeneous topological neighborhood structures, which could cause the models to produce different representations of counterpart entities. In the paper, we propose a global entity alignment model with gated latent space neighborhood aggregation (LatsEA) to address this challenge. Latent space neighborhood is formed by calculating the similarity between the entity embeddings, it can introduce long-range neighbors to expand the topological neighborhood and reconcile the heterogeneous neighborhood structures. Meanwhile, it uses vanilla GCN to aggregate the topological neighborhood and latent space neighborhood respectively. Then, it uses an average gating mechanism to aggregate topological neighborhood information and latent space neighborhood information of the central entity. In order to further consider the interdependence between entity alignment decisions, we propose a global entity alignment strategy, i.e., formulate entity alignment as the maximum bipartite matching problem, which is effectively solved by Hungarian algorithm. Our experiments with ablation studies on three real-world entity alignment datasets prove the effectiveness of the proposed model. Latent space neighborhood information and global entity alignment decisions both contributes to the entity alignment performance improvement. © 2021 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License",Final,
Iglesias C.Á.; Sánchez-Rada J.F.,"Iglesias, Carlos Á. (56357213400); Sánchez-Rada, J. Fernando (56426347900)",56357213400; 56426347900,Sentiment Analysis meets Linguistic Linked Data: An overview of the State of the Art,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126004020&partnerID=40&md5=17ad64d61f470f48ea762b6d6ccc710b,"Sentiment Analysis has received plenty of attention from both industry and academia because its application can reveal new insights from social interactions. The wide range of final users of these services includes public services, businesses, and individuals. Linked data technologies provide an effective and seamless way for integrating services and interlinking language resources. This paper provides an introduction to the main approaches, applications, and datasets. © 2021 Copyright for this paper by its authors",Final,
Calixto I.; Raganato A.; Pasini T.,"Calixto, Iacer (55754926900); Raganato, Alessandro (57190841330); Pasini, Tommaso (56349748900)",55754926900; 57190841330; 56349748900,Wikipedia Entities as Rendezvous across Languages: Grounding Multilingual Language Models by Predicting Wikipedia Hyperlinks,1,,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128159332&partnerID=40&md5=ceeed2bdf67e50e491da5199f5ac7045,"Masked language models have quickly become the de facto standard when processing text. Recently, several approaches have been proposed to further enrich word representations with external knowledge sources such as knowledge graphs. However, these models are devised and evaluated in a monolingual setting only. In this work, we propose a language-independent entity prediction task as an intermediate training procedure to ground word representations on entity semantics and bridge the gap across different languages by means of a shared vocabulary of entities. We show that our approach effectively injects new lexical-semantic knowledge into neural models, improving their performance on different semantic tasks in the zero-shot crosslingual setting. As an additional advantage, our intermediate training does not require any supplementary input, allowing our models to be applied to new datasets right away. In our experiments, we use Wikipedia articles in up to 100 languages and already observe consistent gains compared to strong baselines when predicting entities using only the English Wikipedia. Further adding extra languages lead to improvements in most tasks up to a certain point, but overall we found it non-trivial to scale improvements in model transferability by training on ever increasing amounts of Wikipedia languages. © 2021 Association for Computational Linguistics.",Final,
Sakor A.; Singh K.; Patel A.; Vidal M.-E.,"Sakor, Ahmad (57200274370); Singh, Kuldeep (57212017864); Patel, Anery (57214762067); Vidal, Maria-Esther (7202765018)",57200274370; 57212017864; 57214762067; 7202765018,Falcon 2.0: An Entity and Relation Linking Tool over Wikidata,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095866274&doi=10.1145%2f3340531.3412777&partnerID=40&md5=89836c6a6ea4d848ca13698761f2d222,"The Natural Language Processing (NLP) community has significantly contributed to the solutions for entity and relation recognition from a natural language text, and possibly linking them to proper matches in Knowledge Graphs (KGs). Considering Wikidata as the background KG, there are still limited tools to link knowledge within the text to Wikidata. In this paper, we present Falcon 2.0, the first joint entity and relation linking tool over Wikidata. It receives a short natural language text in the English language and outputs a ranked list of entities and relations annotated with the proper candidates in Wikidata. The candidates are represented by their Internationalized Resource Identifier (IRI) in Wikidata. Falcon 2.0 resorts to the English language model for the recognition task (e.g., N-Gram tiling and N-Gram splitting), and then an optimization approach for the linking task. We have empirically studied the performance of Falcon 2.0 on Wikidata and concluded that it outperforms all the existing baselines. Falcon 2.0 is open source and can be reused by the community; all the required instructions of Falcon 2.0 are well-documented at our GitHub repository (https://github.com/SDM-TIB/falcon2.0). We also demonstrate an online API, which can be run without any technical expertise. Falcon 2.0 and its background knowledge bases are available as resources at https://labs.tib.eu/falcon/falcon2/. © 2020 Owner/Author.",Final,All Open Access; Bronze Open Access; Green Open Access
Declerck T.; Gracia J.; McCrae J.P.,"Declerck, Thierry (22333556000); Gracia, Jorge (55392626700); McCrae, John P. (36666801700)",22333556000; 55392626700; 36666801700,"COST Action ""European network for Web-centred linguistic data science"" (NexusLinguarum); [Acción COST ""Red europea para la ciencia de datos lingüísticos centrada en la web"" (NexusLinguarum)]",1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100976108&doi=10.26342%2f2020-65-11&partnerID=40&md5=1452cb92162078615384e2f7b8d42a15,"We present the current state of the large ""European network for Web-centred linguistic data science"". In its first phase, the network has put in place several working groups to deal with specific topics. The network also already implemented a first round of Short Term Scientific Missions (STSM). © 2020 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.",Final,
Sun J.; Zhou Y.; Zong C.,"Sun, Jian (57756715200); Zhou, Yu (57169094000); Zong, Chengqing (7005615574)",57756715200; 57169094000; 7005615574,Dual Attention Network for Cross-lingual Entity Alignment,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118162781&partnerID=40&md5=61cd41f1405fabda8471fa50432ba931,"Cross-lingual Entity alignment is an essential part of building a knowledge graph, which can help integrate knowledge among different language knowledge graphs. In the real KGs, there exists an imbalance among the information in the same hierarchy of corresponding entities, which results in the heterogeneity of neighborhood structure, making this task challenging. To tackle this problem, we propose a dual attention network for cross-lingual entity alignment (DAEA). Specifically, our dual attention consists of relation-aware graph attention and hierarchical attention. The relation-aware graph attention aims at selectively aggregating multi-hierarchy neighborhood information to alleviate the difference of heterogeneity among counterpart entities. The hierarchical attention adaptively aggregates the low-hierarchy and the high-hierarchy information, which is beneficial to balance the neighborhood information of counterpart entities and distinguish non-counterpart entities with similar structures. Finally, we treat cross-lingual entity alignment as a process of linking prediction. Experimental results on three real-world cross-lingual entity alignment datasets have shown the effectiveness of DAEA. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Pan Y.; Chen Q.; Peng W.; Wang X.; Hu B.; Liu X.; Chen J.; Zhou W.,"Pan, Youcheng (57200421650); Chen, Qingcai (57207818164); Peng, Weihua (57220993199); Wang, Xiaolong (57204318567); Hu, Baotian (55647462200); Liu, Xin (57206739249); Chen, Junying (57385923200); Zhou, Wenxiu (57384305600)",57200421650; 57207818164; 57220993199; 57204318567; 55647462200; 57206739249; 57385923200; 57384305600,MedWriter: Knowledge-Aware Medical Text Generation,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139892424&partnerID=40&md5=e3ce78079138dbef5b8f502fc13e0dea,"To exploit the domain knowledge to guarantee the correctness of generated text has been a hot topic in recent years, especially for high professional domains such as medical. However, most of recent works only consider the information of unstructured text rather than structured information of the knowledge graph. In this paper, we focus on the medical topic-to-text generation task and adapt a knowledge-aware text generation model to the medical domain, named MedWriter, which not only introduces the specific knowledge from the external MKG but also is capable of learning graph-level representation. We conduct experiments on a medical literature dataset collected from medical journals, each of which has a set of topic words, an abstract of medical literature and a corresponding knowledge graph from CMeKG. Experimental results demonstrate incorporating knowledge graph into generation model can improve the quality of the generated text and has robust superiority over the competitor methods. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Kancheva Z.; Radev I.,"Kancheva, Zara (57215965215); Radev, Ivaylo (57215965292)",57215965215; 57215965292,Linguistic vs. Encyclopedic knowledge. classification of mwes on thbase of domain information,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113186014&partnerID=40&md5=4e2910b0455b4635b6086dd44465ddb1,"This paper reports on the first steps in the creation of linked data through the mapping of BTB-WordNet and the Bulgarian Wikipedia. The task of expanding the BTB-WordNet with encyclopedic knowledge is done by mapping its synsets to Wikipedia pages with many MWEs found in the articles and subjected to further analysis. We look for a way to filter the Wikipedia MWEs in the effort of selecting the ones most beneficial to the enrichment of BTB-WN. © 2020, Institute for Bulgarian Language. All rights reserved.",Final,
Ivanov V.; Solnyshkina M.,"Ivanov, Vladimir (57195101229); Solnyshkina, Marina (56429529500)",57195101229; 56429529500,A method for assessment of text complexity based on knowledge graphs,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105003287&partnerID=40&md5=c02abc5d81e98943e3c6b7caaaca1928,"The study explores the problem of assessing text complexity. In this paper we focus on measuring conceptual complexity and propose using knowledge graphs to this end. On the first stage of the research, RuThes-Lite thesaurus, a linguistic knowledge base with a total size of over 100,000 text entries (words and collocations), was used to elicit concepts in the texts of schoolbooks and represent text fragments as graphs. In the second series of experiments, we assessed complexity of English texts using knowledge graphs WordNet and Wikidata. Finally, we identified graph-based semantic characteristics of texts impacting complexity. The most significant research findings include identification of statistically significant correlations of the selected features, such as node degree, number of connected nodes, average shortest path, with text complexity. © 2020 Copyright for this paper by its authors.",Final,
Nordhoff S.,"Nordhoff, Sebastian (55202292000)",55202292000,Modelling and annotating interlinear glossed text from 280 different endangered languages as Linked Data with LIGT,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115109079&partnerID=40&md5=fc42847c2f8cfff3b81a5d4294b7955d,"This paper reports on the harvesting, analysis, and annotation of 20k documents from 4 different endangered language archives in 280 different low-resource languages. The documents are heterogeneous as to their provenance (holding archive, language, geographical area, creator) and internal structure (annotation types, metalanguages), but they have the ELAN-XML format in common. Typical annotations include sentence-level translations, morpheme-segmentation, morpheme-level translations, and parts-of-speech. The ELAN format gives a lot of freedom to document creators, and hence the data set is very heterogeneous. We use regularities in the ELAN format to arrive at a common internal representation of sentences, words, and morphemes, with translations into one or more additional languages. Building upon the paradigm of Linguistic Linked Open Data (LLOD, Chiarcos et al. (2012b)), the document elements receive unique identifiers and are linked to other resources such as Glottolog for languages, Wikidata for semantic concepts, and the Leipzig Glossing Rules list for category abbreviations. We provide an RDF export in the LIGT format (Chiarcos and Ionov (2019)), enabling uniform and interoperable access with some semantic enrichments to a formerly disparate resource type difficult to access. Two use cases (semantic search and colexification) are presented to show the viability of the approach. © 2020 14th Linguistic Annotation Workshop, LAW 2020 - Proceedings. All Rights Reserved.",Final,
Bajčetić L.; Declerck T.,"Bajčetić, L. (57203989889); Declerck, T. (22333556000)",57203989889; 22333556000,Interlinking slovene language datasets,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115011533&partnerID=40&md5=2309a0384246dbb077d806ffb819c97c,"We present the current implementation state of our work consisting in interlinking language data and linguistic information included in different types of Slovenian language resources. The types of resources we currently deal with are a lexical database (which also contains collocations and example sentences), a morphological lexicon, and the Slovene WordNet. We first transform the encoding of the original data into the OntoLex-Lemon model and map the different descriptors used in the original sources onto the LexInfo vocabulary. This harmonization step is enabling the interlinking of the various types of information included in the different resources, by using relations defined in OntoLex-Lemon. As a result, we obtain a partial merging of the information that was originally distributed over different resources, which is leading to a cross-enrichment of those original data sources. A final goal of the presented work is to publish the linked and merged Slovene linguistic datasets in the Linguistic Linked Open Data cloud. © 2020, European Association for Lexicography. All rights reserved.",Final,
Basaldella M.; Liu F.; Shareghi E.; Collier N.,"Basaldella, Marco (56728588100); Liu, Fangyu (57192190518); Shareghi, Ehsan (35957521400); Collier, Nigel (7004876365)",56728588100; 57192190518; 35957521400; 7004876365,COMETA: A corpus for medical entity linking in the social media,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104050301&partnerID=40&md5=171cac0eda6616793ff18f4f90b8ac14,"Whilst there has been growing progress in Entity Linking (EL) for general language, existing datasets fail to address the complex nature of health terminology in layman's language. Meanwhile, there is a growing need for applications that can understand the public's voice in the health domain. To address this we introduce a new corpus called COMETA, consisting of 20k English biomedical entity mentions from Reddit expert-annotated with links to SNOMED CT, a widely-used medical knowledge graph. Our corpus satisfies a combination of desirable properties, from scale and coverage to diversity and quality, that to the best of our knowledge has not been met by any of the existing resources in the field. Through benchmark experiments on 20 EL baselines from string- to neural-based models we shed light on the ability of these systems to perform complex inference on entities and concepts under 2 challenging evaluation scenarios. Our experimental results on COMETA illustrate that no golden bullet exists and even the best mainstream techniques still have a significant performance gap to fill, while the best solution relies on combining different views of data. © 2020 Association for Computational Linguistics",Final,
Wu S.; Li Y.; Zhang D.; Zhou Y.; Wu Z.,"Wu, Sixing (57226035165); Li, Ying (56342873200); Zhang, Dawei (55968068300); Zhou, Yang (55043481500); Wu, Zhonghai (36186428900)",57226035165; 56342873200; 55968068300; 55043481500; 36186428900,Diverse and informative dialogue generation with context-specific commonsense knowledge awareness,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098764003&partnerID=40&md5=06cd1ae45bf6e9d828a4ddc212e64d99,"Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from knowledge graphs. While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the commonsense knowledge for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments. © 2020 Association for Computational Linguistics",Final,
Ghosh S.; Kundu A.; Pramanick A.; Bhattacharya I.,"Ghosh, Subhasish (57271767000); Kundu, Arpita (57271909400); Pramanick, Aniket (57199053591); Bhattacharya, Indrajit (14024110800)",57271767000; 57271909400; 57199053591; 14024110800,Discovering knowledge graph schema from short natural language text via dialog,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118464513&partnerID=40&md5=4f8afa6b778a6d12087b213c9aa77ae4,"We study the problem of schema discovery for knowledge graphs. We propose a solution where an agent engages in multi-turn dialog with an expert for this purpose. Each minidialog focuses on a short natural language statement, and looks to elicit the expert's desired schema-based interpretation of that statement, taking into account possible augmentations to the schema. The overall schema evolves by performing dialog over a collection of such statements. We take into account the probability that the expert does not respond to a query, and model this probability as a function of the complexity of the query. For such mini-dialogs with response uncertainty, we propose a dialog strategy that looks to elicit the schema over as short a dialog as possible. By combining the notion of uncertainty sampling from active learning with generalized binary search, the strategy asks the query with the highest expected reduction of entropy. We show that this significantly reduces dialog complexity while engaging the expert in meaningful dialog. © 2020 Association for Computational Linguistics.",Final,
Xiao D.; Wang N.; Yu J.; Zhang C.; Wu J.,"Xiao, Dinghe (57219715001); Wang, Nannan (57220209445); Yu, Jiangang (57219710937); Zhang, Chunhong (17347108000); Wu, Jiaqi (57220210051)",57219715001; 57220209445; 57219710937; 17347108000; 57220210051,A Practice of Tourism Knowledge Graph Construction based on Heterogeneous Information,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123925498&partnerID=40&md5=d8a760f15ff7c49db567686e5f7538ac,"The increasing amount of semi-structured and unstructured data on tourism websites brings a need for information extraction (IE) so as to construct a Tourism-domain Knowledge Graph (TKG), which is helpful to manage tourism information and develop downstream applications such as tourism search engine, recommendation and Q & A. However, the existing TKG is deficient, and there are few open methods to promote the construction and widespread application of TKG. In this paper, we present a systematic framework to build a TKG for Hainan, collecting data from popular tourism websites and structuring it into triples. The data is multi-source and heterogeneous, which raises a great challenge for processing it. So we develop two pipelines of processing methods for semi-structured data and unstructured data respectively. We refer to tourism InfoBox for semi-structured knowledge extraction and leverage deep learning algorithms to extract entities and relations from unstructured travel notes, which are colloquial and high-noise, and then we fuse the extracted knowledge from two sources. Finally, a TKG with 13 entity types and 46 relation types is established, which totally contains 34,079 entities and 441,371 triples. The systematic procedure proposed by this paper can construct a TKG from tourism websites, which can further applied to many scenarios and provide detailed reference for the construction of other domain-specific knowledge graphs. © 2020 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License",Final,
Shang C.; Dash S.; Chowdhury M.F.M.; Mihindukulasooriya N.; Gliozzo A.,"Shang, Chao (57202291768); Dash, Sarthak (57196468028); Chowdhury, Md Faisal Mahbub (55604498400); Mihindukulasooriya, Nandana (56406504100); Gliozzo, Alfio (55893529800)",57202291768; 57196468028; 55604498400; 56406504100; 55893529800,Taxonomy construction of unseen domains via graph-based cross-domain knowledge transfer,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101645961&partnerID=40&md5=8b71815e0578f3c59caba73dcc253e7c,"Extracting lexico-semantic relations as graph-structured taxonomies, also known as taxonomy construction, has been beneficial in a variety of NLP applications. Recently Graph Neural Network (GNN) has shown to be powerful in successfully tackling many tasks. However, there has been no attempt to exploit GNN to create taxonomies. In this paper, we propose Graph2Taxo, a GNN-based cross-domain transfer framework for the taxonomy construction task. Our main contribution is to learn the latent features of taxonomy construction from existing domains to guide the structure learning of an unseen domain. We also propose a novel method of directed acyclic graph (DAG) generation for taxonomy construction. Specifically, our proposed Graph2Taxo uses a noisy graph constructed from automatically extracted noisy hyponym-hypernym candidate pairs, and a set of taxonomies for some known domains for training. The learned model is then used to generate taxonomy for a new unknown domain given a set of terms for that domain. Experiments on benchmark datasets from science and environment domains show that our approach attains significant improvements correspondingly over the state of the art. © 2020 Association for Computational Linguistics",Final,
Kanojia D.; Dabre R.; Dewangan S.; Bhattacharyya P.; Haffari G.; Kulkarni M.,"Kanojia, Diptesh (56287676100); Dabre, Raj (56288462700); Dewangan, Shubham (57223298352); Bhattacharyya, Pushpak (7101803108); Haffari, Gholamreza (24338096600); Kulkarni, Malhar (57213980897)",56287676100; 56288462700; 57223298352; 7101803108; 24338096600; 57213980897,Harnessing Cross-lingual Features to Improve Cognate Detection for Low-resource Languages,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107052021&partnerID=40&md5=d2309ba9f3986911ac6f28964561d9e0,"Cognates are variants of the same lexical form across different languages; for example “fonema” in Spanish and “phoneme” in English are cognates, both of which mean “a unit of sound”. The task of automatic detection of cognates among any two languages can help downstream NLP tasks such as Cross-lingual Information Retrieval, Computational Phylogenetics, and Machine Translation. In this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen Indian Languages. Our approach introduces the use of context from a knowledge graph to generate improved feature representations for cognate detection. We then evaluate the impact of our cognate detection mechanism on neural machine translation (NMT), as a downstream task. We evaluate our methods to detect cognates on a challenging dataset of twelve Indian languages, namely, Sanskrit, Hindi, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam. Additionally, we create evaluation datasets for two more Indian languages, Konkani and Nepali1. We observe an improvement of up to 18% points, in terms of F-score, for cognate detection. Furthermore, we observe that cognates extracted using our method help improve NMT quality by up to 2.76 BLEU. We also release2 our code, newly constructed datasets and cross-lingual models publicly. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
da Silva A.L.; Rigo S.J.; de Moraes J.B.,"da Silva, Augusto Lopes (57210603547); Rigo, Sandro José (57191605344); de Moraes, Jéssica Braun (57221913940)",57210603547; 57191605344; 57221913940,An algorithm to generate short sentences in natural language from linked open data based on linguistic templates,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100554753&partnerID=40&md5=00e490a74e75e2f5a51c9f83f251b4ab,"The generation of natural language phrases from Linked Open Data can benefit from a significant amount of information available on the internet, as well as from the existence of properties within them, which appears, mostly, in the RDF format. These properties can represent semantic relationships between concepts that might help in creating sentences in natural language. Nevertheless, research in this field tends not to use the information in RDF. We support that this is a factor that might foster the generation of more natural phrases. In this scenario, this research explores these RDF properties for the generation of natural language phrases. The short sentences generated by the algorithm implementation were evaluated regarding their fluency by linguists and native English speakers. The results show that the sentences generated are promising regarding sentence fluency. Copyright © 2020 Inderscience Enterprises Ltd.",Final,
Cimiano P.; Chiarcos C.; McCrae J.P.; Gracia J.,"Cimiano, Philipp (15838793700); Chiarcos, Christian (22333764800); McCrae, John P. (36666801700); Gracia, Jorge (55392626700)",15838793700; 22333764800; 36666801700; 55392626700,"Linguistic Linked Data: Representation, Generation and Applications",1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115737502&doi=10.1007%2f978-3-030-30225-2&partnerID=40&md5=9490e5cabe8ef19303537976b029bd3b,"This is the first monograph on the emerging area of linguistic linked data. Presenting a combination of background information on linguistic linked data and concrete implementation advice, it introduces and discusses the main benefits of applying linked data (LD) principles to the representation and publication of linguistic resources, arguing that LD does not look at a single resource in isolation but seeks to create a large network of resources that can be used together and uniformly, and so making more of the single resource. The book describes how the LD principles can be applied to modelling language resources. The first part provides the foundation for understanding the remainder of the book, introducing the data models, ontology and query languages used as the basis of the Semantic Web and LD and offering a more detailed overview of the Linguistic Linked Data Cloud. The second part of the book focuses on modelling language resources using LD principles, describing how to model lexical resources using Ontolex-lemon, the lexicon model for ontologies, and how to annotate and address elements of text represented in RDF. It also demonstrates how to model annotations, and how to capture the metadata of language resources. Further, it includes a chapter on representing linguistic categories. In the third part of the book, the authors describe how language resources can be transformed into LD and how links can be inferred and added to the data to increase connectivity and linking between different datasets. They also discuss using LD resources for natural language processing. The last part describes concrete applications of the technologies: representing and linking multilingual WordNets, applications in digital humanities and the discovery of language resources. Given its scope, the book is relevant for researchers and graduate students interested in topics at the crossroads of natural language processing/computational linguistics and the Semantic Web/linked data. It appeals to Semantic Web experts who are not proficient in applying the Semantic Web and LD principles to linguistic data, as well as to computational linguists who are used to working with lexical and linguistic resources wanting to learn about a new paradigm for modelling, publishing and exploiting linguistic resources. © Springer Nature Switzerland AG 2020.",Final,
Liu Y.; Yang T.; You Z.; Fan W.; Yu P.S.,"Liu, Ye (57206820506); Yang, Tao (57217802442); You, Zeyu (56303240100); Fan, Wei (7401635674); Yu, Philip S. (7402366049)",57206820506; 57217802442; 56303240100; 7401635674; 7402366049,Commonsense evidence generation and injection in reading comprehension,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112400683&partnerID=40&md5=beb4c3d7e5ce103f367754e3f5ac9179,"Human tackle reading comprehension not only based on the given context itself but often rely on the commonsense beyond. To empower the machine with commonsense reasoning; in this paper, we propose a Commonsense Evidence Generation and Injection framework in reading comprehension, named CEGI. The framework injects two kinds of auxiliary commonsense evidence into comprehensive reading to equip the machine with the ability of rational thinking. Specifically, we build two evidence generators: one aims to generate textual evidence via a language model; the other aims to extract factual evidence (automatically aligned text-triples) from a commonsense knowledge graph after graph completion. Those evidences incorporate contextual commonsense and serve as the additional inputs to the reasoning model. Thereafter, we propose a deep contextual encoder to extract semantic relationships among the paragraph, question, option, and evidence. Finally, we employ a capsule network to extract different linguistic units (word and phrase) from the relations, and dynamically predict the optimal option based on the extracted units. Experiments on the CosmosQA dataset demonstrate that the proposed CEGI model outperforms the current state-ofthe- art approaches and achieves the highest accuracy (83.6%) on the leaderboard.  © 2020 Association for Computational Linguistics.",Final,
Kumar S.; Jat S.; Saxena K.; Talukdar P.,"Kumar, Sawan (57218172676); Jat, Sharmistha (57216622992); Saxena, Karan (57216610927); Talukdar, Partha (25652280700)",57218172676; 57216622992; 57216610927; 25652280700,Zero-shot word sense disambiguation using sense definition embeddings,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075859601&partnerID=40&md5=df7fa442077c5b74e0de03860cb4219b,"Word Sense Disambiguation (WSD) is a longstanding but open problem in Natural Language Processing (NLP). WSD corpora are typically small in size, owing to an expensive annotation process. Current supervised WSD methods treat senses as discrete labels and also resort to predicting the Most-Frequent-Sense (MFS) for words unseen during training. This leads to poor performance on rare and unseen senses. To overcome this challenge, we propose Extended WSD Incorporating Sense Embeddings (EWISE), a supervised model to perform WSD by predicting over a continuous sense embedding space as opposed to a discrete label space. This allows EWISE to generalize over both seen and unseen senses, thus achieving generalized zero-shot learning. To obtain target sense embeddings, EWISE utilizes sense definitions. EWISE learns a novel sentence encoder for sense definitions by using WordNet relations and also ConvE, a recently proposed knowledge graph embedding method. We also compare EWISE against other sentence encoders pretrained on large corpora to generate definition embeddings. EWISE achieves new state-of-the-art WSD performance. © 2019 Association for Computational Linguistics",Final,
Zhao C.; Walker M.; Chaturvedi S.,"Zhao, Chao (57189217850); Walker, Marilyn (55461478300); Chaturvedi, Snigdha (36766996800)",57189217850; 55461478300; 36766996800,Bridging the structural gap between encoding and decoding for data-to-text generation,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095506853&partnerID=40&md5=3fd340163697efc401cb15375abcf4fd,"Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DUALENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text. © 2020 Association for Computational Linguistics",Final,
Gao P.; Zhang X.; Qi G.,"Gao, Peng (57215563748); Zhang, Xiang (8400208700); Qi, Guilin (56393840100)",57215563748; 8400208700; 56393840100,Discovering hypernymy relationships in Chinese traffic legal texts,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081170455&doi=10.1007%2f978-981-15-3412-6_11&partnerID=40&md5=32cae49367164fb7c9d537de018f23d6,"Currently, Knowledge Graph is playing a crucial rule in some knowledge-based applications, such as semantic search and data integration. Due to the particularity of the vocabulary and language pattern in the Chinese legal domain, the exploration of hierarchical legal knowledge structures is still challenging. In this paper, we first explore a combination of pattern-based and linguistic-rule-based approach in helping experts to identify hypernymy relationships in large-scale traffic legal corpus. Using these relationships as ground truths, we then propose a supervised hypernymy classification of candidate term pairs using an attention-based bidirectional LSTM model, in which a global context of each candidate is defined as the feature for classification. We compare the performance of our approach with state-of-art baselines on real-world data. The evaluation results show that our approach is quite effective in finding Chinese hypernym-hyponym in the traffic legal domain. © Springer Nature Singapore Pte Ltd 2020.",Final,
Wang Y.; Zhang H.; Shi G.; Liu Z.; Zhou Q.,"Wang, Yashen (56245915700); Zhang, Huanhuan (57210234150); Shi, Ge (57221957781); Liu, Zhirun (56333302100); Zhou, Qiang (57220842024)",56245915700; 57210234150; 57221957781; 56333302100; 57220842024,A Model of Text-Enhanced Knowledge Graph Representation Learning with Mutual Attention,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082595651&doi=10.1109%2fACCESS.2020.2981212&partnerID=40&md5=175585f822164711b1ac0ec0c87d7c87,"Recently, it has gained lots of interests to jointly learn the embeddings of knowledge graph (KG) and text information. However, previous work fails to incorporate the complex structural signals (from structure representation) and semantic signals (from text representation). This paper proposes a novel text-enhanced knowledge graph representation model, which can utilize textual information to enhance the knowledge representations. Especially, a mutual attention mechanism between KG and text is proposed to learn more accurate textual representations for further improving knowledge graph representation, within a unified parameter sharing semantic space. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KG and text are required to train our model. Besides, the proposed model could fully incorporate the multi-direction signals. Experimental results show that the proposed model achieves the state-of-the-art performance on both link prediction and triple classification tasks, and significantly outperforms previous text-enhanced knowledge representation models. © 2013 IEEE.",Final,All Open Access; Gold Open Access
Gantar P.,"Gantar, Polona (55699375300)",55699375300,Dictionary of modern slovene: From slovene lexical database to digital dictionary database; [Rječnik suvremenoga slovenskog jezika: Od slovenske leksičke baze do digitalne rječničke baze],1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096796818&doi=10.20344%2fAMP.12408&partnerID=40&md5=6a2ef1bb8151b1d2558fbfa750c41c20,"The ability to process language data has become fundamental to the development of technologies in various areas of human life in the digital world. The development of digitally readable linguistic resources, methods, and tools is, therefore, also a key challenge for the contemporary Slovene language. This challenge has been recognized in the Slovene language community both at the professional and state level and has been the subject of many activities over the past ten years, which will be presented in this paper. The idea of a comprehensive dictionary database covering all levels of linguistic description in modern Slovene, from the morphological and lexical levels to the syntactic level, has already formulated within the framework of the European Social Fund's Communication in Slovene (2008-2013) project; the Slovene Lexical Database was also created within the framework of this project. Two goals were pursued in designing the Slovene Lexical Database (SLD): creating linguistic descriptions of Slovene intended for human users that would also be useful for the machine processing of Slovene. Ever since the construction of the first Slovene corpus, it has become evident that there is a need for a description of modern Slovene based on real language data, and that it is necessary to understand the needs of language users to create useful language reference works. It also became apparent that only the digital medium enables the comprehensiveness of language description and that the design of the database must be adapted to it from the start. Also, the description must follow best practices as closely as possible in terms of formats and international standards, as this enables the inclusion of Slovene into a wider network of resources, such as Open Linked Data, babelNet and ELExIS. Due to time pressures and trends in lexicography, procedures to automate the extraction of linguistic data from corpora and the inclusion of crowdsourcing into the lexicographic process were taken into consideration. Following the essential idea of creating an all-inclusive digital dictionary database for Slovene, a few independent databases have been created over the past two years: the Collocations Dictionary of Modern Slovene, and the automatically generated Thesaurus of Modern Slovene, both of which also exist as independent online dictionary portals. One of the novelties that we put forward together with both dictionaries is the 'responsive dictionary' concept, which includes crowdsourcing methods. Ultimately, the Digital Dictionary Database provides all (other) levels of linguistic description: the morphological level with the Sloleks database upgrade, the phraseological level with the construction of a multi-word expressions lexicon, and the syntactic level with the formalization of Slovene verb valency patterns. Each of these databases contains its specific language data that will ultimately be included in the comprehensive Slovene Digital Dictionary Database, which will represent basic linguistic descriptions of Slovene both for the human and machine user. © 2020 Institute of Croatian Language and Linguistics. All rights reserved.",Final,All Open Access; Gold Open Access; Green Open Access
,,,"25th International Conference on Applications of Natural Language to Information Systems, NLDB 2020",1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087501742&partnerID=40&md5=44ab7fc4bc41ae5fc5b4c7f4e25b9031,The proceedings contain 25 papers. The special focus in this conference is on Applications of Natural Language to Information Systems. The topics include: Enhancement of short text clustering by iterative classification; improving latent dirichlet allocation: On reliability of the novel method ldaprototype; pattern learning for detecting defect reports and improvement requests in app reviews; analysis and multilabel classification of quebec court decisions in the domain of housing law; a position aware decay weighted network for aspect based sentiment analysis; studying attention models in sentiment attitude extraction task; a sentiWordNet strategy for curriculum learning in sentiment analysis; the role of personality and linguistic patterns in discriminating between fake news spreaders and fact checkers; literary natural language generation with psychological traits; movies emotional analysis using textual contents; using bert and augmentation in named entity recognition for cybersecurity domain; combining character and word embeddings for affect in arabic informal social media microblogs; towards explainability in using deep learning for the detection of anorexia in social media; an adaptive response matching network for ranking multi-turn chatbot responses; improving the community question retrieval performance using attention-based siamese lstm; jointly linking visual and textual entity mentions with background knowledge; human-in-the-loop conversation agent for customer service; improving named entity recognition for biomedical and patent data using bi-lstm deep neural network models; a user-centred analysis of explanations for a multi-component semantic parser; investigating query expansion and coreference resolution in question answering on bert; CONQUEST: A framework for building template-based iqa chatbots for enterprise knowledge graphs; enabling interactive answering of procedural questions.,Final,
Declerck T.; McCrae J.; Hartung M.; Gracia J.; Chiarcos C.; Montiel E.; Cimiano P.; Revenko A.; Sauri R.; Lee D.; Racioppa S.; Nasir J.; Orlikowski M.; Lanau-Coronas M.; Fäth C.; Rico M.; Elahi M.F.; Khvalchik M.; Gonzalez M.; Cooney K.,"Declerck, Thierry (22333556000); McCrae, John (36666801700); Hartung, Matthias (24724078500); Gracia, Jorge (55392626700); Chiarcos, Christian (22333764800); Montiel, Elena (25654093800); Cimiano, Philipp (15838793700); Revenko, Artem (55225811200); Sauri, Roser (12762099600); Lee, Deirdre (57220028698); Racioppa, Stefania (24725676000); Nasir, Jamal (56419640500); Orlikowski, Matthias (57203946336); Lanau-Coronas, Marta (57211839147); Fäth, Christian (57194612424); Rico, Mariano (22433515100); Elahi, Mohammad Fazleh (57220440466); Khvalchik, Maria (57194613287); Gonzalez, Meritxell (55664440900); Cooney, Katharine (57220030125)",22333556000; 36666801700; 24724078500; 55392626700; 22333764800; 25654093800; 15838793700; 55225811200; 12762099600; 57220028698; 24725676000; 56419640500; 57203946336; 57211839147; 57194612424; 22433515100; 57220440466; 57194613287; 55664440900; 57220030125,Recent developments for the linguistic linked open data infrastructure,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096555711&partnerID=40&md5=ec6a9696a5ce1ca3bf58021ca1a6086d,"In this paper we describe the contributions made by the European H2020 project “Prêt-à-LLOD” ('Ready-to-use Multilingual Linked Language Data for Knowledge Services across Sectors') to the further development of the Linguistic Linked Open Data (LLOD) infrastructure. Prêt-à-LLOD aims to develop a new methodology for building data value chains applicable to a wide range of sectors and applications and based around language resources and language technologies that can be integrated by means of semantic technologies. We describe the methods implemented for increasing the number of language data sets in the LLOD. We also present the approach for ensuring interoperability and for porting LLOD data sets and services to other infrastructures, as well as the contribution of the projects to existing standards. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
Gatiatullin A.; Kirillovich A.; Nevzorova O.,"Gatiatullin, Ayrat (56500678000); Kirillovich, Alexander (55994716700); Nevzorova, Olga (6506234633)",56500678000; 55994716700; 6506234633,On developing of the FrameNet-like resource for Tatar,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098702581&partnerID=40&md5=ae7032e93ab3b0db787a71d2d3c67b9f,"In this paper, we present TatVerbBank, the first FrameNet-like resource for Tatar language. TatVerbBank is organized as a collection of semantic and syntactic frames. A semantic frame contains semantic roles associated with a concept (for example, for the concept of gift, the roles are giver, recipient, gift, time, etc.). A syntactic frame contains a subcategorization model for a particular Tatar lexical entry and its mapping to semantic roles. The developed resource is represented in terms of Lemon, LexInfo and PREMON ontologies and will we published at Linguistic Linked Open Data cloud. © 2020 CEUR-WS. All rights reserved.",Final,
Martín-Chozas P.,"Martín-Chozas, Patricia (57210581382)",57210581382,Creation and enrichment of a terminological knowledge graph in the legal domain,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084616018&partnerID=40&md5=bcb915526ea38ea83a305eab069c6d96,"Domain-specific terminologies are of great use in a number of contexts, such as information retrieval from text documents or supporting humans in translation tasks. However, automated terminology extraction tools usually render plain lists with no additional information (hierarchical relations, definitions or examples of use, amongst others). The output of these tools is very often offered in non-open formats, hampering their reuse and interoperability. Moreover, terminology management tools demand a lot of manual work to curate and enrich the resources and they do not support the representation of terminological relations beyond broader/narrower. The contributions of this Thesis mitigate these problems by automating the creation of rich terminologies from plain text documents, by establishing links to external resources, and by adopting the W3C standards for the Semantic Web. The proposed method comprises six tasks: refinement, disambiguation, enrichment, relation validation, relation extraction and RDF conversion. We have applied this methodology to two different legal corpora, i.e., contracts and collective agreements. The result of this methodology will be a Terminological Knowledge Graph that can be exploited by different Natural Language Processing applications. Copyright © 2020 held by the author.",Final,
Fiorelli M.; Stellato A.; Lorenzetti T.; Turbati A.; Schmitz P.; Francesconi E.; Hajlaoui N.; Batouche B.,"Fiorelli, Manuel (55389632500); Stellato, Armando (23393619500); Lorenzetti, Tiziano (56728575200); Turbati, Andrea (36460343800); Schmitz, Peter (57190608051); Francesconi, Enrico (55920443800); Hajlaoui, Najeh (35317472800); Batouche, Brahim (36166354000)",55389632500; 23393619500; 56728575200; 36460343800; 57190608051; 55920443800; 35317472800; 36166354000,Editing OntoLex-Lemon in VocBench 3,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095127398&partnerID=40&md5=c433d34f15e50fa72bc033afcdab3696,"OntoLex-Lemon is a collection of RDF vocabularies for specifying the verbalization of ontologies in natural language. Beyond its original scope, OntoLex-Lemon, as well as its predecessor Monnet lemon, found application in the Linguistic Linked Open Data cloud to represent and interlink language resources on the Semantic Web. Unfortunately, generic ontology and RDF editors were considered inconvenient to use with OntoLex-Lemon because of its complex design patterns and other peculiarities, including indirection, reification and subtle integrity constraints. This perception led to the development of dedicated editors, trading the flexibility of RDF in combining different models (and the features already available in existing RDF editors) for a more direct and streamlined editing of OntoLex-Lemon patterns. In this paper, we investigate on the benefits gained by extending an already existing RDF editor, VocBench 3, with capabilities closely tailored to OntoLex-Lemon and on the challenges that such extension implies. The outcome of such investigation is twofold: a vertical assessment of a new editor for OntoLex-Lemon and, in the broader scope of RDF editor design, a new perspective on which flexibility and extensibility characteristics an editor should meet in order to cover new core modeling vocabularies, for which OntoLex-Lemon represents a use case. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
Martín-Chozas P.; Ahmadi S.; Montiel-Ponsoda E.,"Martín-Chozas, Patricia (57210581382); Ahmadi, Sina (57210119212); Montiel-Ponsoda, Elena (25654093800)",57210581382; 57210119212; 25654093800,Defying wikidata: Validation of terminological relations in the web of data,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096530716&partnerID=40&md5=8658e3c7154fd8ea391e1f3a2b1933ab,"In this paper we present an approach to validate terminological data retrieved from open encyclopaedic knowledge bases. This need arises from the enrichment of automatically extracted terms with information from existing resources in the Linguistic Linked Open Data cloud. Specifically, the resource employed for this enrichment is WIKIDATA, since it is one of the biggest knowledge bases freely available within the Semantic Web. During the experiment, we noticed that certain RDF properties in the Knowledge Base did not contain the data they are intended to represent, but a different type of information. In this paper we propose an approach to validate the retrieved data based on four axioms that rely on two linguistic theories: the x-bar theory and the multidimensional theory of terminology. The validation process is supported by a second knowledge base specialised in linguistic data; in this case, CONCEPTNET. In our experiment, we validate terms from the legal domain in four languages: Dutch, English, German and Spanish. The final aim is to generate a set of sound and reliable terminological resources in RDF to contribute to the population of the Linguistic Linked Open Data cloud. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
,,,"19th China National Conference on Computational Linguistics, CCL 2020",1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097257280&partnerID=40&md5=5b83a51bd65c456740c51ab4bb879f8e,"The proceedings contain 34 papers. The special focus in this conference is on Computational Linguistics. The topics include: Chinese Named Entity Recognition via Adaptive Multi-pass Memory Network with Hierarchical Tagging Mechanism; a Practice of Tourism Knowledge Graph Construction Based on Heterogeneous Information; a Novel Joint Framework for Multiple Chinese Events Extraction; entity Relative Position Representation Based Multi-head Selection for Joint Entity and Relation Extraction; a Mixed Learning Objective for Neural Machine Translation; multi-reward Based Reinforcement Learning for Neural Machine Translation; low-Resource Text Classification via Cross-Lingual Language Model Fine-Tuning; constructing Uyghur Named Entity Recognition System Using Neural Machine Translation Tag Projection; recognition Method of Important Words in Korean Text Based on Reinforcement Learning; semantic-Aware Chinese Zero Pronoun Resolution with Pre-trained Semantic Dependency Parser; mongolian Questions Classification Based on Multi-Head Attention; the Annotation Scheme of English-Chinese Clause Alignment Corpus; categorizing Offensive Language in Social Networks: A Chinese Corpus, Systems and an Explanation Tool; LiveQA: A Question Answering Dataset Over Sports Live; Chinese and English Elementary Discourse Units Recognition Based on Bi-LSTM-CRF Model; better Queries for Aspect-Category Sentiment Classification; multimodal Sentiment Analysis with Multi-perspective Fusion Network Focusing on Sense Attentive Language; CAN-GRU: A Hierarchical Model for Emotion Recognition in Dialogue; a Joint Model for Aspect-Category Sentiment Analysis with Shared Sentiment Prediction Layer; compress Polyphone Pronunciation Prediction Model with Shared Labels; improving Sentence Classification by Multilingual Data Augmentation and Consensus Learning; multi-task Legal Judgement Prediction Combining a Subtask of the Seriousness of Charges; clickbait Detection with Style-Aware Title Modeling and Co-attention.",Final,
Yan D.; Bi Y.; Huang X.,"Yan, Danhui (57214218203); Bi, Yude (24721086600); Huang, Xian (57206722291)",57214218203; 24721086600; 57206722291,Knowledge Graph Representation of Syntactic and Semantic Information,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078472600&doi=10.1007%2f978-3-030-38189-9_57&partnerID=40&md5=7759781177a3021657ff7f65115cfb8c,"Representation of linguistic knowledge is one of the keys to helping machines understand natural languages. This paper follows the idea from linguistic data to linguistic knowledge and to knowledge representation. At the syntactic level, the syntactic structure and its variants in the corpus are summarized, and the syntactic functions undertaken by the arguments are analyzed. At the semantic level, the semantic roles and semantic types of arguments are analyzed. The purpose is to reveal the interaction between syntax and semantics. Finally, this paper explores a fusion representation method of linguistic data and linguistic knowledge, and carries out a case study. © Springer Nature Switzerland AG 2020.",Final,
Sprugnoli R.; Mambrini F.; Moretti G.; Passarotti M.,"Sprugnoli, Rachele (15077007200); Mambrini, Francesco (57190293497); Moretti, Giovanni (57190677309); Passarotti, Marco (56957111300)",15077007200; 57190293497; 57190677309; 56957111300,Towards the modeling of polarity in a Latin knowledge base,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095966361&partnerID=40&md5=0401ffa5ec60fa70a40954c232432bc9,"In this paper, we describe the process of inclusion of a prior polarity lexicon of Latin lemmas, called LatinAffectus, in a knowledge base of interoperable linguistic resources developed within the LiLa: Linking Latin project. More specifically, a manually-curated list of lemma-sentiment pairs is linked to a comprehensive collection of Latin lemmas by using Semantic Web and Linked Data standards and practices. LatinAffectus is modeled relying on three formal representation frameworks: Lemon and Ontolex to describe the lexicon, and the Marl ontology to describe the sentiment properties of each of its lexical entries. We present the lexicon, the methodology and the results of the linking process, as well as a use case and the planned future work. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Kirillovich A.; Galieva A.; Nevzorova O.; Shaekhov M.; Loukachevitch N.; Ilvovsky D.,"Kirillovich, Alexander (55994716700); Galieva, Alfiya (56500587700); Nevzorova, Olga (6506234633); Shaekhov, Marat (57218311256); Loukachevitch, Natalia (6504197092); Ilvovsky, Dmitry (55967196200)",55994716700; 56500587700; 6506234633; 57218311256; 6504197092; 55967196200,Tatar WordNet: The sources and the component parts,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088754152&doi=10.1007%2f978-3-030-51913-1_13&partnerID=40&md5=4b63210b6ee20e97513a84a03c4f02da,"We describe an ongoing project of construction of the Tatar WordNet. The Tatar WordNet is being constructed on the base of three source resources, developed by us. The first source is TatThes, a bilingual Russian-Tatar Social-Political Thesaurus. TatThes, in turn, has been constructed by manual translation and extension of RuThes, a linguistic ontology for Russian. The second source is a Tatar translation of RuWordNet, a WordNet for Russian. This translation was carried out automatically on the base of a Russian-Tatar dictionary, and then was manually verified. The third source is a semantic classification of Tatar verbs, developed from scratch. We discuss the structure, methodology of compilation and the current state these source resources, and justify the choice of them as the initial resources for building the Tatar WordNet. Our ultimate goal is to publish Tatar WordNet on the Linguistic Linked Open Data cloud and integrate it to the Global WordNet Grid. © Springer Nature Switzerland AG 2020.",Final,
Nikolaev K.; Kirillovich A.,"Nikolaev, Konstantin (57205380412); Kirillovich, Alexander (55994716700)",57205380412; 55994716700,Adapting the LodView RDF browser for navigation over the linguistic linked open data cloud in Russian and the languages of Russia,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098700630&partnerID=40&md5=57fda6920d57dcc3dd48117335d3dd44,"This paper is dedicated to using of LodView RDF browser for navigation on the Linguistic Linked Open Data cloud in Russian and languages of Russia. We reveal several limitations of LodView, that prevents its using for this purpose. These limitations are: 1) resolution of Cyrillic URIs; 2) Cyrillic URIs in Turtle representations of resources; 3) support for Cyrillic literals; 4) support for URIs with IDs of fragments; 5) human-readable URLs for RDF representations of resources; 6) deployment of embedded resources. We updated the LodView for fix the recovered limitations. © 2020 CEUR-WS. All rights reserved.",Final,
Gracia J.; Fäth C.; Hartung M.; Ionov M.; Bosque-Gil J.; Veríssimo S.; Chiarcos C.; Orlikowski M.,"Gracia, Jorge (55392626700); Fäth, Christian (57194612424); Hartung, Matthias (24724078500); Ionov, Max (57192677241); Bosque-Gil, Julia (57031866000); Veríssimo, Susana (57220038311); Chiarcos, Christian (22333764800); Orlikowski, Matthias (57203946336)",55392626700; 57194612424; 24724078500; 57192677241; 57031866000; 57220038311; 22333764800; 57203946336,Leveraging Linguistic Linked Data for Cross-Lingual Model Transfer in the Pharmaceutical Domain,1,,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096625207&doi=10.1007%2f978-3-030-62466-8_31&partnerID=40&md5=4760f3754c42b51d2fd3ed570ec01f69,"We describe the use of linguistic linked data to support a cross-lingual transfer framework for sentiment analysis in the pharmaceutical domain. The proposed system dynamically gathers translations from the Linked Open Data (LOD) cloud, particularly from Apertium RDF, in order to project a deep learning-based sentiment classifier from one language to another, thus enabling scalability and avoiding the need of model re-training when transferred across languages. We describe the whole pipeline traversed by the multilingual data, from their conversion into RDF based on a new dynamic and flexible transformation framework, through their linking and publication as linked data, and finally their exploitation in the particular use case. Based on experiments on projecting a sentiment classifier from English to Spanish, we demonstrate how linked data techniques are able to enhance the multilingual capabilities of a deep learning-based approach in a dynamic and scalable way, in a real application scenario from the pharmaceutical domain. © 2020, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Ahmed A.F.; Sherif M.A.; Ngomo A.-C.N.,"Ahmed, Abdullah Fathi (57188732238); Sherif, Mohamed Ahmed (55901643100); Ngomo, Axel-Cyrille Ngonga (23397850200)",57188732238; 55901643100; 23397850200,Do your resources sound similar?: On the impact of using phonetic similarity in link discovery,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077281634&doi=10.1145%2f3360901.3364426&partnerID=40&md5=4e795910464eb701e47e6e66aba297ce,"An increasing number of heterogeneous datasets abiding by the Linked Data paradigm is published everyday. Discovering links between these datasets is thus central to achieving the vision behind the Data Web. Declarative Link Discovery (LD) frameworks rely on complex Link Specification (LS) to express the conditions under which two resources should be linked. Complex LS combine similarity measures with thresholds to determine whether a given predicate holds between two resources. State of the art LD frameworks rely mostly on string-based similarity measures such as Levenshtein and Jaccard. However, string-based similarity measures often fail to catch the similarity of resources with phonetically similar property values when these property values are represented using different string representation (e.g., names and street labels). In this paper, we evaluate the impact of using phonetics-based similarities in the process of LD. Moreover, we evaluate the impact of phonetic-based similarity measures on a state-of-the-art machine learning approach used to generate LS. Our experiments suggest that the combination of string-based and phonetic-based measures can improve the F-measures achieved by LD frameworks on most datasets. © 2019 ACM.",Final,
Roche C.; Costa R.; Carvalho S.; Almeida B.,"Roche, Christophe (7103052641); Costa, Rute (55958196000); Carvalho, Sara (58064085700); Almeida, Bruno (57222163016)",7103052641; 55958196000; 58064085700; 57222163016,Knowledge-based terminological e-dictionaries: The EndoTerm and al-Andalus Pottery projects,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091466533&doi=10.1075%2fterm.00038.roc&partnerID=40&md5=fdd3c9bf5cdbbd3bce75a974250c6e5c,"The advent of the Semantic Web and of the Linked Data initiative have contributed to new perspectives and opportunities regarding terminology work. Among them are the double dimension approach and the theoretical perspective of ontoterminology anchored therein, which explore the synergies resulting from the systematic organisation of both term systems and concept systems. By doing so, they provide a theoretical and methodological foundation underlying the creation of knowledge-based terminological products that can support the conception and development of different types of e-dictionaries. Within that scope, and based on examples pertaining to two different subject fields, namely endometriosis and Islamic archaeology, this article aims to propose a framework for the creation of a terminological e-dictionary, defined as a reference resource in a specific domain that gathers, structures and describes linguistic data in a systematic way in one, two or more languages, in order to define concepts that are denoted by terms. © John Benjamins Publishing Company",Final,
León-Araúz P.; Reimerink A.; Faber P.,"León-Araúz, Pilar (49861827700); Reimerink, Arianne (16175921700); Faber, Pamela (16174646200)",49861827700; 16175921700; 16174646200,EcoLexicon and by-products: Integrating and reusing terminological resources,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091434930&doi=10.1075%2fterm.00037.leo&partnerID=40&md5=79f916658f2e83de90b487fbd84dd647,"Reutilization and interoperability are major issues in the fields of knowledge representation and extraction, as reflected in initiatives such as the Semantic Web and the Linked Open Data Cloud. This paper shows how terminological resources can be integrated and reused within different types of application. EcoLexicon is a multilingual terminological knowledge base (TKB) on environmental science that integrates conceptual, linguistic and visual information. It has led to the following by-products: (i) the EcoLexicon English Corpus; (ii) EcoLexiCAT, a terminology-enhanced translation tool; and (iii) Manzanilla, an image annotation tool. This paper explains EcoLexicon and its by-products, and shows how the latter exploit and enhance the data in the TKB. © John Benjamins Publishing Company",Final,
Simov K.,"Simov, Kiril (8835805500)",8835805500,Integrated Language and Knowledge Resources for a Bulgarian-Centric Knowledge Graph,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084240830&partnerID=40&md5=f16110765eac6784e8dd66b825ae97ed,"This paper reports on the integration of language and knowledge resources within CLaDA-BG infrastructure. The idea is to encode linguistic knowledge on all levels of language starting from text, grammatical annotation and lemmatization to semantic and conceptual annotation. Our goal is to support conceptual annotation of various research objects (mainly texts). One of the main applications will be the management of a Bulgaria-centric Knowledge Graph. © 2019 Digital Presentation and Preservation of Cultural and Scientific Heritage. All rights reserved.",Final,
Rospocher M.; Corcoglioniti F.; Palmero Aprosio A.,"Rospocher, Marco (14010314000); Corcoglioniti, Francesco (25928189600); Palmero Aprosio, Alessio (55936608300)",14010314000; 25928189600; 55936608300,PreMOn: LODifing linguistic predicate models,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057966885&doi=10.1007%2fs10579-018-9437-8&partnerID=40&md5=b84ee695965b207c1f9d9ef98c61ddd9,"PreMOn is a freely available linguistic resource for exposing predicate models (PropBank, NomBank, VerbNet, and FrameNet) and mappings between them (e.g., SemLink and the predicate matrix) as linguistic linked open data (LOD). It consists of two components: (1) the PreMOn Ontology, that builds on the OntoLex-Lemon model by the W3C ontology-Lexica community group to enable an homogeneous representation of data from various predicate models and their linking to ontological resources; and, (2) the PreMOn Dataset, a LOD dataset integrating various versions of the aforementioned predicate models and mappings, linked to other LOD ontologies and resources (e.g., FrameBase, ESO, WordNet RDF). PreMOn is accessible online in different ways (e.g., SPARQL endpoint), and extensively documented. © 2018, Springer Nature B.V.",Final,
Moussallem D.; Ngomo A.-C.N.; Buitelaar P.; Arcan M.,"Moussallem, Diego (57079181300); Ngomo, Axel-Cyrille Ngonga (23397850200); Buitelaar, Paul (14041096000); Arcan, Mihael (55453083200)",57079181300; 23397850200; 14041096000; 55453083200,Utilizing knowledge graphs for neural machine translation augmentation,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077242522&doi=10.1145%2f3360901.3364423&partnerID=40&md5=00ed4866d01ddb7772e12ec8e6bf6b07,"While neural networks have led to substantial progress in machine translation, their success depends heavily on large amounts of training data. However, parallel training corpora are not always readily available. Moreover, out-of-vocabulary words - -mostly entities and terminological expressions - -pose a difficult challenge to Neural Machine Translation systems. Recent efforts have tried to alleviate the data sparsity problem by augmenting the training data using different strategies, such as external knowledge injection. In this paper, we hypothesize that knowledge graphs enhance the semantic feature extraction of neural models, thus optimizing the translation of entities and terminological expressions in texts and consequently leading to better translation quality. We investigate two different strategies for incorporating knowledge graphs into neural models without modifying the neural network architectures. Additionally, we examine the effectiveness of our augmented models on domain-specific texts and ontologies. Our knowledge-graph-augmented neural translation model, dubbed KG-NMT, achieves significant and consistent improvements of +3 BLEU, METEOR and chrF3 on average on the newstest datasets between 2015 and 2018 for the WMT English-German translation task. © 2019 ACM.",Final,
Chen D.; Li Y.; Yang M.; Zheng H.-T.; Shen Y.,"Chen, Daoyuan (57200530014); Li, Yaliang (56273199400); Yang, Min (56349712700); Zheng, Hai-Tao (57203433967); Shen, Ying (56763084800)",57200530014; 56273199400; 56349712700; 57203433967; 56763084800,Knowledge-aware textual entailment with graph attention network,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075468679&doi=10.1145%2f3357384.3358071&partnerID=40&md5=122e9e69faf8c86a7cfce803b0cf3b2e,"Textual entailment is a central problem of language variability, which has been attracting a lot of interest and it poses significant issues in front of systems aimed at natural language understanding. Recently, various frameworks have been proposed for textual entailment recognition, ranging from traditional computational linguistics techniques to deep learning model based methods. However, recent deep neural networks that achieve the state of the art on textual entailment task only consider the context information of the given sentences rather than the real-world background information and knowledge beyond the context. In the paper, we propose a Knowledge-Context Interactive Textual Entailment Network (KCI-TEN) that learns graph level sentence representations by harnessing external knowledge graph with graph attention network. We further propose a text-graph interaction mechanism for neural based entailment matching learning, which endows the redundancy and noise with less importance and put emphasis on the informative representations. Experiments on the SciTail dataset demonstrate that KCI-TEN outperforms the state-of-the-art methods. © 2019 Association for Computing Machinery.",Final,
Weng J.; Luo J.; Ding G.; Qiu J.; Gao Y.,"Weng, Jinta (57214223755); Luo, Jiahui (57213605160); Ding, Guozhu (57203498387); Qiu, Jing (36618093000); Gao, Ying (57198712979)",57214223755; 57213605160; 57203498387; 36618093000; 57198712979,Group-intelligence construction of linguistic-humanity KG in Chinese verses,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083261030&doi=10.1109%2fSKG49510.2019.00028&partnerID=40&md5=ec439ea0e32cbbf50e04163fda1863d6,"Unlike the instrumental need of language, linguistic humanity of language means that languae, like Chinese verses, always show certain emotion, reflect attitude toward thing and convey creator's characters. To model and visualize such complicated and cross Humanism, Knowledge Graph(KG) is modified to adapt the full-relation Chinese verses and leading-in friendly visualization. Different from conventional Ml or rule-based construction, we adopt the group-intelligence construction with entity adding task, linking adding task and knowledge triple validation task to constructe the KG by alocating task destributed model. While using group-intelligence construction may lead to multi-answer and irrelevant-answer case, socring mechanism with user-consideration and group-consideration is definded. This research shows construction based on the group intelligence can optimize the KG and represent different congnize of Chinese Verses. © 2019 IEEE.",Final,
Tuan Y.-L.; Chen Y.-N.; Lee H.-Y.,"Tuan, Yi-Lin (57204047867); Chen, Yun-Nung (47061006000); Lee, Hung-Yi (34969292900)",57204047867; 47061006000; 34969292900,Dykgchat: Benchmarking dialogue generation grounding on dynamic knowledge graphs,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084288031&partnerID=40&md5=e4262146741d134ceff7c12ef1ab3d43,"Data-driven, knowledge-grounded neural conversation models are capable of generating more informative responses. However, these models have not yet demonstrated that they can zero-shot adapt to updated, unseen knowledge graphs. This paper proposes a new task about how to apply dynamic knowledge graphs in neural conversation model and presents a novel TV series conversation corpus (DyKgChat) for the task. Our new task and corpus aids in understanding the influence of dynamic knowledge graphs on responses generation. Also, we propose a preliminary model that selects an output from two networks at each time step: a sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in order to support dynamic knowledge graphs. To benchmark this new task and evaluate the capability of adaptation, we introduce several evaluation metrics and the experiments show that our proposed approach outperforms previous knowledge-grounded conversation models. The proposed corpus and model can motivate the future research directions1. © 2019 Association for Computational Linguistics",Final,
Martín-Chozas P.; Montiel-Ponsoda E.; Rodríguez-Doncel V.,"Martín-Chozas, Patricia (57210581382); Montiel-Ponsoda, Elena (25654093800); Rodríguez-Doncel, Víctor (35204031900)",57210581382; 25654093800; 35204031900,Language resources as linked data for the legal domain,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071015850&doi=10.3233%2fFAIA190019&partnerID=40&md5=cae02938b5a5871653f9f781cb72e542,"This Chapter describes a four-stage methodology to generate Linguistic Linked Data for the legal domain: identification, creation, transformation (to RDF) and linking. The goal of this process is to enhance the presence of legal language resources in the Linguistic Linked Open Data cloud. Since this Chapter is framed within the H2020 LYNX project, aimed at creating a Legal Knowledge Graph, a parallel objective is to employ the resources generated as a linguistic foundation to annotate, classify and translate the legal resources represented in this graph. © 2019 The authors and IOS Press.",Final,
Speranza G.; Carlino C.; Ahmadi S.,"Speranza, Giulia (57211678175); Carlino, Carola (57211692827); Ahmadi, Sina (57210119212)",57211678175; 57211692827; 57210119212,Creating a Multilingual Terminological Resource using Linked Data: The case of Archaeological Domain in the Italian language,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074832689&partnerID=40&md5=10c0dbfc81df7bc67e5455a6f7bb8809,"The lack of multilingual terminological resources in specialized domains constitutes an obstacle to the access and reuse of information. In the technical domain of cultural heritage and, in particular, archaeology, such an obstacle still exists for Italian language. This paper presents an effort to fill this gap by collecting linguistic data using existing Collaboratively-Constructed Resources and those on the Web of linked data. The collected data are then used to linguistically enrich the ICCD Archaeological Finds Thesaurus– a monolingual Italian thesaurus. Our terminological resource contains 446 terms with translations in four languages and is publicly available in the Resource Description Framework (RDF) in the Ontolex-Lemon model. Copyright © 2019 for this paper by its authors.",Final,
,,,"eLex 2019 - Electronic Lexicography in the 21st Century: Smart Lexicography, Proceedings of the eLex 2019 Conference",1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075360249&partnerID=40&md5=a2ba4148a02df31dc724d983eab07f63,"The proceedings contain 55 papers. The topic discussed include: challenges in the semi-automatic reversion of a Latvian-English dictionary; resource interoperability: exploiting lexicographic data to automatically generate dictionary examples; representation and classification of polyfunctional synsemantic words in monolingual dictionaries and language corpora: the case of the Croatian Lexeme Dakle; reengineering an online historical dictionary for readers of specific texts; assessing EcoLexiCAT: terminology enhancement and post-editing; lexical tools for low-resource languages: a Livonian case-study; ontological knowledge enhancement in EcoLexicon; smart lexicography for low-resource languages: lessons learned from Buddhist Sanskrit and classical Tibetan; and a thesaurus of old English as linguistic linked data: using OntoLex, SKOS and lemon-tree to bring topical thesauri to the semantic web.",Final,
Dimitrova V.; Fäth C.; Chiarcos C.; Renner-Westermann H.; Abromeit F.,"Dimitrova, V. (57213381192); Fäth, C. (57194612424); Chiarcos, C. (22333764800); Renner-Westermann, H. (57198788296); Abromeit, F. (57198810784)",57213381192; 57194612424; 22333764800; 57198788296; 57198810784,Interoperability of language-related information: Mapping the BLL thesaurus to LEXVO and glottolog,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059894498&partnerID=40&md5=74ba8aa9e93ca66c4491595ddc11a885,"Since 2013, the thesaurus of the Bibliography of Linguistic Literature (BLL Thesaurus) has been applied in the context of the Linguistik portal, a hub for linguistically relevant information. Several consecutive projects focus on the modeling of the BLL Thesaurus as ontology and its linking to terminological repositories in the Linguistic Linked Open Data (LLOD) cloud. Those mappings facilitate the connection between the Linguistik portal and the cloud. In the paper, we describe the current efforts to establish interoperability between the language-related index terms and repositories providing language identifiers for the web of Linked Data. After an introduction of Lexvo and Glottolog, we outline the scope, the structure, and the peculiarities of the BLL Thesaurus. We discuss the challenges for the design of scientifically plausible language classification and the linking between divergent classifications. We describe the prototype of the linking model and propose pragmatic solutions for structural or conceptual conflicts. Additionally, we depict the benefits from the envisaged interoperability - for the Linguistik portal, and the Linked Open Data Community in general. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Sakor A.; Mulang I.O.; Singh K.; Shekarpour S.; Vidal M.-E.; Lehmann J.; Auer S.,"Sakor, Ahmad (57200274370); Mulang, Isaiah Onando (57200275670); Singh, Kuldeep (57212017864); Shekarpour, Saeedeh (55298471100); Vidal, Maria-Esther (7202765018); Lehmann, Jens (35229806900); Auer, Sören (23391879500)",57200274370; 57200275670; 57212017864; 55298471100; 7202765018; 35229806900; 23391879500,Old is gold: Linguistic driven approach for entity and relation linking of short text,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081090168&partnerID=40&md5=d93ebebd95c7e03c292d4b885c224512,"Short texts challenge NLP tasks such as named entity recognition, disambiguation, linking and relation inference because they do not provide sufficient context or are partially malformed (e.g. wrt. capitalization, long tail entities, implicit relations). In this work, we present the Falcon approach which effectively maps entities and relations within a short text to its mentions of a background knowledge graph. Falcon overcomes the challenges of short text using a light-weight linguistic approach relying on a background knowledge graph. Falcon performs joint entity and relation linking of a short text by leveraging several fundamental principles of English morphology (e.g. compounding, headword identification) and utilizes an extended knowledge graph created by merging entities and relations from various knowledge sources. It uses the context of entities for finding relations and does not require training data. Our empirical study using several standard benchmarks and datasets show that Falcon significantly outperforms state-of-the-art entity and relation linking for short text query inventories. © 2019 Association for Computational Linguistics",Final,
Passarotti M.C.; Cecchini F.M.; Franzini G.; Litta E.; Mambrini F.; Ruffolo P.,"Passarotti, Marco C. (56957111300); Cecchini, Flavio M. (57170316600); Franzini, Greta (56184554000); Litta, Eleonora (57192942633); Mambrini, Francesco (57190293497); Ruffolo, Paolo (57195437110)",56957111300; 57170316600; 56184554000; 57192942633; 57190293497; 57195437110,The LILA knowledge base of linguistic resources and NLP tools for latin,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069508812&partnerID=40&md5=68fa047075aea852930969826d2ae715,"The LiLa: Linking Latin project was recently awarded funding from the European Research Council to build a Knowledge Base of linguistic resources for Latin. LiLa responds to the growing need in the fields of Computational Linguistics, Humanities Computing and Classics to create an interoperable ecosystem of resources and Natural Language Processing tools for Latin. To this end, LiLa makes use of Linked Open Data practices and standards to connect words to distributed textual and lexical resources via unique identifiers. In so doing, it builds rich knowledge graphs, which can be used for research and teaching purposes alike. This paper details the architecture of the LiLa Knowledge Base and presents the solutions found to address the challenges raised by populating it with a first set of linguistic resources. © Marco C. Passarotti, Flavio M. Cecchini, Greta Franzini, Eleonora Litta, Francesco Mambrini, Paolo Ruffolo.",Final,
Moussallem D.; Sherif M.A.; Esteves D.; Zampieri M.; Ngomo A.-C.N.,"Moussallem, Diego (57079181300); Sherif, Mohamed Ahmed (55901643100); Esteves, Diego (56982847300); Zampieri, Marcos (8948587300); Ngomo, Axel-Cyrille Ngonga (23397850200)",57079181300; 55901643100; 56982847300; 8948587300; 23397850200,Lidioms: A multilingual linked idioms data set,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059907905&partnerID=40&md5=e142cf84b06aab18e248b52ee5649a37,"In this paper, we describe the LIDIOMS data set, a multilingual RDF representation of idioms currently containing five languages: English, German, Italian, Portuguese, and Russian. The data set is intended to support natural language processing applications by providing links between idioms across languages. The underlying data was crawled and integrated from various sources. To ensure the quality of the crawled data, all idioms were evaluated by at least two native speakers. Herein, we present the model devised for structuring the data. We also provide the details of linking LIDIOMS to well-known multilingual data sets such as BabelNet. The resulting data set complies with best practices according to Linguistic Linked Open Data Community. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Bosch S.; Eckart T.; Klimek B.; Goldhahn D.; Quasthoff U.,"Bosch, Sonja (7006472281); Eckart, Thomas (12789736400); Klimek, Bettina (57194613467); Goldhahn, Dirk (36470058200); Quasthoff, Uwe (13906988600)",7006472281; 12789736400; 57194613467; 36470058200; 13906988600,"Preparation and usage of Xhosa lexicographical data for a multilingual, federated environment",1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059916234&partnerID=40&md5=cf2477548ac924e66bb8605f1ad5629c,"The South African linguistic landscape is characterised by multilingualism and the influence between their eleven official and some local languages. Unfortunately, for most of the languages the amount and quality of available lexicographical data is suboptimal, even though its availability is essential for all educational institutions and for the development of state-of-the-art language technology. In this paper we present a new source of lexicographical data for Xhosa, a language spoken by more than eight million speakers. For its utilisation in a multilingual and federated environment it is modelled using a dedicated OWL ontology for Bantu languages and possesses all features that are currently considered integral for the promotion of resource reuse as well as long-term usage. In the future, the introduced ontology may be used for other Bantu languages as well and may ease their combination to achieve more extensive, multilingual data stocks. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Declerck T.; Racioppa S.,"Declerck, Thierry (22333556000); Racioppa, Stefania (24725676000)",22333556000; 24725676000,Porting multilingual morphological resources to ontolex-lemon,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075340207&doi=10.26615%2f978-954-452-056-4_027&partnerID=40&md5=d9d17387a40bd62f49a73ba72cd38b60,We describe work consisting in porting various morphological resources to the OntoLex-Lemon model. A main objective of this work is to offer a uniform representation of different morphological data sets in order to be able to compare and interlink multilingual resources and to cross-check and interlink or merge the content of morphological resources of one and the same language. The results of our work will be published on the Linguistic Linked Open Data cloud. © 2019 Association for Computational Linguistics (ACL). All rights reserved.,Final,All Open Access; Bronze Open Access
Chiarcos C.; Ionov M.,"Chiarcos, Christian (22333764800); Ionov, Maxim (57194612761)",22333764800; 57194612761,Ligt: An LLod-native vocabulary for representing interlinear glossed text as RDF,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068056004&doi=10.4230%2fOASIcs.LDK.2019.3&partnerID=40&md5=1194a6ce49aa6b6b03fd05f91410d0ce,"The paper introduces Ligt, a native RDF vocabulary for representing linguistic examples as text with interlinear glosses (IGT) in a linked data formalism. Interlinear glossing is a notation used in various fields of linguistics to provide readers with a way to understand linguistic phenomena and to provide corpus data when documenting endangered languages. This data is usually provided with morpheme-by-morpheme correspondence which is not supported by any established vocabularies for representing linguistic corpora or automated annotations. Interlinear Glossed Text can be stored and exchanged in several formats specifically designed for the purpose, but these differ in their designs and concepts, and they are tied to particular tools, so the reusability of the annotated data is limited. To improve interoperability and reusability, we propose to convert such glosses to a tool-independent representation well-suited for the Web of Data, i.e., a representation in RDF. Beyond establishing structural (format) interoperability by means of a common data representation, our approach also allows using shared vocabularies and terminology repositories available from the (Linguistic) Linked Open Data cloud. We describe the core vocabulary and the converters that use this vocabulary to convert IGT in a format of various widely-used tools into RDF. Ultimately, a Linked Data representation will facilitate the accessibility of language data from less-resourced language varieties within the (Linguistic) Linked Open Data cloud, as well as enable novel ways to access and integrate this information with (L)LOD dictionary data and other types of lexical-semantic resources. In a longer perspective, data currently only available through these formats will become more visible and reusable and contribute to the development of a truly multilingual (semantic) web. © Christian Chiarcos and Maxim Ionov.",Final,
Sviķe S.; Šķirmante K.,"Sviķe, Silga (57211923383); Šķirmante, Karina (56578728900)",57211923383; 56578728900,Practice of smart LSP lexicography: The case of a new botanical dictionary with Latvian as a basic language,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075356206&partnerID=40&md5=7c603666a328df19e7ef900336e1b3fd,"The article provides an insight into the project “A New Botanical Dictionary: Terms in Latvian, Latin, English, Russian, and German” implemented in the second half of 2017 and in 2018 within the Ventspils University of Applied Sciences (VUAS) internal call for proposals “Development of Scientific Activity at the VUAS”. The VUAS Faculty of Translation Studies in collaboration with the Faculty of Information Technologies in their scientific and research work along with other Latvian universities aim to occupy a niche in the branch of applied linguistics, therefore the research is related to this discipline and offers solutions in practical lexicography. The study describes a new botanical dictionary (NBD) - a mobile application prototype - with Latvian as a basic language. An insight into the macrostructure of the dictionary and the structure of entries is given. The research deals with questions concerning IT solutions in general (simple) and semantic search in particular. It also introduces a general search - a morphological approach developed by the authors of the research specifically for the Latvian language; this approach is used to search for Latvian botanical terms in both singular and plural forms. The extracted and linked data methodology developed by the authors is described in detail, as well as the NBD technical solutions and architecture, technologies used, database model, and additional features. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Ahmadi S.; Hassani H.; McCrae J.P.,"Ahmadi, Sina (57210119212); Hassani, Hossein (57195600305); McCrae, John P. (36666801700)",57210119212; 57195600305; 36666801700,Towards electronic lexicography for the Kurdish language,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075376957&partnerID=40&md5=c7ddaad799f8cb6c1d90e9cc4a7b2988,"This paper describes the development of lexicographic resources for Kurdish and provides a lexical model for this language. Kurdish is considered a less-resourced language, and currently, lacks machine-readable lexical resources. The unique potential which Linked Data and the Semantic Web offer to e-lexicography enables interoperability across lexical resources by elevating the traditional linguistic data to machine-processable semantic formats. Therefore, we present our lexicon in Ontolex-Lemon ontology as a standard model for sharing lexical information on the Semantic Web. The research covers the Sorani, Kurmanji, and Hawrami dialects of Kurdish. This research suggests that although Kurdish is a less-resourced language, in terms of documented lexicons, it has a wide range of resources, but because they are not machine-readable they could not contribute to the language processing. The outcome of this project, which is made publicly available, assists scholars in their efforts towards making Kurdish a resource-rich language. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Orešković M.; Lovrenčić S.; Essert M.,"Orešković, Marko (24922119600); Lovrenčić, Sandra (17435327200); Essert, Mario (24724239500)",24922119600; 17435327200; 24724239500,Croatian Network Lexicon within the Syntactic and Semantic Framework and LLOD Cloud,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068895154&doi=10.1093%2fijl%2fecy024&partnerID=40&md5=03c911cc8ea6a4c7ddd946dd3e7c14b7,"This paper presents a new type of network lexicon for the Croatian language based on a syntactic and semantic computational framework. It begins with an overview of the existing Croatian e-dictionaries and online repositories, as well as a brief outline of other relevant network ontological models. The network lexicon, which is based on an innovative approach to word tagging, is described in the remainder of the paper. Instead of presenting a linear (e.g. MULTEX-East) structure, this paper proposes a new hierarchical tree-like T-structure that is very similar to the structure of an ontology. In this approach, each word is processed on multiple levels: From its internal structure (morphs or syllables), via links to external network resources (encyclopaedias), to multiword expressions that can have distinctive roles, such as semantic domains, collocations and even figurative expressions. A network framework facilitates the fetching and filtering of the information related to the searched word in a paradigmatic sense because of the integration of the CroWN, the Croatian version of the English WordNet, and in a syntagmatic sense by building the database of the T-structure patterns from a selected corpus. Finally, the network framework enables the dynamic integration of the lexicon with the Linguistic Linked Open Data cloud; thus, each change in the lexicon will be automatically reflected in the cloud. It is therefore not necessary to perform any periodical synchronisation of the data, a task that is quite common when working with triples stored in a Virtuoso database. Special attention has been paid to the technical components and the data preparation process, which are described in detail to serve as a guide for transforming existing lexicographic data into Linked Open Data triples. © 2019 Oxford University Press. All rights reserved.",Final,
Passarotti M.; Mambrini F.; Franzini G.; Cecchini F.M.; Litta E.; Moretti G.; Ruffolo P.; Sprugnoli R.,"Passarotti, Marco (56957111300); Mambrini, Francesco (57190293497); Franzini, Greta (56184554000); Cecchini, Flavio Massimiliano (57170316600); Litta, Eleonora (57192942633); Moretti, Giovanni (57190677309); Ruffolo, Paolo (57195437110); Sprugnoli, Rachele (15077007200)",56957111300; 57190293497; 56184554000; 57170316600; 57192942633; 57190677309; 57195437110; 15077007200,Interlinking through lemmas. The lexical collection of the lila knowledge base of linguistic resources for latin,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094869995&partnerID=40&md5=e0f758c892a82fefabcc553d4d628f83,"This paper presents the structure of the LiLa Knowledge Base, i.e. a collection of multifarious linguistic resources for Latin described with the same vocabulary of knowledge description and interlinked according to the principles of the so-called Linked Data paradigm. Following its highly lexically based nature, the core of the LiLa Knowledge Base consists of a large collection of Latin lemmas, serving as the backbone to achieve interoperability between the resources, by linking all those entries in lexical resources and tokens in corpora that point to the same lemma. After detailing the architecture supporting LiLa, the paper particularly focusses on how we approach the challenges raised by harmonizing different strategies of lemmatization that can be found in linguistic resources for Latin. As an example of the process to connect a linguistic resource to LiLa, the inclusion in the Knowledge Base of a dependency treebank is described and evaluated. © 2019, Edizioni ETS. All rights reserved.",Final,
Tittel S.; Gillis-Webber F.,"Tittel, Sabine (36165030000); Gillis-Webber, Frances (57204543421)",36165030000; 57204543421,Identification of languages in linked data: A diachronic-diatopic case study of French,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075366383&partnerID=40&md5=aea148aede353c01085e73c850755362,"When modelling linguistic resources as Linked Data, the identification of languages using language tags and language codes is a mandatory task. IETF's BCP 47 defines the standard for tags, and ISO 639 provides the codes. However, these codes are insufficient for the identification of diatopic variation within a language and, also, for different historical language stages. This weakness hampers the accurate identification of data, which in turn leads to ambiguity when extending, aggregating and re-using this data-a key notion of Linked Open Data and the Semantic Web. We show the limitations of language identification with a case study of French linguistic data from both a diachronic and a diatopic perspective. Our exemplary data derives from dictionaries of Old French, Middle French, and of Modern French dialects, and from a Modern French linguistic atlas. For each exemplar, we propose a solution using the privateuse sub-tag of BCP 47's language tag, staying within the boundaries of existing standards. Using a predefined pattern for the privateuse sub-tag, the solutions enable a dialect, a patois, in combination with a time period, to be defined and identified. This can lead to shared agreement of language tags that will increase interoperability within the context of Linked Data. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Klimek B.; McCrae J.P.; Bosque-Gil J.; Ionov M.; Tauber J.K.; Chiarcos C.,"Klimek, Bettina (57194613467); McCrae, John P. (36666801700); Bosque-Gil, Julia (57031866000); Ionov, Maxim (57194612761); Tauber, James K. (57211924851); Chiarcos, Christian (22333764800)",57194613467; 36666801700; 57031866000; 57194612761; 57211924851; 22333764800,Challenges for the representation of morphology in ontology lexicons,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075400264&partnerID=40&md5=9b44dcee20294d5e1cc0fd3368d8fa3e,"Recent years have experienced a growing trend in the publication of language resources as Linguistic Linked Data (LLD) to enhance their discovery, reuse and the interoperability of tools that consume language data. To this aim, the OntoLex-lemon model has emerged as a de facto standard to represent lexical data on the Web. However, traditional dictionaries contain a considerable amount of morphological information which is not straightforwardly representable as LLD within the current model. In order to fill this gap a new Morphology Module of OntoLex-lemon is currently being developed. This paper presents the results of this model as on-going work as well as the underlying challenges that emerged during the module development. Based on the MMoOn Core ontology, it aims to account for a wide range of morphological information, ranging from endings to derive whole paradigms to the decomposition and generation of lexical entries which is in compliance to other OntoLex-lemon modules and facilitates the encoding of complex morphological data in ontology lexicons. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Cremaschi M.; Bianchi F.; Maurino A.; Pierotti A.P.,"Cremaschi, Marco (56167172000); Bianchi, Federico (57031310100); Maurino, Andrea (22433645700); Pierotti, Andrea Primo (57211692252)",56167172000; 57031310100; 22433645700; 57211692252,Supporting journalism by combining neural language generation and knowledge graphs,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074854423&partnerID=40&md5=deed4622ec53e2a0fcdc4b44f6eb420e,"Natural Language Generation is a field that is becoming relevant in several domains, including journalism. Natural Language Generation techniques can be of great help to journalists, allowing a substantial reduction in the time required to complete repetitive tasks. In this position paper, we enforce the idea that automated tools can reduce the effort required to journalist when writing articles; at the same time we introduce GazelLex (Gazette Lexicalization), a prototype that covers several steps of Natural Language Generation, in order to create soccer articles automatically, using data from Knowledge Graphs, leaving journalists the possibility of refining and editing articles with additional information. We shall present our first results and current limits of the approach, and we shall also describe some lessons learned that might be useful to readers that want to explore this field. Copyright 2019 for this paper by its authors.",Final,
Eckart T.; Bosch S.; Goldhahn D.; Quasthoff U.; Klimek B.,"Eckart, Thomas (12789736400); Bosch, Sonja (7006472281); Goldhahn, Dirk (36470058200); Quasthoff, Uwe (13906988600); Klimek, Bettina (57194613467)",12789736400; 7006472281; 36470058200; 13906988600; 57194613467,Translation-based dictionary alignment for under-resourced Bantu languages,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068051098&doi=10.4230%2fOASIcs.LDK.2019.17&partnerID=40&md5=6df49898ec6d6a555b49857c53fd801e,"Despite a large number of active speakers, most Bantu languages can be considered as under- or less-resourced languages. This includes especially the current situation of lexicographical data, which is highly unsatisfactory concerning the size, quality and consistency in format and provided information. Unfortunately, this does not only hold for the amount and quality of data for monolingual dictionaries, but also for their lack of interconnection to form a network of dictionaries. Current endeavours to promote the use of Bantu languages in primary and secondary education in countries like South Africa show the urgent need for high-quality digital dictionaries. This contribution describes a prototypical implementation for aligning Xhosa, Zimbabwean Ndebele and Kalanga language dictionaries based on their English translations using simple string matching techniques and via WordNet URIs. The RDF-based representation of the data using the Bantu Language Model (BLM) and – partial – references to the established WordNet dataset supported this process significantly. © Thomas Eckart, Sonja Bosch, Dirk Goldhahn, Uwe Quasthoff, and Bettina Klimek.",Final,
Declerck T.; Siegel M.,"Declerck, Thierry (22333556000); Siegel, Melanie (56808730600)",22333556000; 56808730600,Porting a crowd-sourced German lexical semantics resource to ontolex-lemon,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075336841&partnerID=40&md5=e137dbb9d781bada28b9018194c5d52b,"In this paper we present our work consisting of mapping the recently created open source German lexical semantics resource “Open-de-WordNet” (OdeNet) into the OntoLex-Lemon format. OdeNet was originally created in order to be integrated in the Open Multilingual WordNet initiative. One motivation for porting OdeNet to OntoLex-Lemon is to publish in the Linguistic Linked Open Data cloud this new WordNet-compliant resource for German. At the same time we can with the help of OntoLex-Lemon link the lemmas of OdeNet to full lexical descriptions and so extend the linguistic coverage of this new WordNet resource, as we did for French, Italian and Spanish WordNets included in the Open Multilingual WordNet collection. As a side effect, the porting of OdeNet to OntoLex-Lemon helped in discovering some issues in the original data. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Stolk S.,"Stolk, Sander (57195605139)",57195605139,"A thesaurus of old English as linguistic linked data: Using OntoLex, SKOS and lemon-tree to Bring Topical Thesauri to the Semantic Web",1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075365453&partnerID=40&md5=317e447506eac5636d3ea2b3ea08c741,"An increasing number of dictionaries are represented on the Web in the form of linguistic linked data, utilizing OntoLex-Lemon for this purpose. Lexicographic resources other than dictionaries, however, have thus far not been the main focus of efforts surrounding this model. In this paper, we discuss porting a topical thesaurus to the Web: A Thesaurus of Old English. By means of this case study, this paper discusses how this thesaurus - and topical thesauri in general - can be represented with OntoLex-Lemon, SKOS and lemon-tree through a fully automated process. Along with discussing the terminology required for expressing A Thesaurus of Old English as linguistic linked data, this paper indicates challenges encountered in the conversion process. These challenges range from material that is not meant to be made available to the general public to distinctions and relations that have been left implicit in the legacy form but are of much value and, indeed, required to be expressed explicitly in its linked data form. The aim of this paper, thus, is to provide recommendations for representing topical thesauri on the Web and to grant insight into aspects that may be encountered in porting similar lexicographic resources in the future. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Faralli S.; Finocchi I.; Ponzetto S.P.; Velardi P.,"Faralli, Stefano (57193656573); Finocchi, Irene (55914125200); Ponzetto, Simone Paolo (15056538200); Velardi, Paola (6602082790)",57193656573; 55914125200; 15056538200; 6602082790,WebIsAGraph: A very large hypernymy graph from a web corpus,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074808871&partnerID=40&md5=eca0a652e88be374a3995f78c37590b0,"In this paper, we present WebIsAGraph, a very large hypernymy graph compiled from a dataset of is-a relationships extracted from the CommonCrawl. We provide the resource together with a Neo4j plugin to enable efficient searching and querying over such large graph. We use WebIsAGraph to study the problem of detecting polysemous terms in a noisy terminological knowledge graph, thus quantifying the degree of polysemy of terms found in is-a extractions from Web text. Copyright © 2019 for this paper by its authors.",Final,
Gillis-Webber F.; Tittel S.,"Gillis-Webber, Frances (57204543421); Tittel, Sabine (36165030000)",57204543421; 36165030000,The shortcomings of language tags for linked data when modeling lesser-known languages,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068056813&doi=10.4230%2fOASIcs.LDK.2019.4&partnerID=40&md5=652704d65b28a7eae4583ddb6be6fb12,"In recent years, the modeling of data from linguistic resources with Resource Description Framework (RDF), following the Linked Data paradigm and using the OntoLex-Lemon vocabulary, has become a prevalent method to create datasets for a multilingual web of data. An important aspect of data modeling is the use of language tags to mark lexicons, lexemes, word senses, etc. of a linguistic dataset. However, attempts to model data from lesser-known languages show significant shortcomings with the authoritative list of language codes by ISO 639: for many lesser-known languages spoken by minorities and also for historical stages of languages, language codes, the basis of language tags, are simply not available. This paper discusses these shortcomings based on the examples of three such languages, i.e., two varieties of click languages of Southern Africa together with Old French, and suggests solutions for the issues identified. © Frances Gillis-Webber and Sabine.",Final,
Garcia-Silva A.; Denaux R.; Gomez-Perez J.M.,"Garcia-Silva, Andres (36718996900); Denaux, Ronald (8958242500); Gomez-Perez, Jose Manuel (23485087500)",36718996900; 8958242500; 23485087500,"Learning embeddings from scientific corpora using lexical, grammatical and semantic information",1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077823532&partnerID=40&md5=532805ed6a552718a6e8de3f1b4c3abc,"Natural language processing can assist scientists to leverage the increasing amount of information contained in scientific bibliography. The current trend, based on deep learning and embeddings, uses representations at the (sub)word level that require large amounts of training data and neural architectures with millions of parameters to learn successful language models, like BERT. However, these representations may not be well suited for the scientific domain, where it is common to find complex terms, e.g. multi-word, with a domain-specific meaning in a very specific context. In this paper we propose an approach based on a linguistic analysis of the corpus using a knowledge graph to learn representations that can unambiguously capture such terms and their meaning. We learn embeddings from different linguistic annotations on the text and evaluate them through a classification task over the SciGraph taxonomy, showing that our representations outperform (sub)word-level approaches. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Declerck T.; Egorova K.; Schnur E.,"Declerck, Thierry (22333556000); Egorova, Kseniya (57205400529); Schnur, Eileen (57205398470)",22333556000; 57205400529; 57205398470,An integrated formal representation for terminological and lexical data included in classification schemes,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059909606&partnerID=40&md5=0b97173848d589671f6bca2eab7e139a,"This paper presents our work dealing with a potential application in e-lexicography: the automatized creation of specialized multilingual dictionaries from structured data, which are available in the form of comparable multilingual classification schemes or taxonomies. As starting examples, we use comparable industry classification schemes, which frequently occur in the context of stock exchanges and business reports. Initially, we planned to follow an approach based on cross-taxonomies and cross-languages string mapping to automatically detect candidate multilingual dictionary entries for this specific domain. However, the need to first transform the comparable classification schemes into a shared formal representation language in order to be able to properly align their components before implementing the algorithms for the multilingual lexicon extraction soon became apparent. We opted for the SKOS-XL vocabulary for modelling the multilingual terminological part of the comparable taxonomies and for OntoLex-Lemon for modelling the multilingual lexical entries which can be extracted from the original data. In this paper, we present the suggested modelling architecture, which demonstrates how terminological elements and lexical items can be formally integrated and explicitly cross-linked in the context of the Linguistic Linked Open Data (LLOD). © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Mambrini F.; Passarotti M.,"Mambrini, Francesco (57190293497); Passarotti, Marco (56957111300)",57190293497; 56957111300,Harmonizing different lemmatization strategies for building a knowledge base of linguistic resources for Latin,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084299792&partnerID=40&md5=74ddb24df2cd510d88af9e9b77c6dbeb,"The interoperability between lemmatized corpora of Latin and other resources that use the lemma as indexing key is hampered by the multiple lemmatization strategies that different projects adopt. In this paper we discuss how we tackle the challenges raised by harmonizing different lemmatization criteria in a project that aims to connect linguistic resources for Latin using the Linked Data paradigm. The paper introduces the architecture supporting an open-ended, lemma-based Knowledge Base, built to make textual and lexical resources for Latin interoperable. Particularly, the paper describes the inclusion into the Knowledge Base of its lexical basis, of a word formation lexicon and of a lemmatized and syntactically annotated corpus. © 2019 Association for Computational Linguistics",Final,
Chiarcos C.; Pagé-Perron É.; Khait I.; Schenk N.; Reckling L.,"Chiarcos, Christian (22333764800); Pagé-Perron, Émilie (57203468297); Khait, Ilya (57204704002); Schenk, Niko (57003183800); Reckling, Lucas (57205408042)",22333764800; 57203468297; 57204704002; 57003183800; 57205408042,Towards a linked open data edition of sumerian corpora,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056772672&partnerID=40&md5=9c5604b58788ffbe8e0b5eee8b7c38aa,"Linguistic Linked Open Data (LLOD) is a flourishing line of research in the language resource community, so far mostly adopted for selected aspects of linguistics, natural language processing and the semantic web, as well as for practical applications in localization and lexicography. Yet, computational philology seems to be somewhat decoupled from the recent progress in this area: even though LOD as a concept is gaining significant popularity in Digital Humanities, existing LLOD standards and vocabularies are not widely used in this community, and philological resources are underrepresented in the LLOD cloud diagram (http://linguistic-lod.org/llod-cloud). In this paper, we present an application of Linguistic Linked Open Data in Assyriology. We describe the LLOD edition of a linguistically annotated corpus of Sumerian, as well as its linking with lexical resources, repositories of annotation terminology, and the museum collections in which the artifacts bearing these texts are kept. The chosen corpus is the Electronic Text Corpus of Sumerian Royal Inscriptions, a well curated and linguistically annotated archive of Sumerian text, in preparation for the creating and linking of other corpora of cuneiform texts, such as the corpus of Ur III administrative and legal Sumerian texts, as part of the Machine Translation and Automated Analysis of Cuneiform Languages project (https://cdli-gh.github.io/mtaac/). © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Bosque-Gil J.; Lonke D.; Gracia J.; Kernerman I.,"Bosque-Gil, Julia (57031866000); Lonke, Dorielle (57211836386); Gracia, Jorge (55392626700); Kernerman, Ilan (57193091389)",57031866000; 57211836386; 55392626700; 57193091389,Validating the ontolex-lemon lexicography module with K dictionaries' multilingual data,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075396460&partnerID=40&md5=6130be10cc1b02b0dfe7b79f47347d08,"The OntoLex-lemon model has gradually acquired the status of de-facto standard for the representation of lexical information according to the principles of Linked Data (LD). Exposing the content of lexicographic resources as LD brings both benefits for their easier sharing, discovery, reusability and enrichment at a Web scale, as well as for their internal linking and better reuse of their components. However, with lemon being originally devised for the lexicalization of ontologies, a 1:1 mapping between its elements and those of a lexicographic resource is not always attainable. In this paper we report our experience of validating the new lexicog module of OntoLex-lemon, which aims at paving the way to bridge those gaps. To that end, we have applied the module to represent lexicographic data coming from the Global multilingual series of K Dictionaries (KD) as a real use case scenario of this module. Attention is drawn to the structures and annotations that lead to modelling challenges, the ways the lexicog module tackles them, and where this modelling phase stands as regards the conversion process and design decisions for KD's Global series. © 2019 Lexical Computing CZ s.r.o.. All rights reserved.",Final,
Wang C.; Fan Y.; He X.; Zhou A.,"Wang, Chengyu (55926354300); Fan, Yan (57196223698); He, Xiaofeng (55641972700); Zhou, Aoying (55183487900)",55926354300; 57196223698; 55641972700; 55183487900,Predicting hypernym–hyponym relations for Chinese taxonomy learning,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041836685&doi=10.1007%2fs10115-018-1166-1&partnerID=40&md5=372d88ca7d561d032b7c75d1df98b1a5,"Hypernym–hyponym (“is-a”) relations are key components in taxonomies, object hierarchies and knowledge graphs. Robustly harvesting of such relations requires the analysis of the linguistic characteristics of is-a word pairs in the target language. While there is abundant research on is-a relation extraction in English, it still remains a challenge to accurately identify such relations from Chinese knowledge sources due to the flexibility of language expression and the significant differences between the two language families. In this paper, we introduce a weakly supervised framework to extract Chinese is-a relations from user-generated categories. It employs piecewise linear projection models trained on an existing Chinese taxonomy built from Wikipedia and an iterative learning algorithm to update model parameters incrementally. A pattern-based relation selection method is proposed to prevent “semantic drift” in the learning process using bi-criteria optimization. Experimental results on the publicly available test set illustrate that the proposed approach outperforms state-of-the-art methods. © 2018, Springer-Verlag London Ltd., part of Springer Nature.",Final,
Stolk S.,"Stolk, Sander (57195605139)",57195605139,Lemon-tree: Representing topical thesauri on the semantic web,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068038072&doi=10.4230%2fOASIcs.LDK.2019.16&partnerID=40&md5=476879d1b0d006a47ecf98629ca40617,"An increasing number of dictionaries are represented on the Web in the form of linguistic linked data using the lemon vocabulary. Such a representation facilitates interoperability across linguistic resources, has the potential to increase their visibility, and promotes their reuse. Lexicographic resources other than dictionaries have thus far not been the main focus of efforts surrounding lemon and its modules. In this paper, fundamental needs are analysed for representing topical thesauri specifically and a solution is provided for two important areas hitherto problematic: (1) levels that can be distinguished in their topical system and (2) a looser form of categorization than lexicalization. The novel lemon-tree model contains terminology to overcome these issues and acts as bridge between existing Web standards in order to bring topical thesauri, too, to the Semantic Web. © Sander Stolk.",Final,
Klimek B.; Schädlich R.; Kröger D.; Knese E.; Elßmann B.,"Klimek, Bettina (57194613467); Schädlich, Robert (57205402047); Kröger, Dustin (57205401528); Knese, Edwin (57205407529); Elßmann, Benedikt (57205404682)",57194613467; 57205402047; 57205401528; 57205407529; 57205404682,LiDO RDF: From a relational database to a linked data graph of linguistic terms and bibliographic data,1,,1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059893820&partnerID=40&md5=bedc08ce16e4d5a66f66e82e46cdd539,"Forty years ago the linguist Dr. Christian Lehmann developed a framework for documenting linguistic terms, concepts and bibliographic data that resulted in the LiDo Terminological and Bibliographical Database (LiDo TBD). Since 2006 students and linguistic researchers benefit from the data by looking it up on the Web. Even though, the LiDo TBD is implemented as a relational database, its underlying framework aims at yielding a terminological network containing data nodes that are connected via specific relation edges in order to create an interrelated data graph. Now, with the emergence of Semantic Web technologies we were able to implement this pioneering work by converting the LiDo TBD relational database into a Linked Data graph. In this paper we present and describe the creation of the LiDo RDF dataset and introduce the LiDo RDF project. The goals of this project are to enable the direct use and reuse of the data both for the scientific research community and machine processing alike as well as to enable a valuable enrichment of already existing linguistic terminological and bibliographic data by including LiDo RDF in the LLOD cloud. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Grazioso M.; Cera V.; Di Maro M.; Origlia A.; Cutugno F.,"Grazioso, Marco (57205463243); Cera, Valeria (57194711740); Di Maro, Maria (57205469419); Origlia, Antonio (24605794100); Cutugno, Francesco (13104207600)",57205463243; 57194711740; 57205469419; 24605794100; 13104207600,From linguistic linked open data to multimodal natural interaction: A case study,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060155802&doi=10.1109%2fiV.2018.00060&partnerID=40&md5=73aebaecd4858dc7be9e53707492a0cc,"We present here the conversion of Linguistic Linked Open Data into Semantic Maps to be used to produce contents in a set of technological applications for Cultural Heritage. The paper describes the architectural data collection and annotation procedure adopted in the Cultural Heritage Orienting Multimodal Experiences (CHROME) project (PRIN 2015 funded by Italian University and Research Ministry). Such data will be used in Multimodal Dialogue Systems to obtain precise information about Architectural Heritage, by means of pointing gestures or verbal requests. In particular, we design conversational agents accessing fine-detailed semantic data linked to available 3D models of historical buildings. The starting point of our scientific approach is the Getty Vocabulary on Art & Architecture Thesaurus, integrated with the Getty Thesaurus of Geographic Names (TGN) and the Union List of Artist Names (ULAN). These data are related to 3D mesh of the considered buildings in order to associate abstract concepts to architectural elements. In the field of 3D architectural investigation, a significant amount of research has been conducted to allow domain experts to represent semantic data while keeping spatial references. We will discuss how this will make it possible to support multimodal user interaction and generate Cultural Heritage presentations. © 2018 IEEE.",Final,
Huang C.-R.; Hsieh S.-K.; Prévot L.; Hsiao P.-Y.; Chang H.Y.,"Huang, Chu-Ren (22940590100); Hsieh, Shu-Kai (23397094300); Prévot, Laurent (57202367740); Hsiao, Pei-Yi (57208409522); Chang, Henry Y. (56133915900)",22940590100; 23397094300; 57202367740; 57208409522; 56133915900,Linking basic lexicon to shared ontology for endangered languages: A linked data approach toward formosan languages,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064702571&doi=10.1353%2fjcl.2018.0009&partnerID=40&md5=3d66b43be4467b398e9b147c0966175f,"This paper proposes an innovative approach to link basic lexicon (e.g. Swadesh list) to upper ontology as the foundation of OntoLex interface to address the challenge of building language resources for endangered languages in the linked data paradigm. A linked data approach to language resources requires existing, and preferably sizable, language resources. For endangered and other less-resourced languages, however, the scarcity of existing resources limits the possibilities and potential benefits of linking. The challenges are then, how can construction of language resources for endangered language continue to thrive in the linked data paradigm, and how can the linked data approach benefit language resources for endangered languages. Our proposal requires the bare minimum of available data and we show with examples from Formosan languages (Austronesian or aboriginal languages of Taiwan (Blust 2013, 20))i that 1) this approach is applicable to endangered languages, and that 2) in spite of the restrictions imposed by scarcity of resources, the linked linguistic data consisting of basic lexicon + upper ontology generate important new information. Comparing Swadesh lists from different languages allowed us to build a small shared ontology that reflects direct human experience, and can serve as the cross-lingual conceptual core. In addition, these micro-ontologized lexicons can be used as seeds for developing a fully-grown and more comprehensive documentation of linguistically motivated ontology for each language. Copyright © 2018 by the Journal of Chinese Linguistics. All rights reserved.",Final,All Open Access; Green Open Access
Lin K.; Du W.; Wang X.; Wang M.; Yang Z.,"Lin, Kunhui (15319322900); Du, Wenyuan (57203122017); Wang, Xiaoli (57221484400); Wang, Meihong (56066092200); Yang, Zixiang (57203116065)",15319322900; 57203122017; 57221484400; 56066092200; 57203116065,How to enhance Chinese word segmentation using knowledge graphs,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055572191&doi=10.1109%2fICCSE.2018.8468759&partnerID=40&md5=90ea9acebbb9534d188abc5013b20850,"Chinese word segmentation is a very important problem for Chinese information processing. Chinese word segmentation results are the basis for computers to understand natural language. However, unlike most Western languages, Chinese words do not have fixed symbols like white space as word segmentation marks. Moreover, Chinese has a very complex grammar, and the word segmentation criteria are varied with the contexts. Therefore, Chinese word segmentation is a very difficult task. Many existing works have proposed many algorithms to solve this problem. However, to our best knowledge, none of them could outperform all the other methods. In this paper, we develop a novel algorithm based on semantics and contexts. We propose a semantic-based word similarity measure using the concept hierarchy in knowledge graphs, and use this measure to prune the different results which are generated by several state-of-the-art Chinese word segmentation methods. The idea is to respectively compute the concept similarity of these words to other words in the text, and choose the word with the highest concept similarity score. To evaluate the effectiveness of the proposed approach, we conduct a series of experiment on two real datasets. The results show that our method outperforms all the state-of-the-art algorithms by filtering out wrong results and retaining correct ones. © 2018 IEEE.",Final,
Moussallem D.; Wauer M.; Ngomo A.-C.N.,"Moussallem, Diego (57079181300); Wauer, Matthias (36160687500); Ngomo, Axel-Cyrille Ngonga (23397850200)",57079181300; 36160687500; 23397850200,Machine Translation using Semantic Web Technologies: A Survey,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050401657&doi=10.1016%2fj.websem.2018.07.001&partnerID=40&md5=17bff552c618b5eb882b13c045373e4c,"A large number of machine translation approaches have recently been developed to facilitate the fluid migration of content across languages. However, the literature suggests that many obstacles must still be dealt with to achieve better automatic translations. One of these obstacles is lexical and syntactic ambiguity. A promising way of overcoming this problem is using Semantic Web technologies. This article presents the results of a systematic review of machine translation approaches that rely on Semantic Web technologies for translating texts. Overall, our survey suggests that while Semantic Web technologies can enhance the quality of machine translation outputs for various problems, the combination of both is still in its infancy. © 2018 Elsevier B.V.",Final,All Open Access; Green Open Access
Wang C.; Ma X.; Chen J.; Chen J.,"Wang, Chengbin (35088879600); Ma, Xiaogang (22941707200); Chen, Jianguo (16174563800); Chen, Jingwen (57200116545)",35088879600; 22941707200; 16174563800; 57200116545,Information extraction and knowledge graph construction from geoscience literature,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039732196&doi=10.1016%2fj.cageo.2017.12.007&partnerID=40&md5=036ffb8dd33000dbb8efc6fd3ba9afa3,"Geoscience literature published online is an important part of open data, and brings both challenges and opportunities for data analysis. Compared with studies of numerical geoscience data, there are limited works on information extraction and knowledge discovery from textual geoscience data. This paper presents a workflow and a few empirical case studies for that topic, with a focus on documents written in Chinese. First, we set up a hybrid corpus combining the generic and geology terms from geology dictionaries to train Chinese word segmentation rules of the Conditional Random Fields model. Second, we used the word segmentation rules to parse documents into individual words, and removed the stop-words from the segmentation results to get a corpus constituted of content-words. Third, we used a statistical method to analyze the semantic links between content-words, and we selected the chord and bigram graphs to visualize the content-words and their links as nodes and edges in a knowledge graph, respectively. The resulting graph presents a clear overview of key information in an unstructured document. This study proves the usefulness of the designed workflow, and shows the potential of leveraging natural language processing and knowledge graph technologies for geoscience. © 2017 Elsevier Ltd",Final,All Open Access; Bronze Open Access
Chiarcos C.; Khait I.; Pagé-Perron É.; Schenk N.; Jayanth; Fäth C.; Steuer J.; Mcgrath W.; Wang J.,"Chiarcos, Christian (22333764800); Khait, Ilya (57204704002); Pagé-Perron, Émilie (57203468297); Schenk, Niko (57003183800); Jayanth (57204707808); Fäth, Christian (57194612424); Steuer, Julius (57201356258); Mcgrath, William (58869107800); Wang, Jinyan (57204709587)",22333764800; 57204704002; 57203468297; 57003183800; 57204707808; 57194612424; 57201356258; 58869107800; 57204709587,Annotating a low-resource language with LLOD technology: Sumerian morphology and syntax,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056770596&doi=10.3390%2finfo9110290&partnerID=40&md5=130578f66b8e56ab08efe6cc1b2e3005,"This paper describes work on the morphological and syntactic annotation of Sumerian cuneiformas amodel for lowresource languages in general. Cuneiformtexts are invaluable sources for the study of history, languages, economy, and cultures of AncientMesopotamia and its surrounding regions. Assyriology, the discipline dedicated to their study, has vast research potential, but lacks the modern means for computational processing and analysis. Our project, Machine Translation and Automated Analysis of Cuneiform Languages, aims to fill this gap by bringing together corpus data, lexical data, linguistic annotations and object metadata. The project's main goal is to build a pipeline for machine translation and annotation of Sumerian Ur III administrative texts. The rich and structured data is then to bemade accessible in the formof (Linguistic) Linked Open Data (LLOD), which should open themto a larger research community. Our contribution is two-fold: in terms of language technology, our work represents the first attempt to develop an integrative infrastructure for the annotation of morphology and syntax on the basis of RDF technologies and LLOD resources. With respect to Assyriology, we work towards producing the first syntactically annotated corpus of Sumerian. © 2018 by the authors.",Final,All Open Access; Gold Open Access; Green Open Access
Bosque-Gil J.; Gracia J.; Montiel-Ponsoda E.; Gómez-Pérez A.,"Bosque-Gil, J. (57031866000); Gracia, J. (55392626700); Montiel-Ponsoda, E. (25654093800); Gómez-Pérez, A. (6603934482)",57031866000; 55392626700; 25654093800; 6603934482,Models to represent linguistic linked data,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054913966&doi=10.1017%2fS1351324918000347&partnerID=40&md5=b5cebc1af75f655aaff483150cec76fd,"As the interest of the Semantic Web and computational linguistics communities in linguistic linked data (LLD) keeps increasing and the number of contributions that dwell on LLD rapidly grows, scholars (and linguists in particular) interested in the development of LLD resources sometimes find it difficult to determine which mechanism is suitable for their needs and which challenges have already been addressed. This review seeks to present the state of the art on the models, ontologies and their extensions to represent language resources as LLD by focusing on the nature of the linguistic content they aim to encode. Four basic groups of models are distinguished in this work: models to represent the main elements of lexical resources (group 1), vocabularies developed as extensions to models in group 1 and ontologies that provide more granularity on specific levels of linguistic analysis (group 2), catalogues of linguistic data categories (group 3) and other models such as corpora models or service-oriented ones (group 4). Contributions encompassed in these four groups are described, highlighting their reuse by the community and the modelling challenges that are still to be faced. Copyright © Cambridge University Press 2018.",Final,All Open Access; Green Open Access
Khan A.F.,"Khan, Anas Fahad (57205198244)",57205198244,Towards the representation of etymological data on the semantic web,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059041892&doi=10.3390%2finfo9120304&partnerID=40&md5=b9cd784d03714065e3bf861ca6c85ccb,"In this article, we look at the potential for a wide-coverage modelling of etymological information as linked data using the Resource Data Framework (RDF) data model. We begin with a discussion of some of the most typical features of etymological data and the challenges that these might pose to an RDF-based modelling. We then propose a new vocabulary for representing etymological data, the Ontolex-lemon Etymological Extension (lemonETY), based on the ontolex-lemon model. Each of the main elements of our new model is motivated with reference to the preceding discussion. © 2018 by the authors.",Final,All Open Access; Gold Open Access
Scholz J.; Hrastnig E.; Wandl-Vogt E.,"Scholz, Johannes (55837484100); Hrastnig, Emanual (57196039013); Wandl-Vogt, Eveline (24336963100)",55837484100; 57196039013; 24336963100,A spatio-temporal linked data representation for modeling spatio-temporal dialect data,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031278354&doi=10.1007%2f978-3-319-63946-8_44&partnerID=40&md5=67f08b1802bbfabac30c7639b4b464b4,"Collections of linguistic and dialect data often lack a semantic description and the ability to establish relations to external datasets, from e.g. demography, socio-economics, or geography. Based on existing projects—the Database of Bavarian Dialects in Austria and exploreAT!—this paper elaborates on a spatio-temporal Linked Data model for representing linguistic/dialect data. Here we focus on utilizing existing data and publishing them using a virtual RDF graph. Additionally, we exploit external data sources like DBPedia and geonames.org, to specify the meaning of dialect records and make use of stable geographical placenames. In the paper we highlight a spatio-temporal modeling and representation of linguistic records relying on the notion of a discrete lifespan of an object. Based on a real-world example—using the lemma “Karotte” (engl. carrot) we show how the usage of a specific dialect word (“Karottn”) changes from 1916 until 2016—by exploiting the expressive power of GeoSPARQL. © Springer International Publishing AG 2018.",Final,
McCrae J.P.,"McCrae, John P. (36666801700)",36666801700,Mapping WordNet instances to Wikipedia,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043690969&partnerID=40&md5=9981621542ca07a208ae63cbc325a0d1,"Lexical resource differ from encyclopaedic resources and represent two distinct types of resource covering general language and named entities respectively. However, many lexical resources, including Princeton WordNet, contain many proper nouns, referring to named entities in the world yet it is not possible or desirable for a lexical resource to cover all named entities that may reasonably occur in a text. In this paper, we propose that instead of including synsets for instance concepts PWN should instead provide links to Wikipedia articles describing the concept. In order to enable this we have created a gold-quality mapping between all of the 7,742 instances in PWN and Wikipedia (where such a mapping is possible). As such, this resource aims to provide a gold standard for link discovery, while also allowing PWN to distinguish itself from other resources such as DBpedia or BabelNet. Moreover, this linking connects PWN to the Linguistic Linked Open Data cloud, thus creating a richer, more usable resource for natural language processing. © 2018 Global WordNet Association. All rights reserved.",Final,
Perera R.; Nand P.,"Perera, Rivindu (56425389400); Nand, Parma (6506991350)",56425389400; 6506991350,An ensemble architecture for linked data lexicalization,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055443976&doi=10.1007%2f978-3-319-77113-7_34&partnerID=40&md5=326adfaeb7d1d3d741e9e860049613ce,"Linked Data has revamped the representation of knowledge by introducing the triple data structure which can encode knowledge with the associated semantics including the context by interlinking with external resources across documents. Although Linked Data is an attractive and effective mechanism to represent knowledge as created and consumed by humans in the form of a natural language, it still has a dimension of separation from natural language. Hence, in recent times, there has been an increase interest in transforming Linked Data into natural language in order to harness the benefits of Linked Data in applications interacting with natural language. This paper presents a framework that lexicalizes the Linked Data triples into natural language using an ensemble architecture. The proposed architecture is comprised of four different pattern based modules which lexicalize triples by analysing the triple features. The four pattern mining modules are based on occupational metonyms, Context Free Grammar (CFG), relation extraction using Open Information Extraction (OpenIE), and triple properties. The framework was evaluated using a two-fold evaluation process consisting of linguistic accuracy analysis and human evaluation for a test sample. The linguistic accuracy evaluation showed that the framework can produce 283 accurate lexicalization patterns for a set of 25 ontology classes resulting in a 70.75% accuracy, which is an approximately 91% increase compared to the existing state-of-the-art model. © Springer Nature Switzerland AG 2018.",Final,
Tamper M.; Leskinen P.; Apajalahti K.; Hyvönen E.,"Tamper, Minna (57190293971); Leskinen, Petri (56730467000); Apajalahti, Kasper (57079018400); Hyvönen, Eero (8435405300)",57190293971; 56730467000; 57079018400; 8435405300,Using Biographical Texts as Linked Data for Prosopographical Research and Applications,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055421322&doi=10.1007%2f978-3-030-01762-0_11&partnerID=40&md5=0ed343b00888b403c6d13c74a49eab45,"This paper argues that representing texts as semantic Linked Data provides a useful basis for analyzing their contents in Digital Humanities research and for Cultural Heritage application development. The idea is to transform Cultural Heritage texts into a knowledge graph and a Linked Data service that can be used flexibly in different applications via a SPARQL endpoint. The argument is discussed and evaluated in the context of biographical and prosopographical research and a case study where over 13 000 life stories form biographical collections of Biographical Centre of the Finnish Literature Society were transformed into RDF, enriched by data linking, and published in a SPARQL endpoint. Tools for biography and prosopography, data clustering, network analysis, and linguistic analysis were created with promising first results. © 2018, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Kesäniemi J.; Vartiainen T.; Säily T.; Nevalainen T.,"Kesäniemi, Joonas (57211446282); Vartiainen, Turo (55600405400); Säily, Tanja (37091648900); Nevalainen, Terttu (24405921500)",57211446282; 55600405400; 37091648900; 24405921500,Open Science for English historical corpus linguistics: Introducing the language change database,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045345125&partnerID=40&md5=9e25e1611a4212f5dfb8679b09cfef7f,"This paper discusses the development of an open-Access resource that can be used as a baseline for new corpus-linguistic research into the history of English: The Language Change Database (LCD). The LCD draws together information extracted from hundreds of corpusbased articles that investigate the ways in which English has changed in the course of history. The database includes annotated summaries of the articles, as well as numerical data extracted from the articles and transformed into machine-readable form, thus providing scholars of English with the opportunity to study fundamental questions about the nature, rate and direction of language change. It will also make the work done in the field more cumulative by ensuring that the research community will have continuous access to existing results and research data. We will also introduce a tool that takes advantage of this new source of structured research data. The LCD Aggregated Data Analysis workbench (LADA) makes use of annotated versions of the numerical data available from the LCD and provides a workflow for performing meta-Analytical experimentations with an aggregated set of data tables from multiple publications. Combined with the LCD as the source of collaborative, trusted and curated linked research data, the LADA meta-Analysis tool demonstrates how open data can be used in innovative ways to support new research through data-driven aggregation of empirical findings in the context of historical linguistics. © 2018 CEUR-WS. All rights reserved.",Final,
Bhowmik R.; De Melo G.,"Bhowmik, Rajarshi (57207858094); De Melo, Gerard (23088528100)",57207858094; 23088528100,Generating fine-grained open vocabulary entity type descriptions,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063099681&doi=10.18653%2fv1%2fp18-1081&partnerID=40&md5=15fca4c5111b0b729e1f41e051c865a6,"While large-scale knowledge graphs provide vast amounts of structured facts about entities, a short textual description can often be useful to succinctly characterize an entity and its type. Unfortunately, many knowledge graph entities lack such textual descriptions. In this paper, we introduce a dynamic memory-based network that generates a short open vocabulary description of an entity by jointly leveraging induced fact embeddings as well as the dynamic context of the generated sequence of words. We demonstrate the ability of our architecture to discern relevant information for more accurate generation of type description by pitting the system against several strong baselines. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Simov K.; Osenova P.,"Simov, Kiril (8835805500); Osenova, Petya (8933829900)",8835805500; 8933829900,Special thematic section on semantic models for natural language processing,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044005006&doi=10.2478%2fcait-2018-0008&partnerID=40&md5=96a18a0b072e4fb358c5aaff3fb263de,"With the availability of large language data online, cross-linked lexical resources (such as BabelNet, Predicate Matrix and UBY) and semantically annotated corpora (SemCor, OntoNotes, etc.), more and more applications in Natural Language Processing (NLP) have started to exploit various semantic models. The semantic models have been created on the base of LSA, clustering, word embeddings, deep learning, neural networks, etc., and abstract logical forms, such as Minimal Recursion Semantics (MRS) or Abstract Meaning Representation (AMR), etc. Additionally, the Linguistic Linked Open Data Cloud has been initiated (LLOD Cloud) which interlinks linguistic data for improving the tasks of NLP. This cloud has been expanding enormously for the last four-five years. It includes corpora, lexicons, thesauri, knowledge bases of various kinds, organized around appropriate ontologies, such as LEMON. The semantic models behind the data organization as well as the representation of the semantic resources themselves are a challenge to the NLP community. The NLP applications that extensively rely on the above discussed models include Machine Translation, Information Extraction, Question Answering, Text Simplification, etc. © 2001-2018 Institute of Information and Communication Technologies at Bulgarian Academy of Sciences.",Final,All Open Access; Gold Open Access
Me´száros T.; Kiss M.,"Me´száros, Tamás (35318287000); Kiss, Margit (57203088912)",35318287000; 57203088912,The DHmine dictionary work-flow: Creating a knowledge-based author's dictionary,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050453108&partnerID=40&md5=9c736fc9bdf2d1c9b5e698f73b2e7e79,"Digitalized author's dictionaries could play an important role in humanities research. Not only could they provide better ways to study an individual author's vocabulary, but they could also act as a knowledge source for other computer-based methods. We present the process of making an author's dictionary of headwords, writing variations, word forms and corpus citations extended with part-of-speech, linguistic, literary and semantic information. We also describe how this extended dictionary incorporates knowledge from linked open data sources and from critical annotations and builds an RDF knowledge base attached to the dictionary. The result is a vast knowledge source about an author's oeuvre that can be studied and used to enhance corpus analysis. We demonstrate our method on processing a large text corpora of 1.5 million words from the 18th century and on creating the digital author's dictionary of Kelemen Mikes. © Lexicography in Global Contexts.",Final,
Supriyono P.; Scheider S.,"Supriyono, Pandu (57196038778); Scheider, Simon (23390358300)",57196038778; 23390358300,Translating verbally communicated local geographic knowledge using semantic technologies: A balinese example,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301869&doi=10.1007%2f978-3-319-63946-8_36&partnerID=40&md5=52d134b09920a079367628ae50aa167e,"Using cognitive linguistic strategies, people can verbally encode and convey their spatial realities with little effort (i.e. “my house is right across the street from the grocery store”). However, to date there are a limited number of ways to transform such spatial information into forms that are useful for computational analysis in a geographic information system (GIS), and for sharing across research communities. This paper uses a case study in the Balinese language to investigate the spatial and linguistic information necessary to compute such transformations. That is, to transform verbally communicated spatial scenes into GIS-suitable data. We propose an ontology which captures reference frames used in certain Balinese locative expressions together with the parameters (ground, direction and template) required for transformation. The approach allows for the sharing of translation methods and the reuse of contextual information on the Web. Based on this model, we identify open research questions on the way to supporting approximate transformations of locative expressions. © Springer International Publishing AG 2018.",Final,
Gangemi A.; Alam M.; Presutti V.,"Gangemi, Aldo (55605133800); Alam, Mehwish (57201532578); Presutti, Valentina (55885160000)",55605133800; 57201532578; 55885160000,Linked metaphors,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055349844&partnerID=40&md5=dd8e69433a9ec72725d4e8b1f70af660,"The poster summarizes Amnestic Forgery, an ontology for metaphor semantics, based on MetaNet and Framester factual-linguistic linked data. An example of metaphor generation based on linked metaphors is shown. © 2018 CEUR-WS. All rights reserved.",Final,
Krek S.; Kosem I.; McCrae J.P.; Navigli R.; Pedersen B.S.; Tiberius C.; Wissik T.,"Krek, Simon (55581031400); Kosem, Iztok (23008769500); McCrae, John P. (36666801700); Navigli, Roberto (6507102454); Pedersen, Bolette S. (7201713480); Tiberius, Carole (26632410700); Wissik, Tanja (55842078100)",55581031400; 23008769500; 36666801700; 6507102454; 7201713480; 26632410700; 55842078100,European lexicographic infrastructure (ELEXIS),1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059436497&partnerID=40&md5=67932db39b0565fc3f18228fe8d6fa0d,"In the paper we describe a new EU infrastructure project dedicated to lexicography. The project is part of the Horizon 2020 program, with a duration of four years (2018-2022). The result of the project will be an infrastructure which will (1) enable efficient access to high quality lexicographic data, and (2) bridge the gap between more advanced and less-resourced scholarly communities working on lexicographic resources. One of the main issues addressed by the project is the fact that current lexicographic resources have different levels of (incompatible) structuring, and are not equally suitable for application in in Natural Language Processing and other fields. The project will therefore develop strategies, tools and standards for extracting, structuring and linking lexicographic resources to enable their inclusion in Linked Open Data and the Semantic Web, as well as their use in the context of digital humanities. © Lexicography in Global Contexts.",Final,
Abián D.; Guerra F.; Martínez-Romanos J.; Trillo-Lado R.,"Abián, D. (57201578915); Guerra, F. (23396829400); Martínez-Romanos, J. (57201582187); Trillo-Lado, Raquel (42262968500)",57201578915; 23396829400; 57201582187; 42262968500,Wikidata and DBpedia: A Comparative Study,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045296691&doi=10.1007%2f978-3-319-74497-1_14&partnerID=40&md5=9b47e08635e69788aa40eb404f57694a,"DBpedia and Wikidata are two online projects focused on offering structured data from Wikipedia in order to ease its exploitation on the Linked Data Web. In this paper, a comparison of these two widely-used structured data sources is presented. This comparison considers the most relevant data quality dimensions in the state of the art of the scientific research. As fundamental differences between both projects, we can highlight that Wikidata has an open centralised nature, whereas DBpedia is more popular in the Semantic Web and the Linked Open Data communities and depends on the different linguistic editions of Wikipedia. © Springer International Publishing AG 2018.",Final,
Jiang Z.; Gu Q.; Yin Y.; Chen D.,"Jiang, Zhiwei (51563992800); Gu, Qing (57205368016); Yin, Yafeng (55648429800); Chen, Daoxu (7405455672)",51563992800; 57205368016; 55648429800; 7405455672,Enriching word embeddings with domain knowledge for readability assessment,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119407962&partnerID=40&md5=5e5d5bf1d59a8e84a572d8b7dd592b78,"In this paper, we present a method which learns the word embedding for readability assessment. For the existing word embedding models, they typically focus on the syntactic or semantic relations of words, while ignoring the reading difficulty, thus they may not be suitable for readability assessment. Hence, we provide the knowledge-enriched word embedding (KEWE), which encodes the knowledge on reading difficulty into the representation of words. Specifically, we extract the knowledge on word-level difficulty from three perspectives to construct a knowledge graph, and develop two word embedding models to incorporate the difficulty context derived from the knowledge graph to define the loss functions. Experiments are designed to apply KEWE for readability assessment on both English and Chinese datasets, and the results demonstrate both effectiveness and potential of KEWE. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Garcia-Silva A.; Gomez-Perez J.M.,"Garcia-Silva, Andres (36718996900); Gomez-Perez, Jose Manuel (23485087500)",36718996900; 23485087500,Not just about size - A study on the role of distributed word representations in the analysis of scientific publications,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048346653&partnerID=40&md5=2f26e252d5b0328167684c77e6280863,"The emergence of knowledge graphs in the scholarly communication domain and recent advances in artificial intelligence and natural language processing bring us closer to a scenario where intelligent systems can assist scientists over a range of knowledge-intensive tasks. In this paper we present experimental results about the generation of word embeddings from scholarly publications for the intelligent processing of scientific texts extracted from SciGraph. We compare the performance of domain-specific embeddings with existing pre-trained vectors generated from very large and general purpose corpora. Our results suggest that there is a trade-off between corpus speciflcity and volume. Embeddings from domain-specific scientific corpora effectively capture the semantics of the domain. On the other hand, obtaining comparable results through general corpora can also be achieved, but only in the presence of very large corpora of well formed text. Furthermore, we also show that the degree of overlapping between knowledge areas is directly related to the performance of embeddings in domain evaluation tasks. © 2018 CEUR Workshop Proceedings. All rights reserved.",Final,
Rouces J.; De Melo G.; Hose K.,"Rouces, Jacobo (55871390700); De Melo, Gerard (23088528100); Hose, Katja (23388785300)",55871390700; 23088528100; 23388785300,Addressing structural and linguistic heterogeneity in the Web,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059701206&doi=10.3233%2fAIC-170745&partnerID=40&md5=6358c1b60ba67b3e0f6dbecd04747d5a,"An increasing number of structured knowledge bases have become available on the Web, enabling many new forms of analyses and applications. However, the fact that the data is being published by different parties with different vocabularies and ontologies means that there is a high degree of heterogeneity and no common schema. At the same time, the abundance of different human languages across unstructured data presents a similar problem, because most text mining tools only cater to the English language. This paper presents solutions for these two kinds of heterogeneity. It introduces Klint, aWeb-based system that automatically creates mappings to transform knowledge from heterogeneous sources into FrameBase, which is a broad linked data schema that enables the representation of a wide range of knowledge. With Klint, a user can review and edit the mappings with a streamlined interface, which in turn allows for human-level accuracy with minimum human effort. The paper further describes how FrameBase can be extended to support multilingual labels, which can aid in extending current tools for integrating English text into FrameBase knowledge. © 2018 Wolters Kluwer Medknow Publications. All rights reserved.",Final,All Open Access; Green Open Access
Han X.; Liu Z.; Sun M.,"Han, Xu (57205548124); Liu, Zhiyuan (57191691341); Sun, Maosong (7403180987)",57205548124; 57191691341; 7403180987,Neural knowledge acquisition via mutual attention between knowledge graph and text,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060500143&partnerID=40&md5=17c79a5a40150bd0e5fae1214d4a8f93,"We propose a general joint representation learning framework for knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text. In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space. To achieve better fusion, we propose an effective mutual attention between KGs and text. The reciprocal attention mechanism enables us to highlight important features and perform better KGC and RE. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models. Experiments on relation extraction and entity link prediction show that models trained under our joint framework are significantly improved in comparison with other baselines. Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures. The source code of this paper can be obtained from https://github.com/thunlp/JointNRE. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Soares R.; Edelstein E.; Pan J.Z.; Wyner A.,"Soares, Ricardo (57204808269); Edelstein, Elspeth (57204806756); Pan, Jeff Z. (8856621200); Wyner, Adam (7006211789)",57204808269; 57204806756; 8856621200; 7006211789,Knowledge driven intelligent survey systems for linguists,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057271563&doi=10.1007%2f978-3-030-04284-4_1&partnerID=40&md5=f5905e9fe73b222826b1f08a9b247892,"In this paper, we propose Knowledge Graph (KG), an articulated underlying semantic structure, to be a semantic bridge between human and systems. To illustrate our proposal, we focus on KG based intelligent survey systems. In state of the art systems, knowledge is hard-coded or implicit in these systems, making it hard for researchers to reuse, customise, link, or transmit the structured knowledge. Furthermore, such systems do not facilitate dynamic interaction based on the semantic structure. We design and implement a knowledge-driven intelligent survey system which is based on knowledge graph, a widely used technology that facilitates sharing and querying hypotheses, survey content, results, and analyses. The approach is developed, implemented, and tested in the field of Linguistics. Syntacticians and morphologists develop theories of grammar of natural languages. To evaluate theories, they seek intuitive grammaticality (well-formedness) judgments from native speakers, which either support a theory or provide counter-evidence. Our preliminary experiments show that a knowledge graph based linguistic survey can provide more nuanced results than traditional document-based grammaticality judgment surveys by allowing for tagging and manipulation of specific linguistic variables. © Springer Nature Switzerland AG 2018.",Final,All Open Access; Green Open Access
Gracia J.; Villegas M.; Gómez-Pérez A.; Bel N.,"Gracia, Jorge (55392626700); Villegas, Marta (57197393787); Gómez-Pérez, Asunción (6603934482); Bel, Núria (55369471300)",55392626700; 57197393787; 6603934482; 55369471300,The apertium bilingual dictionaries on the web of data,1,,1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048132779&doi=10.3233%2fSW-170258&partnerID=40&md5=41cd0efe9b873ab82788a607f6819531,"Bilingual electronic dictionaries contain collections of lexical entries in two languages, with explicitly declared translation relations between such entries. Nevertheless, they are typically developed in isolation, in their own formats and accessible through proprietary APIs. In this paper we propose the use of Semantic Web techniques to make translations available on the Web to be consumed by other semantic enabled resources in a direct manner, based on standard languages and query means. In particular, we describe the conversion of the Apertium family of bilingual dictionaries and lexicons into RDF (Resource Description Framework) and how their data have been made accessible on the Web as linked data. As a result, all the converted dictionaries (many of them covering under-resourced languages) are connected among them and can be easily traversed from one to another to obtain, for instance, translations between language pairs not originally connected in any of the original dictionaries. © 2018 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Green Open Access
Stolz A.; Hepp M.; Boggs R.A.,"Stolz, Alex (55782475700); Hepp, Martin (23389068200); Boggs, Roy A. (57196343029)",55782475700; 23389068200; 57196343029,Linked open data for linguists: Publishing the hartmann von aue-portal in RDF,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032680307&doi=10.1007%2f978-3-319-69459-7_20&partnerID=40&md5=cf3fed95bfa3f1e8423819bbc19e7333,"The Hartmann von Aue-portal is a decade-long initiative to employ Web technology in order to support the study of the early German. It provides a comprehensive knowledge base on lexicographic and other aspects of the works of Hartmann von Aue, one of the key epic poets of Middle High German literature; namely lemmata, word forms, tagmemes, adverbs, and the like, including original contexts for entries. The portal is available for human users in the form of a Web application. Linked Open Data (LOD) is a recent approach in the evolution of Web technology that supports the publication of information on the Web in a way suitable for the intelligent consumption and processing of contents by computers instead of humans using Web browsers. In this paper, we study the use of modern LOD approaches for linguistics, describe the conversion of the complete Hartmann von Aue-portal into LOD, and show the usage for data-driven analyses via SPARQL queries and literate programming with Python. © 2017, Springer International Publishing AG.",Final,
Ardissono L.; Lucenteforte M.; Mauro N.; Savoca A.; Voghera A.; Riccia L.L.,"Ardissono, Liliana (6603677372); Lucenteforte, Maurizio (55971647000); Mauro, Noemi (57191504166); Savoca, Adriano (56562912600); Voghera, Angioletta (23468238200); Riccia, Luigi La (57199671520)",6603677372; 55971647000; 57191504166; 56562912600; 23468238200; 57199671520,OnToMap - Semantic community maps for knowledge sharing,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026431330&doi=10.1145%2f3078714.3078747&partnerID=40&md5=7121aff747f9d4fb4f94b020548b8f5f,"We present the information retrieval model adopted in the On- ToMap Participatory GIS. the model addresses the limitations of keyword-based and category-based search by semantically interpreting the information needs specified in free-text search queries. the model is based on an ontological representation of linguistic and encyclopaedic knowledge, which makes it possible to exploit terms and synonyms occurring in the definitions of concepts to flexibly match the user's and system's terminologies. this feature enables users to query the application using their own vocabulary. © 2017 Copyright held by the owner/author(s).",Final,
Trandabat D.; Gifu D.,"Trandabat, Diana (23398822800); Gifu, Daniela (42661254500)",23398822800; 42661254500,Social Media and the Web of Linked Data,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027959093&doi=10.1109%2fJCDL.2017.7991624&partnerID=40&md5=91788d3e7156d6dfb7efc8586fee346f,"Written texts have perhaps never been so widely used as they are in today's social media context, with people constantly writing, sharing, commenting, getting involved. At the same time, Linked Data is emerging as an increasingly important topic, and research in this area has resulted in massive amounts of structured linguistic data. In this climate, we intend to analyze how linked data can help to structure and extract meaning from social media's short, informal and context dependent texts, with an emphasis on real-life applications. © 2017 IEEE.",Final,
Both F.; Thoma S.; Rettinger A.,"Both, Fabian (57190138261); Thoma, Steffen (56727815200); Rettinger, Achim (23092350400)",57190138261; 56727815200; 23092350400,Cross-modal knowledge transfer: Improving the word embedding of apple by looking at oranges,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040602084&doi=10.1145%2f3148011.3148026&partnerID=40&md5=824cabcd87f1f2c599a636242b7ee82f,"Capturing knowledge via learned latent vector representations of words, images and knowledge graph (KG) entities has shown state of-the-art performance in computer vision, computational linguistics and KG tasks. Recent results demonstrate that the learning of such representations across modalities can be beneficial, since each modality captures complementary information. However, those approaches are limited to concepts with cross-modal alignments in the training data which are only available for just a few concepts. Especially for visual objects exist far fewer embeddings than for words or KG entities. We investigate whether a word embedding (e.g., for ""apple"") can still capture information from other modalities even if there is no matching concept within the other modalities (i.e., no images or KG entities of apples but of oranges as pictured in the title analogy). The empirical results of our knowledge transfer approach demonstrate that word embeddings do benefit from extrapolating information across modalities even for concepts that are not represented in the other modalities. Interestingly, this applies most to concrete concepts (e.g., dragonfly) while abstract concepts (e.g., animal) benefit most if aligned concepts are available in the other modalities. © 2017 Copyright held by the owner/author(s).",Final,
Loughnane R.; McCurdy K.; Kolb P.; Selent S.,"Loughnane, Robyn (57511227700); McCurdy, Kate (57219499137); Kolb, Peter (57371751200); Selent, Stefan (56469681100)",57511227700; 57219499137; 57371751200; 56469681100,Linked data for language-learning applications,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076448651&partnerID=40&md5=6d479791bc2a43179a7e9b2c1f4b6143,"The use of linked data within languagelearning applications is an open research question. A research prototype is presented that applies linked-data principles to store linguistic annotation generated from language-learning content using a variety of NLP tools. The result is a database that links learning content, linguistic annotation and open-source resources, on top of which a diverse range of tools for language-learning applications can be built. © EMNLP 2017 - 12th Workshop on Innovative Use of NLP for Building Educational Applications, BEA 2017 - Proceedings of the Workshop. All rights reserved.",Final,
Kirillovich A.; Nevzorova O.; Gimadiev E.; Loukachevitch N.,"Kirillovich, Alexander (55994716700); Nevzorova, Olga (6506234633); Gimadiev, Emil (57197728348); Loukachevitch, Natalia (6504197092)",55994716700; 6506234633; 57197728348; 6504197092,RuThes cloud: Towards a multilevel linguistic linked open data resource for Russian,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034266316&doi=10.1007%2f978-3-319-69548-8_4&partnerID=40&md5=429af2d4ae4b394cf5134c923a203adb,"In this paper we present a new multi-level Linguistic Linked Open Data resource for Russian. It covers four linguistic levels: semantic, lexical, morphological and syntactic. The resource has been constructed on base of the well-known RuThes thesaurus and the original hitherto unpublished Extended Zaliznyak grammatical dictionary. The resource is represented in terms of SKOS, Lemon, and LexInfo ontologies and a new custom ontology. Building the resource, we automatically completed the following tasks: merging source resources upon common lexical entries, decomposing complex lexical entries, and publishing constructed resource as LLOD-compatible dataset. We demonstrate the use case in which the developed resource is exploited in IR task. We hope that our work can serve as a crystallization point of the LLOD cloud in Russian. © 2017, Springer International Publishing AG.",Final,
Lecailliez L.,"Lecailliez, Louis (57207064600)",57207064600,Preliminary thoughts on issues of modeling Japanese dictionaries using the OntoLex model,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062198224&partnerID=40&md5=347401fe1a9978811e4ec8034ce61b56,"Recent works aiming at making Linked Data dictionaries make use of the Lemon or OntoLex models. Application to existing dictionaries revealed the need for extensions to the model to properly deal with lexicographic data without loss of information. These works however focus on languages found in Europe, and thus let the issue of Est-Asian lexicography for future exploration. This paper provides a small typology of existing dictionaries in Japan and exposes issues in existing related works that could form the ground of new modules for OntoLex. © 2017 Tribun EU s. r. o. All rights reserved.",Final,
Maynard D.; Bontcheva K.; Augenstein I.,"Maynard, Diana (8704767900); Bontcheva, Kalina (6602790600); Augenstein, Isabelle (55236320300)",8704767900; 6602790600; 55236320300,Natural Language Processing for the Semantic Web,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048908627&doi=10.2200%2fS00741ED1V01Y201611WBE015&partnerID=40&md5=f32a59c28be5f2f2b831a74eb3e35da5,"This book introduces core natural language processing (NLP) technologies to non-experts in an easily accessible way, as a series of building blocks that lead the user to understand key technologies, why they are required, and how to integrate them into Semantic Web applications. Natural language processing and Semantic Web technologies have different, but complementary roles in data management. Combining these two technologies enables structured and unstructured data to merge seamlessly. Semantic Web technologies aim to convert unstructured data to meaningful representations, which benefit enormously from the use of NLP technologies, thereby enabling applications such as connecting text to Linked Open Data, connecting texts to each other, semantic searching, information visualization, and modeling of user behavior in online networks. The first half of this book describes the basic NLP processing tools: tokenization, part-of-speech tagging, and morphological analysis, in addition to the main tools required for an information extraction system (named entity recognition and relation extraction) which build on these components. The second half of the book explains how Semantic Web and NLP technologies can enhance each other, for example via semantic annotation, ontology linking, and population. These chapters also discuss sentiment analysis, a key component in making sense of textual data, and the difficulties of performing NLP on social media, as well as some proposed solutions. The book finishes by investigating some applications of these tools, focusing on semantic search and visualization, modeling user behavior, and an outlook on the future. © Copyright 2017 by Morgan & Claypool.",Final,All Open Access; Green Open Access
Roa-Valverde A.J.; Sanchez-Alonso S.; Sicilia M.-A.; Fensel D.,"Roa-Valverde, Antonio J. (36061477400); Sanchez-Alonso, Salvador (8951086600); Sicilia, Miguel-Angel (8266687800); Fensel, Dieter (56206793500)",36061477400; 8951086600; 8266687800; 56206793500,An approach to measuring and annotating the confidence of Wiktionary translations,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011711366&doi=10.1007%2fs10579-017-9384-9&partnerID=40&md5=66c55efe68e8c2789eea4d671944de2e,"Wiktionary is an online collaborative project based on the same principle than Wikipedia, where users can create, edit and delete entries containing lexical information. While the open nature of Wiktionary is the reason for its fast growth, it has also brought a problem: how reliable is the lexical information contained in every article? If we are planing to use Wiktionary translations as source content to accomplish a certain use case, we need to be able to answer this question and extract measures of their confidence. In this paper we present our work on assessing the quality of Wiktionary translations by introducing confidence metrics. Additionally, we describe our effort to share Wiktionary translations and the associated confidence values as linked data. © 2017, Springer Science+Business Media Dordrecht.",Final,
Casanovas P.; Rodríguez-Doncel V.; González-Conejero J.,"Casanovas, Pompeu (13604673100); Rodríguez-Doncel, Víctor (35204031900); González-Conejero, Jorge (8326998600)",13604673100; 35204031900; 8326998600,The role of pragmatics in the web of data,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028543909&doi=10.1007%2f978-3-319-44601-1_12&partnerID=40&md5=3c501a8367f7f460f5e2f3324c496e69,"This chapter is an introduction to the Semantic Web, the Web of Data, regulatory models, and the law. It does not take anything for granted. The first part of the chapter describes the languages of the Semantic Web, and shows how the perspective of the Web of Services and Linked Data is related to the conditions under which services can be offered, managed and used. The Web has been massively populated with both data and services. Semantically structured data, the Linked Data Cloud, allows and fosters human-machine interaction. Linked Data aims at creating ecosystems to facilitate the browsing, discovery, exploitation and reuse of datasets for applications. Licensed Linked Data is offered along with information about the rights involved. Rights Expression Languages are able to regulate half-automatically the use and reuse of content. The second part of the chapter shows that the nature of law is experiencing a deep transformation in the cloud. What links the information flow, social intelligence, rights management, and modelling in the Web of Data is the pragmatic approach —what we call the pragmatic turn, i.e. the representation of users’ needs and contexts to facilitate the automated interactive and collective management of knowledge. Both ontology building and knowledge acquisition share this perspective. The Web of Data brings about new challenges on agency, knowledge, communication, and the coordination of actions. Institutions can regulate both human and machine behaviours within these new environments. Licensed Linked Data, Licensed Linguistic Linked Data, Right Expression Languages, Semantic Web Regulatory Models, Electronic Institutions, Artificial Socio-cognitive Systems are examples of regulatory and institutional design (Regulations by Design). Regulatory systems become more complex in the cloud, in order to be simpler. © Springer International Publishing Switzerland 2017.",Final,
Bosque-Gil J.; Gracia J.; Montiel-Ponsoda E.,"Bosque-Gil, Julia (57031866000); Gracia, Jorge (55392626700); Montiel-Ponsoda, Elena (25654093800)",57031866000; 55392626700; 25654093800,Towards a module for lexicography in ontolex,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029164729&partnerID=40&md5=59590259367673c6dda5b47b3936819d,"Dictionaries are increasingly being transformed into linguistic linked lata (LLD) relying on the lemon and OntoLex models, but this conversion is not always straightforward. For both linked data (LD) based applications to exploit all content provided in dictionaries and lexicographers adopting LD technologies, the original data and structure should be retrievable from the LLD version to prevent any loss of information in the transformation. In this position statement we motivate the need for a new module in OntoLex targeted at the representation of dictionaries and which will address structures and annotations commonly found in lexicography. Some of the issues we identified in our initial experiences are presented as input for discussion, along with our initial approaches to solve them. Such a module is intended to be compatible with other modules in OntoLex and should guarantee information preservation, making LD a viable mechanism for lexicographers in the development of lexica.",Final,
Tchechmedjiev A.; Mandon T.; Lafourcade M.; Laurent A.; Todorov K.,"Tchechmedjiev, Andon (55667932600); Mandon, Théophile (57196197300); Lafourcade, Mathieu (23094829600); Laurent, Anne (7101728993); Todorov, Konstantin (24774051300)",55667932600; 57196197300; 23094829600; 7101728993; 24774051300,Ontolex JeuxDeMots and its alignment to the linguistic linked open data cloud,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032199318&doi=10.1007%2f978-3-319-68288-4_40&partnerID=40&md5=0db3c34e3d720f2de18b82e094d3c894,"JeuxDeMots (JdM) is a rich collaborative lexical network in French, built on a crowdsourcing principle as a game with a purpose, represented in an ad-hoc tabular format. In the interest of reuse and interoperability, we propose a conversion algorithm for JdM following the Ontolex model, along with a word sense alignment algorithm, called JdMBabelizer, that anchors JdM sense-refinements to synsets in the lemon edition of BabelNet and thus to the Linguistic Linked Open Data cloud. Our alignment algorithm exploits the richness of JdM in terms of weighted semantic-lexical relations—particularly the inhibition relation between senses—that are specific to JdM. We produce a reference alignment dataset for JdM and BabelNet that we use to evaluate the quality of our algorithm and that we make available to the community. The obtained results are comparable to those of state of the art approaches. © Springer International Publishing AG 2017.",Final,All Open Access; Green Open Access
McCrae J.P.; Wood I.; Hicks A.,"McCrae, John P. (36666801700); Wood, Ian (56564912800); Hicks, Amanda (57072854200)",36666801700; 56564912800; 57072854200,The colloquial WordNet: Extending Princeton WordNet with neologisms,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021200771&doi=10.1007%2f978-3-319-59888-8_17&partnerID=40&md5=342fddfc3c9aa9e763e0926c66e2b925,"Princeton WordNet is one of the most important resources for natural language processing, but has not been updated for over ten years and is not suitable for analyzing the fast moving language as used on social media. We propose an extension to WordNet, with new terms that have been found from Twitter and Reddit, and cover language usage that is emergent or vulgar. In addition to our methodology for extraction, we analyze new terms to provide information about how new words are entering the English language. Finally, we discuss publishing this resource both as linguistic linked open data and as part of the Global WordNet Association’s Interlingual Index. © Springer International Publishing AG 2017.",Final,All Open Access; Green Open Access
Marginean A.,"Marginean, Anca (23397594200)",23397594200,Question answering over biomedical linked data with Grammatical Framework,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010934356&doi=10.3233%2fSW-160223&partnerID=40&md5=801d07da07668112d1560beb59e2cbea,"The blending of linked data with ontologies leverages the access to data. GFMed introduces grammars for a controlled natural language targeted towards biomedical linked data and the corresponding controlled SPARQL language. The grammars are described in Grammatical Framework and introduce linguistic and SPARQL phrases mostly about drugs, diseases and relationships between them. The semantic and linguistic chunks correspond to Description Logic constructors. Problems and solutions for querying biomedical linked data with Romanian, besides English, are also considered in the context of GF. © 2017-IOS.",Final,
Li N.; Sun J.,"Li, Nan (55802700400); Sun, Jiqing (56813897100)",55802700400; 56813897100,Improving Chinese term association from the linguistic perspective,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015800333&doi=10.5771%2f0943-7444-2017-1-13&partnerID=40&md5=67bc39c511ee3cdf7051e756735b5646,"The study aims to solve how to construct the semantic relations of specific domain terms by applying linguistic rules. The semantic structure analysis at the morpheme level was used for semantic measure, and a morpheme-based term association model was proposed by improving and combining the literal-based similarity algorithm and co-occurrence relatedness methods. This study provides a novel insight into the method of semantic analysis and calculation by morpheme parsing, and the proposed solution is feasible for the automatic association of compound terms. The results show that this approach could be used to construct appropriate term association and form a reasonable structural knowledge graph. However, due to linguistic differences, the viability and effectiveness of the use of our method in non-Chinese linguistic environments should be verified.",Final,
Rouces J.; De Melo G.; Hose K.,"Rouces, Jacobo (55871390700); De Melo, Gerard (23088528100); Hose, Katja (23388785300)",55871390700; 23088528100; 23388785300,FrameBase: Enabling integration of heterogeneous knowledge,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027393990&doi=10.3233%2fSW-170279&partnerID=40&md5=9ac1b3786a699d788b9981f53c067da2,"Large-scale knowledge graphs such as those in the Linked Open Data cloud are typically stored as subject-predicate-object triples. However, many facts about the world involve more than two entities. While n-ary relations can be converted to triples in a number of ways, unfortunately, the structurally different choices made in different knowledge sources significantly impede our ability to connect them. They also increase semantic heterogeneity, making it impossible to query the data concisely and without prior knowledge of each individual source. This article presents FrameBase, a wide-coverage knowledge base schema that uses linguistic frames to represent and query n-ary relations from other knowledge bases, providing multiple levels of granularity connected via logical entailment. Overall, this provides a means for semantic integration from heterogeneous sources under a single schema and opens up possibilities to draw on natural language processing techniques for querying and data mining. © 2017 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Green Open Access
Chiarcos C.; Ionov M.; Rind-Pawlowski M.; Fäth C.; Schreur J.W.; Nevskaya I.,"Chiarcos, Christian (22333764800); Ionov, Maxim (57194612761); Rind-Pawlowski, Monika (57194613629); Fäth, Christian (57194612424); Schreur, Jesse Wichers (57194609180); Nevskaya, Irina (57189753273)",22333764800; 57194612761; 57194613629; 57194612424; 57194609180; 57189753273,LLODifying linguistic glosses,1,,1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021193597&doi=10.1007%2f978-3-319-59888-8_7&partnerID=40&md5=ef597d9ae10042b6d31316b2cdcc00b1,"Interlinear glossed text (IGT) is a notation used in various fields of linguistics to provide readers with a way to understand the linguistic phenomena. We describe the representation of IGT data in RDF, the conversion from two popular tools, and their automated linking with resources from the Linguistic Linked Open Data (LLOD) cloud. We argue that such an LLOD edition of IGT data facilitates their reusability, their infrastructural support and their integration with external data sources. Our converters are available under an open source license, two data sets will be published along with the final version of this paper. To our best knowledge, this is the first attempt to publish IGT data sets as Linguistic Linked Open Data we are aware of. © Springer International Publishing AG 2017.",Final,
Falk I.; Stein A.,"Falk, Ingrid (24767501200); Stein, Achim (37084047400)",24767501200; 37084047400,"LVF-lemon - Towards a linked data representation of ""Les Verbes français""",1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037070562&partnerID=40&md5=365a74903d639d09137482d95e151c55,In this study we elaborate a road map for the conversion of a traditional lexical syntactico-semantic resource for French into a linguistic linked open data (LLOD) model. Our approach uses current best-practices and the analyses of earlier similar undertakings (lemonUBY and PDEV-lemon) to tease out the most appropriate representation for our resource.,Final,
List J.-M.; Cysouw M.; Forkel R.,"List, Johann-Mattis (36675201700); Cysouw, Michael (24467617300); Forkel, Robert (57195331057)",36675201700; 24467617300; 57195331057,Concepticon: A resource for the linking of concept lists,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037152460&partnerID=40&md5=3122a0ba89f81396469e2cb366878186,"We present an attempt to link the large amount of different concept lists which are used in the linguistic literature, ranging from Swadesh lists in historical linguistics to naming tests in clinical studies and psycholinguistics. This resource, our Concepticon, links 30 222 concept labels from 160 conceptlists to 2495 concept sets. Each concept set is given a unique identifier, a unique label, and a human-readable definition. Concept sets are further structured by defining different relations between the concepts. The resource can be used for various purposes. Serving as a rich reference for new and existing databases in diachronic and synchronic linguistics, it allows researchers a quick access to studies on semantic change, cross-linguistic polysemies, and semantic associations.",Final,
Klimek B.; Arndt N.; Krause S.; Arndt T.,"Klimek, Bettina (57194613467); Arndt, Natanael (42461015000); Krause, Sebastian (57220659616); Arndt, Timotheus (57198791427)",57194613467; 42461015000; 57220659616; 57198791427,Creating linked data morphological language resources with MMoOn the Hebrew Morpheme Inventory,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021200234&partnerID=40&md5=cfec73254b9b1bb4e4b3e76c31ca99fb,"The development of standard models for describing general lexical resources has led to the emergence of numerous lexical datasets of various languages in the Semantic Web. However, there are no models that describe the domain of morphology in a similar manner. As a result, there are hardly any language resources of morphemic data available in RDF to date. This paper presents the creation of the Hebrew Morpheme Inventory from a manually compiled tabular dataset comprising around 52.000 entries. It is an ongoing effort of representing the lexemes, word-forms and morphologigal patterns together with their underlying relations based on the newly created Multilingual Morpheme Ontology (MMoOn). It will be shown how segmented Hebrew language data can be granularly described in a Linked Data format, thus, serving as an exemplary case for creating morpheme inventories of any inflectional language with MMoOn. The resulting dataset is described a) according to the structure of the underlying data format, b) with respect to the Hebrew language characteristic of building word-forms directly from roots, c) by exemplifying how inflectional information is realized and d) with regard to its enrichment with external links to sense resources.",Final,
Krause S.; Hennig L.; Moro A.; Weissenborn D.; Xu F.; Uszkoreit H.; Navigli R.,"Krause, Sebastian (52164089400); Hennig, Leonhard (26430879400); Moro, Andrea (55509205800); Weissenborn, Dirk (56289711700); Xu, Feiyu (7401695091); Uszkoreit, Hans (13007575400); Navigli, Roberto (6507102454)",52164089400; 26430879400; 55509205800; 56289711700; 7401695091; 13007575400; 6507102454,Sar-graphs: A language resource connecting linguistic knowledge with semantic relations from knowledge graphs,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979468241&doi=10.1016%2fj.websem.2016.03.004&partnerID=40&md5=d542dd33fc6a5fbc7011ea0a08f87328,"Recent years have seen a significant growth and increased usage of large-scale knowledge resources in both academic research and industry. We can distinguish two main types of knowledge resources: those that store factual information about entities in the form of semantic relations (e.g., Freebase), namely so-called knowledge graphs, and those that represent general linguistic knowledge (e.g., WordNet or UWN). In this article, we present a third type of knowledge resource which completes the picture by connecting the two first types. Instances of this resource are graphs of semantically-associated relations (sar-graphs), whose purpose is to link semantic relations from factual knowledge graphs with their linguistic representations in human language. We present a general method for constructing sar-graphs using a language- and relation-independent, distantly supervised approach which, apart from generic language processing tools, relies solely on the availability of a lexical semantic resource, providing sense information for words, as well as a knowledge base containing seed relation instances. Using these seeds, our method extracts, validates and merges relation-specific linguistic patterns from text to create sar-graphs. To cope with the noisily labeled data arising in a distantly supervised setting, we propose several automatic pattern confidence estimation strategies, and also show how manual supervision can be used to improve the quality of sar-graph instances. We demonstrate the applicability of our method by constructing sar-graphs for 25 semantic relations, of which we make a subset publicly available at http://sargraph.dfki.de. We believe sar-graphs will prove to be useful linguistic resources for a wide variety of natural language processing tasks, and in particular for information extraction and knowledge base population. We illustrate their usefulness with experiments in relation extraction and in computer assisted language learning. © 2016 Elsevier B.V.",Final,
Parvizi A.; Kohl M.; Gonzàlez M.; Saurí R.,"Parvizi, A. (56209246100); Kohl, M. (57198809813); Gonzàlez, M. (55664440900); Saurí, R. (12762099600)",56209246100; 57198809813; 55664440900; 12762099600,Towards a linguistic ontology with an emphasis on reasoning and knowledge reuse,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029149766&partnerID=40&md5=12d7ec8159d4d10df6decaf424febf12,"The Dictionaries division at Oxford University Press (OUP) is aiming to model, integrate, and publish lexical content for 100 languages focussing on digitally under-represented languages. While there are multiple ontologies designed for linguistic resources, none had adequate features for meeting our requirements, chief of which was the capability to losslessly capture diverse features of many different languages in a dictionary format, while supplying a framework for inferring relations like translation, derivation, etc., between the data. Building on valuable features of existing models, and working with OUP monolingual and bilingual dictionary datasets, we have designed and implemented a new linguistic ontology. The ontology has been reviewed by a number of computational linguists, and we are working to move more dictionary data into it. We have also developed APIs to surface the linked data to dictionary websites.",Final,
Gangemi A.; Alam M.; Asprino L.; Presutti V.; Recupero D.R.,"Gangemi, Aldo (55605133800); Alam, Mehwish (57201532578); Asprino, Luigi (57191745706); Presutti, Valentina (55885160000); Recupero, Diego Reforgiato (57206674454)",55605133800; 57201532578; 57191745706; 55885160000; 57206674454,Framester: A wide coverage linguistic linked data hub,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997124448&doi=10.1007%2f978-3-319-49004-5_16&partnerID=40&md5=cdc7212b9de89606b0d5a31cdceae74c,"Semantic web applications leveraging NLP can benefit from easy access to expressive lexical resources such as FrameNet. However, the usefulness of FrameNet is affected by its limited coverage and nonstandard semantics. The access to existing linguistic resources is also limited because of poor connectivity among them. We present some strategies based on Linguistic Linked Data to broaden FrameNet coverage and formal linkage of lexical and factual resources. We created a novel resource, Framester, which acts as a hub between FrameNet, Word- Net, VerbNet, BabelNet, DBpedia, Yago, DOLCE-Zero, as well as other resources. Framester is not only a strongly connected knowledge graph, but also applies a rigorous formal treatment for Fillmore’s frame semantics, enabling full-fledged OWL querying and reasoning on a large framebased knowledge graph. We also describe Word Frame Disambiguation, an application that reuses Framester data as a base in order to perform frame detection from text, with results comparable in precision to the state of the art, but with a much higher coverage. © Springer International Publishing AG 2016.",Final,
McCrae J.P.; Chiarcos C.; Bond F.; Cimiano P.; Declerck T.; De Melo G.; Gracia J.; Hellmann S.; Klimek B.; Moran S.; Osenova P.; Pareja-Lora A.; Pool J.,"McCrae, John P. (36666801700); Chiarcos, Christian (22333764800); Bond, Francis (7003275857); Cimiano, Philipp (15838793700); Declerck, Thierry (22333556000); De Melo, Gerard (23088528100); Gracia, Jorge (55392626700); Hellmann, Sebastian (35199882400); Klimek, Bettina (57194613467); Moran, Steven (55901459600); Osenova, Petya (8933829900); Pareja-Lora, Antonio (6504385937); Pool, Jonathan (53564209400)",36666801700; 22333764800; 7003275857; 15838793700; 22333556000; 23088528100; 55392626700; 35199882400; 57194613467; 55901459600; 8933829900; 6504385937; 53564209400,The open linguistics working group: Developing the linguistic linked open data cloud,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034244297&partnerID=40&md5=79ee215efebe47247607e41d1aaee252,"The Open Linguistics Working Group (OWLG) brings together researchers from various fields of linguistics, natural language processing, and information technology to present and discuss principles, case studies, and best practices for representing, publishing and linking linguistic data collections. A major outcome of our work is the Linguistic Linked Open Data (LLOD) cloud, an LOD (sub-)cloud of linguistic resources, which covers various linguistic databases, lexicons, corpora, terminologies, and metadata repositories. We present and summarize five years of progress on the development of the cloud and of advancements in open data in linguistics, and we describe recent community activities. The paper aims to serve as a guideline to introduce and involve researchers with the community and more generally with Linguistic Linked Open Data.",Final,
Frontini F.; Del Gratta R.; Monachini M.,"Frontini, Francesca (55162070400); Del Gratta, Riccardo (34976432900); Monachini, Monica (23397766600)",55162070400; 34976432900; 23397766600,GeodomainWordNet: Linking the geonames ontology to WordNet,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981165734&doi=10.1007%2f978-3-319-43808-5_18&partnerID=40&md5=3f1d2bb1b27820ba3aeed8801419595d,"This paper illustrates the transformation of GeoNames’ ontology concepts, with their English labels and glosses, into a Geo-Domain WordNet-like resource in English, its translation into Italian, and its linking to the existing generic WordNets of both languages. The paper describes the criteria used for the linking of domain synsets to each other and to the generic ones and presents the published resource in RDF according to the w3c and lemon schema. © Springer International Publishing Switzerland 2016.",Final,
Bourgonje P.; Moreno-Schneider J.; Nehring J.; Rehm G.; Sasaki F.; Srivastava A.,"Bourgonje, Peter (57191890097); Moreno-Schneider, Julian (36606547100); Nehring, Jan (57191890693); Rehm, Georg (28767949900); Sasaki, Felix (8938640000); Srivastava, Ankit (57191887611)",57191890097; 36606547100; 57191890693; 28767949900; 8938640000; 57191887611,Towards a platform for curation technologies: Enriching text collections with a semantic-web layer,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994527341&doi=10.1007%2f978-3-319-47602-5_14&partnerID=40&md5=bd87b516c5ba0f26a86c73d8b6c06189,"In an attempt to put a Semantic Web-layer that provides linguistic analysis and discourse information on top of digital content, we develop a platform for digital curation technologies. The platform offers language-, knowledge-and data-aware services as a flexible set of workflows and pipelines for the efficient processing of various types of digital content. The platform is intended to enable human experts (knowledge workers) to get a grasp and understand the contents of large document collections in an efficient way so that they can curate, process and further analyse the collection according to their sector-specific needs. © Springer International Publishing AG 2016.",Final,
Gangemi A.; Alam M.; Presutti V.,"Gangemi, Aldo (55605133800); Alam, Mehwish (57201532578); Presutti, Valentina (55885160000)",55605133800; 57201532578; 55885160000,Word frame disambiguation: Evaluating linguistic linked data on frame detection,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992561536&partnerID=40&md5=d9169a3bca9dc7dd19252fb15937c39f,"The usefulness of FrameNet is affected by its limited coverage and non-standard semantics. This paper presents some strategies based on Linguistic Linked Open Data to fully exploit and broaden its coverage. These strategies lead to the creation of a novel resource, Framester, which serves as a hub between FrameNet, WordNet, VerbNet, BabelNet, DBpedia, Yago, DOLCE-Zero, as well as other resources. We also present a Word Frame Disambiguation, an application performing frame detection from text using Framester as a base. The results are comparable in precision to the state-of-the-art machine learning tool, but with a much higher coverage. © 2016, CEUR-WS. All rights reserved.",Final,
Chiarcos C.; Fäth C.; Renner-Westermann H.; Abromeit F.; Dimitrova V.,"Chiarcos, C. (22333764800); Fäth, C. (57194612424); Renner-Westermann, H. (57198788296); Abromeit, F. (57198810784); Dimitrova, V. (57213381192)",22333764800; 57194612424; 57198788296; 57198810784; 57213381192,"Lin|gu|is|tik: Building the linguist's pathway to bibliographies, libraries, language resources and linked open data",1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021238984&partnerID=40&md5=4414354a6f7f836f71f360aaee4b97f6,"This paper introduces a novel research tool for the field of linguistics: The Lin\gu\is\tik web portal provides a virtual library which offers scientific information on every linguistic subject. It comprises selected internet sources and databases as well as catalogues for linguistic literature, and addresses an interdisciplinary audience. The virtual library is the most recent outcome of the Special Subject Collection Linguistics of the German Research Foundation (DFG), and also integrates the knowledge accumulated in the Bibliography of Linguistic Literature. In addition to the portal, we describe long-term goals and prospects with a special focus on ongoing efforts regarding an extension towards integrating language resources and Linguistic Linked Open Data.",Final,
Li H.; Xu F.,"Li, Huiying (57195406213); Xu, Feifei (57201521396)",57195406213; 57201521396,Question answering with DBpedia based on the dependency parser and entity-centric index,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994850866&doi=10.1109%2fICCIA.2016.10&partnerID=40&md5=d27f5e4648b945d672480870bf24972f,"The emerging Linked Open Data provides an opportunity to answer the natural language question based on knowledge bases (KB). This study proposes an approach to question answering (QA) on the DBpedia dataset. After parsing the question by a dependency parser, we locate the entity mention and property mention with predefined templates. We propose an entity-centric indexing model to help search referent entities in KB. After obtaining the referent entities, we expand the property mention with WordNet and ConceptNet to find the referent properties of the returned entities. The values of the referent property are then considered the answer to the question. Evaluations are performed on DBpedia version 2015. Results show that our approach reaches 46% precision when the top-10 entities are returned in the final QA stage. The evaluation tests show that our approach is promising in dealing with QA in Linked Data. © 2016 IEEE.",Final,
Corcoglioniti F.; Rospocher M.; Aprosio A.P.; Tonelli S.,"Corcoglioniti, Francesco (25928189600); Rospocher, Marco (14010314000); Aprosio, Alessio Palmero (55936608300); Tonelli, Sara (14036670900)",25928189600; 14010314000; 55936608300; 14036670900,PreMOn: A lemon extension for exposing predicate models as linked data,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996521101&partnerID=40&md5=35c56745a964db987ac33ebd1911f586,"We introduce PreMOn (predicate model for ontologies), a linguistic resource for exposing predicate models (PropBank, NomBank, VerbNet, and FrameNet) and mappings between them (e.g, SemLink) as Linked Open Data. It consists of two components: (i) the PreMOn Ontology, an extension of the lemon model by the W3C Ontology-Lexica Community Group, that enables to homogeneously represent data from the various predicate models; and, (ii) the PreMOn Dataset, a collection of RDF datasets integrating various versions of the aforementioned predicate models and mapping resources. PreMOn is freely available and accessible online in different ways, including through a dedicated SPARQL endpoint.",Final,
Fang Z.; Wang H.; Gracia J.; Bosque-Gil J.; Ruan T.,"Fang, Zhijia (57026811300); Wang, Haofen (23399118800); Gracia, Jorge (55392626700); Bosque-Gil, Julia (57031866000); Ruan, Tong (35240657900)",57026811300; 23399118800; 55392626700; 57031866000; 35240657900,Zhishi.Lemon: On publishing zhishi.me as linguistic linked open data,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992618544&doi=10.1007%2f978-3-319-46547-0_6&partnerID=40&md5=1248163c87a71e2be8157c7cabb40489,"Recently, a growing number of linguistic resources in different languages have been published and interlinked as part of the Linguistic Linked Open Data (LLOD) cloud. However, in comparison to English and other prominent languages, the presence of Chinese in such a cloud is still limited, despite the fact that Chinese is the most spoken language worldwide. Publishing more Chinese language resources in the LLOD cloud can benefit both academia and industry to better understand the language itself and to further build multilingual applications that will improve the flow of data and services across countries. In this paper we describe Zhishi.lemon, a newly developed dataset based on the lemon model that constitutes the lexical realization of Zhishi.me, one of the largest Chinese datasets in the Linked Open Data (LOD) cloud. Zhishi.lemon combines the lemon core with the lemon translation module in order to build a linked data lexicon in Chinese with translations into Spanish and English. Links to BabelNet (a vast multilingual encyclopedic resource) have been provided as well.We also present a showcase of this module along with the technical details of transforming Zhishi.me to Zhishi.lemon. The dataset is accessible on the Web for both humans (via a Web interface) and software agents (with a SPARQL endpoint). © Springer International Publishing AG 2016.",Final,All Open Access; Bronze Open Access
Gabryszak A.; Krause S.; Hennig L.; Xu F.; Uszkoreit H.,"Gabryszak, Aleksandra (57194692891); Krause, Sebastian (52164089400); Hennig, Leonhard (26430879400); Xu, Feiyu (7401695091); Uszkoreit, Hans (13007575400)",57194692891; 52164089400; 26430879400; 7401695091; 13007575400,Relation- and phrase-level linking of FrameNet with sar-graphs,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037086784&partnerID=40&md5=0b41c874f72fe4702c69393a28f34610,"Recent research shows the importance of linking linguistic knowledge resources for the creation of large-scale linguistic data. We describe our approach for combining two English resources, FrameNet and sar-graphs, and illustrate the benefits of the linked data in a relation extraction setting. While FrameNet consists of schematic representations of situations, linked to lexemes and their valency patterns, sar-graphs are knowledge resources that connect semantic relations from factual knowledge graphs to the linguistic phrases used to express instances of these relations. We analyze the conceptual similarities and differences of both resources and propose to link sar-graphs and FrameNet on the levels of relations/frames as well as phrases. The former alignment involves a manual ontology mapping step, which allows us to extend sar-graphs with new phrase patterns from FrameNet. The phrase-level linking, on the other hand, is fully automatic. We investigate the quality of the automatically constructed links and identify two main classes of errors.",Final,
Nooralahzadeh F.; Lopez C.; Cabrio E.; Gandon F.; Segond F.,"Nooralahzadeh, Farhad (55842877400); Lopez, Cédric (36967886100); Cabrio, Elena (36704505300); Gandon, Fabien (12242656500); Segond, Frédérique (15057017500)",55842877400; 36967886100; 36704505300; 12242656500; 15057017500,Adapting semantic spreading activation to entity linking in text,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977477929&doi=10.1007%2f978-3-319-41754-7_7&partnerID=40&md5=5027d825770508f71c1bb987cfa91b5a,"The extraction and the disambiguation of knowledge guided by textual resources on the web is a crucial process to advance the Web of Linked Data. The goal of our work is to semantically enrich raw data by linking the mentions of named entities in the text to the corresponding known entities in knowledge bases. In our approach multiple aspects are considered: the prior knowledge of an entity in Wikipedia (i.e. the keyphraseness and commonness features that can be precomputed by crawling the Wikipedia dump), a set of features extracted from the input text and from the knowledge base, along with the correlation/relevancy among the resources in Linked Data. More precisely, this work explores the collective ranking approach formalized as a weighted graph model, in which the mentions in the input text and the candidate entities from knowledge bases are linked using the local compatibility and the global relatedness measures. Experiments on the datasets of the Open Knowledge Extraction (OKE) challenge with different configurations of our approach in each phase of the linking pipeline reveal its optimum mode. We investigate the notion of semantic relatedness between two entities represented as sets of neighbours in Linked Open Data that relies on an associative retrieval algorithm, with consideration of common neighbourhood. This measure improves the performance of prior link-based models and outperforms the explicit inter-link relevancy measure among entities (mostly Wikipedia-centric). Thus, our approach is resilient to non-existent or sparse links among related entities. © Springer International Publishing Switzerland 2016.",Final,
Ji K.; Wang S.; Carlson L.,"Ji, Kun (55819343200); Wang, Shanshan (57191747279); Carlson, Lauri (14833726000)",55819343200; 57191747279; 14833726000,Multilingual dictionary linking and aggregation: Quality from consistency,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992573934&partnerID=40&md5=51d48c2d56423bce5da6b05b8084ca46,"The growth of Web-accessible dictionaries and term data has led to a proliferation of platforms distributing the same lexical resources in different combinations and packagings. Finding the right word or translation is like finding a needle in a haystack. The quantity of the data is undercut by the doubtful quality of the resources. Our aim is to cut down the quantity and raise the quality by matching and aggregating entries within and across dictionaries. In this exploratory paper, our goal is to see how far we can get by using information extracted from multiple dictionaries themselves. Our hypothesis is that the more limited quantity of data in dictionaries is compensated by their richer structure and more concentrated information content. We hope to take advantage of the structure of dictionaries by basing quality criteria and measures on linguistic and terminological considerations. The plan of campaign is to derive quality criteria to recognise well-constructed dictionary entries from a model dictionary, and then attempt to convert the criteria into language-independent frequency-based measures. As a model dictionary we use the Princeton WordNet. The measures derived from it are tested against data extracted from BabelNet. © 2016, CEUR-WS. All rights reserved.",Final,
Carvalho S.; Costa R.; Roche C.,"Carvalho, Sara (58064085700); Costa, Rute (55958196000); Roche, Christophe (7103052641)",58064085700; 55958196000; 7103052641,LESS can indeed be more: Linguistic and conceptual challenges in the age of interoperability,1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984808375&partnerID=40&md5=784a0061124f859594770fdb081bdc79,"The advent of the Semantic Web and, more recently, of the Linked Data initiative, has paved the way for new perspectives and opportunities in Terminology, namely regarding the operationalization of terminological products. Within the biomedical domain, changes have been substantial in the past decades and at their heart stand the current challenges regarding the production, use, storage and dissemination of medical data, information, and knowledge. In a context where biomedical terminological resources are becoming increasingly concept-oriented, terminology work should reflect a double dimension (both linguistic and conceptual) that may, in turn, support the aspired operationalization and interoperability in this field. Therefore, the purpose of this paper is to present a case study, based around the concept of <Laparoendoscopic single-site surgery>, in which a methodology anchored in Terminology's double dimension aims to contribute to the enrichment of the Systematized Nomenclature of Medicine-Clinical Terms (SNOMED CT).",Final,
Almas B.; Schroeder C.T.,"Almas, Bridget (55301254400); Schroeder, Caroline T. (26037609100)",55301254400; 26037609100,Applying the canonical text services model to the Coptic SCRIPTORIUM,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011848778&doi=10.5334%2fdsj-2016-013&partnerID=40&md5=a4ebc8858ba4118bf5cc67be0cee118e,"Coptic SCRIPTORIUM is a platform for interdisciplinary and computational research in Coptic texts and linguistics. The purpose of this project was to research and implement a system of stable identification for the texts and linguistic data objects in Coptic SCRIPTORIUM to facilitate their citation and reuse. We began the project with a preferred solution, the Canonical Text Services URN model, which we validated for suitability for the corpus and compared it to other approaches, including HTTP URLs and Handles. The process of applying the CTS model to Coptic SCRIPTORIUM required an in-depth analysis that took into account the domain-specific scholarly research and citation practices, the structure of the textual data, and the data management workflow. © 2016 The Author(s).",Final,All Open Access; Gold Open Access; Green Open Access
Burns G.A.; Hermjakob U.; Ambite J.L.,"Burns, Gully A. (7201692392); Hermjakob, Ulf (6504597847); Ambite, José Luis (55666091900)",7201692392; 6504597847; 55666091900,Abstract meaning representations as linked data,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992597297&doi=10.1007%2f978-3-319-46547-0_2&partnerID=40&md5=11aa13bd011ac43dcb155862f19d1a41,"The complex relationship between natural language and formal semantic representations can be investigated by the development of large, semantically-annotated corpora. The “Abstract Meaning Representation” (AMR) formulation describes the semantics of a whole sentence as a rooted, labeled graph, where nodes represent concepts/entities (such as PropBank frames and named entities) and edges represent relations between concepts (such as verb roles). AMRs have been used to annotate corpora of classic books, newstext and biomedical literature. Research on semantic parsers that generate AMRs from text is progressing rapidly. In this paper, we describe an AMR corpus as Linked Data (AMR-LD) and the techniques used to generate it (including an opensource implementation). We discuss the benefits of AMR-LD, including convenient analysis using SPARQL queries and ontology inferences enabled by embedding into the web of Linked Data, as well as the impact of semantic web representations directly derived from natural language. © Springer International Publishing AG 2016.",Final,All Open Access; Bronze Open Access
Almeida B.; Roche C.; Costa R.,"Almeida, Bruno (57222163016); Roche, Christophe (7103052641); Costa, Rute (55958196000)",57222163016; 7103052641; 55958196000,Terminology and ontology development in the domain of Islamic archaeology,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984796638&partnerID=40&md5=67bb192dcec02562a13487c7d536fc58,"This paper describes an example regarding the terminology of Islamic pottery artefacts in Portuguese and Spanish in the context of an ongoing Ph D project. The approach followed in this paper places knowledge representation at the core of terminology work. More specifically, the development of an ontology, i.e. a formal and computational conceptualisation, enables the integration of a multilingual termbase in the semantic web as linked data, targeted at experts and students of archaeology. This approach allows for the preservation of linguistic diversity, as reflected by the different linguistic practices engaged by Portuguese and Spanish archaeologists in scholarly communication.",Final,
Wang C.; He X.,"Wang, Chengyu (55926354300); He, Xiaofeng (55641972700)",55926354300; 55641972700,Chinese hypernym-hyponym extraction from user generated categories,1,,1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040907214&partnerID=40&md5=4dffd7dea849ef48421b9663021909b9,"Hypernym-hyponym (""is-a"") relations are key components in taxonomies, object hierarchies and knowledge graphs. While there is abundant research on is-a relation extraction in English, it still remains a challenge to identify such relations from Chinese knowledge sources accurately due to the flexibility of language expression. In this paper, we introduce a weakly supervised framework to extract Chinese is-a relations from user generated categories. It employs piece-wise linear projection models trained on a Chinese taxonomy and an iterative learning algorithm to update models incrementally. A pattern-based relation selection method is proposed to prevent ""semantic drift"" in the learning process using bi-criteria optimization. Experimental results illustrate that the proposed approach outperforms state-of-the-art methods. © 1963-2018 ACL.",Final,
Hellmann S.; Brekle J.; Auer S.,"Hellmann, Sebastian (35199882400); Brekle, Jonas (55605197100); Auer, Sören (23391879500)",35199882400; 55605197100; 23391879500,Leveraging the crowdsourcing of lexical resources for bootstrapping a linguistic data cloud,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892985119&doi=10.1007%2f978-3-642-37996-3_13&partnerID=40&md5=39e17920ff15f2ba08cc38a56108b12c,"We present a declarative approach implemented in a comprehensive open-source framework based on DBpedia to extract lexical-semantic resources - an ontology about language use - from Wiktionary. The data currently includes language, part of speech, senses, definitions, synonyms, translations and taxonomies (hyponyms, hyperonyms, synonyms, antonyms) for each lexical word. Main focus is on flexibility to the loose schema and configurability towards differing language-editions of Wiktionary. This is achieved by a declarative mediator/wrapper approach. The goal is to allow the addition of languages just by configuration without the need of programming, thus enabling the swift and resource-conserving adaption of wrappers by domain experts. The extracted data is as fine granular as the source data in Wiktionary and additionally follows the lemon model. It enables use cases like disambiguation or machine translation. By offering a linked data service, we hope to extend DBpedia's central role in the LOD infrastructure to the world of Open Linguistics. © Springer-Verlag 2013.",Final,All Open Access; Green Open Access
Roy S.D.; Zeng W.,"Roy, Suman Deb (57213545927); Zeng, Wenjun (58083194000)",57213545927; 58083194000,Cognitive canonicalization of natural language queries using semantic strata,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891861533&doi=10.1145%2f2539053&partnerID=40&md5=67d12047b8a4c17c9513322579b2c965,"Natural language search relies strongly on perceiving semantics in a query sentence. Semantics is captured by the relationship among the query words, represented as a network (graph). Such a network of words can be fed into larger ontologies, like DBpedia or Google Knowledge Graph, where they appear as subgraphs-fashioning the name subnetworks (subnets). Thus, subnet is a canonical form for interfacing a natural language query to a graph database and is an integral step for graph-based searching. In this article, we present a novel standalone NLP technique that leverages the cognitive psychology notion of semantic strata for semantic subnetwork extraction from natural language queries. The cognitive model describes some of the fundamental structures employed by the human cognition to construct semantic information in the brain, called semantic strata. We propose a computational model based on conditional random fields to capture the cognitive abstraction provided by semantic strata, facilitating cognitive canonicalization of the query. Our results, conducted on approximately 5000 queries, suggest that the cognitive canonicals based on semantic strata are capable of significantly improving parsing and role labeling performance beyond pure lexical approaches, such as parts-of-speech based techniques. We also find that cognitive canonicalized subnets are more semantically coherent compared to syntax trees when explored in graph ontologies like DBpedia and improve ranking of retrieved documents. © 2013 ACM 1550-4875/2013/12-ART17 15.00.",Final,
Menke P.; McCrae J.; Cimiano P.,"Menke, Peter (37007738900); McCrae, John (36666801700); Cimiano, Philipp (15838793700)",37007738900; 36666801700; 15838793700,Releasing multimodal data as Linguistic Linked Open Data: An experience report,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055604675&partnerID=40&md5=167a7935a0cc0443d7462b6485521403,"In this paper we describe an implemented framework for releasing multimodal corpora as Linked Data. In particular, we describe our experiences in releasing a multimodal corpus based on an online chat game as Linked Data. Building on an internal multimodal data model we call FiESTA, we have implemented a library that enhances existing libraries and classes by functionality allowing to convert the data to RDF. Our framework is implemented on the Rails web application framework. We argue that this work can be highly useful for further contributions to the Linked Data community, especially from the fields of spoken dialogue and multimodal communication. © LDL 2013.All right reserved.",Final,
Sorrentino S.; Bergamaschi S.; Fusari E.,"Sorrentino, Serena (23467866400); Bergamaschi, Sonia (7006782238); Fusari, Elisa (55803809200)",23467866400; 7006782238; 55803809200,A semantic multi-lingual method for publishing linked open data,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903553546&partnerID=40&md5=abbae146690bd2b9d5468aadddfcaf98,"Nowadays, there has been an increment of open data initiatives promoting the freely publication of data produced by public administrations (such as public spending, health care, education etc.). However, the great majority of these data are published in an unstructured format (such as spreadsheets or CSV) and is typically accessed only by closed communities. To address this problem, we propose a semiautomatic multi-lingual and semantic method for facilitating resource providers in publishing public data into the Linked Open Data (LOD) cloud, and for helping consumers (companies and citizens) in efficiently accessing and querying them. The method has been applied on a real case on a set of data provided in Italian.",Final,
Bartolini R.; Del Gratta R.; Frontini F.,"Bartolini, Roberto (22333654100); Del Gratta, Riccardo (34976432900); Frontini, Francesca (55162070400)",22333654100; 34976432900; 55162070400,Towards the establishment of a linguistic linked data network for Italian,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037098297&partnerID=40&md5=89c8ca58eb33e3b3f409e2e0ec84c502,"This paper describes the conversion of ItalWordNet and of a domain WordNet into RDF and their linking to the (L)LOD cloud and to other existing resources. A brief presentation of the resources is given, and the conversion and resulting datasets are described. © LDL 2013.All right reserved.",Final,
Elbedweihy K.; Wrigley S.N.; Ciravegna F.; Zhang Z.,"Elbedweihy, Khadija (36715927300); Wrigley, Stuart N. (7004143551); Ciravegna, Fabio (8957737400); Zhang, Ziqi (14326468700)",36715927300; 7004143551; 8957737400; 14326468700,Using BabelNet in bridging the gap between natural language queries and linked data concepts,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924389956&partnerID=40&md5=8100a50afb90f17b4fc3b428021f8274,"Many semantic search tool evaluations have reported a user preference for free natural language as a query input approach as opposed to controlled or view-based inputs. Although the exibility offered by this approach is a significant advantage, it can also be a major difficulty. Allowing users complete freedom in the choice of terms increases the difficulty for the search tools to match terms with the underlying data. This causes either a mismatch which affects precision, or a missing match which affects recall. In this paper, we present an empirical investigation on the use of named entity recognition, word sense disambiguation, and ontology-based heuristics in an approach attempting to bridge this gap between user terms and ontology concepts, properties and entities. We use the dataset provided by the Question Answering over Linked Data (QALD-2) workshop in our analysis and tests.",Final,
Kato F.; Takeda H.; Koide S.; Ohmukai I.,"Kato, Fumihiro (8862007800); Takeda, Hideaki (7403064748); Koide, Seiji (36958437700); Ohmukai, Ikki (8378752000)",8862007800; 7403064748; 36958437700; 8378752000,Building DBpedia japanese and linked data cloud in japanese,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922053615&partnerID=40&md5=ff345c16b24e501cb208def793413b5a,"Wikipedia is one of the most valuable language and onto- logical resources covering wide domains so that DBpedia, LOD based on Wikipedia, plays the important role in the LOD cloud by connecting various resources. DBpedia Japanese is the LOD created from Wikipedia Japanese just as DBpedia data sources in other languages like English and German. We here describe how the conversion could be carried out with the efforts to fit DBpedia software and show the results of the dataset. We also describe how the created DBpedia Japanese is used by other Linked Data and show the Linked Data Cloud in Japanese.",Final,
Chiarcos C.; Cimiano P.; Declerck T.; McCrae J.P.,"Chiarcos, Christian (22333764800); Cimiano, Philipp (15838793700); Declerck, Thierry (22333556000); McCrae, John P. (36666801700)",22333764800; 15838793700; 22333556000; 36666801700,Linguistic Linked Open Data (LLOD) Introduction and Overview,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059046541&partnerID=40&md5=9f2ae4ae81b4f4a20c4a076f5c4b661f,"The explosion of information technology has led to a substantial growth in quantity, diversity and complexity of linguistic data accessible over the internet. The lack of interoperability between linguistic and language resources represents a major challenge that needs to be addressed, in particular, if information from different sources is to be combined, like, say, machine-readable lexicons, corpus data and terminology repositories. For these types of resources, domain- specific standards have been proposed, yet, issues of interoperability between different types of resources persist, commonly accepted strategies to distribute, access and integrate their information have yet to be established, and technologies and infrastructures to address both aspects are still under development. The goal of the 2nd Workshop on Linked Data in Linguistics (LDL-2013) has been to bring together researchers from various fields of linguistics, natural language processing, and information technology to present and discuss principles, case studies, and best practices for representing, publishing and linking linguistic data collections, including corpora, dictionaries, lexical networks, translation memories, thesauri, etc., infrastructures developed on that basis, their use of existing standards, and the publication and distribution policies that were adopted. © LDL 2013.All right reserved.",Final,
Ryman A.G.; Le Hors A.J.; Speicher S.,"Ryman, Arthur G. (36025918200); Le Hors, Arnaud J (56016415000); Speicher, Steve (56016460500)",36025918200; 56016415000; 56016460500,OSLC resource shape a language for defining constraints on linked data,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916627887&partnerID=40&md5=714ac7f0d20d83c7e56598ec8356022c,"IBM has for several years been employing a read/write usage of Linked Data as an architectural style for integrating a suite of applications. We are encouraged by the work done by the W3C Linked Data Platform Working Group which is chartered to produce a W3C Recommendation for HTTP-based (RESTful) application integration patterns using read/write Linked Data . The Linked Data Platform Recommendation will provide the industry with a solid foundation to build on. Yet, more work will need to be done to address in a standard way the needs of enterprise solutions that use Linked Data as an application integration platform. One such need is a type definition language that can be used to communicate and validate constraints on RDF data. This paper explains the need for such a language, why standards like RDFS and OWL are not suitable answers and, finally, introduces OSLC Resource Shapes as a proposed solution.",Final,
Murnane E.L.; Haslhofer B.; Lagoze C.,"Murnane, Elizabeth L. (55942505600); Haslhofer, Bernhard (23396762400); Lagoze, Carl (35614719400)",55942505600; 23396762400; 35614719400,RESLVE: Leveraging user interest to improve entity disambiguation on short text,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893095042&partnerID=40&md5=76145714843a3d376c18dcd090808dd1,"We address the Named Entity Disambiguation (NED) prob- lem for short, user-generated texts on the social Web. In such settings, the lack of linguistic features and sparse lexical context result in a high degree of ambiguity and sharp performance drops of nearly 50% in the accuracy of conven- tional NED systems. We handle these challenges by developing a general model of user-interest with respect to a personal knowledge context and instantiate it using Wikipedia. We conduct systematic evaluations using individuals' posts from Twitter, YouTube, and Flickr and demonstrate that our novel technique is able to achieve performance gains be- yond state-of-the-art NED methods.",Final,
Narducci F.; Palmonari M.; Semeraro G.,"Narducci, Fedelucio (35107856400); Palmonari, Matteo (8835755600); Semeraro, Giovanni (57108777800)",35107856400; 8835755600; 57108777800,Cross-language semantic matching for discovering links to e-gov services in the LOD cloud,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922538421&partnerID=40&md5=623c690799697625acabade880c692e4,"The large diffusion of e-gov initiatives is increasing the attention of public administrations towards the Open Data initiative. The adoption of open data in the e-gov domain produces different advantages in terms of more transparent government, development of better public services, economic growth and social value. However, the process of data opening should adopt standards and open formats. Only in this way it is possible to share experiences with other service providers, to exploit best practices from other cities or countries, and to be easily connected to the Linked Open Data (LOD) cloud. In this paper we present CroSeR (Cross-language Service Retriever), a tool able to match and retrieve cross-language e-gov services stored in the LOD cloud. The main goal of this work is to help public administrations to connect their e-gov services to services, provided by other administrations, already connected to the LOD cloud. We adopted a Wikipedia-based semantic representation in order to overcome the problems related to match really short textual descriptions associated to the services. A preliminary evaluation on an open catalog of e-gov services showed that the adopted techniques are promising and are more effective than techniques based only on keyword representation.",Final,
Hayashi Y.,"Hayashi, Yoshihiko (35475987700)",35475987700,Migrating Psycholinguistic Semantic Feature Norms into Linked Data in Linguistics,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122856650&partnerID=40&md5=f533c148768baf5b9424cec68a0c8750,"Semantic feature norms, originally utilized in the field of psycholinguistics as a tool for studying human semantic representation and computation, have recently attracted the attention of some NLP/IR researchers who wish to improve their task performances. However, currently available semantic feature norms are, by nature, not well-structured, making them difficult to integrate into existing resources of various kinds. In this paper, by examining an actual set of semantic feature norms, we investigate which types of semantic features should be migrated into Linked Data in Linguistics (LDL) and how the migration could be done. © LDL 2013.All right reserved.",Final,
Sànchez-Rada J.F.; Iglesias C.A.,"Sànchez-Rada, J. Fernando (56426347900); Iglesias, Carlos A. (56357213400)",56426347900; 56357213400,Onyx: Describing emotions on the web of data,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921891280&partnerID=40&md5=27c09a1447f4dd117e1549445a220b66,"Textual emotion analysis is a new field whose aim is to detect emotions in user generated content. It complements Sentiment Analysis in the characterization of users subjective opinions and feelings. Nevertheless, there is a lack of available lexical and semantic emotion resources that could foster the development of emotion analysis services. Some of the barriers for developing such resources are the diversity of emotion theories and the absence of a vocabulary to express emotion characteristics. This article presents a semantic vocabulary, called Onyx, intended to provide support to represent emotion characteristics in lexical resources and emotion analysis services. Onyx follows the Linked Data principles as it is aligned with the Provenance Ontology. It also takes a linguistic Linked Data approach: it is aligned with the Provenance Ontology, it represents lexical resources as linked data, and has been integrated with Lemon, an increasingly popular RDF model for representing lexical entries. Furthermore, it does not prescribe any emotion model and can be linked to heterogeneous emotion models expressed as Linked Data. Onyx representations can also be published using W3C EmotionML markup, based on the proposed mapping.",Final,
Moran S.; Brümmer M.,"Moran, Steven (55901459600); Brümmer, Martin (55995213500)",55901459600; 55995213500,Lemon-aid: using Lemon to aid quantitative historical linguistic analysis,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902596084&partnerID=40&md5=46be621b09758cdde3339f8a62f0a54b,"In this short paper, we describe how we converted dictionary and wordlist data made available by the QuantHistLing project into the Lexicon Model for Ontologies. By doing so, we leverage Linked Data to combine disparate lexical resources – more than fifty lexicons and dictionaries – by converting the lexical data into an RDF model that is specified by Lemon. The resulting new Linked Data resource, what we call the QHL dataset, provides researchers with a translation graph, which allows users to query across the underlying lexicons and dictionaries to extract semantically-aligned wordlists. © LDL 2013.All right reserved.",Final,
Murnane E.L.; Haslhofer B.; Lagoze C.,"Murnane, Elizabeth L. (55942505600); Haslhofer, Bernhard (23396762400); Lagoze, Carl (35614719400)",55942505600; 23396762400; 35614719400,RESLVE: Leveraging user interest to improve entity disambigution on short text,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893101000&partnerID=40&md5=3cfbafcf3d45ec74a33b0a5b0445c79e,"We address the Named Entity Disambiguation (NED) problem for short, user-generated texts on the social Web. In such settings, the lack of linguistic features and sparse lexical context result in a high degree of ambiguity and sharp performance drops of nearly 50% in the accuracy of conventional NED systems. We handle these challenges by developing a model of user-interest with respect to a personal knowledge context; and Wikipedia, a particularly well-established and reliable knowledge base, is used to instantiate the procedure. We conduct systematic evaluations using individuals' posts from Twitter, YouTube, and Flickr and demonstrate that our novel technique is able to achieve substantial performance gains beyond state-of-the-art NED methods.",Final,
Miao Q.; Lu H.; Zhang S.; Meng Y.,"Miao, Qingliang (25637571600); Lu, Huayu (56181470300); Zhang, Shu (55713464500); Meng, Yao (35422605300)",25637571600; 56181470300; 55713464500; 35422605300,Cross-lingual link discovery between Chinese and english wiki knowledge bases,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922783862&partnerID=40&md5=f6f8378f947a26f10f4ad4f6f598c9ba,"Wikipedia is an online multilingual encyclopedia that contains a very large number of articles covering most written languages. However, one critical issue for Wikipedia is that the pages in different languages are rarely linked except for the cross-lingual link between pages about the same subject. This could pose serious difficulties to humans and machines who try to seek information from different lingual sources. In order to address above issue, we propose a hybrid approach that exploits anchor strength, topic relevance and entity knowledge graph to automatically discovery cross-lingual links. In addition, we develop CELD, a system for automatically linking key terms in Chinese documents with English Concepts. As demonstrated in the experiment evaluation, the proposed model outperforms several baselines on the NTCIR data set, which has been designed especially for the cross-lingual link discovery evaluation. © 2013 Qingliang Miao, Huayu Lu, Shu Zhang, and Yao Meng.",Final,
Uszkoreit H.; Xu F.,"Uszkoreit, Hans (13007575400); Xu, Feiyu (7401695091)",13007575400; 7401695091,From strings to things SAR-graphs: A new type of resource for connecting knowledge and language,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924363298&partnerID=40&md5=4679a904fad3033c17eed0a18dc12bd2,"Recent research and development have created the necessary ingredients for a major push in web-scale language understanding: large repositories of structured knowledge (DBpedia, the Google knowledge graph, Freebase, YAGO) progress in language processing (parsing, information extraction, computational semantics), linguistic knowledge resources (Treebanks, WordNet, BabelNet, UWN) and new powerful techniques for machine learning. A major goal is the automatic aggregation of knowledge from textual data. A central component of this endeavor is relation extraction (RE). In this paper, we will outline a new approach to connecting repositories of world knowledge with linguistic knowledge (syntactic and lexical semantics) via web-scale relation extraction technologies.",Final,
Gangemi A.; Draicchio F.; Presutti V.; Nuzzolese A.G.; Reforgiato D.,"Gangemi, Aldo (55605133800); Draicchio, Francesco (58332583000); Presutti, Valentina (55885160000); Nuzzolese, Andrea Giovanni (42862074000); Reforgiato, Diego (57206674454)",55605133800; 58332583000; 55885160000; 42862074000; 57206674454,A machine rèader for the semantic web,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924721722&partnerID=40&md5=a03357216569cc4a23ba700a7ca6533c,"FRED is a machine reading tool for converting text into internally well-connected and quality linked-data-ready ontologies in web- service-acceptable time. It implements a novel approach for ontology design from natural language sentences, combining Discourse Representation Theory (DRT), linguistic frame semantics, and Ontology Design Patterns (ODP). The current version of the tool includes Earmark-based markup, and enrichment with word sense disambiguation (WSD) and named entity resolution (NER) off-the-shelf components.",Final,
,,,"Proceedings of the 2nd Workshop on Linked Data in Linguistics: Representing and Linking Lexicons, Terminologies and other Language Data, LDL 2013 - Collocated with the 6th International Conference on Generative Approaches to the Lexicon",1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122894962&partnerID=40&md5=96a899b2a9e8c44ed02a7965e25e95dc,The proceedings contain 12 papers. The topics discussed include: linguistic linked data for sentiment analysis; LIME: towards a metadata module for Ontolex; lemon-aid: using lemon to aid quantitative historical linguistic analysis; transforming the data transcription and analysis tool metadata and labels into a linguistic linked open data cloud resource; releasing multimodal data as linguistic linked open data: an experience report; linguistic resources enhanced with geospatial information; migrating psycholinguistic semantic feature norms into linked data in linguistics; and towards the establishment of a linguistic linked data network for Italian.,Final,
Di Nunzio G.M.,"Di Nunzio, Giorgio Maria (57210368958)",57210368958,Digital geolinguistics: On the use of linked open data for data-level interoperability between geolinguistic resources,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923698965&partnerID=40&md5=3a4a5a8e6715bb11c5e12785e343f742,"The Open Language Archives Community which recently celebrated its first 10 years of activity, is a worldwide network dedicated to collecting information on language resources and developing standard protocols for interoperability. In this context, Linked Open Data paradigm is very promising, because it eases interoperability between different systems by allowing the definition of data-driven models and applications. In this talk, we give an overview of present geolinguistics projects and an approach which moves the focus from the systems handling the linguistic data to the data themselves. As a concrete example, we present a geolinguistic application build upon a real linguistic dataset which provides linguists with a system for investigating variations among closely related languages. © 2013 for the individual papers by the papers' authors.",Final,
Castro L.J.G.; Berlanga R.; Rebholz-Schuhmann D.; Garcia A.,"Castro, Leyla Jael Garcia (57216726687); Berlanga, Rafael (6701785415); Rebholz-Schuhmann, Dietrich (6507852707); Garcia, Alexander (57212956884)",57216726687; 6701785415; 6507852707; 57212956884,Connections across scientific publications based on semantic annotations,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924715587&partnerID=40&md5=624805330bb3d7298046d5d315a45158,"The core information from scientific publications is encoded in natural language text and monolithic documents; therefore it is not well integrated with other structured and unstructured data resources. The text format requires additional processing to semantically interlink the publications and to finally reach interoperability of contained data. Data infrastructures such as the Linked Open Data initiative based on the Resource Description Framework support the connectivity of data from scientific publications once the identification of concepts and relations has been achieved, and the content has been interconnected semantically. In this manuscript we produce and analyze the semantic annotations in scientific articles to investigate on the interconnectivity across the articles. In our initial experiment based on articles from PubMed Central we demonstrate the means and the results leading to the interconnectivity using annotations of Medical Subject Headings concepts, Unified Medical Language System terms, and semantic abstractions of relations. We conclude that the different methods would contribute to different types of relatedness between articles that could be later used in recommendation systems based on semantic links across a network of scientific publications.",Final,
,,,CEUR Workshop Proceedings,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923954870&partnerID=40&md5=887c02a91ad6a10fc6a2766779b551e5,"The proceedings contain 11 papers. The topics discussed include: digital geo-linguistics: on the use of linked open data for data-level interoperability between geo-linguistic resources; towards preservation of semantically enriched architectural knowledge; the role of language evolution in digital archives; BlogNEER: applying named entity evolution recognition on the blogosphere?; elevating natural history museums' cultural collections to the linked data cloud; a linked open data architecture for contemporary historical archives; pundit: creating, exploring and consuming semantic annotations; towards persistent identification of resources in personal information management; a storage ontology for hierarchical storage management systems; and semantic retrieval interface for statistical research data.",Final,
Aggarwal N.; Polajnar T.; Buitelaar P.,"Aggarwal, Nitish (55453057300); Polajnar, Tamara (26436068100); Buitelaar, Paul (14041096000)",55453057300; 26436068100; 14041096000,Cross-lingual natural language querying over the web of data,1,,1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884972019&doi=10.1007%2f978-3-642-38824-8_13&partnerID=40&md5=d9a6a71b02be64505ee73179c1c85e0a,"The rapid growth of the Semantic Web offers a wealth of semantic knowledge in the form of Linked Data and ontologies, which can be considered as large knowledge graphs of marked up Web data. However, much of this knowledge is only available in English, affecting effective information access in the multilingual Web. A particular challenge arises from the vocabulary gap resulting from the difference in the query and the data languages. In this paper, we present an approach to perform cross-lingual natural language queries on Linked Data. Our method includes three components: entity identification, linguistic analysis, and semantic relatedness. We use Cross-Lingual Explicit Semantic Analysis to overcome the language gap between the queries and data. The experimental results are evaluated against 50 German natural language queries. We show that an approach using a cross-lingual similarity and relatedness measure outperforms other systems that use automatic translation. We also discuss the queries that can be handled by our approach. © 2013 Springer-Verlag Berlin Heidelberg.",Final,
Gracia J.; Montiel-Ponsoda E.; Cimiano P.; Gómez-Pérez A.; Buitelaar P.; McCrae J.,"Gracia, Jorge (55392626700); Montiel-Ponsoda, Elena (25654093800); Cimiano, Philipp (15838793700); Gómez-Pérez, Asunción (6603934482); Buitelaar, Paul (14041096000); McCrae, John (36666801700)",55392626700; 25654093800; 15838793700; 6603934482; 14041096000; 36666801700,Challenges for the multilingual Web of Data,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857791906&doi=10.1016%2fj.websem.2011.09.001&partnerID=40&md5=2bd276fb961603349bea90176b48e706,"The Web has witnessed an enormous growth in the amount of semantic information published in recent years. This growth has been stimulated to a large extent by the emergence of Linked Data. Although this brings us a big step closer to the vision of a Semantic Web, it also raises new issues such as the need for dealing with information expressed in different natural languages. Indeed, although the Web of Data can contain any kind of information in any language, it still lacks explicit mechanisms to automatically reconcile such information when it is expressed in different languages. This leads to situations in which data expressed in a certain language is not easily accessible to speakers of other languages. The Web of Data shows the potential for being extended to a truly multilingual web as vocabularies and data can be published in a language-independent fashion, while associated language-dependent (linguistic) information supporting the access across languages can be stored separately. In this sense, the multilingual Web of Data can be realized in our view as a layer of services and resources on top of the existing Linked Data infrastructure adding (i) linguistic information for data and vocabularies in different languages, (ii) mappings between data with labels in different languages, and (iii) services to dynamically access and traverse Linked Data across different languages. In this article, we present this vision of a multilingual Web of Data. We discuss challenges that need to be addressed to make this vision come true and discuss the role that techniques such as ontology localization, ontology mapping, and cross-lingual ontology-based information access and presentation will play in achieving this. Further, we propose an initial architecture and describe a roadmap that can provide a basis for the implementation of this vision. © 2011 Elsevier B.V. All rights reserved.",Final,All Open Access; Green Open Access
Yamamoto Y.; Kawamoto S.,"Yamamoto, Yasunori (55476303500); Kawamoto, Shoko (7201961016)",55476303500; 7201961016,Building linked open data of the Life Science Dictionary,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922691188&partnerID=40&md5=0a44644e56cf3d3115649b07cc5ac342,"There is a growing need for efficient and integrated access to databases provided by diverse institutions. Using a linked data design pattern allows the diverse data on the Internet to be linked effectively and accessed efficiently by computers. In addition, providing a dictionary to translate words into another language in Resource Description Framework (RDF) is useful to cross a language barrier such as English and Japanese when we want to access datasets in multiple languages. Here, we built a Linked Open Dataset of the Life Science Dictionary (LSD) with links to DBpedia. LSD consists of various lexical resources including English-Japanese / Japanese-English dictionaries and a thesaurus using the MeSH vocabulary. The latest version of LSD contains 110 thousand English and 120 thousand Japanese terms. Since we believe that LSD is a useful language resource in the life science domain to process Japanese and English text data seamlessly, linking LSD to DBpedia enables us to find related knowledge more easily and therefore contributes to the life science research community.",Final,
Jain P.; Hitzler P.; Verma K.; Yeh P.Z.; Sheth A.,"Jain, Prateek (57195251929); Hitzler, Pascal (8876646400); Verma, Kunal (7203047283); Yeh, Peter Z. (7102670447); Sheth, Amit (57200763252)",57195251929; 8876646400; 7203047283; 7102670447; 57200763252,Moving beyond sameAs with PLATO: Partonomy detection for linked data,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864056254&doi=10.1145%2f2309996.2310004&partnerID=40&md5=173ee008d0f077450e82adff5308b871,"The Linked Open Data (LOD) Cloud has gained significant traction over the past few years. With over 275 interlinked datasets across diverse domains such as life science, geography, politics, and more, the LOD Cloud has the potential to support a variety of applications ranging from open domain question answering to drug discovery. Despite its significant size (approx. 30 billion triples), the data is relatively sparely interlinked (approx. 400 million links). A semantically richer LOD Cloud is needed to fully realize its potential. Data in the LOD Cloud are currently interlinked mainly via the owl: sameAs property, which is inadequate for many applications. Additional properties capturing relations based on causality or partonomy are needed to enable the answering of complex questions and to support applications. In this paper, we present a solution to enrich the LOD Cloud by automatically detecting partonomic relationships, which are well-established, fundamental properties grounded in linguistics and philosophy. We empirically evaluate our solution across several domains, and show that our approach performs well on detecting partonomic properties between LOD Cloud data. Copyright 2012 ACM.",Final,
Di Buccio E.; Di Nunzio G.M.; Silvello G.,"Di Buccio, Emanuele (36019969000); Di Nunzio, Giorgio Maria (57210368958); Silvello, Gianmaria (23398794400)",36019969000; 57210368958; 23398794400,A system for exposing linguistic linked open data,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867676826&doi=10.1007%2f978-3-642-33290-6_19&partnerID=40&md5=543919d93ecbc214e49abd47f8d9ce8e,"In this paper we introduce the Atlante Sintattico d'Italia, Syntactic Atlas of Italy (ASIt) enterprise which is a linguistic project aiming to account for minimally different variants within a sample of closely related languages. One of the main goals of ASIt is to share and make linguistic data re-usable. In order to create a universally available resource and be compliant with other relevant linguistic projects, we define a Resource Description Framework (RDF) model for the ASIt linguistic data thus providing an instrument to expose these data as Linked Open Data (LOD). By exploiting RDF native capabilities we overcome the ASIt methodological and technical peculiarities and enable different linguistic projects to read, manipulate and re-use linguistic data. © 2012 Springer-Verlag.",Final,
Augenstein I.; Padó S.; Rudolph S.,"Augenstein, Isabelle (55236320300); Padó, Sebastian (10242453100); Rudolph, Sebastian (23009745000)",55236320300; 10242453100; 23009745000,LODifier: Generating linked data from unstructured text,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861720649&doi=10.1007%2f978-3-642-30284-8_21&partnerID=40&md5=97a20dcedfeacd87da0a9ac6928831df,"The automated extraction of information from text and its transformation into a formal description is an important goal in both Semantic Web research and computational linguistics. The extracted information can be used for a variety of tasks such as ontology generation, question answering and information retrieval. LODifier is an approach that combines deep semantic analysis with named entity recognition, word sense disambiguation and controlled Semantic Web vocabularies in order to extract named entities and relations between them from text and to convert them into an RDF representation which is linked to DBpedia and WordNet. We present the architecture of our tool and discuss design decisions made. An evaluation of the tool on a story link detection task gives clear evidence of its practical potential. © 2012 Springer-Verlag.",Final,All Open Access; Bronze Open Access
Zhou W.; Wang H.; Chao J.; Zhang W.; Yu Y.,"Zhou, Wenlei (55250213700); Wang, Haofen (23399118800); Chao, Jiansong (55250392900); Zhang, Weinan (56108513500); Yu, Yong (8723751600)",55250213700; 23399118800; 55250392900; 56108513500; 8723751600,LODDO: Using linked open data description overlap to measure semantic relatedness between named entities,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862180240&doi=10.1007%2f978-3-642-29923-0_18&partnerID=40&md5=15e8ef5c2bc5557755411b680757b500,"Measuring semantic relatedness plays an important role in information retrieval and Natural Language Processing. However, little attention has been paid to measuring semantic relatedness between named entities, which is also very significant. As the existing knowledge based approaches have the entity coverage issue and the statistical based approaches have unreliable result to low frequent entities, we propose a more comprehensive approach by leveraging Linked Open Data (LOD) to solve these problems. LOD consists of lots of data sources from different domains and provides rich a priori knowledge about the entities in the world. By exploiting the semantic associations in LOD, we propose a novel algorithm, called LODDO, to measure the semantic relatedness between named entities. The experimental results show the high performance and robustness of our approach. © 2012 Springer-Verlag.",Final,
Baker T.,"Baker, Thomas (56780500900)",56780500900,"Libraries, languages of description, and linked data: A Dublin Core perspective",1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857719886&doi=10.1108%2f07378831211213256&partnerID=40&md5=d117b210adcdfbb3b25c7a078f5949be,"Purpose: Library-world ""languages of description"" are increasingly being expressed using the resource description framework (RDF) for compatibility with linked data approaches. This article aims to look at how issues around the Dublin Core, a small ""metadata element set,"" exemplify issues that must be resolved in order to ensure that library data meet traditional standards for quality and consistency while remaining broadly interoperable with other data sources in the linked data environment. Design/methodology/approach: The article focuses on how the Dublin Core - originally seen, in traditional terms, as a simple record format - came increasingly to be seen as an RDF vocabulary for use in metadata based on a ""statement"" model, and how new approaches to metadata evolved to bridge the gap between these models. Findings: The translation of library standards into RDF involves the separation of languages of description, per se, from the specific data formats into which they have for so long been embedded. When defined with ""minimal ontological commitment,"" languages of description lend themselves to the sort of adaptation that is inevitably a part of any human linguistic activity. With description set profiles, the quality and consistency of data traditionally required for sharing records among libraries can be ensured by placing precise constraints on the content of data records - without compromising the interoperability of the underlying vocabularies in the wider linked data context. Practical implications: In today's environment, library data must continue to meet high standards of consistency and quality, yet it must be possible to link or merge the data with sources that follow other standards. Placing constraints on the data created, more than on the underlying vocabularies, allows both requirements to be met. Originality/value: This paper examines how issues around the Dublin Core exemplify issues that must be resolved to ensure library data meet quality and consistency standards while remaining interoperable with other data sources. © Emerald Group Publishing Limited.",Final,
Tiddi I.; Mustapha N.B.; Vanrompay Y.; Aufaure M.-A.,"Tiddi, Ilaria (55596365700); Mustapha, Nesrine Ben (57213973905); Vanrompay, Yves (23471267400); Aufaure, Marie-Aude (15055229300)",55596365700; 57213973905; 23471267400; 15055229300,Ontology learning from open linked data and web snippets,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873841493&doi=10.1007%2f978-3-642-33618-8_59&partnerID=40&md5=0ef395ad10fdadc4ed878c932a45af46,"The Web of Open Linked Data (OLD) is a recommended best practice for exposing, sharing, and connecting pieces of data, information, and knowledge on the Semantic Web using URIs and RDF. Such data can be used as a training source for ontology learning from web textual contents in order to bridge the gap between structured data and the Web. In this paper, we propose a new method of ontology learning that consists in learning linguistic patterns related to OLD entities attributes from web snippets. Our insight is to use the Linked Data as a skeleton for ontology construction and for pattern learning from texts. The contribution resides on learning patterns for relations existing in the Web of Linked Data from Web content. These patterns are used to populate the ontology core schema with new entities and attributes values. The experiments of the proposal have shown promising results in precision. © 2012 Springer-Verlag.",Final,All Open Access; Green Open Access
Presutti V.; Draicchio F.; Gangemi A.,"Presutti, Valentina (55885160000); Draicchio, Francesco (58332583000); Gangemi, Aldo (55605133800)",55885160000; 58332583000; 55605133800,Knowledge extraction based on discourse representation theory and linguistic frames,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867674858&doi=10.1007%2f978-3-642-33876-2_12&partnerID=40&md5=049f5a5dbcd8257df05de6ea22b268f2,"We have implemented a novel approach for robust ontology design from natural language texts by combining Discourse Representation Theory (DRT), linguistic frame semantics, and ontology design patterns. We show that DRT-based frame detection is feasible by conducting a comparative evaluation of our approach and existing tools. Furthermore, we define a mapping between DRT and RDF/OWL for the production of quality linked data and ontologies, and present FRED, an online tool for converting text into internally well-connected and linked-data-ready ontologies in web-service-acceptable time. © 2012 Springer-Verlag.",Final,
Pinheiro V.; Furtado V.; Pequeno T.; Ferreira C.,"Pinheiro, Vládia (22433472700); Furtado, Vasco (22333909800); Pequeno, Tarcisio (16022689200); Ferreira, Caio (57197039708)",22433472700; 22333909800; 16022689200; 57197039708,Towards a common sense base in Portuguese for the linked open data cloud,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858427776&doi=10.1007%2f978-3-642-28885-2_15&partnerID=40&md5=44c852eeccc94e8bf61c459775b10a50,"The Linked Open Data (LOD) cloud is a promising reality since the major content producers are offering their data on an open and linked network, through RDF (Resource Description Framework), with the aim of providing Semantic Web applications with a single global database for retrieval of related content and to perform inferences over the network. However, bases with Portuguese-language content are still incipient. In this paper we present the process of inclusion of the InferenceNet - the first resource with common sense and inferentialist knowledge in Portuguese language - on the LOD. Our main goal is to leverage the use and development of Semantic Web applications by content producers in Portuguese language. We develop and evaluated a platform, called SemWidgets, for the creation and execution of widgets able to access and reason over InferenceNet and the open linked data, like DBPedia, Yago, and Article Search API of the New York Times. © 2012 Springer-Verlag.",Final,
Zouaq A.; Gasevic D.; Hatala M.,"Zouaq, Amal (14049497000); Gasevic, Dragan (8549413500); Hatala, Marek (57203069442)",14049497000; 8549413500; 57203069442,Linguistic patterns for information extraction in OntoCmaps,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891808337&partnerID=40&md5=7034faeb0d316549708e5ab24da61899,"Linguistic patterns have proven their importance for the knowledge engineering field especially with the ever-increasing amount of available data. This is especially true for the Semantic Web, which relies on a formalization of knowledge into triples and linked data. This paper presents a number of syntactic patterns, based on dependency grammars, which output triples useful for the ontology learning task. Our experimental results show that these patterns are a good starting base for text mining initiatives in general and ontology learning in particular.",Final,
Chiarcos C.; Hellmann S.; Nordhoff S.; Moran S.; Littauer R.; Eckle-Kohler J.; Gurevych I.; Hartmann S.; Matuschek M.; Meyer C.M.,"Chiarcos, Christian (22333764800); Hellmann, Sebastian (35199882400); Nordhoff, Sebastian (55202292000); Moran, Steven (55901459600); Littauer, Richard (57198898245); Eckle-Kohler, Judith (24168347000); Gurevych, Iryna (24474583400); Hartmann, Silvana (56022813600); Matuschek, Michael (36164981100); Meyer, Christian M. (57212741486)",22333764800; 35199882400; 55202292000; 55901459600; 57198898245; 24168347000; 24474583400; 56022813600; 36164981100; 57212741486,The open linguistics working group,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929349760&partnerID=40&md5=23a55468023dc095631d0483075e7543,"This paper describes the Open Linguistics Working Group (OWLG) of the Open Knowledge Foundation (OKFN). The OWLG is an initiative concerned with linguistic data by scholars from diverse fields, including linguistics, NLP, and information science. The primary goal of the working group is to promote the idea of open linguistic resources, to develop means for their representation and to encourage the exchange of ideas across different disciplines. This paper summarizes the progress of the working group, goals that have been identified, problems that we are going to address, and recent activities and ongoing developments. Here, we put particular emphasis on the development of a Linked Open Data (sub-)cloud of linguistic resources that is currently being pursued by several OWLG members.",Final,
Kuwabara K.; Kinomura S.,"Kuwabara, Kazuhiro (7102487276); Kinomura, Shingo (55520280500)",7102487276; 55520280500,Mediating accesses to multiple information sources in a multi-lingual application,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870872899&doi=10.1007%2f978-3-642-34630-9_34&partnerID=40&md5=4cc9e955a8d6ecce59cd0ccc5c887cdf,"This paper describes an approach to mediating accesses to multiple information sources in a multi-lingual application. There are many information sources available on the Internet in different languages, and machine translation services are also available to allow multi-lingual access to information sources. Domain-dependent translation dictionaries are often used to make translation more appropriate. In the proposed approach, the domain-dependent translation dictionaries are represented as linked data. Using the data available from the translation dictionaries, accesses to the information sources that are represented as linked data can be customized. By applying the linked data concept, a multi-lingual application can be constructed in a flexible way. © 2012 Springer-Verlag.",Final,
Chen L.-P.; Shih Y.-L.; Chen C.-T.; Ku T.; Hsieh W.-T.; Chiu H.-S.; Yang R.-D.,"Chen, Liang-Pu (55446888100); Shih, Yu-Lun (54993156100); Chen, Chien-Ting (55835793300); Ku, Tsun (36166989500); Hsieh, Wen-Tai (36791400800); Chiu, Hung-Sheng (7401986348); Yang, Ren-Dar (55467574600)",55446888100; 54993156100; 55835793300; 36166989500; 36791400800; 7401986348; 55467574600,English-to-traditional Chinese cross-lingual link discovery in articles with wikipedia corpus,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883015565&partnerID=40&md5=6e2872c73a5d9b1703f494652aa89227,"In this paper, we design a processing flow to produce linked data in articles, providing anchor-based term's additional information and related terms in different languages (English to Chinese). Wikipedia has been a very important corpus and knowledge bank. Although Wikipedia describes itself not a dictionary or encyclopedia, it is if high potential values in applications and data mining researches. Link discovery is a useful IR application, based on Data Mining and NLP algorithms and has been used in several fields. According to the results of our experiment, this method does make the result has improved.",Final,
Aggarwal N.; Buitelaar P.,"Aggarwal, Nitish (55453057300); Buitelaar, Paul (14041096000)",55453057300; 14041096000,A system description of natural language query over DBpedia,1,,1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893280764&partnerID=40&md5=a5abfafedd1db93d78ad06f4e1057074,"This paper describes our system, which is developed as a first step towards implementing a methodology for natural language querying over semantic structured information (semantic web). This work focuses on interpretation of natural language queries (NL-Query) to facilitate querying over Linked Data. This interpretation includes query annotation with Linked Data concepts (classes and instances), a deep linguistic analysis and semantic similarity/relatedness to generate potential SPARQL queries for a given NL-Query. We evaluate our approach on QALD-2 test dataset and achieve a F1 score of 0.46, an average precision of 0.44 and an average recall of 0.48.",Final,
Freitas A.; Oliveira J.G.; O'Riain S.; Curry E.; Pereira Da Silva J.C.,"Freitas, André (36631806600); Oliveira, João Gabriel (42861980200); O'Riain, Seán (56878816000); Curry, Edward (12790805000); Pereira Da Silva, João Carlos (24830066700)",36631806600; 42861980200; 56878816000; 12790805000; 24830066700,Treo: Best-effort natural language queries over linked data,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959657728&doi=10.1007%2f978-3-642-22327-3_40&partnerID=40&md5=bc92930f4071aaf6d20cda41523149eb,"Linked Data promises an unprecedented availability of data on the Web. However, this vision comes together with the associated challenges of querying highly heterogeneous and distributed data. In order to query Linked Data on the Web today, end-users need to be aware of which datasets potentially contain the data and the data model behind these datasets. This query paradigm, deeply attached to the traditional perspective of structured queries over databases, does not suit the heterogeneity and scale of the Web, where it is impractical for data consumers to have an a priori understanding of the structure and location of available datasets. This work describes Treo, a best-effort natural language query mechanism for Linked Data, which focuses on the problem of bridging the semantic gap between end-user natural language queries and Linked Datasets. © 2011 Springer-Verlag.",Final,All Open Access; Green Open Access
Yang Y.; Singh P.; Yao J.; Au Yeung C.-M.; Zareian A.; Wang X.; Cai Z.; Salvadores M.; Gibbins N.; Hall W.; Shadbolt N.,"Yang, Yang (36163477100); Singh, Priyanka (55463326400); Yao, Jiadi (42462755700); Au Yeung, Ching-Man (24480248600); Zareian, Amir (43862110300); Wang, Xiaowei (43862022500); Cai, Zhonglun (23977626000); Salvadores, Manuel (23390628500); Gibbins, Nicholas (6602976204); Hall, Wendy (55326967000); Shadbolt, Nigel (56867428600)",36163477100; 55463326400; 42462755700; 24480248600; 43862110300; 43862022500; 23977626000; 23390628500; 6602976204; 55326967000; 56867428600,Distributed human computation framework for linked data co-reference resolution,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960061916&doi=10.1007%2f978-3-642-21034-1_3&partnerID=40&md5=264031c840ba1fd772cd249da2afb7f5,"Distributed Human Computation (DHC) is used to solve computational problems by incorporating the collaborative effort of a large number of humans. It is also a solution to AI-complete problems such as natural language processing. The Semantic Web with its root in AI has many research problems that are considered as AI-complete. E.g. co-reference resolution, which involves determining whether different URIs refer to the same entity, is a significant hurdle to overcome in the realisation of large-scale Semantic Web applications. In this paper, we propose a framework for building a DHC system on top of the Linked Data Cloud to solve various computational problems. To demonstrate the concept, we are focusing on handling the co-reference resolution when integrating distributed datasets. Traditionally machine-learning algorithms are used as a solution for this but they are often computationally expensive, error-prone and do not scale. We designed a DHC system named iamResearcher, which solves the scientific publication author identity co-reference problem when integrating distributed bibliographic datasets. In our system, we aggregated 6 million bibliographic data from various publication repositories. Users can sign up to the system to audit and align their own publications, thus solving the co-reference problem in a distributed manner. The aggregated results are dereferenceable in the Open Linked Data Cloud. © 2011 Springer-Verlag Berlin Heidelberg.",Final,All Open Access; Bronze Open Access; Green Open Access
Montiel-Ponsoda E.; Gracia J.; Aguado-De-Cea G.; Gómez-Pérez A.,"Montiel-Ponsoda, Elena (25654093800); Gracia, Jorge (55392626700); Aguado-De-Cea, Guadalupe (6507619884); Gómez-Pérez, Asunción (6603934482)",25654093800; 55392626700; 6507619884; 6603934482,Representing translations on the semantic Web,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891078136&partnerID=40&md5=d5572583822d5e3291b8f8a2c8816273,"The increase of ontologies and data sets published in the Web in languages other than English raises some issues related to the representation of linguistic (multilingual) information in ontologies. Such linguistic descriptions can contribute to the establishment of links between ontologies and data sets described in multiple natural languages in the Linked Open Data cloud. For these reasons, several models have been proposed recently to enable richer linguistic descriptions in ontologies. Among them, we find lemon, an RDF ontology-lexicon model that defines specific modules for different types of linguistic descriptions. In this contribution we propose a new module to represent translation relations between lexicons in different natural languages associated to the same ontology or belonging to different ontologies. This module can enable the representation of different types of translation relations, as well as translation metadata such as provenance or the reliability score of translations.",Final,
Ferrara A.; Nikolov A.; Scharffe F.,"Ferrara, Alfio (7201825221); Nikolov, Andriy (24071604200); Scharffe, François (15137559900)",7201825221; 24071604200; 15137559900,Data linking for the semantic web,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857578944&doi=10.4018%2fjswis.2011070103&partnerID=40&md5=0a41deed4891b8a445ca725d1cec6536,"By specifying that published datasets must link to other existing datasets, the 4th linked data principle ensures a Web of data and not just a set of unconnected data islands. The authors propose in this paper the term data linking to name the problem of finding equivalent resources on the Web of linked data. In order to perform data linking, many techniques were developed, finding their roots in statistics, database, natural language processing and graph theory. The authors begin this paper by providing background information and terminological clarifications related to data linking. Then a comprehensive survey over the various techniques available for data linking is provided. These techniques are classified along the three criteria of granularity, type of evidence, and source of the evidence. Finally, the authors survey eleven recent tools performing data linking and we classify them according to the surveyed techniques. © 2011 IGI Global.",Final,All Open Access; Green Open Access
Chiarcos C.; Hellmann S.; Nordhoff S.,"Chiarcos, Christian (22333764800); Hellmann, Sebastian (35199882400); Nordhoff, Sebastian (55202292000)",22333764800; 35199882400; 55202292000,Towards a linguistic linked open data cloud: The open linguistics working group,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869199991&partnerID=40&md5=16b47f25f046793e265102f1832e1432,"The Open Linguistics Working Group (OWLG) is an initiative of experts from different fields concerned with linguistic data, including academic linguistics (e.g. typology, corpus linguistics), applied linguistics (e.g. computational linguistics, lexicography and language documentation), and NLP (e.g. from the Semantic Web community). The primary goals of the working group are 1) promoting the idea of open linguistic resources, 2) developing means for their representation, and 3) encouraging the exchange of ideas across different disciplines. To a certain extent, the activities of the Open Linguistics Working Group converge towards the creation of a Linguistic Linked Open Data cloud, which is a topic addressed from different angles by several members of the Working Group. In this article, some of these currently on-going activities are presented and described.",Final,
Sun W.; Celli F.; Morshed A.; Jaques Y.; Keizer J.,"Sun, Wei (7404011052); Celli, Fabrizio (54681679400); Morshed, Ahsan (53363838700); Jaques, Yves (53363569200); Keizer, Johannes (16645793800)",7404011052; 54681679400; 53363838700; 53363569200; 16645793800,Design and implementation of a SOLR plug-in for Chinese-English cross-language query expansion based on SKOS thesauri,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856889354&doi=10.1007%2f978-3-642-25992-0_51&partnerID=40&md5=748eae0a3b5aa1c7b35f698d8b7eb6fa,"Given that existing studies for query expansion techniques for Chinese-English are relatively few and their level of standardization low, in order to improve efficiency of Chinese-English cross-language retrieval, this paper discusses the design and implementation of a SOLR plug-in for Chinese-English cross-language query expansion based on SKOS thesauri and used within the AGRIS agricultural bibliographic system. The paper also elaborates the key techniques involved in the plug-in. Finally, taking the AGRIS data resources as an example, the paper shows application examples for segmentation of mixed Chinese and English, user query parsing and AGRIS retrieval system etc., techniques that have improved the Chinese-English cross-language retrieval efficiency to a certain extent, and laid a technical foundation for research about knowledge retrieval and discovery in related fields. © 2011 Springer-Verlag.",Final,All Open Access; Green Open Access
Hayashi Y.,"Hayashi, Yoshihiko (35475987700)",35475987700,Direct and indirect linking of lexical objects for evolving lexical linked data,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891124416&partnerID=40&md5=4dfb614a158c5969b4e336e79321ede8,"Servicization of language resources in a Web-based environment has opened up the potential for dynamically combined virtual lexical resources. Evolving lexical linked data could be realized, provided being recovered/discovered links among lexical resources are properly organized and maintained. This position paper examines a scenario, in which lexical semantic resources are cross-linguistically enriched, and sketches how this scenario could come about while discussing necessary ingredients. The discussions naturally include how the existing lexicon modeling framework could be applied and should be extended.",Final,
Freitas A.; Oliveira J.G.; O'Riain S.; Curry E.; Pereira Da Silva J.C.,"Freitas, André (36631806600); Oliveira, João Gabriel (42861980200); O'Riain, Seán (56878816000); Curry, Edward (12790805000); Pereira Da Silva, João Carlos (24830066700)",36631806600; 42861980200; 56878816000; 12790805000; 24830066700,Querying linked data using semantic relatedness: A vocabulary independent approach,1,,1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959637229&doi=10.1007%2f978-3-642-22327-3_5&partnerID=40&md5=9247d80361293060b08ea25cca680a0e,"Linked Data brings the promise of incorporating a new dimension to the Web where the availability of Web-scale data can determine a paradigmatic transformation of the Web and its applications. However, together with its opportunities, Linked Data brings inherent challenges in the way users and applications consume the available data. Users consuming Linked Data on the Web, or on corporate intranets, should be able to search and query data spread over potentially a large number of heterogeneous, complex and distributed datasets. Ideally, a query mechanism for Linked Data should abstract users from the representation of data. This work focuses on the investigation of a vocabulary independent natural language query mechanism for Linked Data, using an approach based on the combination of entity search, a Wikipedia-based semantic relatedness measure and spreading activation. The combination of these three elements in a query mechanism for Linked Data is a new contribution in the space. Wikipedia-based relatedness measures address existing limitations of existing works which are based on similarity measures/term expansion based on WordNet. Experimental results using the query mechanism to answer 50 natural language queries over DBPedia achieved a mean reciprocal rank of 61.4%, an average precision of 48.7% and average recall of 57.2%, answering 70% of the queries. © 2011 Springer-Verlag.",Final,All Open Access; Green Open Access
Araúz P.L.; Redondo P.J.M.,"Araúz, Pilar León (49861827700); Redondo, Pedro Javier Magaña (8875878500)",49861827700; 8875878500,Ecolexicon: Contextualizing an environmental ontology,1,,1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887508763&partnerID=40&md5=81f959af16c8c4a9740dec860d3351e8,"EcoLexicon is a Terminological Knowledge Base (TKB) on environment enhanced by both linguistic and knowledge representation techniques. Our TKB is primarily hosted in a relational database (RDB) but at the same time integrated in an ontological model. This is a powerful representational model, as it adds the semantic expressiveness lacking in RDBs. In turn, the design of ontologies can also benefit from the theoretical background of linguistics, especially from cognitive approaches. Consequently, the upper-level classes in our ontology correspond to basic semantic roles (AGENT, PATIENT, RESULT, etc.) as described in Frame Semantics (Fillmore, 1992). On the other hand, ontologies provide a suitable schema for sharing and reusing semantic resources. In this sense, Linked Data is a good initiative to cope with the current information overload in the web and make the most of other similar approaches. This could also enrich our system with new information, complementing our TKB from a different perspective or even with other contents, such as real-world geographical instances. Nevertheless, information overload not only occurs when interconnecting different systems. Before considering the interoperability of other environmental knowledge-based projects, we must first deal with overinformation in our own TKB, mostly due to multidimensionality and contextual variation.",Final,
Hulliyah K.; Kusuma H.T.,"Hulliyah, Khodijah (49663430700); Kusuma, Husni Teja (49663511600)",49663430700; 49663511600,Application of knowledge graph for making Text Summarization (Analizing a text of educational issues),1,,1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052351173&doi=10.1109%2fICT4M.2010.5971919&partnerID=40&md5=649b688264fcf2756bc2c2e0fc8b129d,"Text Summerization, is a topic that is related to the fields of philosophy and linguistics [2] are also included in the social sciences, so often sought by researchers in computer science who prefer something in the field of exact sciences. Interestingly, the Text Summerization applications, is a system that will make a summary or conclusion of tens or hundreds of texts with similar themes in an overview that produces new knowledge. This system becomes very important if you have a problem cases to take a series of conclusions from existing text. The purpose of this research is to develop knowledge-graph method to do case studies to determine whether the knowledge graph that can be used as an efficient instrument in analyzing a text with the same theme in large numbers, then the results become much simpler in the form of graphs that can be used as new knowledge. © 2010 IEEE.",Final,
Ni Y.; Zhang L.; Qiu Z.; Wang C.,"Ni, Yuan (16068896200); Zhang, Lei (57216889918); Qiu, Zhaoming (14042519500); Wang, Chen (57191195766)",16068896200; 57216889918; 14042519500; 57191195766,Enhancing the open-domain classification of named entity using linked open data,1,,1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650922445&doi=10.1007%2f978-3-642-17746-0_36&partnerID=40&md5=cc6e831b28ac06d2dec2a31ff8da76c6,"Many applications make use of named entity classification. Machine learning is the preferred technique adopted for many named entity classification methods where the choice of features is critical to final performance. Existing approaches explore only the features derived from the characteristic of the named entity itself or its linguistic context. With the development of the Semantic Web, a large number of data sources are published and connected across the Web as Linked Open Data (LOD). LOD provides rich a priori knowledge about entity type information, knowledge that can be a valuable asset when used in connection with named entity classification. In this paper, we explore the use of LOD to enhance named entity classification. Our method extracts information from LOD and builds a type knowledge base which is used to score a (named entity string, type) pair. This score is then injected as one or more features into the existing classifier in order to improve its performance. We conducted a thorough experimental study and report the results, which confirm the effectiveness of our proposed method. © 2010 Springer-Verlag.",Final,All Open Access; Bronze Open Access
Damljanovic D.; Agatonovic M.; Cunningham H.,"Damljanovic, Danica (24385303600); Agatonovic, Milan (34970726000); Cunningham, Hamish (56249644700)",24385303600; 34970726000; 56249644700,Natural language interfaces to ontologies: Combining syntactic analysis and ontology-based lookup through the user interaction,1,,1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954390899&doi=10.1007%2f978-3-642-13486-9_8&partnerID=40&md5=4e6a55d69eca22038f0bbeecffe80ba2,"With large datasets such as Linked Open Data available, there is a need for more user-friendly interfaces which will bring the advantages of these data closer to the casual users. Several recent studies have shown user preference to Natural Language Interfaces (NLIs) in comparison to others. Although many NLIs to ontologies have been developed, those that have reasonable performance are domain-specific and tend to require customisation for each new domain which, from a developer's perspective, makes them expensive to maintain. We present our system FREyA, which combines syntactic parsing with the knowledge encoded in ontologies in order to reduce the customisation effort. If the system fails to automatically derive an answer, it will generate clarification dialogs for the user. The user's selections are saved and used for training the system in order to improve its performance over time. FREyA is evaluated using Mooney Geoquery dataset with very high precision and recall. © 2010 Springer-Verlag.",Final,All Open Access; Bronze Open Access; Green Open Access
Thoutenhoofd E.D.,"Thoutenhoofd, Ernst Daniël (21740269400)",21740269400,The development of a filemaker Pro database for the morphemic analysis of productive forms in BSL,1,,1,2001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989380176&doi=10.1075%2fsll.4.12.08tho&partnerID=40&md5=ad5a8b81a32162efdc034f684e4e4248,"This article reports on a ‘rapid application development’ or RAD process to construct a research database in entry-level commercial database software, in this case FileMaker Pro. The database was required for a sign linguistic investigation into the morphology of the productive lexicon of British Sign Language (cf. Brennan’s article in this volume). Although at an early stage of development, the productive lexicon database (PLD) is an open and modifiable set of loosely-linked data files which can be reconfigured and remodelled according to user requirements, research aims or commercial objectives. The example offered is that of a trilingual sign/spoken language dictionary. The PLD’s flexible data model allows, as a matter of principle, for the combination of datasets irrespective of linguistic conventions used for data description. It is suggested that data models of this kind therefore open opportunities for research collaboration and commercial exploitation without necessitating detailed prior agreement on linguistic data description conventions or standards. © 2001 John Benjamins Publishing Company.",Final,
Wen Q.; Tian Y.; Zhang X.; Hu R.; Wang J.; Hou L.; Li J.,"Wen, Qinghua (57219632858); Tian, Yunzhe (57221045656); Zhang, Xiaohui (57226294785); Hu, Ruoyun (57226270480); Wang, Jinsong (57221359912); Hou, Lei (56622056400); Li, Juanzi (8304332600)",57219632858; 57221045656; 57226294785; 57226270480; 57221359912; 56622056400; 8304332600,Type-Aware Open Information Extraction via Graph Augmentation Model,1,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111047447&doi=10.1007%2f978-981-16-1964-9_10&partnerID=40&md5=ca85f8c987b989ed0016a00b02bffc14,"Open information extraction (IE) can support knowledge graph enrichment. Open IE systems are capable of extracting relational tuples from texts without the need for a pre-specified vocabulary. There have been more researches on open IE in English than in Chinese, and most of them rely on word segmentation and syntactic analysis tools, which have a great influence on the results. Besides, the lack of annotated Chinese corpus also makes it difficult to classify triples in a supervised manner. To address the problems, we propose an unsupervised Chinese open IE model, named graph augmentation model (GAM). It first uses the knowledge graph to obtain linked entities and types of entities, where the linked entities can benefit the word segmentation accuracy and the entity types can help obtain the domain and range of relations for knowledge graph schema completion. Then it uses manually set rules to obtain candidate triples and uses a designed graph-based algorithm to iteratively calculate the importance and accuracy of triples. Experiments demonstrate that our method outperforms existing baseline methods. Specifically, GAM is proved to effectively extract domain and range of relations that other methods cannot. GAM achieves high accuracy of triples above a certain threshold, and the triples obtained show benefits in enriching a knowledge graph without the need for data annotation. © 2021, Springer Nature Singapore Pte Ltd.",Final,
Hu L.; Yang T.; Zhang L.; Zhong W.; Tang D.; Shi C.; Duan N.; Zhou M.,"Hu, Linmei (56181376700); Yang, Tianchi (57204945425); Zhang, Luhao (57215425975); Zhong, Wanjun (57211975950); Tang, Duyu (56181336700); Shi, Chuan (55447999200); Duan, Nan (52163366000); Zhou, Ming (55587890800)",56181376700; 57204945425; 57215425975; 57211975950; 56181336700; 55447999200; 52163366000; 55587890800,Compare to the knowledge: Graph neural fake news detection with external knowledge,1,1,1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118918173&partnerID=40&md5=d45c2848d5b7bf759bf5812f6d2aabf0,"Nowadays, fake news detection, which aims to verify whether a news document is trusted or fake, has become urgent and important. Most existing methods rely heavily on linguistic and semantic features from the news content, and fail to effectively exploit external knowledge which could help determine whether the news document is trusted. In this paper, we propose a novel end-to-end graph neural model called CompareNet, which compares the news to the knowledge base (KB) through entities for fake news detection. Considering that fake news detection is correlated with topics, we also incorporate topics to enrich the news representation. Specifically, we first construct a directed heterogeneous document graph for each news incorporating topics and entities. Based on the graph, we develop a heterogeneous graph attention network for learning the topic-enriched news representation as well as the contextual entity representations that encode the semantics of the news content. The contextual entity representations are then compared to the corresponding KB-based entity representations through a carefully designed entity comparison network, to capture the consistency between the news content and KB. Finally, the topic-enriched news representation combining the entity comparison features are fed into a fake news classifier. Experimental results on two benchmark datasets demonstrate that CompareNet significantly outperforms state-of-the-art methods. © 2021 Association for Computational Linguistics",Final,
,,,Mixedemotions: Social semantic emotion analysis for innovative multilingual big data analytics markets,1,1,1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084018220&partnerID=40&md5=82531f0de0132d37ea389517ab75d1f1,"Emotion analysis is central to tracking customer and user behaviour and satisfaction, which can be observed from user interaction in the form of explicit feedback through email, call centre interaction, social media comments, etc., as well as implicit acknowledgment of approval or rejection through facial expressions, speech or other non-verbal feedback. In Europe specifically, but increasingly also globally, an added factor here is that user feedback can be in multiple languages, in text as well as in speech and audio-visual content. This implies different cultural backgrounds and thus different ways to produce and perceive emotions in everyday interactions, beyond the fact of having specific rules for encoding and decoding emotions in each language. Making sense of accumulated user interaction from different (‘mixed’) data sources, modalities and languages is challenging and has not yet been explored in fullness in an industrial context. Commercial solutions exist but do not address the multilingual aspect in a robust and large-scale setting and do not scale up to huge data volumes that need to be processed, or the integration of emotion analysis observations across data sources and/or modalities on a meaningful level, i.e. keeping track of entities involved as well the connections between them (who said what? to whom? in the context of which event, product, service?) The MixedEmotions project will implement an integrated Big Linked Data platform for emotion analysis across heterogeneous data sources, languages and modalities, building on existing state-of-the-art tools, services and approaches that will enable the tracking of emotional aspects of user interaction and feedback on an entity level. The platform will provide an integrated solution for: Large-scale emotion analysis and fusion on heterogeneous, multilingual, text, speech, video and social media data streams, leveraging open access and proprietary data sources, exploiting also social context by leveraging social network graphs Semantic-level emotion information aggregation and integration through robust extraction of social semantic knowledge graphs for emotion analysis along multidimensional clusters The platform will be developed and evaluated in the context of three cross-domain pilot projects that are representative of a variety of data analytics markets: Social TV, Brand Reputation Management, Call Centre Operations. © 2015 European Association for Machine Translation. All rights reserved.",Final,
Patton E.W.; McGuinness D.L.,"Patton, Evan W. (36025753600); McGuinness, Deborah L. (7006256751)",36025753600; 7006256751,Connecting science data using semantics and information extraction,1,1,1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939491390&partnerID=40&md5=0f783dcd1f20db9e4bfbc37c5886f4c0,"We are developing prototypes that explicate our vision of connecting personal medical data to scientific literature as well as to emerging grey literature (e.g., community forums) to help people find and understand information relevant to complex medical journeys. We focus on robust combinations of natural language processing along with linked data and knowledge representation to build knowledge graphs that help people make sense of current conditions and enable new manners of scientific hypothesis generation. We present our work in the context of a breast cancer use case. We discuss the benefits of biomedical linked data resources and describe some potential assistive technology for navigating rich, diverse medical content.",Final,
Wang Z.; Li L.; Zeng D.,"Wang, Zikang (57205674634); Li, Linjing (27171789200); Zeng, Daniel (57280387700)",57205674634; 27171789200; 57280387700,Knowledge-Enhanced Natural Language Inference Based on Knowledge Graphs,1,1,1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118819345&partnerID=40&md5=3cb022a173acf84d242a962c1bc4b235,"Natural Language Inference (NLI) is a vital task in natural language processing. It aims to identify the logical relationship between two sentences. Most of the existing approaches make such inference based on semantic knowledge obtained through training corpus. The adoption of background knowledge is rarely seen or limited to a few specific types. In this paper, we propose a novel Knowledge Graph-enhanced NLI (KGNLI) model to leverage the usage of background knowledge stored in knowledge graphs in the field of NLI. KGNLI model consists of three components: a semantic-relation representation module, a knowledge-relation representation module, and a label prediction module. Different from previous methods, various kinds of background knowledge can be flexibly combined in the proposed KGNLI model. Experiments on four benchmarks, SNLI, MultiNLI, SciTail, and BNLI, validate the effectiveness of our model. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Thießen F.; D’Souza J.; Stocker M.,"Thießen, Freya (58679414600); D’Souza, Jennifer (57215346447); Stocker, Markus (44461998000)",58679414600; 57215346447; 44461998000,Probing Large Language Models for Scientific Synonyms,-1,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175633008&partnerID=40&md5=ebda6ee4dbdf11fe1bd59423f9b78103,"Purpose: Automatically identifying synonyms is an important but challenging aspect of entity normalization in knowledge graphs. Entity normalization is crucial in ensuring that information in knowledge graphs is well connected and therefore efficiently reusable. We aim to investigate the potential of pre-trained large language models (LLMs) for this task. Methodology: We use k-Means clustering to compare latent concepts learned by LLMs with human-defined scientific synonymy concept clusters sourced from ORKG, CS-KG, SemEval 2017, and SciERC data. We investigate the models BERT, RoBERTa, BART, and OpenAI GPT3 (text-embedding-ada-002 variant) and evaluate clustering results by model layer. Findings: F1 scores average around 0.7 to 0.75 depending on the dataset and layer. The best results are reached using OpenAI GPT3 (max F1=0.914). We further notice no advantage of models trained on scientific data. Value: Our results suggest information learned by transformer models aligns with human-defined scientific synonyms. This shows the potential of information encoded in pre-trained LLMs to be leveraged for synonymy detection. © 2023 Copyright for this paper by its authors.",Final,
Mərginean A.,"Mərginean, Anca (57190575057)",57190575057,GFMed: Question answering over Biomedical linked data with Grammatical Framework,-1,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981241186&partnerID=40&md5=4c67f55835ec27743d5919f6a305fbe2,"This paper reports on the participation of the system GF-Med in QALD-4 question answering challenge for Biomedical interlinked data. GFMed introduces grammars for a controlled natural language targeted towards biomedical information and the corresponding controlled SPARQL language. The grammars are described in Grammatical Framework and introduce linguistic and SPARQL phrases mostly about drugs, diseases and relationships between them.",Final,
Sheng J.; Guo S.; Chen Z.; Yue J.; Wang L.; Liu T.; Xu H.,"Sheng, Jiawei (57224580691); Guo, Shu (55515151500); Chen, Zhenyu (57224578480); Yue, Juwei (57224569612); Wang, Lihong (57007714500); Liu, Tingwen (35956637400); Xu, Hongbo (57450935500)",57224580691; 55515151500; 57224578480; 57224569612; 57007714500; 35956637400; 57450935500,Adaptive attentional network for few-shot knowledge graph completion,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110908639&partnerID=40&md5=44077835fe3b0773e22b4f83e7c66ca3,"Few-shot Knowledge Graph (KG) completion is a focus of current research, where each task aims at querying unseen facts of a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-the-art results with different few-shot sizes. The source code is available at https://github.com/JiaweiSheng/FAAN. © 2020 Association for Computational Linguistics",Final,
Wang Q.; Huang L.; Jiang Z.; Knight K.; Ji H.; Bansal M.; Luan Y.,"Wang, Qingyun (57207885167); Huang, Lifu (57193240973); Jiang, Zhiying (57216621946); Knight, Kevin (7202745471); Ji, Heng (35240121900); Bansal, Mohit (16466939600); Luan, Yi (56414288900)",57207885167; 57193240973; 57216621946; 7202745471; 35240121900; 16466939600; 56414288900,Paperrobot: Incremental draft generation of scientific ideas,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084054543&partnerID=40&md5=3b48e9d67065c5752c07e3055e1e06f4,"We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively1. © 2019 Association for Computational Linguistics",Final,
Buitelaar P.; Arcan M.; Iglesias C.A.; Sánchez-Rada J.F.; Strapparava C.,"Buitelaar, Paul (14041096000); Arcan, Mihael (55453083200); Iglesias, Carlos A. (56357213400); Sánchez-Rada, J. Fernando (56426347900); Strapparava, Carlo (6602773549)",14041096000; 55453083200; 56357213400; 56426347900; 6602773549,Linguistic Linked Data for Sentiment Analysis,-1,-1,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122863688&partnerID=40&md5=b189674396f36ea315943209f3691ba6,[No abstract available],Final,
Becquin G.; Esmeir S.,"Becquin, Guillaume (54987318400); Esmeir, Saher (8201407300)",54987318400; 8201407300,Semantic Similarity Covariance Matrix Shrinkage,-1,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183300840&partnerID=40&md5=462ccf86cbd2ba60b244f637bfc47cae,"An accurate estimation of the covariance matrix is a critical component of many applications in finance, including portfolio optimization. The sample covariance suffers from the curse of dimensionality when the number of observations is in the same order or lower than the number of variables. This tends to be the case in portfolio optimization, where a portfolio manager can choose between thousands of stocks using historical daily returns to guide their investment decisions. To address this issue, past works proposed linear covariance shrinkage to regularize the estimated matrix. While effective, the proposed methods relied solely on historical price data and thus ignored company fundamental data. In this work, we propose to utilise semantic similarity derived from textual descriptions or knowledge graphs to improve the covariance estimation. Rather than using the semantic similarity directly as a biased estimator to the covariance, we employ it as a shrinkage target. The resulting covariance estimators leverage both semantic similarity and recent price history, and can be readily adapted to a broad range of financial securities. The effectiveness of the approach is demonstrated for a period including diverse market conditions and compared with the covariance shrinkage prior art. © 2023 Association for Computational Linguistics.",Final,
Voskarides N.; Meij E.; Tsagkias M.; De Rijke M.; Weerkamp W.,"Voskarides, Nikos (56151753800); Meij, Edgar (23398197500); Tsagkias, Manos (27868138100); De Rijke, Maarten (54790525600); Weerkamp, Wouter (23394448300)",56151753800; 23398197500; 27868138100; 54790525600; 23394448300,Learning to explain entity relationships in knowledge graphs,-1,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943740328&doi=10.3115%2fv1%2fp15-1055&partnerID=40&md5=8c07724f26c915d18f4f8a42a4218f51,"We study the problem of explaining relationships between pairs of knowledge graph entities with human-readable descriptions. Our method extracts and enriches sentences that refer to an entity pair from a corpus and ranks the sentences according to how well they describe the relationship between the entities. We model this task as a learning to rank problem for sentences and employ a rich set of features. When evaluated on a large set of manually annotated sentences, we find that our method significantly improves over state-of-The-Art baseline models. © 2015 Association for Computational Linguistics.",Final,All Open Access; Bronze Open Access; Green Open Access
Zhang T.; Cai Z.; Wang C.; Qiu M.; Yang B.; He X.,"Zhang, Taolin (57221142663); Cai, Zerui (57245833400); Wang, Chengyu (55926354300); Qiu, Minghui (55537463100); Yang, Bite (57208648880); He, Xiaofeng (55641972700)",57221142663; 57245833400; 55926354300; 55537463100; 57208648880; 55641972700,SMedBERT: A knowledge-enhanced pre-trained language model with structured semantics for medical text mining,-1,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115667288&partnerID=40&md5=f2a063d45b53f12db67ca76c9d82132c,"Recently, the performance of Pre-trained Language Models (PLMs) has been significantly improved by injecting knowledge facts to enhance their abilities of language understanding. For medical domains, the background knowledge sources are especially useful, due to the massive medical terms and their complicated relations are difficult to understand in text. In this work, we introduce SMedBERT, a medical PLM trained on large-scale medical corpora, incorporating deep structured semantics knowledge from neighbours of linked-entity. In SMedBERT, the mention-neighbour hybrid attention is proposed to learn heterogeneous-entity information, which infuses the semantic representations of entity types into the homogeneous neighbouring entity structure. Apart from knowledge integration as external features, we propose to employ the neighbors of linked-entities in the knowledge graph as additional global contexts of text mentions, allowing them to communicate via shared neighbors, thus enrich their semantic representations. Experiments demonstrate that SMedBERT significantly outperforms strong baselines in various knowledge-intensive Chinese medical tasks. It also improves the performance of other tasks such as question answering, question matching and natural language inference. © 2021 Association for Computational Linguistics",Final,
Xu Z.; Wang C.; Li P.; Li Y.; Wang M.; Hou B.; Qiu M.; Tang C.; Huang J.,"Xu, Ziyun (57314388000); Wang, Chengyu (55926354300); Li, Peng (57221127569); Li, Yang (57219793158); Wang, Ming (57195214769); Hou, Boyu (57221648195); Qiu, Minghui (55537463100); Tang, Chengguang (57219766342); Huang, Jun (57199287007)",57314388000; 55926354300; 57221127569; 57219793158; 57195214769; 57221648195; 55537463100; 57219766342; 57199287007,When Few-Shot Learning Meets Large-Scale Knowledge-Enhanced Pre-training: Alibaba at FewCLUE,-1,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118186400&doi=10.1007%2f978-3-030-88483-3_34&partnerID=40&md5=8a0de7e7136b15724ab66cbef0d7b68e,"With the wide popularity of Pre-trained Language Models (PLMs), it has been a hot research topic to improve the performance of PLMs in the few-shot learning setting. FewCLUE is a new benchmark to evaluate the few-shot learning ability of PLMs over nine challenging Chinese language understanding tasks, which poses significant challenges to the learning process of PLMs with very little training data available. In this paper, we present our solution to FewCLUE tasks by means of large-scale knowledge-enhanced pre-training over massive texts and knowledge triples, together with a new few-shot learning algorithm for downstream tasks. Experimental results show that the generated models achieve the best performance in both limited and unlimited tracks of FewCLUE. Our solution is developed upon the PyTorch version of the EasyTransfer toolkit and will be released to public. © 2021, Springer Nature Switzerland AG.",Final,
Kaur S.; Sahai V.; Jaiswal A.; Chanda S.,"Kaur, Samarjeet (57220196775); Sahai, Vedant (57217043082); Jaiswal, Aditi (57221606022); Chanda, Sayonsom (56400437500)",57220196775; 57217043082; 57221606022; 56400437500,Knowledge Mining for Defining Systemic Engineering Practices,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099603190&doi=10.1109%2fICECA49313.2020.9297380&partnerID=40&md5=321064d9f205943ed92bee74c5b08ee9,"This paper addresses the problem on generating knowledge graphs from research papers related to wildfires, and their impacts on the electrical grid infrastructure. A novel framework based on part-of-speech tagging, word frequency statistics, and document clustering is proposed for extracting information and generating knowledge graphs from a selfcurated corpus of wildfire-related research work abstracts. The proposed method is capable of capturing a wide range of insightful information from the self-generated domain-specific corpus. Systemic engineering practices, such as strategies for wildfire mitigation by electric utilities has been included as a case study in this paper. An application of the research is implemented for simulating the management and mitigation of wildfires by electric utilities in California. © 2020 IEEE.",Final,
Kumar A.; Pandey A.; Gadia R.; Mishra M.,"Kumar, Abhijeet (57221102336); Pandey, Abhishek (57221009567); Gadia, Rohit (57220038190); Mishra, Mridul (57220027526)",57221102336; 57221009567; 57220038190; 57220027526,Building knowledge graph using pre-trained language model for learning entity-aware relationships,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096601581&doi=10.1109%2fGUCON48875.2020.9231227&partnerID=40&md5=bf7d199155bd226e4a030188be0c9d66,"Relations exhibited among entities from textual content can be a potential source of information for any business domain. This paper encompasses a wholesome approach to mine entity-relation and building knowledge graph from textual documents. The paper concentrates on two approaches to classify directional entity relations. We build on extending pretrained language model i.e. BERT for text classification along-side providing entity and directionality information as input making it entity-aware BERT classifier. We also did ablation studies of presented model in terms of various ways of providing entity information on the learning capabilities of model. We demonstrate the end to end pipeline for building an entity-relation extraction system in a business application. The techniques proposed in the paper are also evaluated against SemEval-2010 Task 8, a popular relation classification dataset. The experimental results demonstrate that learning entity-aware relations through language models outperforms almost all the previous state-of-the-art (SOTA) models. © 2020 IEEE.",Final,
Liang J.; Ye R.; Han M.; Zhang Q.; Lai R.; Zhang X.; Cao Z.; Huang X.; Wei Z.,"Liang, Jingcong (58784439200); Ye, Rong (57223723457); Han, Meng (58314426400); Zhang, Qi (57203621188); Lai, Ruofei (57857551200); Zhang, Xinyu (57224828442); Cao, Zhao (57224829459); Huang, Xuanjing (8983710700); Wei, Zhongyu (51666060600)",58784439200; 57223723457; 58314426400; 57203621188; 57857551200; 57224828442; 57224829459; 8983710700; 51666060600,Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining,-1,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184818054&partnerID=40&md5=53bb73b0b1b737ff971d422e9c08d82a,"The knowledge graph is a structure to store and represent knowledge, and recent studies have discussed its capability to assist language models for various applications. Some variations of knowledge graphs aim to record arguments and their relations for computational argumentation tasks. However, many must simplify semantic types to fit specific schemas, thus losing flexibility and expression ability. In this paper, we propose the Hierarchical Argumentation Graph (Hi-ArG), a new structure to organize arguments. We also introduce two approaches to exploit Hi-ArG, including a text-graph multi-modal model GreaseArG and a new pre-training framework augmented with graph information. Experiments on two argumentation tasks have shown that after further pre-training and fine-tuning, GreaseArG supersedes same-scale language models on these tasks, while incorporating graph information during further pre-training can also improve the performance of vanilla language models. Code for this paper is available at https://github.com/ljcleo/Hi-ArG. ©2023 Association for Computational Linguistics.",Final,
Kochsiek A.; Gemulla R.,"Kochsiek, Adrian (57488409100); Gemulla, Rainer (9940328100)",57488409100; 9940328100,A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs,-1,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183308839&partnerID=40&md5=869d8b953883f3d54deae7a952353780,"Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of predicting facts for new, previously unseen entities based on context information. Although new entities can be integrated by retraining the model from scratch in principle, such an approach is infeasible for large-scale KGs, where retraining is expensive and new entities may arise frequently. In this paper, we propose and describe a large-scale benchmark to evaluate semi-inductive LP models. The benchmark is based on and extends Wikidata5M: It provides transductive, k-shot, and 0-shot LP tasks, each varying the available information from (i) only KG structure, to (ii) including textual mentions, and (iii) detailed descriptions of the entities. We report on a small study of recent approaches and found that semi-inductive LP performance is far from transductive performance on long-tail entities throughout all experiments. The benchmark provides a test bed for further research into integrating context and textual information in semi-inductive LP models. © 2023 Association for Computational Linguistics.",Final,
Liu X.; Sarikaya R.,"Liu, Xiaohu (56304436600); Sarikaya, Ruhi (6602907269)",56304436600; 6602907269,A discriminative model based entity dictionary weighting approach for spoken language understanding,-1,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983097788&doi=10.1109%2fSLT.2014.7078573&partnerID=40&md5=4a1f103560cb8c4b099d8ef01bc0adcf,"Spoken language understanding (SLU) systems use various features to detect the domain, intent and semantic slots of a query. In addition to n-grams, features generated from entity dictionaries are often used in model training. Clean or properly weighted dictionaries are critical to improve model's coverage and accuracy for unseen entities during test time. However, clean dictionaries are hard to obtain for some applications since they are automatically generated and can potentially contain millions of entries (e.g. movie names, person names) with significant noise in them. This paper proposes a discriminative model based approach to weight entities in noisy dictionaries using multiple knowledge resources. The model makes use of features extracted from query click logs, knowledge graph and live search results for accurate entity weighting. Experiments for both intent detection and slots tagging tasks in entertainment search covering five domains show significant gains over the baselines. © 2014 IEEE.",Final,
Xu H.; Moon S.; Liu H.; Liu B.; Shah P.; Liu B.; Yu P.S.,"Xu, Hu (57193612773); Moon, Seungwhan (57216616433); Liu, Honglei (57221580639); Liu, Bing (56889958600); Shah, Pararth (57207854850); Liu, Bing (36063168200); Yu, Philip S. (7402366049)",57193612773; 57216616433; 57221580639; 56889958600; 57207854850; 36063168200; 7402366049,User Memory Reasoning for Conversational Recommendation,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149632141&partnerID=40&md5=2ce96d806517c16ce19d3e50c2105674,"We study an end-to-end approach for conversational recommendation that dynamically manages and reasons over users’ past (offline) preferences and current (online) requests through a structured and cumulative user memory knowledge graph. This formulation extends existing state tracking beyond the boundary of a single dialog to user state tracking (UST). For this study, we create a new Memory Graph (MG) ↔ Conversational Recommendation parallel corpus called MGConvRex with 7K+ human-to-human role-playing dialogs, grounded on a large-scale user memory bootstrapped from real-world user scenarios. MGConvRex captures human-level reasoning over user memory and has disjoint training/testing sets of users for zero-shot (cold-start) reasoning for recommendation. We propose a simple yet expandable formulation for constructing and updating the MG, and an end-to-end graph-based reasoning model that updates MG from unstructured utterances and predicts optimal dialog policies (e.g. recommendation) based on updated MG. The prediction of our proposed model inherits the graph structure, providing a natural way to explain policies. Experiments are conducted for both offline metrics and online simulation, showing competitive results. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Amin S.; Dunfield K.A.; Vechkaeva A.; Neumann G.,"Amin, Saadullah (57210371505); Dunfield, Katherine Ann (57210372087); Vechkaeva, Anna (57210378936); Neumann, Günter (7202631822)",57210371505; 57210372087; 57210378936; 7202631822,A data-driven approach for noise reduction in distantly supervised biomedical relation extraction,-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114681580&partnerID=40&md5=9784a567907dd647999afbd659b502e0,"Fact triples are a common form of structured knowledge used within the biomedical domain. As the amount of unstructured scientific texts continues to grow, manual annotation of these texts for the task of relation extraction becomes increasingly expensive. Distant supervision offers a viable approach to combat this by quickly producing large amounts of labeled, but considerably noisy, data. We aim to reduce such noise by extending an entity-enriched relation classification BERT model to the problem of multiple instance learning, and defining a simple data encoding scheme that significantly reduces noise, reaching state-of-the-art performance for distantly-supervised biomedical relation extraction. Our approach further encodes knowledge about the direction of relation triples, allowing for increased focus on relation learning by reducing noise and alleviating the need for joint learning with knowledge graph completion © Association for Computation Linguistics.",Final,
,,,"17th Extended Semantic Web Conference, ESWC 2020",-1,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097299535&partnerID=40&md5=580805d56a52c2a2c73136e154609a6c,The proceedings contain 39 papers. The special focus in this conference is on Extended Semantic Web. The topics include: A Parthood Approach for Modeling Tangible Objects’ Composition TOC - An Application on Cultural Heritage; LandCover2RDF: An API for Computing the Land Cover of a Geographical Area and Generating the RDF Graph; N3X: Notation3 with SPARQL Expressions; CounQER: A System for Discovering and Linking Count Information in Knowledge Bases; EventKG+BT: Generation of Interactive Biography Timelines from a Knowledge Graph; Toward OWL Restriction Reconciliation in Merging Knowledge; Linked Data Creation with ExcelRDF; publishing and Using Legislation and Case Law as Linked Open Data on the Semantic Web; towards Cost-Model-Based Query Execution over Hybrid Linked Data Fragments Interfaces; cqp4rdf: Towards a Suite for RDF-Based Corpus Linguistics; Elas4RDF: Multi-perspective Triple-Centered Keyword Search over RDF Using Elasticsearch; Answering Controlled Natural Language Questions over RDF Clinical Data; Training NER Models: Knowledge Graphs in the Loop; ABECTO: An ABox Evaluation and Comparison Tool for Ontologies; linkedPipes Applications - Automated Discovery of Configurable Linked Data Applications; medTable: Extracting Disease Types from Web Tables; Can a Transformer Assist in Scientific Writing? Generating Semantic Web Paper Snippets with GPT-2; Assessing the Quality of RDF Mappings with EvaMap;  $$\mathtt{LODsyndesis}:{IE}$$ : Entity Extraction from Text and Enrichment Using Hundreds of Linked Datasets; how Good Is This Merged Ontology?; how Many Stars Do You See in This Constellation?; A Study About the Use of OWL 2 Semantics in RDF-Based Knowledge Graphs; Visual Analysis of Ontology Matching Results with the MELT Dashboard; preface.,Final,
Beek W.; Ilievski F.; Debattista J.; Schlobach S.; Wielemaker J.,"Beek, Wouter (36463094500); Ilievski, Filip (57188757237); Debattista, Jeremy (55802821600); Schlobach, Stefan (55916058700); Wielemaker, Jan (13405968000)",36463094500; 57188757237; 55802821600; 55916058700; 13405968000,Literally better: Analyzing and improving the quality of literals,-1,-1,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037706022&doi=10.3233%2fSW-170288&partnerID=40&md5=5f90ce5ceb2012ba84f4865e2bc4c953,"Quality is a complicated and multifarious topic in contemporary Linked Data research. The aspect of literal quality in particular has not yet been rigorously studied. Nevertheless, analyzing and improving the quality of literals is important since literals form a substantial (one in seven statements) and crucial part of the Semantic Web. Specifically, literals allow infinite value spaces to be expressed and they provide the linguistic entry point to the LOD Cloud. We present a toolchain that builds on the LOD Laundromat data cleaning and republishing infrastructure and that allows us to analyze the quality of literals on a very large scale, using a collection of quality criteria we specify in a systematic way. We illustrate the viability of our approach by lifting out two particular aspects in which the current LOD Cloud can be immediately improved by automated means: value canonization and language tagging. Since not all quality aspects can be addressed algorithmically, we also give an overview of other problems that can be used to guide future endeavors in tooling, training, and best practice formulation. © 2018 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Green Open Access
Jiang T.; Liu T.; Ge T.; Sha L.; Chang B.; Li S.; Sui Z.,"Jiang, Tingsong (55976256400); Liu, Tianyu (57200413781); Ge, Tao (55953962900); Sha, Lei (56441043200); Chang, Baobao (55837183200); Li, Sujian (53984734300); Sui, Zhifang (23091994600)",55976256400; 57200413781; 55953962900; 56441043200; 55837183200; 53984734300; 23091994600,Towards time-aware knowledge graph completion,-1,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045239331&partnerID=40&md5=d1c0c2ac6bd70e4a20d5d5491a8a7787,"Knowledge graph (KG) completion adds new facts to a KG by making inferences from existing facts. Most existing methods ignore the time information and only learn from time-unknown fact triples. In dynamic environments that evolve over time, it is important and challenging for knowledge graph completion models to take into account the temporal aspects of facts. In this paper, we present a novel time-aware knowledge graph completion model that is able to predict links in a KG using both the existing facts and the temporal information of the facts. To incorporate the happening time of facts, we propose a time-aware KG embedding model using temporal order information among facts. To incorporate the valid time of facts, we propose a joint time-aware inference model based on Integer Linear Programming (ILP) using temporal consistency information as constraints. We further integrate two models to make full use of global temporal information. We empirically evaluate our models on time-aware KG completion task. Experimental results show that our time-aware models achieve the state-of-the-art on temporal facts consistently. © 1963-2018 ACL.",Final,
Pan S.; Luo L.; Wang Y.; Chen C.; Wang J.; Wu X.,"Pan, Shirui (55522732400); Luo, Linhao (57214679113); Wang, Yufei (58747837700); Chen, Chen (58383960100); Wang, Jiapu (58143874800); Wu, Xindong (55533800700)",55522732400; 57214679113; 58747837700; 58383960100; 58143874800; 55533800700,Unifying Large Language Models and Knowledge Graphs: A Roadmap,-1,-1,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182350576&doi=10.1109%2fTKDE.2024.3352100&partnerID=40&md5=96523fd500b93b54566f08f6d7695d1b,"Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, <italic>1) KG-enhanced LLMs,</italic> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic>2) LLM-augmented KGs,</italic> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic>3) Synergized LLMs + KGs</italic>, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions. IEEE",Article in press,All Open Access; Green Open Access
Li P.; Bai X.; Li J.; Dong Y.; Yang J.,"Li, Pei (57431111200); Bai, Xuejun (58303267000); Li, Jingyi (58282091400); Dong, Yancheng (58805820200); Yang, Jian (57202707748)",57431111200; 58303267000; 58282091400; 58805820200; 57202707748,Automatic Construction of Knowledge Graph for Personal Sensitive Data,-1,-1,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181979036&doi=10.1007%2f978-981-99-9331-4_17&partnerID=40&md5=a558a77e3b509305bd030e49ab3de7c7,"This article demonstrates an automated method for producing a knowledge graph for sensitive personal information by utilizing natural language processing techniques. It employs a combination of rule-based and machine learning-based methods to extract entities and relationships from textual data and represent them as a knowledge graph. The study presents two major contributions. Firstly, it achieves unsupervised extraction of entities and relationships by using pre-trained linguistic models to extract high-quality labeled embeddings. This enables efficient clustering and scoring of potential entities and relationships, even without labeled data. To enhance the accuracy and generalization ability of extracting sensitive personal information relationships, a more comprehensive set of relationship types is considered. The experimental results demonstrate that this method significantly improves entity recognition accuracy and coverage compared to traditional named entity recognition methods. Secondly, a context-aware graph fusion mechanism is introduced to merge subgraphs extracted from multiple sentences into a unified knowledge graph. This mechanism preserves important semantic information, reduces noise and inconsistency, and results in a more accurate and robust knowledge graph with improved accuracy and coverage in identifying sensitive personal information entities. According to the experimental findings, this approach leads to a significant increase in the accuracy of relationship extraction and its ability to generalize, comparable to conventional methods. These results imply that the proposed approach can effectively generate knowledge graphs for sensitive personal information with high accuracy and generalization ability, making it suitable for fields such as personal information protection and privacy security. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.",Final,
Zhang L.,"Zhang, Limin (57193861250)",57193861250,English Translation Stylistic Features and Syntax Translation with Application of Knowledge Mapping,-1,-1,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179389408&doi=10.2478%2famns.2023.2.01203&partnerID=40&md5=a597ec89603d99f1b7cfd8a99f6f3b24,"Aiming at the problems of excessive instantiation complexity, poor interpretability and low generalization ability of knowledge reasoning techniques, this paper unites inductive logic programming ILP with HET neural network to construct a hybrid logic rule and neural network knowledge graph reasoning model - HETIL model. The ILP is utilized to quantify the first-order logic rules, and the multi-layer rule space is constructed by arranging and combining the rules through logic symbols. The rules are instantiated and fed into the HET network, and the attention coefficients aggregate the node features to complete the end-to-end training and generate the rule learning model. Finally, the validity of the model is verified by machine translation experiments, and the results show that the accuracy of the HETIL model in syntactic structure types is more than 0.8 overall. The accuracy in terms of phrase structure reaches 0.879. The average BLEU value of the HETIL model can reach 29.24, which is 1.51 BLEU points higher than the benchmark model. Therefore, the effect of English translation by applying a knowledge graph is better than traditional machine translation. © 2023 Limin Zhang, published by Sciendo.",Final,All Open Access; Gold Open Access
Ashrafimoghari V.,"Ashrafimoghari, Vahid (57817671000)",57817671000,Detecting Cross-Lingual Information Gaps in Wikipedia,-1,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159560515&doi=10.1145%2f3543873.3587539&partnerID=40&md5=fdde0b8e85d2fbd0423221df83f77ff5,"An information gap exists across Wikipedia's language editions, with a considerable proportion of articles available in only a few languages. As an illustration, it has been observed that 10 languages possess half of the available Wikipedia articles, despite the existence of 330 Wikipedia language editions. To address this issue, this study presents an approach to identify the information gap between the different language editions of Wikipedia. The proposed approach employs Latent Dirichlet Allocation (LDA) to analyze linked entities in a cross-lingual knowledge graph in order to determine topic distributions for Wikipedia articles in 28 languages. The distance between paired articles across language editions is then calculated. The potential applications of the proposed algorithm to detecting sources of information disparity in Wikipedia are discussed, and directions for future research are put forward.  © 2023 ACM.",Final,
Chang1 D.; Balažević I.; Allen C.; Chawla D.; Brandt C.; Taylor R.A.,"Chang1, David (57315555700); Balažević, Ivana (57211205320); Allen, Carl (57211204384); Chawla, Daniel (57215791624); Brandt, Cynthia (35513998400); Taylor, Richard Andrew (57223661992)",57315555700; 57211205320; 57211204384; 57215791624; 35513998400; 57223661992,Benchmark and best practices for biomedical knowledge graph embeddings,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109384757&partnerID=40&md5=746f3152acecb0e25bb20aecb1ea4d19,"Much of biomedical and healthcare data is encoded in discrete, symbolic form such as text and medical codes. There is a wealth of expert-curated biomedical domain knowledge stored in knowledge bases and ontologies, but the lack of reliable methods for learning knowledge representation has limited their usefulness in machine learning applications. While text-based representation learning has significantly improved in recent years through advances in natural language processing, attempts to learn biomedical concept embeddings so far have been lacking. A recent family of models called knowledge graph embeddings have shown promising results on general domain knowledge graphs, and we explore their capabilities in the biomedical domain. We train several state-of-the-art knowledge graph embedding models on the SNOMEDCT knowledge graph, provide a benchmark with comparison to existing methods and indepth discussion on best practices, and make a case for the importance of leveraging the multi-relational nature of knowledge graphs for learning biomedical knowledge representation. The embeddings, code, and materials will be made available to the community © Association for Computation Linguistics.",Final,
Wang C.; Yan M.; Yi C.; Sha Y.,"Wang, Changjian (57205504967); Yan, Minghui (57211170202); Yi, Chuanrun (57211169991); Sha, Ying (8688564600)",57205504967; 57211170202; 57211169991; 8688564600,Capturing Semantic and Syntactic Information for Link Prediction in Knowledge Graphs,,-1,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075713658&doi=10.1007%2f978-3-030-30793-6_38&partnerID=40&md5=ba1d4c2071dd7674147b5eb99f33d9b1,"Link prediction has recently been a major focus of knowledge graphs (KGs). It aims at predicting missing links between entities to complement KGs. Most previous works only consider the triples, but the triples provide less information than the paths. Although some works consider the semantic information (i.e. similar entities get similar representations) of the paths using the Word2Vec models, they ignore the syntactic information (i.e. the order of entities and relations) of the paths. In this paper, we propose RW-LMLM, a novel approach for link prediction. RW-LMLM consists of a random walk algorithm for KG (RW) and a language model-based link prediction model (LMLM). The paths generated by RW are viewed as pseudo-sentences for LMLM training. RW-LMLM can capture the semantic and syntactic information in KGs by considering entities, relations, and order information of the paths. Experimental results show that our method outperforms several state-of-the-art models on benchmark datasets. Further analysis shows that our model is highly parameter efficient. © 2019, Springer Nature Switzerland AG.",Final,
Javed S.; Usman M.; Sandin F.; Liwicki M.; Mokayed H.,"Javed, Saleha (57201061129); Usman, Muhammad (57217521134); Sandin, Fredrik (10642298900); Liwicki, Marcus (14021418000); Mokayed, Hamam (35085400100)",57201061129; 57217521134; 10642298900; 14021418000; 35085400100,Deep Ontology Alignment Using a Natural Language Processing Approach for Automatic M2M Translation in IIoT,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175279210&doi=10.3390%2fs23208427&partnerID=40&md5=11650f0b24458ffd934372d4d4dbfbae,"The technical capabilities of modern Industry 4.0 and Industry 5.0 are vast and growing exponentially daily. The present-day Industrial Internet of Things (IIoT) combines manifold underlying technologies that require real-time interconnection and communication among heterogeneous devices. Smart cities are established with sophisticated designs and control of seamless machine-to-machine (M2M) communication, to optimize resources, costs, performance, and energy distributions. All the sensory devices within a building interact to maintain a sustainable climate for residents and intuitively optimize the energy distribution to optimize energy production. However, this encompasses quite a few challenges for devices that lack a compatible and interoperable design. The conventional solutions are restricted to limited domains or rely on engineers designing and deploying translators for each pair of ontologies. This is a costly process in terms of engineering effort and computational resources. An issue persists that a new device with a different ontology must be integrated into an existing IoT network. We propose a self-learning model that can determine the taxonomy of devices given their ontological meta-data and structural information. The model finds matches between two distinct ontologies using a natural language processing (NLP) approach to learn linguistic contexts. Then, by visualizing the ontological network as a knowledge graph, it is possible to learn the structure of the meta-data and understand the device's message formulation. Finally, the model can align entities of ontological graphs that are similar in context and structure.Furthermore, the model performs dynamic M2M translation without requiring extra engineering or hardware resources.",Final,All Open Access; Gold Open Access; Green Open Access
Han S.; Guan Z.; Li S.; Wang J.; Zhou X.,"Han, Song (58418970000); Guan, Zhengyi (57220852131); Li, Sihui (57880141000); Wang, Jin (56802804300); Zhou, Xiaobing (55743213500)",58418970000; 57220852131; 57880141000; 56802804300; 55743213500,Knowledge Graph Completing with Dual Confrontation Learning Model based on Variational Information Bottleneck Method,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182513682&doi=10.1109%2fQRS60937.2023.00077&partnerID=40&md5=2c33a41028e90d106fb0d86c38de799a,"In natural language learning, pre-trained language models (PLM) can acquire rich knowledge and concepts from rich corpora, making it possible to use PLM-based models for knowledge graph completion (KGC) tasks. However, in previous research, when applying pre-trained models to knowledge graph completion tasks, two main challenges persist: (1) Existing knowledge graph completion models are typically evaluated based on the closed-world assumption(CWA), thus lacking evaluation methods suitable for the open-world assumption(OWA), which constitutes a significant challenge in the current field of knowledge graph completion. (2) Extracting useful information, reducing noise, and providing clear interpretability for extracting effective information from the extensive prior knowledge embedded in pre-trained language models is also a crucial issue. Although the loss function can reduce noise to a certain extent, from the perspective of information theory, only relying on the loss function has a limited effect on noise reduction, and the model needs more professional tools to reduce noise and reduce the impact of irrelevant information on model performance. To address the aforementioned challenges, we propose a dual confrontation learning model based on the variational information bottleneck method. This model restricts information flow and feature selection from the perspective of information theory to reduce noise and enhance model performance while providing clear interpretability for this process. Based on extensive experiments and comprehensive evaluations conducted under both closed-world and open-world assumptions, this model successfully extracts valuable knowledge from pre-trained language models to accomplish KGC tasks. Simultaneously, it minimizes noise, removes non-robust features, enhances model reliability, and optimizes model performance. More importantly, we offer a strong interpretability for the process in which our model constrains information flow to reduce noise.  © 2023 IEEE.",Final,
Li Q.; Ji C.; Guo S.; Liang Z.; Wang L.; Li J.,"Li, Qian (57221243818); Ji, Cheng (57211948440); Guo, Shu (55515151500); Liang, Zhaoji (58659673200); Wang, Lihong (57007714500); Li, Jianxin (55720560100)",57221243818; 57211948440; 55515151500; 58659673200; 57007714500; 55720560100,Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183309574&partnerID=40&md5=5563e572a773581d49af2de77ffa4078,"Multi-Modal Entity Alignment (MMEA) is a critical task that aims to identify equivalent entity pairs across multi-modal knowledge graphs (MMKGs). However, this task faces challenges due to the presence of different types of information, including neighboring entities, multimodal attributes, and entity types. Directly incorporating the above information (e.g., concatenation or attention) can lead to an unaligned information space. To address these challenges, we propose a novel MMEA transformer, called MoAlign, that hierarchically introduces neighbor features, multi-modal attributes, and entity types to enhance the alignment task. Taking advantage of the transformer's ability to better integrate multiple information, we design a hierarchical modifiable self-attention block in a transformer encoder to preserve the unique semantics of different information. Furthermore, we design two entity-type prefix injection methods to integrate entity-type information using type prefixes, which help to restrict the global information of entities not present in the MMKGs. Our extensive experiments on benchmark datasets demonstrate that our approach outperforms strong competitors and achieves excellent entity alignment performance. © 2023 Association for Computational Linguistics.",Final,
Han Z.; Feng Y.; Sun M.,"Han, Zhen (57219766233); Feng, Yue (57202036487); Sun, Mingming (58846714500)",57219766233; 57202036487; 58846714500,A Graph-Guided Reasoning Approach for Open-ended Commonsense Question Answering,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184996663&partnerID=40&md5=9a6fde47a2b7c53b919ff4421a36c59e,"Recently, end-to-end trained models for multiple-choice commonsense question answering (QA) have delivered promising results. However, such question-answering systems cannot be directly applied in real-world scenarios where answer candidates are not provided. Hence, a new benchmark challenge set for open-ended commonsense reasoning (OpenCSR) has been recently released, which contains natural science questions without any predefined choices. On the OpenCSR challenge set, many questions require implicit multi-hop reasoning and have a large decision space, reflecting the difficult nature of this task. Existing work on OpenCSR sorely focuses on improving the retrieval process, which extracts relevant factual sentences from a textual knowledge base, leaving the important and non-trivial reasoning task outside the scope. In this work, we extend the scope to include a reasoner that constructs a question-dependent open knowledge graph based on retrieved supporting facts and employs a sequential subgraph reasoning process to predict the answer. The subgraph itself can be seen as a concise and compact graphical explanation of the prediction. Experiments on two OpenCSR datasets show that the proposed model achieves great performance on benchmark OpenCSR datasets. © 2023 Association for Computational Linguistics.",Final,
Jain P.; Lapata M.,"Jain, Parag (57214221258); Lapata, Mirella (55910108500)",57214221258; 55910108500,Conversational Semantic Parsing using Dynamic Context Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184795806&partnerID=40&md5=ecc07c1d471fc26c2ad599aef95c229a,"In this paper we consider the task of conversational semantic parsing over general purpose knowledge graphs (KGs) with millions of entities, and thousands of relation-types. We focus on models which are capable of interactively mapping user utterances into executable logical forms (e.g., SPARQL) in the context of the conversational history. Our key idea is to represent information about an utterance and its context via a subgraph which is created dynamically, i.e., the number of nodes varies per utterance. Rather than treating the subgraph as a sequence, we exploit its underlying structure and encode it with a graph neural network which further allows us to represent a large number of (unseen) nodes. Experimental results show that dynamic context modeling is superior to static approaches, delivering performance improvements across the board (i.e., for simple and complex questions). Our results further confirm that modeling the structure of context is better at processing discourse information, (i.e., at handling ellipsis and resolving coreference) and longer interactions. © 2023 Association for Computational Linguistics.",Final,
,,,AT4SSL 2023 - Proceedings of the 2nd International Workshop on Automatic Translation for Signed and Spoken Languages,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184582552&partnerID=40&md5=207976d1beee281eecea37d4ab1caf99,"The proceedings contain 6 papers. The topics discussed include: analyzing the potential of linguistic features for sign spotting: a look at approximative features; a linked data approach for linking and aligning sign language and spoken language data; an open-source gloss-based baseline for spoken to signed language translation; a new English-Dutch-NGT corpus for the hospitality domain; BSL-Hansard: a parallel, multimodal corpus of English and interpreted British sign language data from parliamentary proceedings; and towards accommodating gerunds within the sign language lexicon.",Final,
Xu N.; Liang Y.; Guo C.; Meng B.; Zhou X.; Hu Y.; Zhang B.,"Xu, Na (57200440339); Liang, Yanxiang (58763225400); Guo, Chaoran (58034168800); Meng, Bo (55174989500); Zhou, Xueqing (58034341300); Hu, Yuting (58034673500); Zhang, Bo (55619300152)",57200440339; 58763225400; 58034168800; 55174989500; 58034341300; 58034673500; 55619300152,Entity recognition in the field of coal mine construction safety based on a pre-training language model,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180710402&doi=10.1108%2fECAM-05-2023-0512&partnerID=40&md5=3133f3251561594bcb9446e5e19e68b5,"Purpose: Safety management plays an important part in coal mine construction. Due to complex data, the implementation of the construction safety knowledge scattered in standards poses a challenge. This paper aims to develop a knowledge extraction model to automatically and efficiently extract domain knowledge from unstructured texts. Design/methodology/approach: Bidirectional encoder representations from transformers (BERT)-bidirectional long short-term memory (BiLSTM)-conditional random field (CRF) method based on a pre-training language model was applied to carry out knowledge entity recognition in the field of coal mine construction safety in this paper. Firstly, 80 safety standards for coal mine construction were collected, sorted out and marked as a descriptive corpus. Then, the BERT pre-training language model was used to obtain dynamic word vectors. Finally, the BiLSTM-CRF model concluded the entity’s optimal tag sequence. Findings: Accordingly, 11,933 entities and 2,051 relationships in the standard specifications texts of this paper were identified and a language model suitable for coal mine construction safety management was proposed. The experiments showed that F1 values were all above 60% in nine types of entities such as security management. F1 value of this model was more than 60% for entity extraction. The model identified and extracted entities more accurately than conventional methods. Originality/value: This work completed the domain knowledge query and built a Q&A platform via entities and relationships identified by the standard specifications suitable for coal mines. This paper proposed a systematic framework for texts in coal mine construction safety to improve efficiency and accuracy of domain-specific entity extraction. In addition, the pretraining language model was also introduced into the coal mine construction safety to realize dynamic entity recognition, which provides technical support and theoretical reference for the optimization of safety management platforms. © 2023, Emerald Publishing Limited.",Article in press,
Chekalina V.; Razzhigaev A.; Panchenko A.; Sayapin A.; Frolov E.,"Chekalina, Viktoriia (57224213101); Razzhigaev, Anton (57219788402); Panchenko, Alexander (55632785700); Sayapin, Albert (57667752800); Frolov, Evgeny (57191519981)",57224213101; 57219788402; 55632785700; 57667752800; 57191519981,MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering,,-1,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147549506&partnerID=40&md5=cf4872af0ff7515f2f40f8ba633d4b0a,"Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG embedding contains concise data used in NLP tasks requiring implicit information about the real world. Furthermore, the size of KGs that may be useful in actual NLP assignments is enormous, and creating embedding over it has memory cost issues. We represent KG as a 3rd-order binary tensor and move beyond the standard CP decomposition (Hitchcock, 1927) by using a data-specific generalized version of it (Hong et al., 2020). The generalization of the standard CP-ALS algorithm allows obtaining optimization gradients without a backpropagation mechanism. It reduces the memory needed in training while providing computational benefits. We propose a MEKER, a memory-efficient KG embedding model, which yields SOTA-comparable performance on link prediction tasks and KG-based Question Answering. © 2022 Association for Computational Linguistics.",Final,
Zhang W.; Feng S.; Chen Z.; Lei Z.; Li J.; Luo M.,"Zhang, Wenqian (58373085100); Feng, Shangbin (57225889811); Chen, Zilong (57305046600); Lei, Zhenyu (57609586200); Li, Jundong (56186042700); Luo, Minnan (57189687190)",58373085100; 57225889811; 57305046600; 57609586200; 56186042700; 57189687190,KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media,,-1,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136156444&partnerID=40&md5=7cf1088d23c7dfa3ae8fc8fe07a17edc,"Political perspective detection has become an increasingly important task that can help combat echo chambers and political polarization. Previous approaches generally focus on leveraging textual content to identify stances, while they fail to reason with background knowledge or leverage the rich semantic and syntactic textual labels in news articles. In light of these limitations, we propose KCD, a political perspective detection approach to enable multi-hop knowledge reasoning and incorporate textual cues as paragraph-level labels. Specifically, we firstly generate random walks on external knowledge graphs and infuse them with news text representations. We then construct a heterogeneous information network to jointly model news content as well as semantic, syntactic and entity cues in news articles. Finally, we adopt relational graph neural networks for graph-level representation learning and conduct political perspective detection. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods on two benchmark datasets. We further examine the effect of knowledge walks and textual cues and how they contribute to our approach's data efficiency. © 2022 Association for Computational Linguistics.",Final,
Goyal N.; Sachdeva N.; Kumaraguru P.,"Goyal, Nidhi (57211288625); Sachdeva, Niharika (54891477600); Kumaraguru, Ponnurangam (14042000100)",57211288625; 54891477600; 14042000100,Spy the Lie: Fraudulent Jobs Detection in Recruitment Domain using Knowledge Graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113790625&doi=10.1007%2f978-3-030-82147-0_50&partnerID=40&md5=ecea09ca5c2446aae6b7215fae045b42,"Fraudulent jobs are an emerging threat over online recruitment platforms such as LinkedIn, Glassdoor. Fraudulent job postings affect the platform’s trustworthiness and have a negative impact on user experience. Therefore, these platforms need to detect and remove these fraudulent jobs. Generally, fraudulent job postings contain untenable facts about domain-specific entities such as mismatch in skills, industries, offered compensation, etc. However, existing approaches focus on studying writing styles, linguistics, and context-based features, and ignore the relationships among domain-specific entities. To bridge this gap, we propose an approach based on the Knowledge Graph (KG) of domain-specific entities to detect fraudulent jobs. In this paper, we present a multi-tier novel end-to-end framework called FRaudulent Jobs Detection (FRJD) Engine, which considers a) fact validation module using KGs, b) contextual module using deep neural networks c) meta-data module to capture the semantics of job postings. We conduct our experiments using a fact validation dataset containing 4 million facts extracted from job postings. Extensive evaluation shows that FRJD yields a 0.96 F1-score on the curated dataset of 157,880 job postings. Finally, we provide insights on the performance of different fact-checking algorithms on recruitment domain datasets. © 2021, Springer Nature Switzerland AG.",Final,
Chen W.; Chen X.; Xiong S.,"Chen, Wei (57231617800); Chen, Xiaoying (57208188277); Xiong, Shengwu (57203905556)",57231617800; 57208188277; 57203905556,Global Entity Alignment with Gated Latent Space Neighborhood Aggregation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113479697&doi=10.1007%2f978-3-030-84186-7_25&partnerID=40&md5=59a5fdf6b55011d2fc11060ff1cf2ae9,"Existing entity alignment models mainly use the topology structure of the original knowledge graph and have achieved promising performance. However, they are still challenged by the heterogeneous topological neighborhood structures, which could cause the models to produce different representations of counterpart entities. In the paper, we propose a global entity alignment model with gated latent space neighborhood aggregation (LatsEA) to address this challenge. Latent space neighborhood is formed by calculating the similarity between the entity embeddings, it can introduce long-range neighbors to expand the topological neighborhood and reconcile the heterogeneous neighborhood structures. Meanwhile, it uses vanilla GCN to aggregate the topological neighborhood and latent space neighborhood respectively. Then, it uses an average gating mechanism to aggregate topological neighborhood information and latent space neighborhood information of the central entity. In order to further consider the interdependence between entity alignment decisions, we propose a global entity alignment strategy, i.e., formulate entity alignment as the maximum bipartite matching problem, which is effectively solved by Hungarian algorithm. Our experiments with ablation studies on three real-world entity alignment datasets prove the effectiveness of the proposed model. Latent space neighborhood information and global entity alignment decisions both contributes to the entity alignment performance improvement. © 2021, Springer Nature Switzerland AG.",Final,
,,,CEUR Workshop Proceedings,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925258874&partnerID=40&md5=6e11777bf0367e274f32bee7896c8f41,The proceedings contain 9 papers. The topics discussed include: crossing the chasm with semantic technologies; CROCUS: cluster-based ontology data cleansing; IRIS: a protégé plug-in to extract and serialize product attribute name-value pairs; ontology design patterns: adoption challenges and solutions; mapping representation based on meta-data and SPIN for localization workflows; WaSABi 2014: breakout brainstorming session summary; a linked data approach to sentiment and emotion analysis of Twitter in the financial domain; analyzing stock market fraud cases using a linguistics-based text mining approach; predicting the impact of central bank communications on financial market investors' interest rate expectations; predicting stocks returns correlations based on unstructured data sources; and crossing the chasm with semantic technologies.,Final,
Zee K.; Kuncak V.; Rinard M.C.,"Zee, Karen (23011099300); Kuncak, Viktor (6602919120); Rinard, Martin C. (7003321126)",23011099300; 6602919120; 7003321126,An integrated proof language for imperative programs,,-1,-1,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949167460&doi=10.1145%2f1542476.1542514&partnerID=40&md5=935348ec64492da5e19709bcb5ecb2a6,"We present an integrated proof language for guiding the actions of multiple reasoning systems as they work together to prove complex correctness properties of imperative programs. The language operates in the context of a program verification system that uses multiple reasoning systems to discharge generated proof obligations. It is designed to 1) enable developers to resolve key choice points in complex program correctness proofs, thereby enabling automated reasoning systems to successfully prove the desired correctness properties; 2) allow developers to identify key lemmas for the reasoning systems to prove, thereby guiding the reasoning systems to find an effective proof decomposition; 3) enable multiple reasoning systems to work together productively to prove a single correctness property by providing a mechanism that developers can use to divide the property into lemmas, each of which is suitable for a different reasoning system; and 4) enable developers to identify specific lemmas that the reasoning systems should use when attempting to prove other lemmas or correctness properties, thereby appropriately confining the search space so that the reasoning systems can find a proof in an acceptable amount of time. The language includes a rich set of declarative proof constructs that enables developers to direct the reasoning systems as little or as much as they desire. Because the declarative proof statements are embedded into the program as specialized comments, they also serve as verified documentation and are a natural extension of the assertion mechanism found in most program verification systems. We have implemented our integrated proof language in the context of a program verification system for Java and used the resulting system to verify a collection of linked data structure implementations. Our experience indicates that our proof language makes it possible to successfully prove complex program correctness properties that are otherwise beyond the reach of automated reasoning systems. Copyright © 2009 ACM.",Final,All Open Access; Green Open Access
Lin S.; Yuan Y.; Jin C.; Pan Y.,"Lin, Shiyong (58259516500); Yuan, Yiping (57206472223); Jin, Carol (58258373600); Pan, Yi (58601394500)",58259516500; 57206472223; 58258373600; 58601394500,Skill Graph Construction From Semantic Understanding,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159640603&doi=10.1145%2f3543873.3587667&partnerID=40&md5=d267435bba1c0b1e2e5e7e06ae12c00e,"LinkedIn is building a skill graph to power a skill-first talent marketplace. Constructing a skill graph from a flat list is not an trivial task, especially by human curation. In this paper, we leverage the pre-trained large language model BERT to achieve this through semantic understanding on synthetically generated texts as training data. We automatically create positive and negative labels from the seed skill graph. The training data are encoded by pre-trained language models into embeddings and they are consumed by the downstream classification module to classify the relationships between skill pairs.  © 2023 ACM.",Final,
Liu J.; Mao Q.; Lin C.; Song Y.; Li J.,"Liu, Junnan (57224832512); Mao, Qianren (57207455023); Lin, Chenghua (35322970500); Song, Yangqiu (58787931000); Li, Jianxin (55720560100)",57224832512; 57207455023; 35322970500; 58787931000; 55720560100,LATENTLOGIC: Learning Logic Rules in Latent Space over Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290048&partnerID=40&md5=23394595e30e81a6dedd9bc91815c887,"Learning logic rules for knowledge graph reasoning is essential as such rules provide interpretable explanations for reasoning and can be generalized to different domains. However, existing methods often face challenges such as searching in a vast search space (e.g., enumeration of relational paths or multiplication of high-dimensional matrices) and inefficient optimization (e.g., techniques based on reinforcement learning or EM algorithm). To address these limitations, this paper proposes a novel framework called LATENTLOGIC to efficiently mine logic rules by controllable generation in the latent space. Specifically, to map the discrete relational paths into the latent space, we leverage a pre-trained VAE and employ a discriminator to establish an energy-based distribution. Additionally, we incorporate a sampler based on ordinary differential equations, enabling the efficient generation of logic rules in our approach. Extensive experiments on benchmark datasets demonstrate the effectiveness and efficiency of our proposed method. © 2023 Association for Computational Linguistics.",Final,
Qi C.; Li B.; Hui B.; Wang B.; Li J.; Wu J.; Laili Y.,"Qi, Chengwen (58664644600); Li, Bowen (57551120100); Hui, Binyuan (57215133979); Wang, Bailin (57205546448); Li, Jinyang (57810421200); Wu, Jinwang (58664644700); Laili, Yuanjun (35220331000)",58664644600; 57551120100; 57215133979; 57205546448; 57810421200; 58664644700; 35220331000,An Investigation of LLMs' Inefficacy in Understanding Converse Relations,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182435991&partnerID=40&md5=0039cab34f070f2cde3c6d1a32d220dd,"Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, a natural question rises that do LLMs really understand the structured semantics of formal languages. In this paper, we investigate this problem on a special case, converse binary relation. We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets. Our ConvRe features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs' ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three popular LLM families and have observed various scaling trends. The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark. © 2023 Association for Computational Linguistics.",Final,
Atzeni M.; Plekhanov M.; Dreyer F.A.; Kassner N.; Merello S.; Martin L.; Cancedda N.,"Atzeni, Mattia (57195407967); Plekhanov, Mikhail (57223757336); Dreyer, Frédéric A. (58342387200); Kassner, Nora (57219632761); Merello, Simone (16064271600); Martin, Louis (57685148600); Cancedda, Nicola (58714162700)",57195407967; 57223757336; 58342387200; 57219632761; 16064271600; 57685148600; 58714162700,Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184800340&partnerID=40&md5=51771f7d7fc6b84e46e77ae9b43ca89f,"Entity linking methods based on dense retrieval are widely adopted in large-scale applications for their efficiency, but they can fall short of generative models, as they are sensitive to the structure of the embedding space. To address this issue, this paper introduces DUCK, an approach to infusing structural information in the space of entity representations, using prior knowledge of entity types. Inspired by duck typing in programming languages, we define the type of an entity based on its relations with other entities in a knowledge graph. Then, porting the concept of box embeddings to spherical polar coordinates, we represent relations as boxes on the hypersphere. We optimize the model to place entities inside the boxes corresponding to their relations, thereby clustering together entities of similar type. Our experiments show that our method sets new state-of-the-art results on standard entity-disambiguation benchmarks. It improves the performance of the model by up to 7.9 F1 points, outperforms other type-aware approaches, and matches the results of generative models with 18 times more parameters. © 2023 Association for Computational Linguistics.",Final,
Ye H.; Gui H.; Xu X.; Chen X.; Chen H.; Zhang N.,"Ye, Hongbin (57221148832); Gui, Honghao (58312582900); Xu, Xin (57421213500); Chen, Xi (57218347633); Chen, Huajun (35268022500); Zhang, Ningyu (55923601900)",57221148832; 58312582900; 57421213500; 57218347633; 35268022500; 55923601900,Schema-adaptable Knowledge Graph Construction,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183304801&partnerID=40&md5=9f7bce789c05ea62364f689e5a99b094,"Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schema-adaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We further propose a simple yet effective baseline dubbed ADAKGC, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that ADAKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community. © 2023 Association for Computational Linguistics.",Final,
Sheng J.,"Sheng, Jinghua (58847616900)",58847616900,An Augmentable Domain-specific Models for Financial Analysis,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183315038&doi=10.1109%2fCISP-BMEI60920.2023.10373245&partnerID=40&md5=56b43bcf9f0e6b428eadab39e6baf2ec,"Large-scale language models such as GPT-4 have revolutionized data analysis and interpretation by generating human-like text, automating insights, and detecting data errors. Large-scale language models have been applied in various fields and played an important role in many aspects. Large language models can also perform financial and technical analysis by cleaning data, generating synthetic data, handling bias, and supporting natural language queries. This paper proposes a language model that integrates multimodal data with external knowledge bases and domain-specific data, enhancing its reasoning ability by extending domain-specific data. Reduce hallucinations and fine-tune domain-specific data by incorporating external knowledge bases to deepen model understanding of industry-specific language, concepts, and context. And technologies such as knowledge graph, attention mechanism, cross-modal embedding and federated collaborative training are used to deal with the challenges of different structures and semantics of multi-modal data. The model also employs a feedback loop mechanism to allow the model to adapt to changing conditions, such as changing languages or new domain information. Experimental results show that the proposed model has a preliminary domain-specific ability to analyze and predict multimodal financial and technical data. © 2023 IEEE.",Final,
Lee D.-H.; Ahrabian K.; Jin W.; Morstatter F.; Pujara J.,"Lee, Dong-Ho (57216623177); Ahrabian, Kian (57204606639); Jin, Woojeong (57193517627); Morstatter, Fred (39061777700); Pujara, Jay (52664421900)",57216623177; 57204606639; 57193517627; 39061777700; 52664421900,Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182442697&partnerID=40&md5=8ef89e61d4e4e7a0830d480e90a24824,"Temporal knowledge graph (TKG) forecasting benchmarks challenge models to predict future facts using knowledge of past facts. In this paper, we develop an approach to use in-context learning (ICL) with large language models (LLMs) for TKG forecasting. Our extensive evaluation compares diverse baselines, including both simple heuristics and state-of-the-art (SOTA) supervised models, against pre-trained LLMs across several popular benchmarks and experimental settings. We observe that naive LLMs perform on par with SOTA models, which employ carefully designed architectures and supervised training for the forecasting task, falling within the (-3.6%, +1.5%) Hits@1 margin relative to the median performance. To better understand the strengths of LLMs for forecasting, we explore different approaches for selecting historical facts, constructing prompts, controlling information propagation, and parsing outputs into a probability distribution. A surprising finding from our experiments is that LLM performance endures (±0.4% Hit@1) even when semantic information is removed by mapping entities/relations to arbitrary numbers, suggesting that prior semantic knowledge is unnecessary; rather, LLMs can leverage the symbolic patterns in the context to achieve such a strong performance. Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond frequency and recency biases. ©2023 Association for Computational Linguistics.",Final,
Chen Q.; Wu W.; Li S.,"Chen, Qinyu (57327436400); Wu, Wenhao (57223893746); Li, Sujian (53984734300)",57327436400; 57223893746; 53984734300,Exploring In-Context Learning for Knowledge Grounded Dialog Generation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183299642&partnerID=40&md5=7c2398300c313461cb2287d9f8bf1820,"Large neural-based dialog generation models have been applied in many real-life scenarios, yet they are prone to hallucination and tend to produce factually inaccurate outputs which raise great concerns. To alleviate this problem, we propose a plug-and-play retrieval-based framework IKA, which leverages in-context learning and retrieval techniques to enhance LLMs on knowledge grounded dialog generation. We design thorough experiments on a large-scale knowledge graph with 1M+ facts (Moon et al., 2019) to investigate the effectiveness and generalization of our framework. Experiments show that our method surpasses previous training-based SOTA by a large margin, specifically 46.67% in BLEU4, 26.01% in ROUGE-L, 122.90% in BARTScore and 30.50% in Entity Coverage F1. Further analysis shows promising abilities of LLMs to perform knowledge-intensive tasks, which is previously considered weak and understudied. © 2023 Association for Computational Linguistics.",Final,
Taffa T.A.; Usbeck R.,"Taffa, Tilahun Abedissa (58749762200); Usbeck, Ricardo (43661711000)",58749762200; 43661711000,Leveraging LLMs in Scholarly Knowledge Graph Question Answering,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546080&partnerID=40&md5=ccf7f534c71dcf553c48378d6818a7ee,"This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner. The model initially identifies the top-n similar training questions related to a given test question via a BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the top-n similar question-SPARQL pairs as an example and the test question creates a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of the Scholarly-QALD-23 challenge benchmarks. © 2023 CEUR-WS. All rights reserved.",Final,
Roush A.; Mezzetti D.,"Roush, Allen (57221318463); Mezzetti, David (58718265400)",57221318463; 58718265400,DebateKG - Automatic Policy Debate Case Creation with Semantic Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184998972&partnerID=40&md5=8fef6e6bff434e52ace8f0fa979df6a3,"Recent work within the Argument Mining community has shown the applicability of Natural Language Processing systems for solving problems found within competitive debate. One of the most important tasks within competitive debate is for debaters to create high quality debate cases. We show that effective debate cases can be constructed using constrained shortest path traversals on Argumentative Semantic Knowledge Graphs. We study this potential in the context of a type of American Competitive Debate, called “Policy Debate”, which already has a large scale dataset targeting it called “DebateSum”. We significantly improve upon DebateSum by introducing 53180 new examples, as well as further useful metadata for every example, to the dataset. We leverage the txtai semantic search and knowledge graph toolchain to produce and contribute 9 semantic knowledge graphs built on this dataset. We create a unique method for evaluating which knowledge graphs are better in the context of producing policy debate cases. A demo which automatically generates debate cases, along with all other code and the Knowledge Graphs, are open-sourced and made available to the public here: https://huggingface.co/spaces/Hellisotherpeople/DebateKG. © 2023 Association for Computational Linguistics.",Final,
Yang C.; Zhang P.; Qiao W.; Gao H.; Zhao J.,"Yang, Chang (58882572400); Zhang, Peng (55547109921); Qiao, Wenbo (58882572500); Gao, Hui (57218710755); Zhao, Jiaming (58882284200)",58882572400; 55547109921; 58882572500; 57218710755; 58882284200,Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184816372&partnerID=40&md5=c45de9d7b294ca72d6a528027d39a7e2,"In the era of widespread dissemination through social media, the task of rumor detection plays a pivotal role in establishing a trustworthy and reliable information environment. Nonetheless, existing research on rumor detection confronts several challenges: the limited expressive power of text encoding sequences, difficulties in domain knowledge coverage and effective information extraction with knowledge graph-based methods, and insufficient mining of semantic structural information. To address these issues, we propose a Crowd Intelligence and ChatGPT-Assisted Network(CICAN) for rumor classification. Specifically, we present a crowd intelligence-based semantic feature learning module to capture textual content's sequential and hierarchical features. Then, we design a knowledge-based semantic structural mining module that leverages ChatGPT for knowledge enhancement. Finally, we construct an entity-sentence heterogeneous graph and design Entity-Aware Heterogeneous Attention to integrate diverse structural information meta-paths effectively. Experimental results demonstrate that CICAN achieves performance improvement in rumor detection tasks, validating the effectiveness and rationality of using large language models as auxiliary tools. © 2023 Association for Computational Linguistics.",Final,
Du H.; Huang Q.; Li C.; Zhang C.; Li Y.; Zhao D.,"Du, Haowei (57315089800); Huang, Quzhe (57224976126); Li, Chen (58604348700); Zhang, Chen (57225061047); Li, Yang (57219793158); Zhao, Dongyan (55387416000)",57315089800; 57224976126; 58604348700; 57225061047; 57219793158; 55387416000,Relation-Aware Question Answering for Heterogeneous Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183295202&partnerID=40&md5=87f02780dfc4f14ee9ef47294261973b,"Multi-hop Knowledge Base Question Answering(KBQA) aims to find the answer entity in a knowledge graph (KG), which requires multiple steps of reasoning. Existing retrieval-based approaches solve this task by concentrating on the specific relation at different hops and predicting the intermediate entity within the reasoning path. During the reasoning process of these methods, the representation of relations are fixed but the initial relation representation may not be optimal. We claim they fail to utilize information from head-tail entities and the semantic connection between relations to enhance the current relation representation, which undermines the ability to capture information of relations in KGs. To address this issue, we construct a dual relation graph where each node denotes a relation in the original KG (primal entity graph) and edges are constructed between relations sharing same head or tail entities. Then we iteratively do primal entity graph reasoning; dual relation graph information propagation, and interaction between these two graphs. In this way, the interaction between entity and relation is enhanced, and we derive better entity and relation representations. Experiments on two public datasets, WebQSP and CWQ, show that our approach achieves a significant performance gain over the prior state-of-the-art. Our code is available on https://github.com/yanmenxue/RAH-KBQA. © 2023 Association for Computational Linguistics.",Final,
Hwang E.; Thost V.; Shwartz V.; Ma T.,"Hwang, EunJeong (58315144400); Thost, Veronika (55821112400); Shwartz, Vered (57193241999); Ma, Tengfei (57194786822)",58315144400; 55821112400; 57193241999; 57194786822,Knowledge Graph Compression Enhances Diverse Commonsense Generation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184817508&partnerID=40&md5=1afad3734676c3b44a48d5b0e29a865d,"Generating commonsense explanations requires reasoning about commonsense knowledge beyond what is explicitly mentioned in the context. Existing models use commonsense knowledge graphs such as ConceptNet to extract a subgraph of relevant knowledge pertaining to concepts in the input. However, due to the large coverage and, consequently, vast scale of ConceptNet, the extracted subgraphs may contain loosely related, redundant and irrelevant information, which can introduce noise into the model. We propose to address this by applying a differentiable graph compression algorithm that focuses on more salient and relevant knowledge for the task. The compressed subgraphs yield considerably more diverse outputs when incorporated into models for the tasks of generating commonsense and abductive explanations. Moreover, our model achieves better quality-diversity tradeoff than a large language model with 100 times the number of parameters. Our generic approach can be applied to additional NLP tasks that can benefit from incorporating external knowledge. ©2023 Association for Computational Linguistics.",Final,
Wehnert S.; Fiorelli M.; Picca D.; De Luca E.W.; Stellato A.,"Wehnert, Sabine (57210978233); Fiorelli, Manuel (55389632500); Picca, Davide (34772021800); De Luca, Ernesto William (14026533600); Stellato, Armando (23393619500)",57210978233; 55389632500; 34772021800; 14026533600; 23393619500,Summary of the Workshop Legal Information Retrieval meets Artificial Intelligence (LIRAI’23),,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180760956&partnerID=40&md5=83d83486982ba7052487ffba340cf4d6,"This paper summarizes the workshop Legal Information Retrieval meets Artificial Intelligence (LIRAI’23), held in Rome, Italy and co-located with the ACM Hypertext conference. In this workshop, 6 publications on the intersection between Legal Information Retrieval and Artificial Intelligence were presented. Enrico Francesconi held a keynote on Profiles of Knowledge Representation and Reasoning for Legal Information Retrieval and Compliance Checking. Overall, the workshop fostered fruitful discussions in various current research areas and challenges, such as the lack of datasets in the legal domain that are dedicated to the evaluation of explainability, the use of Semantic Web together with state-of-the-art transformer architectures, as well as the use of Large Language Models in the legal domain. © 2023 Copyright for this paper by its authors.",Final,
Lu Y.-H.; Wang C.-D.; Lai P.-Y.; Lai J.-H.,"Lu, Yi-Hong (58894539700); Wang, Chang-Dong (55157826700); Lai, Pei-Yuan (58096804400); Lai, Jian-Huang (57216303737)",58894539700; 55157826700; 58096804400; 57216303737,PKAT: Pre-training in Collaborative Knowledge Graph Attention Network for Recommendation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185392764&doi=10.1109%2fICDM58522.2023.00054&partnerID=40&md5=b2078791519d1a14d99c2d70cd4ce3b2,"With the rapid growth of online platforms and the abundance of available information, personalized recommender systems have become essential for assisting users in discovering relevant and interesting content. Among the various methods, knowledge-aware recommendation model has achieved notable success by leveraging the rich semantic information encoded in knowledge graphs. However, it overlooks the fact that users' historical click sequences can better reflect their preferences within a period of time, thus imposing certain limitations on the recommendation performance. On the other hand, the application of pre-trained language models in recommender systems has demonstrated increasingly significant potential, as they can capture sequential patterns and dependencies within users' historical click sequences and effectively capture contextual information in user-item interactions. To this end, we propose a hybrid recommendation model that leverages Pre-training in the collaborative Knowledge graph Attention neTwork (PKAT), to extract both the high-order connectivity information in collaborative knowledge graphs and the contextual information in users' historical click sequences captured by Bidirectional Encoder Representations from Transformers (BERT). The collaborative knowledge graph attention network enables the model to effectively capture the intricate relationships between users, items, and knowledge entities, thus enhancing the representation learning process. Furthermore, what sets PKAT apart from other state-of-the-art knowledge-aware recommendation methods is the incorporation of the BERT language model. This integration allows PKAT to capture the contextual sequence information of user behavior, enabling it to generate more accurate and personalized recommendations. Extensive experiments are conducted on multiple benchmark datasets. And the results demonstrate that our PKAT model outperforms several state-of-the-art baselines.  © 2023 IEEE.",Final,
Xu Y.; He S.; Wang C.; Cai L.; Liu K.; Zhao J.,"Xu, Yao (36697356200); He, Shizhu (56021680600); Wang, Cunguang (58680456700); Cai, Li (55145480500); Liu, Kang (55729555700); Zhao, Jun (57190004147)",36697356200; 56021680600; 58680456700; 55145480500; 55729555700; 57190004147,Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183311585&partnerID=40&md5=d0b46cea1d2840c7bf5cc516305c944c,"Complex Query Answering (CQA) is a challenge task of Knowledge Graph (KG). Due to the incompleteness of KGs, query embedding (QE) methods have been proposed to encode queries and entities into the same embedding space, and treat logical operators as neural set operators to obtain answers. However, these methods train KG embeddings and neural set operators concurrently on both simple (one-hop) and complex (multi-hop and logical) queries, which causes performance degradation on simple queries and low training efficiency. In this paper, we propose Query to Triple (Q2T), a novel approach that decouples the training for simple and complex queries. Q2T divides the training into two stages: (1) Pre-training a neural link predictor on simple queries to predict tail entities based on the head entity and relation. (2) Training a query encoder on complex queries to encode diverse complex queries into a unified triple form that can be efficiently solved by the pretrained neural link predictor. Our proposed Q2T is not only efficient to train, but also modular, thus easily adaptable to various neural link predictors that have been studied well. Extensive experiments demonstrate that, even without explicit modeling for neural set operators, Q2T still achieves state-of-the-art performance on diverse complex queries over three public benchmarks. © 2023 Association for Computational Linguistics.",Final,
Wang K.; Han S.C.; Poon J.,"Wang, Kunze (57221155018); Han, Soyeon Caren (55361191400); Poon, Josiah (7005903715)",57221155018; 55361191400; 7005903715,Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183303607&partnerID=40&md5=93886210a3d9dacf1ceabf4e0677a42b,"Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting aims to predict the missing entity from a fact in the future, posing a challenge that aligns more closely with real-world prediction problems. Existing research mostly encodes entities and relations using sequential graph neural networks applied to recent snapshots. However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction. Additionally, we introduce a two-phase forward propagation method to prevent information leakage. Through the evaluation on six TKGC (extrapolation) datasets, we demonstrate that our model outperforms all eight recent state-of-the-art models by a significant margin. © 2023 Association for Computational Linguistics.",Final,
Chepurova A.; Bulatov A.; Kuratov Y.; Burtsev M.,"Chepurova, Alla (57491141600); Bulatov, Aydar (57814426800); Kuratov, Yuri (57207878253); Burtsev, Mikhail (6603556673)",57491141600; 57814426800; 57207878253; 6603556673,Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183297590&partnerID=40&md5=ca9870c4c210f39b83d1d0cda1c8586b,"Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection. © 2023 Association for Computational Linguistics.",Final,
Kosten C.; Cudre-Mauroux P.; Stockinger K.,"Kosten, Catherine (57223722201); Cudre-Mauroux, Philippe (22333444100); Stockinger, Kurt (6603748288)",57223722201; 22333444100; 6603748288,Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184975243&doi=10.1109%2fBigData59044.2023.10386182&partnerID=40&md5=ef56e1d7fe443d48f25523a312f555a4,"With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL -a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research.  © 2023 IEEE.",Final,All Open Access; Green Open Access
Pliukhin D.; Radyush D.; Kovriguina L.; Mouromtsev D.,"Pliukhin, Dmitrii (57223279213); Radyush, Daniil (58234958500); Kovriguina, Liubov (56119059000); Mouromtsev, Dmitry (55575780100)",57223279213; 58234958500; 56119059000; 55575780100,Improving Subgraph Extraction Algorithms for One-Shot SPARQL Query Generation with Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180551320&partnerID=40&md5=d3d62c78b1b2b37274a9e88314393de0,"Question answering over scholarly knowledge graphs involves many challenges: complex graph patterns, long-tail distributed data, revision and evolution of the scholarly ontologies, and knowledge graphs incompleteness due to constant research dynamics. In this work, we present an LLM-based approach for SPARQL query generation over Open Research Knowledge Graph (ORKG) for the ISWC SciQA Challenge. Our approach proposes a couple of improvements to the recently published SPARQLGEN approach, that performs one-shot SPARQL query generation by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. Similar to SPARQLGEN, we include heterogeneous data sources in the SPARQL generation prompt: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query. In the current work, we focused on designing subgraph extraction algorithms, that are close to real-life scenarios of generative KGQA, and replaced the random choice of example question-query pair with similarity scoring. © 2023 CEUR-WS. All rights reserved.",Final,
Hou Z.; Jin X.; Li Z.; Bai L.; Guan S.; Zeng Y.; Guo J.; Cheng X.,"Hou, Zhongni (57437579600); Jin, Xiaolong (16417309500); Li, Zixuan (57201739412); Bai, Long (57219876463); Guan, Saiping (57196080482); Zeng, Yutao (57210602016); Guo, Jiafeng (24174196100); Cheng, Xueqi (55855927900)",57437579600; 16417309500; 57201739412; 57219876463; 57196080482; 57210602016; 24174196100; 55855927900,Temporal Knowledge Graph Reasoning Based on N-tuple Modeling,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183308353&partnerID=40&md5=63ee241afbe07e6127833f1963fcb03d,"Reasoning over Temporal Knowledge Graphs (TKGs) that predicts temporal facts (e.g., events) in the future is crucial for many applications. The temporal facts in existing TKGs only contain their core entities (i.e., the entities playing core roles therein) and formulate them as quadruples, i.e., (subject entity, predicate, object entity, timestamp). This formulation oversimplifies temporal facts and inevitably causes information loss. Therefore, we propose to describe a temporal fact more accurately as an n-tuple, containing not only its predicate and core entities, but also its auxiliary entities, as well as the roles of all entities. By so doing, TKGs are augmented to N-tuple Temporal Knowledge Graphs (N-TKGs). To conduct reasoning over N-TKGs, we further propose N-tuple Evolutional Network (NE-Net). It recurrently learns the evolutional representations of entities and predicates in temporal facts at different timestamps in the history via modeling the relations among those entities and predicates. Based on the learned representations, reasoning tasks at future timestamps can be realized via task-specific decoders. Experiment results on two newly built datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net. © 2023 Association for Computational Linguistics.",Final,
Arnaout H.; Razniewski S.,"Arnaout, Hiba (57192645741); Razniewski, Simon (37117560500)",57192645741; 37117560500,Can large language models generate salient negative statements?,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179558782&partnerID=40&md5=8dc78d7f3aa74c3f6097d131906d405f,"We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning. © 2023 CEUR-WS. All rights reserved.",Final,
Jiang L.; Yan X.; Usbeck R.,"Jiang, Longquan (57423404600); Yan, Xi (57423464800); Usbeck, Ricardo (43661711000)",57423404600; 57423464800; 43661711000,A Structure and Content Prompt-based Method for Knowledge Graph Question Answering over Scholarly Data,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180545725&partnerID=40&md5=f5ab3853af26941c54e4799988381362,"Answering scholarly questions is challenging without the help of query-based systems. Thus, we develop a divide-and-conquer approach based on a Large Language Model (LLM) for scholarly Knowledge Graph (KG) Question Answering (QA). Our system integrates the KG ontology into the LLM prompts and leverages a hybrid prompt learning strategy with both query structure and content. Our experiments suggest that given an ontology of a specific KG, LLMs are capable of automatically choosing the corresponding classes or predicates required to generate a target SPARQL query from a natural language question. Our approach shows state-of-the-art results over one scholarly KGQA dataset, namely sciQA [1]. © 2023 CEUR-WS. All rights reserved.",Final,
Li X.; Qin Y.; Zhu R.; Lin T.; Fan Y.; Kang Y.; Song K.; Zhao F.; Sun C.; Tang H.; Liu X.,"Li, Xurui (57196078782); Qin, Yue (57299411000); Zhu, Rui (57218108189); Lin, Tianqianjing (58881939500); Fan, Yongming (58882371100); Kang, Yangyang (55486938100); Song, Kaisong (55131158400); Zhao, Fubang (57224919264); Sun, Changlong (57209225440); Tang, Haixu (10043216700); Liu, Xiaozhong (55218252500)",57196078782; 57299411000; 57218108189; 58881939500; 58882371100; 55486938100; 55131158400; 57224919264; 57209225440; 10043216700; 55218252500,STINMatch: Semi-Supervised Semantic-Topological Iteration Network for Financial Risk Detection via News Label Diffusion,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184806981&partnerID=40&md5=e33f5a3c46f13280206d097dfb4cd574,"Commercial news provide rich semantics and timely information for automated financial risk detection. However, unaffordable large-scale annotation as well as training data sparseness barrier the full exploitation of commercial news in risk detection. To address this problem, we propose a semi-supervised Semantic-Topological Iteration Network, STINMatch, along with a News-Enterprise Knowledge Graph (NEKG) to endorse the risk detection enhancement. The proposed model incorporates a label-correlation matrix and interactive consistency regularization techniques into the iterative joint learning framework of text and graph modules. The carefully designed framework takes full advantage of the labeled and unlabeled data as well as their interrelations, enabling deep label diffusion coordination between article-level semantics and label correlations following the topological structure. Extensive experiments demonstrate the superior effectiveness and generalization ability of STINMatch. © 2023 Association for Computational Linguistics.",Final,
Jiang J.; Zhou K.; Zhao W.X.; Li Y.; Wen J.-R.,"Jiang, Jinhao (57222071901); Zhou, Kun (57212192211); Zhao, Wayne Xin (58122248100); Li, Yaliang (56273199400); Wen, Ji-Rong (7402697777)",57222071901; 57212192211; 58122248100; 56273199400; 7402697777,ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184801972&partnerID=40&md5=e28bc8ab5c1adcb42b9b540cf9ae3265,"Question Answering over Knowledge Graph (KGQA) aims to seek answer entities for the natural language question from a large-scale Knowledge Graph (KG). To better perform reasoning on KG, recent work typically adopts a pre-trained language model (PLM) to model the question, and a graph neural network (GNN) based module to perform multi-hop reasoning on the KG. Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions. To solve it, we aim to simplify the above two-module approach, and develop a more capable PLM that can directly support subgraph reasoning for KGQA, namely ReasoningLM. In our approach, we propose a subgraph-aware self-attention mechanism to imitate the GNN for performing structured reasoning; and also adopt an adaptation tuning strategy to adapt the model parameters with 20,000 subgraphs with synthesized questions. After adaptation, the PLM can be parameter-efficient fine-tuned on downstream tasks. Experiments show that ReasoningLM surpasses state-of-the-art models by a large margin, even with fewer updated parameters and less training data. Our codes and data are publicly available at https://github.com/RUCAIBox/ReasoningLM. ©2023 Association for Computational Linguistics.",Final,
Li Y.; Ding K.; Lee K.,"Li, Yichuan (57217298234); Ding, Kaize (57206477217); Lee, Kyumin (55587884200)",57217298234; 57206477217; 55587884200,Grenade: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180341611&partnerID=40&md5=9d17405f99fa995434a1e98d94ce8ae4,"Self-supervised representation learning on text-attributed graphs, which aims to create expressive and generalizable representations for various downstream tasks, has received increasing research attention lately. However, existing methods either struggle to capture the full extent of structural context information or rely on task-specific training labels, which largely hampers their effectiveness and generalizability in practice. To solve the problem of self-supervised representation learning on text-attributed graphs, we develop a novel GraphCentric Language model - Grenade. Specifically, Grenade exploits the synergistic effect of both pre-trained language model and graph neural network by optimizing with two specialized self-supervised learning algorithms: graph-centric contrastive learning and graph-centric knowledge alignment. The proposed graph-centric self-supervised learning algorithms effectively help Grenade to capture informative textual semantics as well as structural context information on text-attributed graphs. Through extensive experiments, Grenade shows its superiority over state-of-the-art methods. Implementation is available at https://github.com/bigheiniu/GRENADE. © 2023 Association for Computational Linguistics.",Final,
Wang Z.,"Wang, Zhu (57203515076)",57203515076,AMD Results for OAEI 2023,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180779638&partnerID=40&md5=5de524163e7e345de6e2c5ebd3bde262,"AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2023 Copyright for this paper by its authors.",Final,
Cheng L.; Hosseini M.J.; Steedman M.,"Cheng, Liang (58316675200); Hosseini, Mohammad Javad (57216617622); Steedman, Mark (6602901918)",58316675200; 57216617622; 6602901918,Complementary Roles of Inference and Language Models in QA,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184997143&partnerID=40&md5=c3f314cab000d6e14375f9dec0cbe581,"Answering open-domain questions through unsupervised methods poses challenges for both machine-reading (MR) and language model (LM)-based approaches. The MR-based approach suffers from sparsity issues in extracted knowledge graphs (KGs), while the performance of the LM-based approach significantly depends on the quality of the retrieved context for questions. In this paper, we compare these approaches and propose a novel methodology that leverages directional predicate entailment (inference) to address these limitations. We use entailment graphs (EGs), with natural language predicates as nodes and entailment as edges, to enhance parsed KGs by inferring unseen assertions, effectively mitigating the sparsity problem in the MR-based approach. We also show EGs improve context retrieval for the LM-based approach. Additionally, we present a Boolean QA task, demonstrating that EGs exhibit comparable directional inference capabilities to large language models (LLMs). Our results highlight the importance of inference in open-domain QA and the improvements brought by leveraging EGs. © 2023 Association for Computational Linguistics.",Final,
West P.; Le Bras R.; Sorensen T.; Lin B.Y.; Jiang L.; Lu X.; Chandu K.; Hessel J.; Baheti A.; Bhagavatula C.; Choi Y.,"West, Peter (57216690053); Le Bras, Ronan (37042388500); Sorensen, Taylor (57223710707); Lin, Bill Yuchen (57205548667); Jiang, Liwei (57209400459); Lu, Ximing (57222033823); Chandu, Khyathi (57195643170); Hessel, Jack (57190382287); Baheti, Ashutosh (57197640222); Bhagavatula, Chandra (57216430904); Choi, Yejin (36172231400)",57216690053; 37042388500; 57223710707; 57205548667; 57209400459; 57222033823; 57195643170; 57190382287; 57197640222; 57216430904; 36172231400,NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183298776&partnerID=40&md5=03ba1ac2f7521d5faf15961d403adc9c,"We present NOVACOMET, an open commonsense knowledge model, that combines the best aspects of knowledge models and general task models. Compared to previous knowledge models, NOVACOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, NOVACOMET explicitly centers knowledge, enabling superior performance for commonsense reasoning. NOVACOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NOVATOMIC, a publicly-released discrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NOVACOMET on NOVATOMIC by finetuning an open-source pretrained model. NOVACOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs. The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like Flan-T5 on a range of commonsense generation tasks. NOVACOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well. © 2023 Association for Computational Linguistics.",Final,
Zhong V.; Shi W.; Yih S.W.-T.; Zettlemoyer L.,"Zhong, Victor (57192160369); Shi, Weijia (57225007353); Yih, Scott Wen-Tau (57731717000); Zettlemoyer, Luke (57204370628)",57192160369; 57225007353; 57731717000; 57204370628,"RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering",,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306181&partnerID=40&md5=8a5fdb26fda8bc55fb1b2bd9b9f55587,"We introduce RoMQA, the first benchmark for robust, multi-evidence, multi-answer question answering (QA). RoMQA contains clusters of questions that are derived from related constraints mined from the Wikidata knowledge graph. RoMQA evaluates robustness of QA models to varying constraints by measuring worst-case performance within each question cluster. Compared to prior QA datasets, RoMQA has more human-written questions that require reasoning over more evidence text and have, on average, many more correct answers. In addition, human annotators rate RoMQA questions as more natural or likely to be asked by people. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is challenging: zero-shot and few-shot models perform similarly to naive baselines, while supervised retrieval methods perform well below gold evidence upper bounds. Moreover, existing models are not robust to variations in question constraints, but can be made more robust by tuning on clusters of related questions. Our results show that RoMQA is a challenging benchmark for large language models, and provides a quantifiable test to build more robust QA methods. © 2023 Association for Computational Linguistics.",Final,
Procko T.T.; Elvira T.; Ochoa O.,"Procko, Tyler Thomas (57561957000); Elvira, Timothy (57561184200); Ochoa, Omar (8982210700)",57561957000; 57561184200; 8982210700,GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808375&doi=10.1109%2fTransAI60598.2023.00043&partnerID=40&md5=10fd5c5e6afb21570af17fd717479d4c,"Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive 'knowledge bases' with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some 'understanding' of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the 'understanding' an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.  © 2023 IEEE.",Final,
Anand A.; Gupta M.; Prasad K.; Goel U.; Lal N.; Verma A.; Shah R.R.,"Anand, Avinash (58508044100); Gupta, Mohit (58825226300); Prasad, Kritarth (57199760710); Goel, Ujjwal (58778218800); Lal, Naman (58205141600); Verma, Astha (57661763200); Shah, Rajiv Ratn (56121902800)",58508044100; 58825226300; 57199760710; 58778218800; 58205141600; 57661763200; 56121902800,KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180543792&doi=10.1007%2f978-3-031-49601-1_3&partnerID=40&md5=90a653ca5f034054a35f19088a4bd22a,"Citation Text Generation (CTG) is a task in natural language processing (NLP) that aims to produce text that accurately cites or references a cited document within a source document. In CTG, the generated text draws upon contextual cues from both the source document and the cited paper, ensuring accurate and relevant citation information is provided. Previous work in the field of citation generation is mainly based on the text summarization of documents. Following this, this paper presents a framework, and a comparative study to demonstrate the use of Large Language Models (LLMs) for the task of citation generation. Also, we have shown the improvement in the results of citation generation by incorporating the knowledge graph relations of the papers in the prompt for the LLM to better learn the relationship between the papers. To assess how well our model is performing, we have used a subset of standard S2ORC dataset, which only consists of computer science academic research papers in the English Language. Vicuna performs best for this task with 14.15 Meteor, 12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and improves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by including knowledge graphs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Han K.; Gardent C.,"Han, Kelvin (57219685438); Gardent, Claire (14015644100)",57219685438; 14015644100,Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183301185&partnerID=40&md5=c3c71c28ee87ed8ff5a22404de019ce6,"The ability to bridge Question Generation (QG) and Question Answering (QA) across structured and unstructured modalities has the potential for aiding different NLP applications. One key application is in QA-based methods that have recently been shown to be useful for automatically evaluating Natural Language (NL) texts generated from Knowledge Graphs (KG). While methods have been proposed for QG-QA across these modalities, these efforts have been in English only; in this work, we bring multilinguality (Brazilian Portuguese and Russian) to multimodal (KG and NL) QG-QA. Using synthetic data generation and machine translation to produce QG-QA data that is aligned between graph and text, we are able to train multimodal, multi-task models that can perform multimodal QG and QA in Portuguese and Russian. We show that our approach outperforms a baseline which is derived from previous work on English and adapted to handle these two languages. Our code, data and models are available at https://gitlab.inria.fr/hankelvin/multlingual_kg-text_qgqa. © 2023 Association for Computational Linguistics.",Final,
Zhu K.; Huang J.; Chang K.C.-C.,"Zhu, Kerui (57712860900); Huang, Jie (57226877159); Chang, Kevin Chen-Chuan (7407034942)",57712860900; 57226877159; 7407034942,Descriptive Knowledge Graph in Biomedical Domain,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183295018&partnerID=40&md5=fb2704be7a034024887c36de5b4a42eb,"We present a novel system that automatically extracts and generates informative and descriptive sentences from the biomedical corpus and facilitates the efficient search for relational knowledge. Unlike previous search engines or exploration systems that retrieve unconnected passages, our system organizes descriptive sentences as a relational graph, enabling researchers to explore closely related biomedical entities (e.g., diseases treated by a chemical) or indirectly connected entities (e.g., potential drugs for treating a disease). Our system also uses ChatGPT and a fine-tuned relation synthesis model to generate concise and reliable descriptive sentences from retrieved information, reducing the need for extensive human reading effort. With our system, researchers can easily obtain both high-level knowledge and detailed references and interactively steer to the information of interest. We spotlight the application of our system in COVID-19 research, illustrating its utility in areas such as drug repurposing and literature curation. © 2023 Association for Computational Linguistics.",Final,
Lin Q.; Mao R.; Liu J.; Xu F.; Cambria E.,"Lin, Qika (57204147391); Mao, Rui (57207859287); Liu, Jun (55904548100); Xu, Fangzhi (57372934200); Cambria, Erik (56140547500)",57204147391; 57207859287; 55904548100; 57372934200; 56140547500,Fusing topology contexts and logical rules in language models for knowledge graph completion,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139295245&doi=10.1016%2fj.inffus.2022.09.020&partnerID=40&md5=23462bd2365c3dfdcb7520aff0491118,"Knowledge graph completion (KGC) aims to infer missing facts based on the observed ones, which is significant for many downstream applications. Given the success of deep learning and pre-trained language models (LMs), some LM-based methods are proposed for the KGC task. However, most of them focus on modeling the text of fact triples and ignore the deeper semantic information (e.g., topology contexts and logical rules) that is significant for KG modeling. For such a reason, we propose a unified framework FTL-LM to Fuse Topology contexts and Logical rules in Language Models for KGC, which mainly contains a novel path-based method for topology contexts learning and a variational expectation–maximization (EM) algorithm for soft logical rule distilling. The former utilizes a heterogeneous random-walk to generate topology paths and further reasoning paths that can represent topology contexts implicitly and can be modeled by a LM explicitly. The strategies of mask language modeling and contrastive path learning are introduced to model these topology contexts. The latter implicitly fuses logical rules by a variational EM algorithm with two LMs. Specifically, in the E-step, the triple LM is updated under the supervision of observed triples and valid hidden triples verified by the fixed rule LM. And in the M-step, we fix the triple LM and fine-tune the rule LM to update logical rules. Experiments on three common KGC datasets demonstrate the superiority of the proposed FTL-LM, e.g., it achieves 2.1% and 3.1% Hits@10 improvement over the state-of-the-art LM-based model LP-BERT in the WN18RR and FB15k-237, respectively. © 2022 Elsevier B.V.",Final,All Open Access; Bronze Open Access
Ma J.; Chen C.; Hou C.; Yuan X.,"Ma, Jing (57142999800); Chen, Chen (56424713800); Hou, Chunyan (35114931500); Yuan, Xiaojie (15764008700)",57142999800; 56424713800; 35114931500; 15764008700,KAPALM: Knowledge grAPh enhAnced Language Model for Fake News Detection,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183304054&partnerID=40&md5=64c2cb72edb9cbfb289587a6a8fa4c67,"Social media has not only facilitated news consumption, but also led to the wide spread of fake news. Because news articles in social media are usually condensed and full of knowledge entities, existing methods of fake news detection use external entity knowledge to improve the effectiveness. However, the majority of these methods focus on news entity information and ignore the structured relation knowledge among news entities. To address this issue, in this work, we propose a Knowledge grAPh enhAnced Language Model (KAPALM) which is a novel model that fuses coarse- and fine-grained representations of entity knowledge from Knowledge Graphs (KGs). Firstly, we identify entities in news content and link them to entities in KGs. Then, a subgraph of KGs is extracted to provide structured relation knowledge of entities in KGs and fed into a graph neural network to obtain the coarse-grained knowledge representation. This subgraph is pruned to provide fine-grained knowledge and fed into the attentive graph pooling layer. Finally, we integrate the coarse- and fine-grained entity knowledge representations with the representation of news content for fake news detection. The experimental results on two benchmark datasets show that our method is superior to state-of-the-art baselines in the full-scale setting. In addition, our model is competitive in the few-shot setting. © 2023 Association for Computational Linguistics.",Final,
,,,ROCLING 2023 - Proceedings of the 35th Conference on Computational Linguistics and Speech Processing,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184899235&partnerID=40&md5=85a7036387c42e6af71ee947cd853f67,The proceedings contain 56 papers. The topics discussed include: XFEVER: exploring fact verification across languages; story co-telling dialogue generation via reinforcement learning and knowledge graph; improving end-to-end Taiwanese-speech-to-Chinese-text translation by semi-supervised learning; WordRank: a word ranking based training strategy for abstractive document summarization; exploring cross-institutional recognition of cancer registration items: a case study on catastrophic forgetting; enhancing automated English speaking assessment for L2 speakers with BERT and Wav2vec2.0 fusion; impact of feature selection algorithms on readability model; multimodal speech training for the hard of hearing in Mandarin; and Is GPT-4 a good Islamic expert for answering Quran questions?.,Final,
Kim H.; Hessel J.; Jiang L.; West P.; Lu X.; Yu Y.; Zhou P.; Le Bras R.; Alikhani M.; Kim G.; Sap M.; Choi Y.,"Kim, Hyunwoo (57215327662); Hessel, Jack (57190382287); Jiang, Liwei (57209400459); West, Peter (57216690053); Lu, Ximing (57222033823); Yu, Youngjae (57201326268); Zhou, Pei (57207759495); Le Bras, Ronan (37042388500); Alikhani, Malihe (57052531100); Kim, Gunhee (55685918100); Sap, Maarten (56419784900); Choi, Yejin (36172231400)",57215327662; 57190382287; 57209400459; 57216690053; 57222033823; 57201326268; 57207759495; 37042388500; 57052531100; 55685918100; 56419784900; 36172231400,SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180115102&partnerID=40&md5=12b0e44e0a319f34c4059a94a40028d7,"Data scarcity has been a long standing issue in the field of open-domain social dialogue. To quench this thirst, we present SODA: the first publicly available, million-scale high-quality social dialogue dataset. By contextualizing social commonsense knowledge from a knowledge graph, we are able to distill an exceptionally broad spectrum of social interactions from a large language model. Human evaluation shows that conversations in SODA are more consistent, specific, and (surprisingly) natural than those in prior human-authored datasets. Using SODA, we train COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna). Experiments reveal COSMO is sometimes even preferred to the original human-written gold responses. Additionally, our results shed light on the distinction between knowledge-enriched conversations and natural social chitchats. We make our data, models, and code public. ©2023 Association for Computational Linguistics.",Final,
Deng Z.; Wang W.; Wang Z.; Liu X.; Song Y.,"Deng, Zheye (57219500934); Wang, Weiqi (57222025650); Wang, Zhaowei (57937889000); Liu, Xin (57206739249); Song, Yangqiu (58787931000)",57219500934; 57222025650; 57937889000; 57206739249; 58787931000,GOLD: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183298012&partnerID=40&md5=80adca4605ab1a221384a46441ad3d02,"Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning; yet constructing them through human annotations can be costly. As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage. However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs. To address this issue, we propose GOLD (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG. Experiment results demonstrate that GOLD outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks. Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task. Our code and data are publicly available at https://github.com/HKUST-KnowComp/GOLD. © 2023 Association for Computational Linguistics.",Final,
Liu Z.; Tan L.; Li M.; Wan Y.; Jin H.; Shi X.,"Liu, Zhengtao (58846944400); Tan, Lei (57661573000); Li, Mengfan (58846795800); Wan, Yao (57089582400); Jin, Hai (56434989100); Shi, Xuanhua (8935128100)",58846944400; 57661573000; 58846795800; 57089582400; 56434989100; 8935128100,SiMFy: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183297160&partnerID=40&md5=4de8e2828423ce57f317c5f09f9722d5,"Temporal Knowledge Graph (TKG) reasoning; which focuses on leveraging temporal information to infer future facts in knowledge graphs, plays a vital role in knowledge graph completion. Typically, existing works for this task design graph neural networks and recurrent neural networks to respectively capture the structural and temporal information in KGs. Despite their effectiveness, in our practice, we find that they tend to suffer the issues of low training efficiency and insufficient generalization ability, which can be attributed to the over design of model architectures. To this end, this paper aims to figure out whether the current complex model architectures are necessary for temporal knowledge graph reasoning. As a result, we put forward a simple yet effective approach (termed SiMFy), which simply utilizes multilayer per-ceptron (MLP) to model the structural dependencies of events and adopts a fixed-frequency strategy to incorporate historical frequency during inference. Extensive experiments on real-world datasets demonstrate that our SiMFy can reach state-of-the-art performance with the following strengths: 1) faster convergence speed and better generalization ability; 2) a much smaller time consumption in the training process; and 3) better ability to capture the structural dependencies of events in KGs. These results provide evidence that the substitution of complex models with simpler counterparts is a feasible strategy. © 2023 Association for Computational Linguistics.",Final,
Zhou W.; Zhao J.; Gui T.; Zhang Q.; Huang X.,"Zhou, Wentao (58846793900); Zhao, Jun (57190004147); Gui, Tao (57211256586); Zhang, Qi (57203621188); Huang, Xuanjing (8983710700)",58846793900; 57190004147; 57211256586; 57203621188; 8983710700,Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183302828&partnerID=40&md5=5ac3aa2d3effd6540a81b3e03b025aa9,"The inductive inference of the knowledge graph aims to complete the potential relations between the new unknown entities in the graph. Most existing methods are based on entity-independent features such as graph structure information and relationship information to inference. However, the neighborhood of these new entities is often too sparse to obtain enough information to build these features effectively. In this work, we propose a knowledge graph inductive inference method that fuses ontology information. Based on the enclosing subgraph, we bring in feature embeddings of concepts corresponding to entities to learn the semantic information implicit in the ontology. Considering that the ontology information of entities may be missing, we build a type constraint regular loss to explicitly model the semantic connections between entities and concepts, and thus capture the missing concepts of entities. Experimental results show that our approach significantly outperforms large language models like ChatGPT on two benchmark datasets, YAGO21K-610 and DB45K-165, and improves the MRR metrics by 15.4% and 44.1%, respectively, when compared with the state-of-the-art methods. © 2023 Association for Computational Linguistics.",Final,
Hertling S.; Paulheim H.,"Hertling, Sven (55583440200); Paulheim, Heiko (35095438500)",55583440200; 35095438500,OLaLa Results for OAEI 2023,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180814848&partnerID=40&md5=b8d5fac66dc9350abb833bd534428cf1,"This paper presents the results of the OLaLa matching system participating in the OAEI 2023. The system is based on sentence-transformers as well as large language models. The former is used to generate correspondence candidates which is independent of any overlapping tokens because the comparison is only based on embeddings. To finally select the best mappings, a large language model is used to decide if two given textual representations of the source and target concept are equal or not. Based on positive and negative words that the LLM predicts, a confidence is extracted. Still, there are a lot of decisions that heavily influence the final result like (1) how can each concept be verbalized into text, (2) which prompt to use, and (3) which language model to choose. A lot of combinations were executed and the most useful one is submitted and packaged as a matching system. © 2023 Copyright for this paper by its authors.",Final,
Das S.; Bagchi M.; Hussey P.,"Das, Subhashis (57202838768); Bagchi, Mayukh (57218899033); Hussey, Pamela (56913085700)",57202838768; 57218899033; 56913085700,How To Teach Domain Ontology-based Knowledge Graph Construction? An Irish Experiment,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185134300&doi=10.5771%2f0943-7444-2023-3-182&partnerID=40&md5=9889b2687f7fd7fbc1a74a92fed1688b,"Domains represent concepts which belong to specific parts of the world. The particularized meaning of words linguistically encoding such domain concepts are provided by domain specific resources. The explicit meaning of such words are increasingly captured computationally using domain-specific ontologies, which, even for the same reference domain, are most often than not semantically incompatible. As information systems that rely on domain ontologies expand, there is a growing need to not only design domain ontologies and domain ontology-grounded Knowledge Graphs (KGs) but also to align them to general standards and conventions for interoperability. This often presents an insurmountable challenge to domain experts who have to additionally learn the construction of domain ontologies and KGs. Until now, several research methodologies have been proposed by different research groups using different technical approaches and based on scenarios of different domains of application. However, no methodology has been proposed which not only facilitates designing conceptually well-founded ontologies, but is also, equally, grounded in the general pedagogical principles of knowledge organization and, thereby, flexible enough to teach, and reproduce vis-à-vis domain experts. The purpose of this paper is to provide such a general, pedagogically flexible semantic knowledge modelling methodology. We exemplify the methodology by examples and illustrations from a professional-level digital healthcare course, and conclude with an evaluation grounded in technological parameters as well as user experience design principles. © 2023, International Society for Knowledge Organization. All rights reserved.",Final,
Yue L.; Zhang Y.; Yao Q.; Li Y.; Wu X.; Zhang Z.; Lin Z.; Zheng Y.,"Yue, Ling (58666596400); Zhang, Yongqi (57209508370); Yao, Quanming (57002177700); Li, Yong (57189401839); Wu, Xian (57209291701); Zhang, Ziheng (57220158275); Lin, Zhenxi (57222054366); Zheng, Yefeng (8062522600)",58666596400; 57209508370; 57002177700; 57189401839; 57209291701; 57220158275; 57222054366; 8062522600,Relation-aware Ensemble Learning for Knowledge Graph Embedding,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184799357&partnerID=40&md5=0a503b66b9072ba3c072dd329d474b1b,"Knowledge graph (KG) embedding is a fundamental task in natural language processing, and various methods have been proposed to explore semantic patterns in distinctive ways. In this paper, we propose to learn an ensemble by leveraging existing methods in a relation-aware manner. However, exploring these semantics using relation-aware ensemble leads to a much larger search space than general ensemble methods. To address this issue, we propose a divide-search-combine algorithm RelEns-DSC that searches the relation-wise ensemble weights independently. This algorithm has the same computation cost as general ensemble methods but with much better performance. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed method in efficiently searching relation-aware ensemble weights and achieving state-of-the-art embedding performance. The code is public at https://github.com/LARS-research/RelEns.. ©2023 Association for Computational Linguistics.",Final,
Yu D.; Xiong C.; Gu Y.; Yang Y.,"Yu, Donghan (57219492469); Xiong, Chenyan (56405071400); Gu, Yu (57219488842); Yang, Yiming (35231480000)",57219492469; 56405071400; 57219488842; 35231480000,COMPLEQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183288571&partnerID=40&md5=a2d8c032ce2e7293d28c17ab211dc108,"How much success in Knowledge Graph Completion (KGC) would translate into the performance enhancement in downstream tasks is an important question that has not been studied in depth. In this paper, we introduce a novel benchmark, namely COMPLEQA, to comprehensively assess the influence of representative KGC methods on Knowledge Graph Question Answering (KGQA), one of the most important downstream applications. This benchmark includes a knowledge graph with 3 million triplets across 5 distinct domains, coupled with over 5,000 question-answering pairs and a completion dataset that is well-aligned with these questions. Our evaluation of four well-known KGC methods in combination with two state-of-the-art KGQA systems shows that effective KGC can significantly mitigate the impact of knowledge graph incompleteness on question-answering performance. Surprisingly, we also find that the best-performing KGC method(s) does not necessarily lead to the best QA results, underscoring the need to consider downstream applications when doing KGC. © 2023 Association for Computational Linguistics.",Final,
Ren Z.; Zhao Y.; Zong C.,"Ren, Zixuan (58846598700); Zhao, Yang (57202271643); Zong, Chengqing (7005615574)",58846598700; 57202271643; 7005615574,Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306120&partnerID=40&md5=85e02c018d29e3146ef9dd25a7746c30,"Pretrained language models (PLMs), especially large language models (LLMs) demonstrate impressive capabilities in open-ended text generation. While our statistical results show that LLMs often suffer from over-concentrated information, where the generated texts overly focus on the given prompt and fail to provide sufficient background and detailed information as humans do. To address this issue, we propose a dynamic knowledge-guided informative open-ended text generation approach, that utilizes a knowledge graph to help the model generate more contextually related entities and detailed facts. Specifically, we first employ a local knowledge filter to extract relevant knowledge from the comprehensive knowledge graph for a given topic sentence. Then we introduce a dynamic knowledge selector to predict the entity to be mentioned in the subsequent sentence. Finally, we utilize a knowledge-enhanced text generator to produce a more informative output. To evaluate the effectiveness of our approach, we evaluate the proposed approach in two scenarios: fine-tuning for small PLMs and prompt tuning for LLMs. Experimental results show that our approach could generate more informative texts than baselines. © 2023 Association for Computational Linguistics.",Final,
Radevski G.; Gashteovski K.; Hung C.-C.; Lawrence C.; Glavaš G.,"Radevski, Gorjan (57202999676); Gashteovski, Kiril (57210585423); Hung, Chia-Chien (57313522100); Lawrence, Carolin (57204284641); Glavaš, Goran (36462569800)",57202999676; 57210585423; 57313522100; 57204284641; 36462569800,Linking Surface Facts to Large-Scale Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184812378&partnerID=40&md5=8bb7b78fb1171f0350586594a9308242,"Open Information Extraction (OIE) methods extract facts from natural language text in the form of (“subject”; “relation”; “object”) triples. These facts are, however, merely surface forms, the ambiguity of which impedes their downstream usage; e.g., the surface phrase “Michael Jordan” may refer to either the former basketball player or the university professor. Knowledge Graphs (KGs), on the other hand, contain facts in a canonical (i.e., unambiguous) form, but their coverage is limited by a static schema (i.e., a fixed set of entities and predicates). To bridge this gap, we need the best of both worlds: (i) high coverage of free-text OIEs, and (ii) semantic precision (i.e., monosemy) of KGs. In order to achieve this goal, we propose a new benchmark with novel evaluation protocols that can, for example, measure fact linking performance on a granular triple slot level, while also measuring if a system has the ability to recognize that a surface form has no match in the existing KG. Our extensive evaluation of several baselines shows that detection of out-of-KG entities and predicates is more difficult than accurate linking to existing ones, thus calling for more research efforts on this difficult task. We publicly release all resources (data, benchmark and code). © 2023 Association for Computational Linguistics.",Final,
Zhou W.; Peng X.; Riedl M.,"Zhou, Wei (58100636300); Peng, Xiangyu (57219758425); Riedl, Mark (7004421643)",58100636300; 57219758425; 7004421643,Dialogue Shaping: Empowering Agents through NPC Interaction,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665948&partnerID=40&md5=3414366cf8442f5670cd116895edef3c,"One major challenge in reinforcement learning (RL) is the large amount of steps for the RL agent needs to converge in the training process and learn the optimal policy, especially in text-based game environments where the action space is extensive. However, non-player characters (NPCs) sometimes hold some key information about the game, which can potentially help to train RL agents faster. Thus, this paper explores how to interact and converse with NPC agents to get the key information using large language models (LLMs), as well as incorporate this information to speed up RL agent’s training using knowledge graphs (KGs) and Story Shaping. © 2023 Copyright for this paper by its authors.",Final,
Zhao F.; Zou H.; Yan C.,"Zhao, Feng (57191956476); Zou, Hongzhi (58882371000); Yan, Cheng (57678335700)",57191956476; 58882371000; 57678335700,Structure-aware Knowledge Graph-to-Text Generation with Planning Selection and Similarity Distinction,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184821659&partnerID=40&md5=164f386499e2635966504e7d1824b6c6,"The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. One of the primary challenges in this task is bridging the gap between the diverse structures of the KG and the target text, while preserving the details of the input KG. To address this, we propose a novel approach that efficiently integrates graph structure-aware modules with pre-trained language models. Unlike conventional techniques, which only consider direct connections between first-order neighbors, our method delves deeper by incorporating Relative Distance Encoding as a bias within the graph structure-aware module. This enables our model to better capture the intricate topology information present in the KG. To further elevate the fidelity of the generated text, Planning Selection and Similarity Distinction are introduced. Our approach filters the most relevant linearized sequences by employing a planning scorer, while simultaneously distinguishing similar input KGs through contrastive learning techniques. Experiments on two datasets demonstrate the superiority of our model. © 2023 Association for Computational Linguistics.",Final,
Kim J.; Kwon Y.; Jo Y.; Choi E.,"Kim, Jiho (58382271300); Kwon, Yeonsu (58078253400); Jo, Yohan (58615299200); Choi, Edward (58706111300)",58382271300; 58078253400; 58615299200; 58706111300,KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183304875&partnerID=40&md5=871260707ab165c28f57b71fbe635cb0,"While large language models (LLMs) have made considerable advancements in understanding and generating unstructured text, their application in structured data remains underexplored. Particularly, using LLMs for complex reasoning tasks on knowledge graphs (KGs) remains largely untouched. To address this, we propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and Inference, each aimed at partitioning sentences, retrieving relevant graph components, and deriving logical conclusions, respectively. We evaluate KG-GPT using KG-based fact verification and KGQA benchmarks, with the model showing competitive and robust performance, even outperforming several fully-supervised models. Our work, therefore, marks a significant step in unifying structured and unstructured data processing within the realm of LLMs. © 2023 Association for Computational Linguistics.",Final,
Wang R.; Zhang Z.; Rossetto L.; Ruosch F.; Bernstein A.,"Wang, Ruijie (57219371499); Zhang, Zhiruo (58723738900); Rossetto, Luca (56595519700); Ruosch, Florian (57203863147); Bernstein, Abraham (57212626682)",57219371499; 58723738900; 56595519700; 57203863147; 57212626682,NLQxform: A Language Model-based Question to SPARQL Transformer,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546292&partnerID=40&md5=478a7698b1a9c96e643c4b1a1903d1c1,"In recent years, scholarly data has grown dramatically in terms of both scale and complexity. It becomes increasingly challenging to retrieve information from scholarly knowledge graphs that include large-scale heterogeneous relationships, such as authorship, affiliation, and citation, between various types of entities, e.g., scholars, papers, and organizations. As part of the Scholarly QALD Challenge, this paper presents a question-answering (QA) system called NLQxform, which provides an easy-to-use natural language interface to facilitate accessing scholarly knowledge graphs. NLQxform allows users to express their complex query intentions in natural language questions. A transformer-based language model, i.e., BART, is employed to translate questions into standard SPARQL queries, which can be evaluated to retrieve the required information. According to the public leaderboard of the Scholarly QALD Challenge at ISWC 2023 (Task 1: DBLP-QUAD — Knowledge Graph Question Answering over DBLP), NLQxform achieved an F1 score of 0.85 and ranked first on the QA task, demonstrating the competitiveness of the system. © 2023 CEUR-WS. All rights reserved.",Final,
Chen Z.; Xu C.; Su F.; Huang Z.; Dou Y.,"Chen, Zhongwu (58041847800); Xu, Chengjin (57195741972); Su, Fenglong (57452650700); Huang, Zhen (56188479000); Dou, Yong (15131095400)",58041847800; 57195741972; 57452650700; 56188479000; 15131095400,Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290982&partnerID=40&md5=65e4d2d00ca8b3368249c3ea78a38d46,"Real-world Temporal Knowledge Graphs keep growing with time and new entities and facts emerge continually, necessitating a model that can extrapolate to future timestamps and transfer knowledge for new components. Therefore, our work first dives into this more realistic issue, lifelong TKG reasoning; where existing methods can only address part of the challenges. Specifically, we formulate lifelong TKG reasoning as a temporal-path-based reinforcement learning (RL) framework. Then, we add temporal displacement into the action space of RL to extrapolate for the future and further propose a temporal-rule-based reward shaping to guide the training. To transfer and update knowledge, we design a new edge-aware message passing module, where the embeddings of new entities and edges are inductive. We conduct extensive experiments on three newly constructed benchmarks for lifelong TKG reasoning. Experimental results show the outperforming effectiveness of our model against all well-adapted baselines. © 2023 Association for Computational Linguistics.",Final,
Yáñez-Romero F.A.,"Yáñez-Romero, Fabio Antonio (58754723400)",58754723400,Entity Modelling through Ontologies and Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184831862&partnerID=40&md5=e7bfd8a5401e242aa037a5e8fd7e0a4e,"The aim of this paper is to present a line of research focused on improving the knowledge represented in natural language processing tasks through the use of ontologies, combining these with machine learning techniques. It is expected that with this kind of techniques it will be possible to fight against phenomena such as the hallucination present in current generative language models and to reach the state of the art in different tasks taking into account semantic knowledge. Initially, we will try to solve the problem of semantics in specific areas such as medicine, where the external knowledge that can be incorporated would help to provide knowledge that does not exist in unstructured data such as all ICD-10 codes. Therefore, we expect obtain enough conclusions to apply this methodology with other dominions. © 2021 Copyright for this paper by its authors.",Final,
Zhang T.; Xu R.; Wang C.; Duan Z.; Chen C.; Qiu M.; Cheng D.; He X.; Qian W.,"Zhang, Taolin (57221142663); Xu, Ruyao (57644992200); Wang, Chengyu (55926354300); Duan, Zhongjie (57945712100); Chen, Cen (56425231100); Qiu, Minghui (55537463100); Cheng, Dawei (57191748068); He, Xiaofeng (55641972700); Qian, Weining (7201831316)",57221142663; 57644992200; 55926354300; 57945712100; 56425231100; 55537463100; 57191748068; 55641972700; 7201831316,Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184823320&partnerID=40&md5=100ebc66d9766fe36c228e5bc9d58539,"Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the performance of various downstream NLP tasks by injecting knowledge facts from large-scale Knowledge Graphs (KGs). However, existing methods for pre-training KEPLMs with relational triples are difficult to be adapted to close domains due to the lack of sufficient domain graph semantics. In this paper, we propose a Knowledgeenhanced lANGuAge Representation learning framework for various clOsed dOmains (KANGAROO) via capturing the implicit graph structure among the entities. Specifically, since the entity coverage rates of closed-domain KGs can be relatively low and may exhibit the global sparsity phenomenon for knowledge injection, we consider not only the shallow relational representations of triples but also the hyperbolic embeddings of deep hierarchical entity-class structures for effective knowledge fusion. Moreover, as two closed-domain entities under the same entity-class often have locally dense neighbor subgraphs counted by max point biconnected component, we further propose a data augmentation strategy based on contrastive learning over subgraphs to construct hard negative samples of higher quality. It makes the underlying KELPMs better distinguish the semantics of these neighboring entities to further complement the global semantic sparsity. In the experiments, we evaluate KANGAROO over various knowledge-aware and general NLP tasks in both full and few-shot learning settings, outperforming various KEPLM training paradigms performance in closed-domains significantly.. ©2023 Association for Computational Linguistics.",Final,
Nguyen M.H.; Samaradivakara Y.; Sasikumar P.; Nanayakkara S.; Gupta C.,"Nguyen, Mia Huong (58846711200); Samaradivakara, Yasith (58847166200); Sasikumar, Prasanth (57212406932); Nanayakkara, Suranga (23009527800); Gupta, Chitralekha (36023604600)",58846711200; 58847166200; 57212406932; 23009527800; 36023604600,EMO-KNOW: A Large Scale Dataset on Emotion and Emotion-cause,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183295918&partnerID=40&md5=bd651d0cf0a644050180458c7784f50e,"Emotion-Cause analysis has attracted the attention of researchers in recent years. However, most existing datasets are limited in size and number of emotion categories. They often focus on extracting parts of the document that contain the emotion cause and fail to provide more abstractive, generalizable root cause. To bridge this gap, we introduce a large-scale dataset of emotion causes, derived from 9.8 million cleaned tweets over 15 years. We describe our curation process, which includes a comprehensive pipeline for data gathering, cleaning, labeling, and validation, ensuring the dataset's reliability and richness. We extract emotion labels and provide abstractive summarization of the events causing emotions. The final dataset comprises over 700,000 tweets with corresponding emotion-cause pairs spanning 48 emotion classes, validated by human evaluators. The novelty of our dataset stems from its broad spectrum of emotion classes and the abstractive emotion cause that facilitates the development of an emotion-cause knowledge graph for nuanced reasoning. Our dataset will enable the design of emotion-aware systems that account for the diverse emotional responses of different people for the same event. © 2023 Association for Computational Linguistics.",Final,
Singh I.; Kaur N.; Gaur G.; Mausam,"Singh, Ishaan (58598203200); Kaur, Navdeep (58584909600); Gaur, Garima (57198888092); Mausam (58882512900)",58598203200; 58584909600; 57198888092; 58882512900,NeuSTIP: A Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184823284&partnerID=40&md5=eddee5bde4cb112c96afde383b087f2c,"Neuro-symbolic (NS) models for knowledge graph completion (KGC) combine the benefits of symbolic models (interpretable inference) with those of distributed representations (parameter sharing, high accuracy). While several NS models exist for KGs with static facts, there is limited work on temporal KGC (TKGC) for KGs where a fact is associated with a time interval. In response, we propose a novel NS model for TKGC called NeuSTIP, which performs link prediction and time interval prediction in a TKG. NeuSTIP learns temporal rules with Allen predicates, which ensure temporal consistency between neighboring predicates in the rule body. We further design a unique scoring function that evaluates the confidence of the candidate answers while performing link and time interval predictions by utilizing the learned rules. Our empirical evaluation on two time interval based TKGC datasets shows that our model shows competitive performance on link prediction and establishes a new state of the art on time prediction. ©2023 Association for Computational Linguistics.",Final,
Luo L.; Vu T.-T.; Phung D.; Haffari G.,"Luo, Linhao (57214679113); Vu, Thuy-Trang (57215718440); Phung, Dinh (7003397144); Haffari, Gholamreza (24338096600)",57214679113; 57215718440; 7003397144; 24338096600,Systematic Assessment of Factual Knowledge in Large Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183300786&partnerID=40&md5=16c4c33f7a0276a282d59858af569cde,"Previous studies have relied on existing question-answering benchmarks to evaluate the knowledge stored in large language models (LLMs). However, this approach has limitations regarding factual knowledge coverage, as it mostly focuses on generic domains which may overlap with the pretraining data. This paper proposes a framework to systematically assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions and expected answers from the facts stored in a given KG, and then evaluates the accuracy of LLMs in answering these questions. We systematically evaluate the state-of-the-art LLMs with KGs in generic and specific domains. The experiment shows that ChatGPT is consistently the top performer across all domains. We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context. © 2023 Association for Computational Linguistics.",Final,
Wu S.; Wan H.; Chen W.; Wu Y.; Shen J.; Lin Y.,"Wu, Shuhan (58676800100); Wan, Huaiyu (35189888000); Chen, Wei (57210470762); Wu, Yuting (57211752642); Shen, Junfeng (58676800200); Lin, Youfang (7407358559)",58676800100; 35189888000; 57210470762; 57211752642; 58676800200; 7407358559,Towards Enhancing Relational Rules for Knowledge Graph Link Prediction,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296294&partnerID=40&md5=f4756306b9f223fce4f7638e16a5ad71,"Graph neural networks (GNNs) have shown promising performance for knowledge graph reasoning. A recent variant of GNN called progressive relational graph neural network (PRGNN), utilizes relational rules to infer missing knowledge in relational digraphs and achieves notable results. However, during reasoning with PRGNN, two important properties are often overlooked: (1) the sequentiality of relation composition, where the order of combining different relations affects the semantics of the relational rules, and (2) the lagged entity information propagation, where the transmission speed of required information lags behind the appearance speed of new entities. Ignoring these properties leads to incorrect relational rule learning and decreased reasoning accuracy. To address these issues, we propose a novel knowledge graph reasoning approach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN). Specifically, RUN-GNN employs a query related fusion gate unit to model the sequentiality of relation composition and utilizes a buffering update mechanism to alleviate the negative effect of lagged entity information propagation, resulting in higher-quality relational rule learning. Experimental results on multiple datasets demonstrate the superiority of RUN-GNN is superior on both transductive and inductive link prediction tasks. © 2023 Association for Computational Linguistics.",Final,
Li N.; Haihong E.; Shi L.; Sun M.; Yao T.; Song M.; Wang Y.; Luo H.,"Li, Ningyuan (57713271400); Haihong, E. (36679915000); Shi, Li (58658218700); Sun, Mingzhi (57713678400); Yao, Tianyu (57819884500); Song, Meina (8419354200); Wang, Yong (57891212500); Luo, Haoran (57226337519)",57713271400; 36679915000; 58658218700; 57713678400; 57819884500; 8419354200; 57891212500; 57226337519,TR-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292090&partnerID=40&md5=307a54b25964818a3a7f22da89cf5da6,"Temporal knowledge graph (TKG) has been proved to be an effective way for modeling dynamic facts in real world. Many efforts have been devoted into predicting future events i.e. extrapolation, on TKGs. Recently, rule-based knowledge graph completion methods which are considered to be more interpretable than embedding-based methods, have been transferred to temporal knowledge graph extrapolation. However, rule-based models suffer from temporal redundancy when leveraged under dynamic settings, which results in inaccurate rule confidence calculation. In this paper, we define the problem of temporal redundancy and propose TR-Rules which solves the temporal redundancy issues through a simple but effective strategy. Besides, to capture more information lurking in TKGs, apart from cyclic rules, TR-Rules also mines and properly leverages acyclic rules, which has not been explored by existing models. Experimental results on three benchmarks show that TR-Rules achieves state-of-the-art performance. Ablation study shows the impact of temporal redundancy and demonstrates the performance of acyclic rules is much more promising due to its higher sensitivity to the number of sampled walks during learning stage. © 2023 Association for Computational Linguistics.",Final,
Colas A.; Araki J.; Zhou Z.; Wang B.; Feng Z.,"Colas, Anthony (57215596114); Araki, Jun (55968686500); Zhou, Zhengyu (57221189119); Wang, Bingqing (24765635600); Feng, Zhe (57201516996)",57215596114; 55968686500; 57221189119; 24765635600; 57201516996,Knowledge-grounded Natural Language Recommendation Explanation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184801777&partnerID=40&md5=742342321064ff6173a99b2534505f28,"Explanations accompanying a recommendation can assist users in understanding the decision made by recommendation systems, which in turn increases a user’s confidence and trust in the system. Recently, research has focused on generating natural language explanations in a human-readable format. Thus far, the proposed approaches leverage item reviews written by users, which are often subjective, sparse in language, and unable to account for new items that have not been purchased or reviewed before. Instead, we aim to generate fact-grounded recommendation explanations that are objectively described with item features while implicitly considering a user’s preferences, based on the user’s purchase history. To achieve this, we propose a knowledge graph (KG) approach to natural language explainable recommendation. Our approach draws on user-item features through a novel collaborative filtering-based KG representation to produce fact-grounded, personalized explanations, while jointly learning user-item representations for recommendation scoring. Experimental results show that our approach consistently outperforms previous state-of-the-art models on natural language explainable recommendation metrics.1 ©2023 Association for Computational Linguistics.",Final,
Liu S.; Omran P.G.; Taylor K.,"Liu, Shixuan (58827059000); Omran, Pouya Ghiasnezhad (57192670755); Taylor, Kerry (22433897700)",58827059000; 57192670755; 22433897700,Data Augmented Knowledge Graph Completion via Pre-trained Language Models,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184354990&partnerID=40&md5=8ac87e44d4d35b497b627abe7932f875,"Knowledge graphs provide significant assistance for many artificial intelligence tasks, but they are usually incomplete. Techniques for knowledge graph completion can improve the coverage of Knowledge Graphs (KGs) by inducing new facts. Traditional methods for completion use structural representations in embedding space, but textual information can also be helpful. Recently, pre-trained language models have shown impressive performance on natural language processing tasks. KG-BERT is a pre-trained language model that is used for knowledge graph completion and achieves appealing performance. However, KG-BERT struggles when the number of facts is inadequate. We consider the inadequacy of data for various relations and the compensation for sparsity via data augmentation. We propose two knowledge graph data augmentation methods to generate facts with novel relations. Specifically, multi-hop relations between two entities are extracted to form multi-hop facts, and implicit relations are generated by horn rules. Moreover, we find multi-hop facts are useful for few-shot learning scenarios. Our system improves the performance of KG-BERT regarding the accuracy of the link prediction task. The experimental results demonstrate that our models make significant enhancements for KG-BERT on several knowledge graph completion benchmarks (e.g., WN18RR and UMLS). © 2023 Copyright for this paper by its authors.",Final,
Anand A.; Prasad K.; Goel U.; Gupta M.; Lal N.; Verma A.; Shah R.R.,"Anand, Avinash (58508044100); Prasad, Kritarth (57199760710); Goel, Ujjwal (58778218800); Gupta, Mohit (58825226300); Lal, Naman (58205141600); Verma, Astha (57661763200); Shah, Rajiv Ratn (56121902800)",58508044100; 57199760710; 58778218800; 58825226300; 58205141600; 57661763200; 56121902800,Context-Enhanced Language Models for Generating Multi-paper Citations,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180532354&doi=10.1007%2f978-3-031-49601-1_6&partnerID=40&md5=fd71ef30d11bfae8b754b6d245d73761,"Citation text plays a pivotal role in elucidating the connection between scientific documents, demanding an in-depth comprehension of the cited paper. Constructing citations is often time-consuming, requiring researchers to delve into extensive literature and grapple with articulating relevant content. To address this challenge, the field of citation text generation (CTG) has emerged. However, while earlier methods have primarily centered on creating single-sentence citations, practical scenarios frequently necessitate citing multiple papers within a single paragraph. To bridge this gap, we propose a method that leverages Large Language Models (LLMs) to generate multi-citation sentences. Our approach involves a single source paper and a collection of target papers, culminating in a coherent paragraph containing multi-sentence citation text. Furthermore, we introduce a curated dataset named MCG-S2ORC, composed of English-language academic research papers in Computer Science, showcasing multiple citation instances. In our experiments, we evaluate three LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this endeavor. Additionally, we exhibit enhanced performance by integrating knowledge graphs from target papers into the prompts for generating citation text. This research underscores the potential of harnessing LLMs for citation generation, opening a compelling avenue for exploring the intricate connections between scientific documents. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Shomer H.; Ma Y.; Li J.; Wu B.; Aggarwal C.C.; Tang J.,"Shomer, Harry (57713283500); Ma, Yao (57201255717); Li, Juanhui (57192109219); Wu, Bo (57734918200); Aggarwal, Charu C. (7006797289); Tang, Jiliang (56245477300)",57713283500; 57201255717; 57192109219; 57734918200; 7006797289; 56245477300,Distance-Based Propagation for Efficient Knowledge Graph Reasoning,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808692&partnerID=40&md5=993213a1b35de7d4b2fe6a5a23a5df33,"Knowledge graph completion (KGC) aims to predict unseen edges in knowledge graphs (KGs), resulting in the discovery of new facts. A new class of methods have been proposed to tackle this problem by aggregating path information. These methods have shown tremendous ability in the task of KGC. However they are plagued by efficiency issues. Though there are a few recent attempts to address this through learnable path pruning, they often sacrifice the performance to gain efficiency. In this work, we identify two intrinsic limitations of these methods that affect the efficiency and representation quality. To address the limitations, we introduce a new method, TAGNet, which is able to efficiently propagate information. This is achieved by only aggregating paths in a fixed window for each source-target pair. We demonstrate that the complexity of TAGNet is independent of the number of layers. Extensive experiments demonstrate that TAGNet can cut down on the number of propagated messages by as much as 90% while achieving competitive performance on multiple KG datasets. ©2023 Association for Computational Linguistics.",Final,
Rajpal S.; Usbeck R.,"Rajpal, Shreya (57204283557); Usbeck, Ricardo (43661711000)",57204283557; 43661711000,BERTologyNavigator: Advanced Question Answering with BERT-based Semantics,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180554489&partnerID=40&md5=f6c27c1a723639b8d0c67728dd67e8f6,"The development and integration of knowledge graphs and language models has significance in artificial intelligence and natural language processing. In this study, we introduce the BERTologyNavigator- a two-phased system that combines relation extraction techniques and BERT embeddings to navigate the relationships within the DBLP Knowledge Graph (KG). Our approach focuses on extracting one-hop relations and labelled candidate pairs in the first phases. This is followed by employing BERT's CLS embeddings and additional heuristics for relation selection in the second phase. Our system reaches an F1 score of 0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score on the subset of the DBLP QuAD test dataset during the QA phase. © 2023 CEUR-WS. All rights reserved.",Final,
Hu Z.; Gutiérrez-Basulto V.; Xiang Z.; Li R.; Pan J.Z.,"Hu, Zhiwei (57204826103); Gutiérrez-Basulto, Víctor (36607853700); Xiang, Zhiliang (57701809900); Li, Ru (57192310904); Pan, Jeff Z. (8856621200)",57204826103; 36607853700; 57701809900; 57192310904; 8856621200,Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184819864&partnerID=40&md5=7934e2526f23ee2db1d9baef6cee6de0,"Knowledge graph entity typing (KGET) aims at inferring plausible types of entities in knowledge graphs. Existing approaches to KGET focus on how to better encode the knowledge provided by the neighbors and types of an entity into its representation. However, they ignore the semantic knowledge provided by the way in which types can be clustered together. In this paper, we propose a novel method called Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET), which effectively encodes the coarse-grained knowledge provided by clusters into entity and type embeddings. MCLET is composed of three modules: i) Multi-view Generation and Encoder module, which encodes structured information from entity-type, entity-cluster and cluster-type views; ii) Cross-view Contrastive Learning module, which encourages different views to collaboratively improve view-specific representations of entities and types; iii) Entity Typing Prediction module, which integrates multi-head attention and a Mixture-of-Experts strategy to infer missing entity types. Extensive experiments show the strong performance of MCLET compared to the state-of-the-art. ©2023 Association for Computational Linguistics.",Final,
Wu Z.; Li R.; Guo J.; Wang Z.; Liang C.,"Wu, Zhengqian (58759418600); Li, Ruizhe (58759456800); Guo, Jiahao (58575838100); Wang, Zhongyuan (57203515592); Liang, Chao (35409725100)",58759418600; 58759456800; 58575838100; 57203515592; 35409725100,A Deep Understanding Video Q&A System for Film Education in Acting Department,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665653&doi=10.1109%2fIEIR59294.2023.10391232&partnerID=40&md5=1239aa0b36ed5beef56c7df5242d6a9a,"Recently, advancements in artificial intelligence technology have greatly influenced the field of education, particularly in the area of intelligent homework assistance. However, current approaches are primarily designed for procedural and logical tasks and often lack comprehension abilities. This limitation is particularly evident when it comes to multi-hop and continuous tasks. To address this challenge, the integration of Large Language Model (LLM) has significantly enhanced the capability of AI systems to handle multi-hop and highly interconnected inputs. In this study, we focus on the learning needs of students in Acting Department, specifically their study of movies and the significance of classic movie videos in their learning process. However, assessing deep comprehension of classic movies poses its own challenges. To overcome these challenges, we develop a quiz system utilizing Knowledge Graphs (KG) and LLM to facilitate a deeper understanding of classic films. The generation of video quiz pairs is achieved through the use of Automatic Speech Recognition (ASR) technology, which leverages movie subtitles for question generation. For answering these questions, we employ techniques KG and LLM to process questions and retrieve corresponding answers. The proposed method achieves good performance in Deep Video Understanding (DVU) task of NIST TRECVID, demonstrating its effectiveness.  © 2023 IEEE.",Final,
Yang Y.; Huang H.; Liu Y.; Gao Y.,"Yang, Yizhe (57549570000); Huang, Heyan (7405614195); Liu, Yuhang (57189344893); Gao, Yang (56333535500)",57549570000; 7405614195; 57189344893; 56333535500,Graph vs. Sequence: An Empirical Study on Knowledge Forms for Knowledge-Grounded Dialogue,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184825299&partnerID=40&md5=9341cf335f8d5c9824d04970a4f6cc85,"Knowledge-grounded dialogue is a task of generating an informative response based on both the dialogue history and external knowledge source. In general, there are two forms of knowledge: manually annotated knowledge graphs and knowledge text from website. From various evaluation viewpoints, each type of knowledge has advantages and downsides. To further distinguish the principles and determinants from the intricate factors, we conduct a thorough experiment and study on the task to answer three essential questions. The questions involve the choice of appropriate knowledge form, the degree of mutual effects between knowledge and the model selection, and the few-shot performance of knowledge. Supported by statistical shreds of evidence, we offer conclusive solutions and sensible suggestions for directions and standards of future research. ©2023 Association for Computational Linguistics.",Final,
Li J.; Wang Q.; Liu Y.; Zhang L.; Mao Z.,"Li, Jiaang (58202375700); Wang, Quan (55584980300); Liu, Yi (58748512200); Zhang, Licheng (57312168200); Mao, Zhendong (29467706600)",58202375700; 55584980300; 58748512200; 57312168200; 29467706600,Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation,,-1,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184809787&partnerID=40&md5=779f7466ea8e85c10f8e3eefa6632743,"Representation Learning on Knowledge Graphs (KGs) is essential for downstream tasks. The dominant approach, KG Embedding (KGE), represents entities with independent vectors and faces the scalability challenge. Recent studies propose an alternative way for parameter efficiency, which represents entities by composing entity-corresponding codewords matched from predefined small-scale codebooks. We refer to the process of obtaining corresponding codewords of each entity as entity quantization, for which previous works have designed complicated strategies. Surprisingly, this paper shows that simple random entity quantization can achieve similar results to current strategies. We analyze this phenomenon and reveal that entity codes, the quantization outcomes for expressing entities, have higher entropy at the code level and Jaccard distance at the codeword level under random entity quantization. Therefore, different entities become more easily distinguished, facilitating effective KG representation. The above results show that current quantization strategies are not critical for KG representation, and there is still room for improvement in entity distinguishability beyond current strategies. The code to reproduce our results is available here. ©2023 Association for Computational Linguistics.",Final,
Han Z.; Ding Z.; Ma Y.; Gu Y.; Tresp V.,"Han, Zhen (57219766233); Ding, Zifeng (57260888700); Ma, Yunpu (57194413081); Gu, Yujia (57260779700); Tresp, Volker (6603805670)",57219766233; 57260888700; 57194413081; 57260779700; 6603805670,Learning Neural Ordinary Equations for Forecasting Future Links on Temporal Knowledge Graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123503812&partnerID=40&md5=258c5ad249e1fa19a1ec8e9d437af989,"There has been an increasing interest in inferring future links on temporal knowledge graphs (KG). While links on temporal KGs vary continuously over time, the existing approaches model the temporal KGs in discrete state spaces. To this end, we propose a novel continuum model by extending the idea of neural ordinary differential equations (ODEs) to multi-relational graph convolutional networks. The proposed model preserves the continuous nature of dynamic multi-relational graph data and encodes both temporal and structural information into continuous-time dynamic embeddings. In addition, a novel graph transition layer is applied to capture the transitions on the dynamic graph, i.e., edge formation and dissolution. We perform extensive experiments on five benchmark datasets for temporal KG reasoning; showing our model's superior performance on the future link forecasting task. © 2021 Association for Computational Linguistics",Final,
Du L.; Ding X.; Liu T.; Qin B.,"Du, Li (57216695850); Ding, Xiao (56375894000); Liu, Ting (57199476645); Qin, Bing (8575883100)",57216695850; 56375894000; 57199476645; 8575883100,Learning event graph knowledge for abductive reasoning,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118921647&partnerID=40&md5=f752f2d33a418531b0826cedefd96ca0,"Abductive reasoning aims at inferring the most plausible explanation for observed events, which would play critical roles in various NLP applications, such as reading comprehension and question answering. To facilitate this task, a narrative text based abductive reasoning task aNLI is proposed, together with explorations about building reasoning framework using pretrained language models. However, abundant event commonsense knowledge is not well exploited for this task. To fill this gap, we propose a variational autoencoder based model ege-RoBERTa, which employs a latent variable to capture the necessary commonsense knowledge from event graph for guiding the abductive reasoning task. Experimental results show that through learning the external event graph knowledge, our approach outperforms the baseline methods on the aNLI task. © 2021 Association for Computational Linguistics",Final,
Zhao H.; Yuan S.; Leng J.; Pan X.; Xue Z.; Ma Q.; Liang Y.,"Zhao, Hanyu (57203149266); Yuan, Sha (57205187114); Leng, Jiahong (57232986100); Pan, Xiang (57231843700); Xue, Zhao (57232299500); Ma, Quanyue (57232758300); Liang, Yangxiao (57231609500)",57203149266; 57205187114; 57232986100; 57231843700; 57232299500; 57232758300; 57231609500,A Chinese Machine Reading Comprehension Dataset Automatic Generated Based on Knowledge Graph,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113578050&doi=10.1007%2f978-3-030-84186-7_18&partnerID=40&md5=e17697829fea1c40d22e12c9ef982cff,"Machine reading comprehension (MRC) is a typical natural language processing (NLP) task and has developed rapidly in the last few years. Various reading comprehension datasets have been built to support MRC studies. However, large-scale and high-quality datasets are rare due to the high complexity and huge workforce cost of making such a dataset. Besides, most reading comprehension datasets are in English, and Chinese datasets are insufficient. In this paper, we propose an automatic method for MRC dataset generation, and build the largest Chinese medical reading comprehension dataset presently named CMedRC. Our dataset contains 17k questions generated by our automatic method and some seed questions. We obtain the corresponding answers from a medical knowledge graph and manually check all of them. Finally, we test BiLSTM and BERT-based pre-trained language models (PLMs) on our dataset and propose a baseline for the following studies. Results show that the automatic MRC dataset generation method is considerable for future model improvements. © 2021, Springer Nature Switzerland AG.",Final,
Jambor D.; Teru K.; Pineau J.; Hamilton W.L.,"Jambor, Dora (57219527395); Teru, Komal (57219492015); Pineau, Joelle (13404973100); Hamilton, William L. (56096744700)",57219527395; 57219492015; 13404973100; 56096744700,Exploring the limits of few-shot link prediction in knowledge graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107317130&partnerID=40&md5=c6cabb1b38515022d246bb29aa33ffb5,"Real-world knowledge graphs are often characterized by low-frequency relations-a challenge that has prompted an increasing interest in few-shot link prediction methods. These methods perform link prediction for a set of new relations, unseen during training, given only a few example facts of each relation at test time. In this work, we perform a systematic study on a spectrum of models derived by generalizing the current state of the art for few-shot link prediction, with the goal of probing the limits of learning in this few-shot setting. We find that a simple zero-shot baseline-which ignores any relation-specific information-achieves surprisingly strong performance. Moreover, experiments on carefully crafted synthetic datasets show that having only a few examples of a relation fundamentally limits models from using fine-grained structural information and only allows for exploiting the coarse-grained positional information of entities. Together, our findings challenge the implicit assumptions and inductive biases of prior work and highlight new directions for research in this area. © 2021 Association for Computational Linguistics",Final,
Lovera F.; Cardinale Y.; Buscaldi D.; Charnois T.; Homsi M.N.,"Lovera, Fernando (57226596225); Cardinale, Yudith (8963079200); Buscaldi, Davide (55930335200); Charnois, Thierry (6507953398); Homsi, Masun Nabhan (24528430800)",57226596225; 8963079200; 55930335200; 6507953398; 24528430800,Deep learning enhanced with graph knowledge for sentiment analysis,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112083993&partnerID=40&md5=f6e86d7819591ee4655c859f97d0637e,"The traditional way to address the problem of sentiment classification is based on Machine Learning techniques; however, these models are not able to grasp all the richness of the text that comes from different social media, personal web pages, blogs, etc., ignoring the semantic of the text. Knowledge Graphs give a way to extract structured knowledge from images and texts, in order to facilitate their semantic analysis. In this work, we propose a new hybrid approach for Sentiment Analysis based on Knowledge Graphs and Deep Learning techniques, to identify the sentiment polarity (positive or negative) in short documents, particularly in 3 tweets. We represent the tweets using graphs, then graph similarity metrics and a Deep Learning classification algorithm are applied to produce sentiment predictions. This approach facilitates the traceability and explainability of the classification results, since it is possible to visually inspect the graphs. We compare our proposal with character n-gram embeddings based Deep Learning models to perform Sentiment Analysis. Results show that our proposal is able to outperforms classical n-gram models, with a recall up to 89% and F1-score of 88%.  © 2021 Copyright for this paper by its authors.",Final,
Shen X.; Chen J.; Xiao Y.,"Shen, Xinyao (57314304200); Chen, Jiangjie (57209507608); Xiao, Yanghua (24377046200)",57314304200; 57209507608; 24377046200,Diversified Paraphrase Generation with Commonsense Knowledge Graph,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118146205&doi=10.1007%2f978-3-030-88480-2_28&partnerID=40&md5=f991dfd535e9f3e29009580feb424211,"Paraphrases refer to text with different expressions conveying the same meaning, which is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Traditional Seq2Seq models mainly concentrate on fidelity while ignoring the diversity of paraphrases. Although recent studies begin to focus on the diversity of generated paraphrases, they either adopt inflexible control mechanisms or restrict to synonyms and topic knowledge. In this paper, we propose KnowledgE-Enhanced Paraphraser (KEEP) for diversified paraphrase generation, which leverages a commonsense knowledge graph to explicitly enrich the expressions of paraphrases. Specifically, KEEP retrieves word-level and phrase-level knowledge from an external knowledge graph, and learns to choose more related ones using graph attention mechanism. Extensive experiments on benchmarks of paraphrase generation show the strengths especially in the diversity of our proposed model compared with several strong baselines. © 2021, Springer Nature Switzerland AG.",Final,
Peng X.; Chen G.; Lin C.; Stevenson M.,"Peng, Xutan (57216844829); Chen, Guanyi (57216703480); Lin, Chenghua (35322970500); Stevenson, Mark (57205888219)",57216844829; 57216703480; 35322970500; 57205888219,Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116722893&partnerID=40&md5=71c08e8d00736df436e8b35d9b2213f8,"Knowledge Graph Embeddings (KGEs) have been intensively explored in recent years due to their promise for a wide range of applications. However, existing studies focus on improving the final model performance without acknowledging the computational cost of the proposed approaches, in terms of execution time and environmental impact. This paper proposes a simple yet effective KGE framework which can reduce the training time and carbon footprint by orders of magnitudes compared with state-of-the-art approaches, while producing competitive performance. We highlight three technical innovations: full batch learning via relational matrices, closed-form Orthogonal Procrustes Analysis for KGEs, and non-negative-sampling training. In addition, as the first KGE method whose entity embeddings also store full relation information, our trained models encode rich semantics and are highly interpretable. Comprehensive experiments and ablation studies involving 13 strong baselines and two standard datasets verify the effectiveness and efficiency of our algorithm. © 2021 Association for Computational Linguistics.",Final,
Pramanick A.; Bhattacharya I.,"Pramanick, Aniket (57199053591); Bhattacharya, Indrajit (14024110800)",57199053591; 14024110800,"Joint learning of representations for web-tables, entities and types using graph convolutional network",,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107282503&partnerID=40&md5=6fb6b4f0ff73a69c338af18f7347d97e,"Existing approaches for table annotation with entities and types either capture the structure of table using graphical models, or learn embeddings of table entries without accounting for the complete syntactic structure. We propose TabGCN, which uses Graph Convolutional Networks to capture the complete structure of tables, knowledge graph and the training annotations, and jointly learns embeddings for table elements as well as the entities and types. To account for knowledge incompleteness, TabGCN's embeddings can be used to discover new entities and types. Using experiments on 5 benchmark datasets, we show that TabGCN significantly outperforms multiple state-of-the-art baselines for table annotation, while showing promising performance on downstream table-related applications. © 2021 Association for Computational Linguistics",Final,
Sun P.; Gu L.,"Sun, Pingping (57221920804); Gu, Lingang (57221914139)",57221920804; 57221914139,Fuzzy knowledge graph system for artificial intelligence-based smart education,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100537501&doi=10.3233%2fJIFS-189332&partnerID=40&md5=8674f773cfca5ecb4006776cda59d2f5,"Fuzzy knowledge graph system is a semantic network that reveals the relationships between entities, and a tool or methodology that can formally describe things in the real world and their relationships. Smart education is an educational concept or model that uses advanced information technology to build a smart environment, integrates theory and practice to build an educational framework for information age, and provides paths to practice it. Artificial intelligence (AI) is a comprehensive discipline developed by the interpenetration of computer science, cybernetics, information theory, linguistics, neurophysiology and other disciplines, which is a direction for the development of information technology in the future. On the basis of summarizing and analyzing of previous research works, this paper expounded the research status and significance of AI technology, elaborated the development background, current status and future challenges of the construction and application of fuzzy knowledge graph system for smart education, introduced the methods and principles of data acquisition methods and digitalized apprenticeship, realized the process design, information extraction, entity recognition and relationship mining of smart education, constructed a systematic framework for fuzzy knowledge graph, and analyzed the high-quality resources sharing and personalized service of AI-Assisted smart education, discussed automatic knowledge acquisition and fusion of fuzzy knowledge graph, performed co-occurrence relationship analysis, and finally conducted application case analysis. The results show that the smart education knowledge graph for AI-Assisted smart education can integrate teaching experience and domain knowledge of discipline experts, enhance explainable and robust machine intelligence for AI-Assisted smart education, and provide data-driven and knowledge-driven information processing methods; it can also discover the analysis hotspots and main content of research objects through clustering of high-frequency topic words, reveal the corresponding research structure in depth, and then systematically explore its research dimensions, subject background and theoretical basis. © 2021-IOS Press. All rights reserved.",Final,
Srivastava S.; Patidar M.; Chowdhury S.; Agarwal P.; Bhattacharya I.; Shroff G.,"Srivastava, Saurabh (57213822605); Patidar, Mayur (57193614634); Chowdhury, Sudip (57224213316); Agarwal, Puneet (57197344914); Bhattacharya, Indrajit (14024110800); Shroff, Gautam (6601910743)",57213822605; 57193614634; 57224213316; 57197344914; 14024110800; 6601910743,Complex question answering on knowledge graphs using machine translation and multi-task learning,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107260439&partnerID=40&md5=c373d59afaff7a0f2c643c3999a4ce8c,"Question answering (QA) over a knowledge graph (KG) is a task of answering a natural language (NL) query using the information stored in KG. In a real-world industrial setting, this involves addressing multiple challenges including entity linking, multi-hop reasoning over KG, etc. Traditional approaches handle these challenges in a modularized sequential manner where errors in one module lead to the accumulation of errors in downstream modules. Often these challenges are inter-related and the solutions to them can reinforce each other when handled simultaneously in an end-to-end learning setup. To this end, we propose a multi-task BERT based Neural Machine Translation (NMT) model to address these challenges. Through experimental analysis, we demonstrate the efficacy of our proposed approach on one publicly available and one proprietary dataset. © 2021 Association for Computational Linguistics",Final,
Jin W.; Khanna R.; Kim S.; Lee D.-H.; Morstatter F.; Galstyan A.; Ren X.,"Jin, Woojeong (57193517627); Khanna, Rahul (57219734469); Kim, Suji (57226112832); Lee, Dong-Ho (57216623177); Morstatter, Fred (39061777700); Galstyan, Aram (7003679856); Ren, Xiang (58619993600)",57193517627; 57219734469; 57226112832; 57216623177; 39061777700; 7003679856; 58619993600,FORECASTQA: A question answering challenge for event forecasting with temporal text data,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116383221&partnerID=40&md5=8e5d61c3b75e48906c4e74e038d5425f,"Event forecasting is a challenging, yet important task, as humans seek to constantly plan for the future. Existing automated forecasting studies rely mostly on structured data, such as time-series or event-based knowledge graphs, to help predict future events. In this work, we aim to formulate a task, construct a dataset, and provide benchmarks for developing methods for event forecasting with large volumes of unstructured text data. To simulate the forecasting scenario on temporal news documents, we formulate the problem as a restricted-domain, multiple-choice, question-answering (QA) task. Unlike existing QA tasks, our task limits accessible information, and thus a model has to make a forecasting judgement. To showcase the usefulness of this task formulation, we introduce FORECASTQA, a question-answering dataset consisting of 10,392 event forecasting questions, which have been collected and verified via crowdsourcing efforts. We present our experiments on FORECASTQA using BERT-based models and find that our best model achieves 61.0% accuracy on the dataset, which still lags behind human performance by about 19%. We hope FORECASTQA will support future research efforts in bridging this gap. © 2021 Association for Computational Linguistics",Final,
Ma K.; Ilievski F.; Francis J.; Bisk Y.; Nyberg E.; Oltramari A.,"Ma, Kaixin (57219619491); Ilievski, Filip (57188757237); Francis, Jonathan (57194176946); Bisk, Yonatan (52163161300); Nyberg, Eric (7004097831); Oltramari, Alessandro (6506019992)",57219619491; 57188757237; 57194176946; 52163161300; 7004097831; 6506019992,Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100458691&partnerID=40&md5=b0c67ab2455abbae1823099dcff6fe62,"Recent developments in pre-trained neural language modeling have led to leaps in accuracy on commonsense question-answering benchmarks. However, there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zeroshot evaluations have shown promise as a more robust measure of a model's general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses, the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pretraining models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense questionanswering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Wang Q.; Yavuz S.; Lin X.V.; Ji H.; Rajani N.F.,"Wang, Qingyun (57207885167); Yavuz, Semih (57207854542); Lin, Xi Victoria (57205402852); Ji, Heng (35240121900); Rajani, Nazneen Fatema (37075761000)",57207885167; 57207854542; 57205402852; 35240121900; 37075761000,Stage-wise fine-tuning for graph-to-text generation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118925579&partnerID=40&md5=a1a35b41bc9a9938a14327a42fe16431,"Graph-to-text generation has benefited from pre-trained language models (PLMs) in achieving better performance than structured graph encoders. However, they fail to fully utilize the structure information of the input graph. In this paper, we aim to further improve the performance of the pre-trained language model by proposing a structured graph-to-text model with a two-step fine-tuning mechanism which first fine-tunes the model on Wikipedia before adapting to the graph-to-text generation. In addition to using the traditional token and position embeddings to encode the knowledge graph (KG), we propose a novel tree-level embedding method to capture the interdependency structures of the input graph. This new approach has significantly improved the performance of all text generation metrics for the English WebNLG 2017 dataset. © 2021 Association for Computational Linguistics.",Final,
Zhou B.; Cai X.; Zhang Y.; Yuan X.,"Zhou, Baohang (57221050137); Cai, Xiangrui (55954059800); Zhang, Ying (55954386400); Yuan, Xiaojie (57218614021)",57221050137; 55954059800; 55954386400; 57218614021,An end-to-end progressive multi-task learning framework for medical named entity recognition and normalization,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117375009&partnerID=40&md5=db96e7a7fb4422580e823536b0529333,"Medical named entity recognition (NER) and normalization (NEN) are fundamental for constructing knowledge graphs and building QA systems. Existing implementations for medical NER and NEN are suffered from the error propagation between the two tasks. The mispredicted mentions from NER will directly influence the results of NEN. Therefore, the NER module is the bottleneck of the whole system. Besides, the learnable features for both tasks are beneficial to improving the model performance. To avoid the disadvantages of existing models and exploit the generalized representation across the two tasks, we design an end-to-end progressive multi-task learning model for jointly modeling medical NER and NEN in an effective way. There are three level tasks with progressive difficulty in the framework. The progressive tasks can reduce the error propagation with the incremental task settings which implies the lower level tasks gain the supervised signals other than errors from the higher level tasks to improve their performances. Besides, the context features are exploited to enrich the semantic information of entity mentions extracted by NER. The performance of NEN profits from the enhanced entity mention features. The standard entities from knowledge bases are introduced into the NER module for extracting corresponding entity mentions correctly. The empirical results on two publicly available medical literature datasets demonstrate the superiority of our method over nine typical methods. © 2021 Association for Computational Linguistics",Final,
Dai Q.; Inoue N.; Takahashi R.; Inui K.,"Dai, Qin (57202889179); Inoue, Naoya (53877335300); Takahashi, Ryo (57196123404); Inui, Kentaro (35487508600)",57202889179; 53877335300; 57196123404; 35487508600,Two training strategies for improving relation extraction over universal graph,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107315579&partnerID=40&md5=c424387b6941ddb1decdff3e741a8211,"This paper explores how the Distantly Supervised Relation Extraction (DS-RE) can benefit from the use of a Universal Graph (UG), the combination of a Knowledge Graph (KG) and a large-scale text collection. A straightforward extension of a current state-of-the-art neural model for DS-RE with a UG may lead to degradation in performance. We first report that this degradation is associated with the difficulty in learning a UG and then propose two training strategies: (1) Path Type Adaptive Pretraining, which sequentially trains the model with different types of UG paths so as to prevent the reliance on a single type of UG path; and (2) Complexity Ranking Guided Attention mechanism, which restricts the attention span according to the complexity of a UG path so as to force the model to extract features not only from simple UG paths but also from complex ones. Experimental results on both biomedical and NYT10 datasets prove the robustness of our methods and achieve a new state-ofthe-art result on the NYT10 dataset. The code and datasets used in this paper are available at https://github.com/baodaiqin/ UGDSRE. © 2021 Association for Computational Linguistics",Final,
Biswas R.; Sofronova R.; Alam M.; Heist N.; Paulheim H.; Sack H.,"Biswas, Russa (57202431946); Sofronova, Radina (57219024016); Alam, Mehwish (57201532578); Heist, Nicolas (57196194675); Paulheim, Heiko (35095438500); Sack, Harald (7102918498)",57202431946; 57219024016; 57201532578; 57196194675; 35095438500; 7102918498,Do Judge an Entity by Its Name! Entity Typing Using Language Models,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115845674&doi=10.1007%2f978-3-030-80418-3_12&partnerID=40&md5=d4b7cc03fa214a9c6a9b54d6d76ee668,"The entity type information in a Knowledge Graph (KG) plays an important role in a wide range of applications in Natural Language Processing such as entity linking, question answering, relation extraction, etc. However, the available entity types are often noisy and incomplete. Entity Typing is a non-trivial task if enough information is not available for the entities in a KG. In this work, neural language models and a character embedding model are exploited to predict the type of an entity from only the name of the entity without any other information from the KG. The model has been successfully evaluated on a benchmark dataset. © 2021, Springer Nature Switzerland AG.",Final,
Jiang H.; Gurajada S.; Lu Q.; Neelam S.; Popa L.; Sen P.; Li Y.; Gray A.,"Jiang, Hang (57225218959); Gurajada, Sairam (35317349200); Lu, Qiuhao (57211255287); Neelam, Sumit (56319767900); Popa, Lucian (7006538930); Sen, Prithviraj (57201526762); Li, Yunyao (10739396100); Gray, Alexander (57213004841)",57225218959; 35317349200; 57211255287; 56319767900; 7006538930; 57201526762; 10739396100; 57213004841,LNN-EL: A neuro-symbolic approach to short-text entity linking,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118921105&partnerID=40&md5=574c8cee5c137482019988dffa5bacea,"Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or black-box neural methods, here we propose LNN-EL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than 4% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy. © 2021 Association for Computational Linguistics",Final,
Kacupaj E.; Plepi J.; Singh K.; Thakkar H.; Lehmann J.; Maleshkova M.,"Kacupaj, Endri (57211820469); Plepi, Joan (57222809799); Singh, Kuldeep (57212017864); Thakkar, Harsh (57190131577); Lehmann, Jens (35229806900); Maleshkova, Maria (36706361500)",57211820469; 57222809799; 57212017864; 57190131577; 35229806900; 36706361500,Conversational question answering over knowledge graphs with transformer and graph attention networks,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107293854&partnerID=40&md5=815093af9a707bd0294af27c66c66de1,"This paper addresses the task of (complex) conversational question answering over a knowledge graph. For this task, we propose LASAGNE (muLti-task semAntic parSing with trAnsformer and Graph atteNtion nEtworks). It is the first approach, which employs a transformer architecture extended with Graph Attention Networks for multi-task neural semantic parsing. LASAGNE uses a transformer model for generating the base logical forms, while the Graph Attention model is used to exploit correlations between (entity) types and predicates to produce node representations. LASAGNE also includes a novel entity recognition module which detects, links, and ranks all relevant entities in the question context. We evaluate LASAGNE on a standard dataset for complex sequential question answering, on which it outperforms existing baseline averages on all question types. Specifically, we show that LASAGNE improves the F1-score on eight out of ten question types; in some cases, the increase in F1-score is more than 20% compared to the state of the art. © 2021 Association for Computational Linguistics",Final,
Sun Z.; Chen M.; Hu W.,"Sun, Zequn (57191745946); Chen, Muhao (57077271100); Hu, Wei (57191221527)",57191745946; 57077271100; 57191221527,Knowing the no-match: Entity alignment with dangling cases,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117997109&partnerID=40&md5=0514e316a94e2cf1dedd4b5f5c1e3486,"This paper studies a new problem setting of entity alignment for knowledge graphs (KGs). Since KGs possess different sets of entities, there could be entities that cannot find alignment across them, leading to the problem of dangling entities. As the first attempt to this problem, we construct a new dataset and design a multi-task learning framework for both entity alignment and dangling entity detection. The framework can opt to abstain from predicting alignment for the detected dangling entities. We propose three techniques for dangling entity detection that are based on the distribution of nearest-neighbor distances, i.e., nearest neighbor classification, marginal ranking and background ranking. After detecting and removing dangling entities, an incorporated entity alignment model in our framework can provide more robust alignment for remaining entities. Comprehensive experiments and analyses demonstrate the effectiveness of our framework. We further discover that the dangling entity detection module can, in turn, improve alignment learning and the final performance. The contributed resource is publicly available to foster further research. © 2021 Association for Computational Linguistics",Final,
Li J.; Tang T.; Zhao W.X.; Wei Z.; Yuan N.J.; Wen J.-R.,"Li, Junyi (57215097872); Tang, Tianyi (57222076359); Zhao, Wayne Xin (36769862300); Wei, Zhicheng (57219876432); Yuan, Nicholas Jing (55818206900); Wen, Ji-Rong (7402697777)",57215097872; 57222076359; 36769862300; 57219876432; 55818206900; 7402697777,Few-shot Knowledge Graph-to-Text Generation with Pretrained Language Models,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108081957&partnerID=40&md5=797d120e91b0571f1178771fc49088c7,"This paper studies how to automatically generate a natural language text that describes the facts in knowledge graph (KG). Considering the few-shot setting, we leverage the excellent capacities of pretrained language models (PLMs) in language understanding and generation. We make three major technical contributions, namely representation alignment for bridging the semantic gap between KG encodings and PLMs, relation-biased KG linearization for deriving better input representations, and multi-task learning for learning the correspondence between KG and text. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our model on KG-to-text generation task. In particular, our model outperforms all comparison methods on both fully-supervised and few-shot settings. Our code and datasets are available at https://github.com/RUCAIBox/Few-Shot-KG2Text. © 2021 Association for Computational Linguistics",Final,
Hu Z.; Cao Y.; Huang L.; Chua T.-S.,"Hu, Zikun (57209225981); Cao, Yixin (57015851100); Huang, Lifu (57193240973); Chua, Tat-Seng (7101702977)",57209225981; 57015851100; 57193240973; 7101702977,How knowledge graph and attention help? A quantitative analysis into bag-level relation extraction,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118918083&partnerID=40&md5=1922ab36dc0690e7e80b7f56f3bf47f8,"Knowledge Graph (KG) and attention mechanism have been demonstrated effective in introducing and selecting useful information for weakly supervised methods. However, only qualitative analysis and ablation study are provided as evidence. In this paper, we contribute a dataset and propose a paradigm to quantitatively evaluate the effect of attention and KG on bag-level relation extraction (RE). We find that (1) higher attention accuracy may lead to worse performance as it may harm the model's ability to extract entity mention features; (2) the performance of attention is largely influenced by various noise distribution patterns, which is closely related to real-world datasets; (3) KG-enhanced attention indeed improves RE performance, while not through enhanced attention but by incorporating entity prior; and (4) attention mechanism may exacerbate the issue of insufficient training data. Based on these findings, we show that a straightforward variant of RE model can achieve significant improvements (6% AUC on average) on two real-world datasets as compared with three state-of-the-art baselines. Our codes and datasets are available at https://github.com/zigkwin-hu/how-KG-ATT-help. © 2021 Association for Computational Linguistics",Final,
Tian X.; Jing L.; He L.; Liu F.,"Tian, Xuetao (57197750211); Jing, Liping (8893085600); He, Lu (57331618700); Liu, Feng (57195394660)",57197750211; 8893085600; 57331618700; 57195394660,StereoRel: Relational triple extraction from a stereoscopic perspective,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118920822&partnerID=40&md5=d062c0d70e55a67157992b450c431427,"Relational triple extraction is critical to understanding massive text corpora and constructing large-scale knowledge graph, which has attracted increasing research interest. However, existing studies still face some challenging issues, including information loss, error propagation and ignoring the interaction between entity and relation. To intuitively explore the above issues and address them, in this paper, we provide a revealing insight into relational triple extraction from a stereoscopic perspective, which rationalizes the occurrence of these issues and exposes the shortcomings of existing methods. Further, a novel model is proposed for relational triple extraction, which maps relational triples to a three-dimension (3-D) space and leverages three decoders to extract them, aimed at simultaneously handling the above issues. Extensive experiments are conducted on five public datasets, demonstrating that the proposed model outperforms the recent advanced baselines. © 2021 Association for Computational Linguistics",Final,
Tang J.; Lin H.; Liao M.; Lu Y.; Han X.; Sun L.; Xie W.; Xu J.,"Tang, Jialong (57210426452); Lin, Hongyu (57207858382); Liao, Meng (57223908219); Lu, Yaojie (57198799378); Han, Xianpei (35302334000); Sun, Le (55453689000); Xie, Weijian (57225959594); Xu, Jin (57213421781)",57210426452; 57207858382; 57223908219; 57198799378; 35302334000; 55453689000; 57225959594; 57213421781,From discourse to narrative: Knowledge projection for event relation extraction,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118945669&partnerID=40&md5=30495c3a9ae19013e165f78aa3a99c07,"Current event-centric knowledge graphs highly rely on explicit connectives to mine relations between events. Unfortunately, due to the sparsity of connectives, these methods severely undermine the coverage of EventKGs. The lack of high-quality labelled corpora further exacerbates that problem. In this paper, we propose a knowledge projection paradigm for event relation extraction: projecting discourse knowledge to narratives by exploiting the commonalities between them. Specifically, we propose Multi-tier Knowledge Projection Network (MKPNet), which can leverage multi-tier discourse knowledge effectively for event relation extraction.In this way, the labelled data requirement is significantly reduced, and implicit event relations can be effectively extracted. Intrinsic experimental results show that MKPNet achieves the new state-of-the-art performance, and extrinsic experimental results verify the value of the extracted event relations. © 2021 Association for Computational Linguistics",Final,
Orogat A.; Liu I.; El-Roby A.,"Orogat, Abdelghny (57192382907); Liu, Isabelle (57224546750); El-Roby, Ahmed (55975785300)",57192382907; 57224546750; 55975785300,Cbench: Towards better evaluation of question answering knowledge graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115299221&doi=10.14778%2f3457390.3457398&partnerID=40&md5=166f214eb8cc635f55359211a1100b16,"Recently, there has been an increase in the number of knowledge graphs that can be only queried by experts. However, describing questions using structured queries is not straightforward for non-expert users who need to have sufficient knowledge about both the vocabulary and the structure of the queried knowledge graph, as well as the syntax of the structured query language used to describe the user’s information needs. The most popular approach introduced to overcome the aforementioned challenges is to use natural language to query these knowledge graphs. Although several question answering benchmarks can be used to evaluate question-answering systems over a number of popular knowledge graphs, choosing a benchmark to accurately assess the quality of a question answering system is a challenging task. In this paper, we introduce CBench, an extensible, and more informative benchmarking suite for analyzing benchmarks and evaluating question answering systems. CBench can be used to analyze existing benchmarks with respect to several fine-grained linguistic, syntactic, and structural properties of the questions and queries in the benchmark. We show that existing benchmarks vary significantly with respect to these properties deeming choosing a small subset of them unreliable in evaluating QA systems. Until further research improves the quality and comprehensiveness of benchmarks, CBench can be used to facilitate this evaluation using a set of popular benchmarks that can be augmented with other user-provided benchmarks. CBench not only evaluates a question answering system based on popular single-number metrics but also gives a detailed analysis of the linguistic, syntactic, and structural properties of answered and unanswered questions to better help the developers of question answering systems to better understand where their system excels and where it struggles. © 2021, VLDB Endowment. All rights reserved.",Final,
Lovelace J.; Newman-Griffis D.; Vashishth S.; Lehman J.F.; Rosé C.P.,"Lovelace, Justin (57219816779); Newman-Griffis, Denis (57201858761); Vashishth, Shikhar (57191342794); Lehman, Jill Fain (7101828013); Rosé, Carolyn Penstein (8097137900)",57219816779; 57201858761; 57191342794; 7101828013; 8097137900,Robust knowledge graph completion with stacked convolutions and a student re-ranking network,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118936605&partnerID=40&md5=b6284df2ab42d3d9861f9514700dc6f4,Knowledge Graph (KG) completion research usually focuses on densely connected benchmark datasets that are not representative of real KGs. We curate two KG datasets that include biomedical and encyclopedic knowledge and use an existing commonsense KG dataset to explore KG completion in the more realistic setting where dense connectivity is not guaranteed. We develop a deep convolutional network that utilizes textual entity representations and demonstrate that our model outperforms recent KG completion methods in this challenging setting. We find that our model's performance improvements stem primarily from its robustness to sparsity. We then distill the knowledge from the convolutional network into a student network that re-ranks promising candidate entities. This re-ranking stage leads to further improvements in performance and demonstrates the effectiveness of entity re-ranking for KG completion. © 2021 Association for Computational Linguistics,Final,
Xu C.; Chen Y.-Y.; Nayyeri M.; Lehmann J.,"Xu, Chengjin (57195741972); Chen, Yung-Yu (57223092413); Nayyeri, Mojtaba (35776892400); Lehmann, Jens (35229806900)",57195741972; 57223092413; 35776892400; 35229806900,Temporal Knowledge Graph Completion using a Linear Temporal Regularizer and Multivector Embeddings,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115881799&partnerID=40&md5=859204245d04c710f769ab061e73760b,"Representation learning approaches for knowledge graphs have been mostly designed for static data. However, many knowledge graphs involve evolving data, e.g., the fact (The President of the United States is Barack Obama) is valid only from 2009 to 2017. This introduces important challenges for knowledge representation learning since the knowledge graphs change over time. In this paper, we present a novel time-aware knowledge graph em-bebdding approach, TeLM, which performs 4th-order tensor factorization of a Temporal knowledge graph using a Linear temporal regularizer and Multivector embeddings. Moreover, we investigate the effect of the temporal dataset’s time granularity on temporal knowledge graph completion. Experimental results demonstrate that our proposed models trained with the linear temporal regularizer achieve the state-of-the-art performances on link prediction over four well-established temporal knowledge graph completion benchmarks. © 2021 Association for Computational Linguistics.",Final,
Kamigaito H.; Hayashi K.,"Kamigaito, Hidetaka (55579307700); Hayashi, Katsuhiko (55628535930)",55579307700; 55628535930,Unified interpretation of softmax cross-entropy and negative sampling: With case study for knowledge graph embedding,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118917947&partnerID=40&md5=03e4e46dc3e44c9b9cb6012d8c630fdb,"In knowledge graph embedding, the theoretical relationship between the softmax cross-entropy and negative sampling loss functions has not been investigated. This makes it difficult to fairly compare the results of the two different loss functions. We attempted to solve this problem by using the Bregman divergence to provide a unified interpretation of the softmax cross-entropy and negative sampling loss functions. Under this interpretation, we can derive theoretical findings for fair comparison. Experimental results on the FB15k-237 and WN18RR datasets show that the theoretical findings are valid in practical settings. © 2021 Association for Computational Linguistics",Final,
Batini C.; Rula A.,"Batini, Carlo (7006303555); Rula, Anisa (53980361500)",7006303555; 53980361500,From data quality to big data quality: A data integration scenario,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118786399&partnerID=40&md5=e468e8b4e0865e0c476926ba18223929,"Big data has made its appearance in many fields, including scientific research, business, public administration and so on. Although, it is acknowledged that there exist different aspects (e.g., acquisition of data, extraction, pre-processing, analysis modelling and functionality, interpretation, etc.) that might affect the benefit of such data, several authors identify data quality as the most decisive one. More recently, a variety of data types have arisen from linguistic and visual information, used and diffused through social networks, Internet of things, enterprise and public sector information systems as well as the Web. The big data phenomenon has deeply impacted on the diversity of types of data. In our previous work, we provided a deep investigation on how data quality concepts can be extended to such vast set of data types, encompassing, e.g., semi-structured texts, maps, images and linked data. In this work, we focus on Linked Data, a type of data that can be viewed as big data and study the effect of data quality in a data integration scenario. © 2021 Copyright for this paper by its authors.",Final,
Zhang S.; Rao X.; Tay Y.; Zhang C.,"Zhang, Shuai (57195627262); Rao, Xi (57219545790); Tay, Yi (57193627780); Zhang, Ce (58502033600)",57195627262; 57219545790; 57193627780; 58502033600,KNOWLEDGE ROUTER: Learning Disentangled Representations for Knowledge Graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115721438&partnerID=40&md5=14ef528c286983168c0f1d39cb0ebed6,"The design of expressive representations of entities and relations in a knowledge graph is an important endeavor. While many of the existing approaches have primarily focused on learning from relational patterns and structural information, the intrinsic complexity of KG entities has been more or less overlooked. More concretely, we hypothesize KG entities may be more complex than we think, i.e., an entity may wear many hats and relational triplets may form due to more than a single reason. To this end, this paper proposes to learn disentangled representations of KG entities - a new method that disentangles the inner latent properties of KG entities. Our disentangled process operates at the graph level and a neighborhood mechanism is leveraged to disentangle the hidden properties of each entity. This disentangled representation learning approach is model agnostic and compatible with canonical KG embedding approaches. We conduct extensive experiments on several benchmark datasets, equipping a variety of models (DistMult, SimplE, and QuatE) with our proposed disentangling mechanism. Experimental results demonstrate that our proposed approach substantially improves performance on key metrics. © 2021 Association for Computational Linguistics.",Final,
Choi B.; Jang D.; Ko Y.,"Choi, Bonggeun (57263655600); Jang, Daesik (57262926800); Ko, Youngjoong (8082612400)",57263655600; 57262926800; 8082612400,MEM-KGC: Masked Entity Model for Knowledge Graph Completion with Pre-Trained Language Model,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115164523&doi=10.1109%2fACCESS.2021.3113329&partnerID=40&md5=bbe48818c7904f5ca87bf7bcdaa3285c,"The knowledge graph completion (KGC) task aims to predict missing links in knowledge graphs. Recently, several KGC models based on translational distance or semantic matching methods have been proposed and have achieved meaningful results. However, existing models have a significant shortcoming-they cannot train entity embedding when an entity does not appear in the training phase. As a result, such models use randomly initialized embeddings for entities that are unseen in the training phase and cause a critical decrease in performance during the test phase. To solve this problem, we propose a new approach that performs KGC task by utilizing the masked language model (MLM) that is used for a pre-trained language model. Given a triple (head entity, relation, tail entity), we mask the tail entity and consider the head entity and the relation as a context for the tail entity. The model then predicts the masked entity from among all entities. Then, the task is conducted by the same process as an MLM, which predicts a masked token with a given context of tokens. Our experimental results show that the proposed model achieves significantly improved performances when unseen entities appear during the test phase and achieves state-of-the-art performance on the WN18RR dataset.  © 2013 IEEE.",Final,All Open Access; Gold Open Access
Jiang Z.; Han J.; Sisman B.; Dong X.L.,"Jiang, Zhengbao (57216621895); Han, Jialong (56170972000); Sisman, Bunyamin (55339063700); Dong, Xin Luna (55800289000)",57216621895; 56170972000; 55339063700; 55800289000,CoRI: Collective relation integration with data augmentation for open information extraction,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118924156&partnerID=40&md5=52901fd9d1dbc55fe9040f4e8adcee72,"Integrating extracted knowledge from the Web to knowledge graphs (KGs) can facilitate tasks like question answering. We study relation integration that aims to align free-text relations in subject-relation-object extractions to relations in a target KG. To address the challenge that free-text relations are ambiguous, previous methods exploit neighbor entities and relations for additional context. However, the predictions are made independently, which can be mutually inconsistent. We propose a two-stage Collective Relation Integration (CoRI) model, where the first stage independently makes candidate predictions, and the second stage employs a collective model that accesses all candidate predictions to make globally coherent predictions. We further improve the collective model with augmented data from the portion of the target KG that is otherwise unused. Experiment results on two datasets show that CoRI can significantly outperform the baselines, improving AUC from.677 to.748 and from.716 to.780, respectively. © 2021 Association for Computational Linguistics",Final,
Xu Y.; Zhu C.; Xu R.; Liu Y.; Zeng M.; Huang X.,"Xu, Yichong (57195953104); Zhu, Chenguang (57210636804); Xu, Ruochen (57220778246); Liu, Yang (57221696273); Zeng, Michael (57211638200); Huang, Xuedong (7410247202)",57195953104; 57210636804; 57220778246; 57221696273; 57211638200; 7410247202,Fusing Context Into Knowledge Graph for Commonsense Question Answering,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115832574&partnerID=40&md5=7425b6b9b4a6af9dc783b70372eba7ed,"Commonsense question answering (QA) requires a model to grasp commonsense and factual knowledge to answer questions about world events. Many prior methods couple language modeling with knowledge graphs (KG). However, although a KG contains rich structural information, it lacks the context to provide a more precise understanding of the concepts. This creates a gap when fusing knowledge graphs into language modeling, especially when there is insufficient labeled data. Thus, we propose to employ external entity descriptions to provide contextual information for knowledge understanding. We retrieve descriptions of related concepts from Wiktionary and feed them as additional input to pre-trained language models. The resulting model achieves state-of-the-art result in the CommonsenseQA dataset and the best result among non-generative models in OpenBookQA. © 2021 Association for Computational Linguistics",Final,
Wang D.,"Wang, Dapeng (57222615749)",57222615749,Construction of Knowledge Graph Corpus Under the Framework of Artificial Intelligence,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103442208&doi=10.1007%2f978-3-030-69999-4_6&partnerID=40&md5=fd910814569cbc4f01568354dc43911f,"In recent years, artificial intelligence technology has been widely used. With the development of artificial intelligence technology, the traditional corpus building mode has entered the era of knowledge atlas corpus. In this process, artificial intelligence technology plays an important role, but at the same time, the existing construction technology of artificial intelligence knowledge graph corpus is still insufficient. Therefore, this paper establishes the research on the construction of knowledge graph corpus under the framework of artificial intelligence. This paper makes an in-depth study on the characteristics of corpus data under big data. According to the results, the construction of corpus under big data is faced with various types of data and uneven data quality. How to build a corpus under big data needs to be carried out from many aspects. In view of these problems, this paper puts forward the optimization and improvement strategy. The strategy is mainly operated from corpus construction and text preprocessing, optimization of knowledge reasoning algorithm, and knowledge fusion. Through the optimization measures in this paper, we can make up for the shortcomings of the existing knowledge graph corpus construction method. Compared with HanLP algorithm, the accuracy of part of speech tagging is improved by 27.242%, recall rate is increased by 20.364%, and harmonic average value is increased by 23.866%. Moreover, the accuracy of calculation is greatly improved by weighting. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Kriman S.; Ji H.,"Kriman, Samuel (57218454116); Ji, Heng (35240121900)",57218454116; 35240121900,Joint detection and coreference resolution of entities and events with document-level context aggregation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118916243&partnerID=40&md5=f19e2705417a22dd4396450c70d106ce,"Constructing knowledge graphs from unstructured text is an important task that is relevant to many domains. Most previous work focuses on extracting information from sentences or paragraphs, due to the difficulty of analyzing longer contexts. In this paper we propose a new jointly trained model that can be used for various information extraction tasks at the document level. The tasks performed in this paper are entity and event identification, typing, and coreference resolution. In order to improve entity and event extraction, we utilize context-aware representations aggregated from the detected mentions of the corresponding entities and event triggers across the entire document. By extending our system to document-level, we can improve our results by incorporating cross-sentence dependencies and additional contextual information that might not be available at the sentence level, which allows for more globally optimized predictions. We evaluate our system on documents from the ACE05-E+ dataset and find significant improvement over the sentence-level state-of-the-art on entity extraction and event detection. © 2021 Association for Computational Linguistics.",Final,
Chao L.; He J.; Wang T.; Chu W.,"Chao, Linlin (58714697900); He, Jianshan (57218925932); Wang, Taifeng (57212061763); Chu, Wei (57198886369)",58714697900; 57218925932; 57212061763; 57198886369,PairRE: Knowledge graph embeddings via paired relation vectors,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116808039&partnerID=40&md5=7ef33a25d9913a19e4150ef9b7a7dae4,"Distance based knowledge graph embedding methods show promising results on link prediction task, on which two topics have been widely studied: one is the ability to handle complex relations, such as N-to-1, 1-to-N and N-to-N, the other is to encode various relation patterns, such as symmetry/antisymmetry. However, the existing methods fail to solve these two problems at the same time, which leads to unsatisfactory results. To mitigate this problem, we propose PairRE, a model with paired vectors for each relation representation. The paired vectors enable an adaptive adjustment of the margin in loss function to fit for complex relations. Besides, PairRE is capable of encoding three important relation patterns, symmetry/antisymmetry, inverse and composition. Given simple constraints on relation representations, PairRE can encode subrelation further. Experiments on link prediction benchmarks demonstrate the proposed key capabilities of PairRE. Moreover, We set a new state-of-the-art on two knowledge graph datasets of the challenging Open Graph Benchmark. © 2021 Association for Computational Linguistics",Final,
Chandrahas; Talukdar P.P.,"Chandrahas (57207858418); Talukdar, Partha Pratim (25652280700)",57207858418; 25652280700,OKGIT: Open Knowledge Graph Link Prediction with Implicit Types,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114689240&partnerID=40&md5=da32e1a26a68d32f3d6c211829f73d05,"Open Knowledge Graphs (OpenKG) refer to a set of (head noun phrase, relation phrase, tail noun phrase) triples such as (tesla, return to, New York) extracted from a corpus using OpenIE tools. While OpenKGs are easy to bootstrap for a domain, they are very sparse and far from being directly usable in an end task. Therefore, the task of predicting new facts, i.e., link prediction, becomes an important step while using these graphs in downstream tasks such as text comprehension, question answering, and web search query recommendation. Learning embeddings for OpenKGs is one approach for link prediction that has received some attention lately. However, on careful examination, we found that current OpenKG link prediction algorithms often predict noun phrases (NPs) with incompatible types for given noun and relation phrases. We address this problem in this work and propose OKGIT that improves OpenKG link prediction using novel type compatibility score and type regularization. With extensive experiments on multiple datasets, we show that the proposed method achieves state-of-the-art performance while producing type compatible NPs in the link prediction task. © 2021 Association for Computational Linguistics",Final,
Al-Khatib K.; Trautner L.; Wachsmuth H.; Hou Y.; Stein B.,"Al-Khatib, Khalid (57191850712); Trautner, Lukas (57331380700); Wachsmuth, Henning (52164608000); Hou, Yufang (55746803800); Stein, Benno (23013265500)",57191850712; 57331380700; 52164608000; 55746803800; 23013265500,Employing argumentation knowledge graphs for neural argument generation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118945370&partnerID=40&md5=e5502312ee82e85a5b249ec70dca3fb5,"Generating high-quality arguments, while being challenging, may benefit a wide range of downstream applications, such as writing assistants and argument search engines. Motivated by the effectiveness of utilizing knowledge graphs for supporting general text generation tasks, this paper investigates the usage of argumentation-related knowledge graphs to control the generation of arguments. In particular, we construct and populate three knowledge graphs, employing several compositions of them to encode various knowledge into texts of debate portals and relevant paragraphs from Wikipedia. Then, the texts with the encoded knowledge are used to fine-tune a pre-trained text generation model, GPT-2. We evaluate the newly created arguments manually and automatically, based on several dimensions important in argumentative contexts, including argumentativeness and plausibility. The results demonstrate the positive impact of encoding the graphs' knowledge into debate portal texts for generating arguments with superior quality than those generated without knowledge. © 2021 Association for Computational Linguistics",Final,
Bollegala D.; Hakami H.; Yoshida Y.; Kawarabayashi K.-I.,"Bollegala, Danushka (13006618600); Hakami, Huda (57003240000); Yoshida, Yuichi (35575532400); Kawarabayashi, Ken-Ichi (7004831911)",13006618600; 57003240000; 35575532400; 7004831911,RelWalk - A latent variable model approach to knowledge graph embedding,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107266626&partnerID=40&md5=ee5cb804340c32f9f486f0b7f8d830ec,"Embedding entities and relations of a knowledge graph in a low-dimensional space has shown impressive performance in predicting missing links between entities. Although progresses have been achieved, existing methods are heuristically motivated and theoretical understanding of such embeddings is comparatively underdeveloped. This paper extends the random walk model (Arora et al., 2016a) of word embeddings to Knowledge Graph Embeddings (KGEs) to derive a scoring function that evaluates the strength of a relation R between two entities h (head) and t (tail). Moreover, we show that marginal loss minimisation, a popular objective used in much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. Using the derived objective, accurate KGEs are learnt from FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory. © 2021 Association for Computational Linguistics",Final,
Xu W.; Zhang H.; Cai D.; Lam W.,"Xu, Weiwen (57216692929); Zhang, Huihui (57224744863); Cai, Deng (57211727333); Lam, Wai (57203073460)",57216692929; 57224744863; 57211727333; 57203073460,Dynamic Semantic Graph Construction and Reasoning for Explainable Multi-hop Science Question Answering,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115683408&partnerID=40&md5=f13f9401947f83026a980b648ba54da7,"Knowledge retrieval and reasoning are two key stages in multi-hop question answering (QA) at web scale. Existing approaches suffer from low confidence when retrieving evidence facts to fill the knowledge gap and lack transparent reasoning process. In this paper, we propose a new framework to exploit more valid facts while obtaining explainability for multi-hop QA by dynamically constructing a semantic graph and reasoning over it. We employ Abstract Meaning Representation (AMR) as semantic graph representation. Our framework contains three new ideas: (a) AMR-SG, an AMR-based Semantic Graph, constructed by candidate fact AMRs to uncover any hop relations among question, answer and multiple facts. (b) A novel path-based fact analytics approach exploiting AMR-SG to extract active facts from a large fact pool to answer questions. (c) A fact-level relation modeling leveraging graph convolution network (GCN) to guide the reasoning process. Results on two scientific multi-hop QA datasets show that we can surpass recent approaches including those using additional knowledge graphs while maintaining high explainability on OpenBookQA and achieve a new state-of-the-art result on ARC-Challenge in a computationally practicable setting. © 2021 Association for Computational Linguistics",Final,
Zhang Z.; Parulian N.; Ji H.; Elsayed A.S.; Myers S.; Palmer M.,"Zhang, Zixuan (57331625300); Parulian, Nikolaus (57210570303); Ji, Heng (35240121900); Elsayed, Ahmed S. (57224805620); Myers, Skatje (57220023360); Palmer, Martha (7401916649)",57331625300; 57210570303; 35240121900; 57224805620; 57220023360; 7401916649,Fine-grained information extraction from biomedical literature based on knowledge-enriched abstract meaning representation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115867463&partnerID=40&md5=1589ab2a22a2d2f1b0cf316aabe44065,"Biomedical Information Extraction from scientific literature presents two unique and nontrivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model's understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8% and 3.0% absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community. © 2021 Association for Computational Linguistics",Final,
Hongwimol P.; Kehasukcharoen P.; Laohawarutchai P.; Lertvittayakumjorn P.; Ng A.B.; Lai Z.; Liu T.; Vateekul P.,"Hongwimol, Pollawat (57331346300); Kehasukcharoen, Peeranuth (57331222500); Laohawarutchai, Pasit (57330974200); Lertvittayakumjorn, Piyawat (57189246466); Ng, Aik Beng (57219764732); Lai, Zhangsheng (57219760961); Liu, Timothy (57330974300); Vateekul, Peerapon (24829867400)",57331346300; 57331222500; 57330974200; 57189246466; 57219764732; 57219760961; 57330974300; 24829867400,ESRA: Explainable scientific research assistant,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118942127&partnerID=40&md5=b67cdbd3d46527806d507dbc19ad92bf,"We introduce Explainable Scientific Research Assistant (ESRA), a literature discovery platform that augments search results with relevant details and explanations, aiding users in understanding more about their queries and the returned papers beyond existing literature search systems. Enabled by a knowledge graph we extracted from abstracts of 23k papers on the arXiv’s cs.CL category, ESRA provides three main features: explanation (for why a paper is returned to the user), list of facts (that are relevant to the query), and graph visualization (drawing connections between the query and each paper with surrounding related entities). The experimental results with humans involved show that ESRA can accelerate the users’ search process with paper explanations and helps them better explore the landscape of the topics of interest by exploiting the underlying knowledge graph. We provide the ESRA web application at http://esra.cp.eng.chula.ac.th/. © 2021 Association for Computational Linguistics",Final,
Chen Y.; Zhang Y.; Hu C.; Huang Y.,"Chen, Yubo (57935192700); Zhang, Yunqi (58067011400); Hu, Changran (57223743642); Huang, Yongfeng (14627673100)",57935192700; 58067011400; 57223743642; 14627673100,Jointly Extracting Explicit and Implicit Relational Triples with Reasoning Pattern Enhanced Binary Pointer Network,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118068294&partnerID=40&md5=305fe78ec53d549715553352615df5ff,"Relational triple extraction is a crucial task for knowledge graph construction. Existing methods mainly focused on explicit relational triples that are directly expressed, but usually suffer from ignoring implicit triples that lack explicit expressions. This will lead to serious incompleteness of the constructed knowledge graphs. Fortunately, other triples in the sentence provide supplementary information for discovering entity pairs that may have implicit relations. Also, the relation types between the implicitly connected entity pairs can be identified with relational reasoning patterns in the real world. In this paper, we propose a unified framework to jointly extract explicit and implicit relational triples. To explore entity pairs that may be implicitly connected by relations, we propose a binary pointer network to extract overlapping relational triples relevant to each word sequentially and retain the information of previously extracted triples in an external memory. To infer the relation types of implicit relational triples, we propose to introduce real-world relational reasoning patterns in our model and capture these patterns with a relation network. We conduct experiments on several benchmark datasets, and the results prove the validity of our method. © 2021 Association for Computational Linguistics.",Final,
,,,"15th International Conference on Future Information Technology, Future Tech  2020",,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098280490&partnerID=40&md5=4f3d4111c6fd0b83cbf04d13e7f2d161,The proceedings contain 27 papers. The special focus in this conference is on Future Information Technology. The topics include: Automatic computing device selection scheme between cpu and gpu for enhancing the computation efficiency; experimentation of human activity recognition by using accelerometer data based on lstm; graph and convolution recurrent neural networks for protein-compound interaction prediction; current status and forecast of blockchain application in security technology; blockchain-based secure digital twin framework for smart healthy city; blended learning as an effective approach to english language teaching at the institutions of higher learning—a case study; cultural discourse in human-computer interactions: Linguistic aspects of digital communication; hierarchical similarity hash for fast malware detection; construct of data compression system for urgent data transmission in smart dust environment; a study on dropout techniques to reduce overfitting in deep neural networks; improvement efficiency of fingerprint database using mathematical methods; academic paper personalized search based on interest subject tracking and search performance evaluation; implementation of an authentication system gtpass; designing a predictive model for efficient learning outcomes in korean education; development of korean tourist information platform based on big data; analysis design study for fake news identification and evaluation; system architecture with respect to indoor localization; deep learning adoption blockchain secure framework for cyber physical system; entity summarization in fuzzy knowledge graph based on fuzzy concept analysis; interlacing data to classify software in linear regression approach; blockchain and trusted execution environment based fairness incentive mechanism in crowdsensing; design of a multi-core ip-ndn gateway for smart dust iot environments.,Final,
Lai T.; Ji H.; Zhai C.; Tran Q.H.,"Lai, Tuan (57209252914); Ji, Heng (35240121900); Zhai, ChengXiang (35232046000); Tran, Quan Hung (57191843710)",57209252914; 35240121900; 35232046000; 57191843710,Joint biomedical entity and relation extraction with knowledge-enhanced collective inference,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114519900&partnerID=40&md5=a37a60f89adeb6120ac8af03ee7f338e,"Compared to the general news domain, information extraction (IE) from biomedical text requires much broader domain knowledge. However, many previous IE methods do not utilize any external knowledge during inference. Due to the exponential growth of biomedical publications, models that do not go beyond their fixed set of parameters will likely fall behind. Inspired by how humans look up relevant information to comprehend a scientific text, we present a novel framework that utilizes external knowledge for joint entity and relation extraction named KECI (Knowledge-Enhanced Collective Inference). Given an input text, KECI first constructs an initial span graph representing its initial understanding of the text. It then uses an entity linker to form a knowledge graph containing relevant background knowledge for the the entity mentions in the text. To make the final predictions, KECI fuses the initial span graph and the knowledge graph into a more refined graph using an attention mechanism. KECI takes a collective approach to link mention spans to entities by integrating global relational information into local representations using graph convolutional networks. Our experimental results show that the framework is highly effective, achieving new state-of-the-art results in two different benchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse drug event extraction). For example, KECI achieves absolute improvements of 4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity and relation extraction tasks. © 2021 Association for Computational Linguistics",Final,
Xing Y.; Shi Z.; Meng Z.; Lakemeyer G.; Ma Y.; Wattenhofer R.,"Xing, Yiran (57222031703); Shi, Zai (57222017909); Meng, Zhao (57221156021); Lakemeyer, Gerhard (6603571701); Ma, Yunpu (57194413081); Wattenhofer, Roger (6701529043)",57222031703; 57222017909; 57221156021; 6603571701; 57194413081; 6701529043,KM-BART: Knowledge enhanced multimodal BART for visual commonsense generation,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118931504&partnerID=40&md5=6ac5818aafafe229bb12cfbe8bfddc02,"We present Knowledge Enhanced Multimodal BART (KM-BART), which is a Transformer-based sequence-to-sequence model capable of reasoning about commonsense knowledge from multimodal inputs of images and texts. We adapt the generative BART architecture (Lewis et al., 2020) to a multimodal model with visual and textual inputs. We further develop novel pretraining tasks to improve the model performance on the Visual Commonsense Generation (VCG) task. In particular, our pretraining task of Knowledge-based Commonsense Generation (KCG) boosts model performance on the VCG task by leveraging commonsense knowledge from a large language model pretrained on external commonsense knowledge graphs. To the best of our knowledge, we are the first to propose a dedicated task for improving model performance on the VCG task. Experimental results show that our model reaches state-of-the-art performance on the VCG task (Park et al., 2020) by applying these novel pretraining tasks. © 2021 Association for Computational Linguistics",Final,
,,,"20th China National Conference on Computational Linguistics, CCL 2021",,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113557207&partnerID=40&md5=4023128558227b7f3af7fb155750442d,The proceedings contain 31 papers. The special focus in this conference is on Computational Linguistics. The topics include: Topic Knowledge Acquisition and Utilization for Machine Reading Comprehension in Social Media Domain; category-Based Strategy-Driven Question Generator for Visual Dialogue; from Learning-to-Match to Learning-to-Discriminate: Global Prototype Learning for Few-shot Relation Classification; multi-strategy Knowledge Distillation Based Teacher-Student Framework for Machine Reading Comprehension; LRRA:A Transparent Neural-Symbolic Reasoning Framework for Real-World Visual Question Answering; meaningfulness and Unit of Zipf’s Law: Evidence from Danmu Comments; unifying Discourse Resources with Dependency Framework; a Chinese Machine Reading Comprehension Dataset Automatic Generated Based on Knowledge Graph; morphological Analysis Corpus Construction of Uyghur; low-Resource Machine Translation Based on Asynchronous Dynamic Programming; improving Entity Linking by Encoding Type Information into Entity Embeddings; a Unified Representation Learning Strategy for Open Relation Extraction with Ranked List Loss; NS-Hunter: BERT-Cloze Based Semantic Denoising for Distantly Supervised Relation Classification; a Trigger-Aware Multi-task Learning for Chinese Event Entity Recognition; improving Low-Resource Named Entity Recognition via Label-Aware Data Augmentation and Curriculum Denoising; global Entity Alignment with Gated Latent Space Neighborhood Aggregation; few-Shot Charge Prediction with Multi-grained Features and Mutual Information; sketchy Scene Captioning: Learning Multi-level Semantic Information from Sparse Visual Scene Cues; BDCN: Semantic Embedding Self-explanatory Breast Diagnostic Capsules Network; GCN with External Knowledge for Clinical Event Detection; uyghur Metaphor Detection via Considering Emotional Consistency; a Prompt-Independent and Interpretable Automated Essay Scoring Method for Chinese Second Language Writing; A Robustly Optimized BERT Pre-training Approach with Post-training; incorporating Translation Quality Estimation into Chinese-Korean Neural Machine Translation.,Final,
Du L.; Ding X.; Xiong K.; Liu T.; Qin B.,"Du, Li (57216695850); Ding, Xiao (56375894000); Xiong, Kai (57331610200); Liu, Ting (57199476645); Qin, Bing (8575883100)",57216695850; 56375894000; 57331610200; 57199476645; 8575883100,ExCAR: Event graph knowledge enhanced explainable causal reasoning,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118955543&partnerID=40&md5=baefd6ae55bdb77541fb7c0c7c27b61f,"Prior work infers the causation between events mainly based on the knowledge induced from the annotated causal event pairs. However, additional evidence information intermediate to the cause and effect remains unexploited. By incorporating such information, the logical law behind the causality can be unveiled, and the interpretability and stability of the causal reasoning system can be improved. To facilitate this, we present an Event graph knowledge enhanced explainable CAusal Reasoning framework (ExCAR). ExCAR first acquires additional evidence information from a large-scale causal event graph as logical rules for causal reasoning. To learn the conditional probabilistic of logical rules, we propose the Conditional Markov Neural Logic Network (CMNLN) that combines the representation learning and structure learning of logical rules in an end-to-end differentiable manner. Experimental results demonstrate that ExCAR outperforms previous state-of-the-art methods. Adversarial evaluation shows the improved stability of ExCAR over baseline systems. Human evaluation shows that ExCAR can achieve a promising explainable performance. © 2021 Association for Computational Linguistics",Final,
,,,"5th China Conference on Knowledge Graph, and Semantic Computing, CCKS 2020",,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111063720&partnerID=40&md5=d7bf413235d1e5f6c06b0a44456abb0e,"The proceedings contain 26 papers. The special focus in this conference is on Knowledge Graph, and Semantic Computing. The topics include: IBRE: An Incremental Bootstrapping Approach for Chinese Appointment and Dismissal Relation Extraction; hybrid Syntactic Graph Convolutional Networks for Chinese Event Detection; meta Learning for Event Argument Extraction via Domain-Specific Information Enhanced; a Survey on Event Relation Identification; employing Multi-cues to Identify Event Factuality; end-to-End Event Factuality Identification via Hybrid Neural Networks; on Building a Knowledge Graph of Open Courses; improving Question Answering over Knowledge Base with External Linguistic Knowledge; effectively Incorporating Knowledge in Open-Domain Dialogue Generation; sememe Tree Prediction for English-Chinese Word Pairs; what Linguistic Information Does Reading Comprehension Require?; enhancing Embedding via Two-Level Features for Machine Reading Comprehension; obstetric Diagnosis Assistant via Knowledge Powered Attention and Information-Enhanced Strategy; emotion Role Identification in Social Network; academic Field and Future Influence Prediction for Scholar Profile Construction; exploiting Knowledge Embedding to Improve the Description for Image Captioning; knowledge-Enhanced Collaborative Meta Learner for Long-Tail Recommendation; FGN: Fusion Glyph Network for Chinese Named Entity Recognition; semantic Label Enhanced Named Entity Recognition with Incompletely Annotated Data; Named Entity Recognition Using a Semi-supervised Model Based on BERT and Bootstrapping; reinforcement Learning for Clue Selection in Web-Based Entity Translation Mining; neural Fusion Model for Chinese Semantic Matching; improving Relation Extraction Using Semantic Role and Multi-task Learning; learning Global Representations for Document-Level Biomedical Relation Extraction.",Final,
Li Z.; Jin X.; Guan S.; Li W.; Guo J.; Wang Y.; Cheng X.,"Li, Zixuan (57201739412); Jin, Xiaolong (16417309500); Guan, Saiping (57196080482); Li, Wei (57221638294); Guo, Jiafeng (24174196100); Wang, Yuanzhuo (57195838928); Cheng, Xueqi (55855927900)",57201739412; 16417309500; 57196080482; 57221638294; 24174196100; 57195838928; 55855927900,Search from history and reason for future: Two-stage reasoning on temporal knowledge graphs,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115696411&partnerID=40&md5=2b00bf4b1dd024b7f365d8f4edadca4a,"Temporal Knowledge Graphs (TKGs) have been developed and used in many different areas. Reasoning on TKGs that predicts potential facts (events) in the future brings great challenges to existing models. When facing a prediction task, human beings usually search useful historical information (i.e., clues) in their memories and then reason for future meticulously. Inspired by this mechanism, we propose CluSTeR to predict future facts in a two-stage manner, Clue Searching and Temporal reasoning; accordingly. Specifically, at the clue searching stage, CluSTeR learns a beam search policy via reinforcement learning (RL) to induce multiple clues from historical facts. At the temporal reasoning stage, it adopts a graph convolution network based sequence method to deduce answers from clues. Experiments on four datasets demonstrate the substantial advantages of CluSTeR compared with the state-of-the-art methods. Moreover, the clues found by CluSTeR further provide interpretability for the results. © 2021 Association for Computational Linguistics",Final,
Xiang Y.; Zhang Z.; Chen J.; Chen X.; Lin Z.; Zheng Y.,"Xiang, Yuejia (57224544026); Zhang, Ziheng (57220158275); Chen, Jiaoyan (55827415100); Chen, Xi (57218347633); Lin, Zhenxi (57222054366); Zheng, Yefeng (8062522600)",57224544026; 57220158275; 55827415100; 57218347633; 57222054366; 8062522600,OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115125403&partnerID=40&md5=0c31626d3dd6b20ce0397ce90a940db0,"Semantic embedding has been widely investigated for aligning knowledge graph (KG) entities. Current methods have explored and utilized the graph structure, the entity names, and attributes, but ignore the ontology (or ontological schema) which contains critical meta information such as classes and their membership relationships with entities. In this paper, we propose an ontology-guided entity alignment method named OntoEA, where both KGs and their ontologies are jointly embedded, and the class hierarchy and the class disjointness are utilized to avoid false mappings. Extensive experiments on seven public and industrial benchmarks have demonstrated the state-of-the-art performance of OntoEA and the effectiveness of the ontologies. © 2021 Association for Computational Linguistics",Final,
Bhardwaj P.; Kelleher J.; Costabello L.; O'Sullivan D.,"Bhardwaj, Peru (57202714534); Kelleher, John (14035902400); Costabello, Luca (53979719800); O'Sullivan, Declan (57202521703)",57202714534; 14035902400; 53979719800; 57202521703,Poisoning knowledge graph embeddings via relation inference patterns,,-1,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118936129&partnerID=40&md5=858e4c20c3f9a52b12550f5881951cca,"We study the problem of generating data poisoning attacks against Knowledge Graph Embedding (KGE) models for the task of link prediction in knowledge graphs. To poison KGE models, we propose to exploit their inductive abilities which are captured through the relationship patterns like symmetry, inversion and composition in the knowledge graph. Specifically, to degrade the model's prediction confidence on target facts, we propose to improve the model's prediction confidence on a set of decoy facts. Thus, we craft adversarial additions that can improve the model's prediction confidence on decoy facts through different inference patterns. Our experiments demonstrate that the proposed poisoning attacks outperform state-of-art baselines on four KGE models for two publicly available datasets. We also find that the symmetry pattern based attacks generalize across all model-dataset combinations which indicates the sensitivity of KGE models to this pattern. © 2021 Association for Computational Linguistics",Final,
Eddamiri S.; Benghabrit A.; Zemmouri E.,"Eddamiri, Siham (57205200269); Benghabrit, Asmaa (55933106700); Zemmouri, Elmoukhtar (36703758100)",57205200269; 55933106700; 36703758100,RDF graph mining for cluster-based theme identification,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084193699&doi=10.1108%2fIJWIS-10-2019-0048&partnerID=40&md5=bc86a713e11f774664f29f6da344df6c,"Purpose: The purpose of this paper is to present a generic pipeline for Resource Description Framework (RDF) graph mining to provide a comprehensive review of each step in the knowledge discovery from data process. The authors also investigate different approaches and combinations to extract feature vectors from RDF graphs to apply the clustering and theme identification tasks. Design/methodology/approach: The proposed methodology comprises four steps. First, the authors generate several graph substructures (Walks, Set of Walks, Walks with backward and Set of Walks with backward). Second, the authors build neural language models to extract numerical vectors of the generated sequences by using word embedding techniques (Word2Vec and Doc2Vec) combined with term frequency-inverse document frequency (TF-IDF). Third, the authors use the well-known K-means algorithm to cluster the RDF graph. Finally, the authors extract the most relevant rdf:type from the grouped vertices to describe the semantics of each theme by generating the labels. Findings: The experimental evaluation on the state of the art data sets (AIFB, BGS and Conference) shows that the combination of Set of Walks-with-backward with TF-IDF and Doc2vec techniques give excellent results. In fact, the clustering results reach more than 97% and 90% in terms of purity and F-measure, respectively. Concerning the theme identification, the results show that by using the same combination, the purity and F-measure criteria reach more than 90% for all the considered data sets. Originality/value: The originality of this paper lies in two aspects: first, a new machine learning pipeline for RDF data is presented; second, an efficient process to identify and extract relevant graph substructures from an RDF graph is proposed. The proposed techniques were combined with different neural language models to improve the accuracy and relevance of the obtained feature vectors that will be fed to the clustering mechanism. © 2020, Emerald Publishing Limited.",Final,
Kannan R.; Sao P.; Lu H.; Herrmannova D.; Thakkar V.; Patton R.; Vuduc R.; Potok T.,"Kannan, Ramakrishnan (12783287600); Sao, Piyush (56014553000); Lu, Hao (56449659200); Herrmannova, Drahomira (55368776900); Thakkar, Vijay (57210185560); Patton, Robert (12344542600); Vuduc, Richard (8629966900); Potok, Thomas (6602733479)",12783287600; 56014553000; 56449659200; 55368776900; 57210185560; 12344542600; 8629966900; 6602733479,Scalable knowledge graph analytics at 136 petaflop/s,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102356024&doi=10.1109%2fSC41405.2020.00010&partnerID=40&md5=c5bfaca5e697d70cf37b0d0fe851c597,"We are motivated by newly proposed methods for data mining large-scale corpora of scholarly publications, such as the full biomedical literature, which may consist of tens of millions of papers spanning decades of research. In this setting, analysts seek to discover how concepts relate to one another. They construct graph representations from annotated text databases and then formulate the relationship-mining problem as one of computing all-pairs shortest paths (APSP), which becomes a significant bottleneck. In this context, we present a new high-performance algorithm and implementation of the Floyd-Warshall algorithm for distributed-memory parallel computers accelerated by GPUs, which we call DSNAPSHOT (Distributed Accelerated Semiring All-Pairs Shortest Path). For our largest experiments, we ran DSNAPSHOT on a connected input graph with millions of vertices using 4, 096nodes (24,576GPUs) of the Oak Ridge National Laboratory's Summit supercomputer system. We find DSNAPSHOT achieves a sustained performance of ;136× 10{15}; floating-point operations per second (136petaflop/s) at a parallel efficiency of 90% under weak scaling and, in absolute speed, 70% of the best possible performance given our computation (in the single-precision tropical semiring or 'min-plus' algebra). Looking forward, we believe this novel capability will enable the mining of scholarly knowledge corpora when embedded and integrated into artificial intelligence-driven natural language processing workflows at scale. © 2020 IEEE.",Final,All Open Access; Green Open Access
Li X.; Chen C.-H.; Zheng P.; Wang Z.; Jiang Z.; Jiang Z.,"Li, Xinyu (56455381400); Chen, Chun-Hsien (25921980900); Zheng, Pai (56352424300); Wang, Zuoxu (57204931556); Jiang, Zuhua (56411292300); Jiang, Zhixing (57199784379)",56455381400; 25921980900; 56352424300; 57204931556; 56411292300; 57199784379,A knowledge graph-Aided concept–Knowledge approach for evolutionary smart product–Service system development,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089729213&doi=10.1115%2f1.4046807&partnerID=40&md5=abaec16b11d639f166214b6b1d1beff3,"In order to meet user expectations and to optimize user experience with a higher degree of flexibility and sustainability, the Smart product–service system (Smart PSS), as a novel value proposition paradigm considering both online and offline smartness, was proposed. However, conventional manners for developing PSS require many professional consultations and still cannot meet with the new features of Smart PSS, such as user context-awareness and ever-evolving knowledge management. Therefore, aiming to assist Smart PSS development cost-effectively, this paper adopted the knowledge graph (KG) technique and concept–knowledge (C-K) model to propose an evolutionary design approach. Two knowledge graphs are firstly established with open-source knowledge, prototype specifications, and user-generated textual data. Then, triggered by personalized requirements, four KG-aided C-K operators are conducted based on graph-based query patterns and computational linguistics algorithms, thus generating innovative solutions for evolving Smart PSS. To validate the performance of the proposed approach, a case study of a smart nursing bed fulfilling multiple personalized requirements is conducted, and the evaluation result of its knowledge evolution is acceptable. It hopes that this work can offer insightful guidance to industrial organizations in their development of Smart PSS. Copyright © 2020 by ASME.",Final,All Open Access; Green Open Access
To N.D.; Reformat M.,"To, Nhuan D. (57195642538); Reformat, Marek (6603618138)",57195642538; 6603618138,Question-Answering System with Linguistic Terms over RDF Knowledge Graphs,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098868066&doi=10.1109%2fSMC42975.2020.9282949&partnerID=40&md5=4cf41fa3ed18f99db6eab803a5e0f497,"Resource Description Framework (RDF) is an important way of representing data on the Web. Although RDF is a data format suitable for publishing individual pieces of information together with relations between them, it represents a challenging format for answering questions. Thus, a system and a user interface that are easy and intuitive for users to access and operate on RDF data are of significant importance.In this paper, we introduce a Question-Answering (QA) system that allows users to ask questions in English. The uniqueness of this system is its ability to answer questions containing linguistic terms, i.e., concepts such as SMALL, LARGE, or TALL. Those concepts are defined via membership functions drawn by users using a dedicated software designed for entering 'shapes' of these functions. The system is built based on an analogical problem solving approach, and is suitable for providing users with comprehensive answers. We demonstrate the capability of the proposed QA system by answering questions asked over two RDF stores: DBpedia and Wikidata. © 2020 IEEE.",Final,
Jiang C.; Dehghan M.; Jagersand M.,"Jiang, Chen (57210792958); Dehghan, Masood (51461138500); Jagersand, Martin (6602596558)",57210792958; 51461138500; 6602596558,Understanding contexts inside robot and human manipulation tasks through vision-language model and ontology system in video streams,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094109055&doi=10.1109%2fIROS45743.2020.9340905&partnerID=40&md5=ce9c7a8c7d61899d482443c8994f21c7,"Manipulation tasks in daily life, such as pouring water, unfold through human intentions. Being able to process contextual knowledge from these Activities of Daily Living (ADLs) over time can help us understand manipulation intentions, which are essential for an intelligent robot to transition smoothly between various manipulation actions. In this paper, to model the intended concepts of manipulation, we present a vision dataset under a strictly constrained knowledge domain for both robot and human manipulations, where manipulation concepts and relations are stored by an ontology system in a taxonomic manner. Furthermore, we propose a scheme to generate a combination of visual attentions and an evolving knowledge graph filled with commonsense knowledge. Our scheme works with real-world camera streams and fuses an attention-based Vision-Language model with the ontology system. The experimental results demonstrate that the proposed scheme can successfully represent the evolution of an intended object manipulation procedure for both robots and humans. The proposed scheme allows the robot to mimic human-like intentional behaviors by watching real-time videos. We aim to develop this scheme further for real-world robot intelligence in Human-Robot Interaction. © 2020 IEEE.",Final,
Bella G.; Elliot L.; Das S.; Pavis S.; Turra E.; Robertson D.; Giunchiglia F.,"Bella, Gábor (57020988700); Elliot, Liz (57219227481); Das, Subhashis (57202838768); Pavis, Stephen (6603617321); Turra, Ettore (57219224494); Robertson, David (57210541603); Giunchiglia, Fausto (7005768672)",57020988700; 57219227481; 57202838768; 6603617321; 57219224494; 57210541603; 7005768672,Cross-border medical research using multi-layered and distributed knowledge,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091759780&doi=10.3233%2fFAIA200469&partnerID=40&md5=09d60dbb029e50f5ec726cd016b319d8,"As medical research becomes ever finer-grained, experiments require healthcare data in quantities that single countries cannot provide. Cross-jurisdictional data collection remains, however, extremely challenging due to the diverging legal, professional, linguistic, normative, and technological contexts of the participating countries. Medical data heterogeneity, in particular, is still a largely unsolved problem on the international level, due to the complexity of data combined with strict precision and data protection constraints. We propose a scalable solution based on a novel knowledge architecture and the corresponding knowledge graph integration methodology. Medical knowledge that drives the scalable integration process is divided into multiple functional layers and is maintained in a distributed manner across participating countries. We successfully applied the approach in the context of a research experiment across Scotland and Italy, and are currently adapting it within other initiatives of Europe-wide health data interoperability. © 2020 The authors and IOS Press.",Final,
Waller K.M.J.; Hedley J.A.; Rosales B.M.; De La Mata N.L.; Thomson I.K.; Walker J.; Kelly P.J.; O'Leary M.J.; Cavazzoni E.; Wyburn K.R.; Webster A.C.,"Waller, Karen M.J. (57195102472); Hedley, James A. (57205659152); Rosales, Brenda M. (57205660289); De La Mata, Nicole L. (56891657800); Thomson, Imogen K. (57194435204); Walker, John (57214331427); Kelly, Patrick J. (27172282100); O'Leary, Michael J. (56670853900); Cavazzoni, Elena (56338772800); Wyburn, Kate R. (6507147700); Webster, Angela C. (7202946991)",57195102472; 57205659152; 57205660289; 56891657800; 57194435204; 57214331427; 27172282100; 56670853900; 56338772800; 6507147700; 7202946991,Effect of language and country of birth on the consent process and medical suitability of potential organ donors; a linked-data cohort study 2010–2015,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078658798&doi=10.1016%2fj.jcrc.2020.01.025&partnerID=40&md5=195572c2a5fb8fa570a8e9b34a7b8436,"Purpose: Australia has unmet need for transplantation. We sought to assess the impact of cultural and linguistic diversity (CALD) on family consent and medical suitability for organ donation. Method: Cohort study of New South Wales donor referrals, 2010–2015. Logistic regression estimated effects of primary language other than English and birthplace outside Australia (odds ratios OR, with 95% confidence intervals, 95%CI). Outcomes were whether families were asked for consent to donation, provided consent for donation, and whether the referral was medically suitable for donation. Results: Of 2977 organ donor referrals, a similar proportion of families had consent for donation was sought between non-English speakers and English speakers (p = .07), and between overseas-born compared to Australian-born referrals (p = .3). However, consent was less likely to be given for both non-English speakers than English speakers (OR 0.44, 95%CI:0.29–0.67), and those overseas-born than Australian-born (OR 0.54, 95%CI:0.41–0.72). For referrals both overseas-born and non-English speaking, families were both less likely to be asked for consent (OR 0.67; 95%CI:0.49–0.91) or give consent (OR 0.24; 95%CI0.16–0.37). There was no difference in medical suitability between English speakers and non-English speakers (p = .6), or between Australian-born and overseas-born referrals (p = .6). Conclusion: Intervention to improve consent rates from CALD families may increase donation. © 2020 Elsevier Inc.",Final,
Potnis A.V.; Shinde R.C.; Durbha S.S.,"Potnis, Abhishek V. (57192087600); Shinde, Rajat C. (57213188267); Durbha, Surya S. (54999762600)",57192087600; 57213188267; 54999762600,Towards Natural Language Question Answering over Earth Observation Linked Data Using Attention-Based Neural Machine Translation,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101965854&doi=10.1109%2fIGARSS39084.2020.9323183&partnerID=40&md5=eee853e634616b7ba339655bcda7bd5f,"With an increase in Geospatial Linked Open Data being adopted and published over the web, there is a need to develop intuitive interfaces and systems for seamless and efficient exploratory analysis of such rich heterogeneous multi-modal datasets. This work is geared towards improving the exploration process of Earth Observation (EO) Linked Data by developing a natural language interface to facilitate querying. Questions asked over Earth Observation Linked Data have an inherent spatio-temporal dimension and can be represented using GeoSPArql. This paper seeks to study and analyze the use of RNN-based neural machine translation with attention for transforming natural language questions into GeoSPArql queries. Specifically, it aims to assess the feasibility of a neural approach for identifying and mapping spatial predicates in natural language to GeoSPARQL's topology vocabulary extension including - Egenhofer and RCC8 relations. The queries can then be executed over a triple store to yield answers for the natural language questions. A dataset consisting of mappings from natural language questions to GeoSPArql queries over the Corine Land Cover(CLC) Linked Data has been created to train and validate the deep neural network. From our experiments, it is evident that neural machine translation with attention is a promising approach for the task of translating spatial predicates in natural language questions to GeoSPArql queries. © 2020 IEEE.",Final,All Open Access; Green Open Access
Pandey S.; Sahoo S.,"Pandey, Shriram (57208906265); Sahoo, Sidhartha (36680552300)",57208906265; 36680552300,Research collaboration and authorship pattern in the field of semantic digital libraries,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097547646&doi=10.14429%2fdjlit.40.6.15680&partnerID=40&md5=66c2044798ae94ea27dce2556ecf2418,"This study aims to explore research collaborations and authorship patterns in the field of semantic digital libraries(SDL). The data is extracted (N=2075) from the Scopus database using keywords related to semantic digital libraries by considering all types of publications during 1983-2019. The analysis of each document is based on the following scientometrics indicators: author productivity, degree of collaboration, collaboration index, collaboration coefficient and modified collaboration coefficient. Correlation matrices were also calculated and inferences drawn in terms of authors and publications. A network visualisation tool VOSviewer was used to present authorship correlation network strength and keyword mapping for a better insight into the emerging areas in the field of SDL. The resulting average degree of collaboration of 0.898 indicates that a large number of publications are multi-authored and that there is a higher level of collaborative research in the field of semantic digital libraries. Meghini C from the Institute of Information Science and Technologies, Italy has produced the highest number of research paper(n=18) whereas Egenhofer MJ found to be a profoundly impacted author with 851 citations on in the studied domain. Results also reveal that the focus areas of research related to SDL include digital libraries, semantic web, ontology, metadata and information retrieval. However, keywords such as natural language processing system, computational linguistics, linked data are also repeated frequently in the published literature, thus revealing the emerging areas of the future research in the domain of SDL. © 2020, DESIDOC.",Final,
Duan J.; Zhao H.; Zhou Q.; Qiu M.; Liu M.,"Duan, Jiajia (57217993813); Zhao, Hui (55804567500); Zhou, Qian (57221200366); Qiu, Meikang (57216130886); Liu, Meiqin (26643265600)",57217993813; 55804567500; 57221200366; 57216130886; 26643265600,A Study of Pre-trained Language Models in Natural Language Processing,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098480175&doi=10.1109%2fSmartCloud49737.2020.00030&partnerID=40&md5=4a4a4dbd5141f5b890522c963ff07ad1,"Pre-trained Language Model (PLM) is a very popular topic in natural language processing (NLP). It is the rapid development of pre-trained language models (PLMs) that has led to the achievements of natural language today. In this article, we give a review of important PLMs. First, we generally introduce the development history and achievements of PLMs. Second, we present several extraordinary PLMs, including BERT, the variants of BERT, Multimodal PLMs, PLMs combined with Knowledge Graph and PLMs applied to natural language generation. In the end, we summarize and look into the future of PLMs. We expect this article will provide a practical guide for learners to understanding, using and developing PLMs with the abundant literature existing for various NLP tasks.  © 2020 IEEE.",Final,
,,,"2020 IEEE 3rd International Conference on Automation, Electronics and Electrical Engineering, AUTEEE 2020",,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100591694&partnerID=40&md5=9dfa76e873554e982a11b2c7c7ddad33,The proceedings contain 106 papers. The topics discussed include: application of deep learning algorithm in generator fault prediction; image noise estimation with using pre-trained conventional neural network; research on green suppliers selection based on hesitant fuzzy linguistic PROMETHEE method; research on the temporal and spatial law of respiratory dust concentration in fully-mechanized mine; multi-scale hybrid attention cascade network for pancreas segmentation; design of mobile garbage collection robot based on visual recognition; design and research of the multifunctional mobile manipulator based on ROS; basic methodologies used in nlp area; automatic algorithmically generated domain detection with deep learning methods; and knowledge graph oriented anti-ship combat command information ontology model.,Final,
Yang H.; Qin Y.; Deng Y.; Wang M.,"Yang, Hao (57208745952); Qin, Ying (57208747392); Deng, Yao (57216588471); Wang, Minghan (57216592504)",57208745952; 57208747392; 57216588471; 57216592504,NMT Enhancement based on Knowledge Graph Mining with Pre-trained Language Model,,-1,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083976347&doi=10.23919%2fICACT48636.2020.9061292&partnerID=40&md5=cc951d3c317a2158323411691da1d742,"Pre-trained language models like Bert, RoBERTa, GPT, etc. have achieved SOTA effects on multiple NLP tasks (e.g. sentiment classification, information extraction, event extraction, etc.). We propose a simple method based on knowledge graph to improve the quality of machine translation. First, we propose a multi-task learning model that learns subjects, objects, and predicates at the same time. Second, we treat different predicates as different fields, and improve the recognition ability of NMT models in different fields through classification labels. Finally, beam search combined with L2R, R2L rearranges results through entities. Based on the CWMT2018 experimental data, using the predicate's domain classification identifier, the BLUE score increased from 33.58% to 37.63%, and through L2R, R2L rearrangement, the BLEU score increased to 39.25%, overall improvement is more than 5 percentage. © 2020 Global IT Research Institute - GIRI.",Final,
,,,"15th International Semantic Web Conference, ISWC 2016",,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992603240&partnerID=40&md5=315ea227e4b0bd326c8504bacc2bcb34,"The proceedings contain 36 papers. The special focus in this conference is on International Semantic Web. The topics include: Ontological representation of audio features; abstract meaning representations as linked data; interoperability for smart appliances in the IoT world; an ontology of soil properties and processes; on publishing zhishi.me as linguistic linked open data; linked disambiguated distributional semantic networks; a benchmark for end-user structured data user interfaces; efficient distributed evaluation of SPARQL; comparing SPARQL, relational and graph databases; bringing Chinese physical and human geography in linked open data; multipurpose linked data generator; generating custom OWL 2 benchmark ontologies; spreading RDF streams on the web; conference linked data; the scholarlydata project; food in open data; a multilingual knowledge base from Wikipedia, WordNet, and geonames; enabling combined software and data engineering at web-scale; a replication study of the top performing systems in SemEval twitter sentiment analysis; translating ontologies in real-world settings; extracting semantic information for e-commerce; ontology-based design of space systems; towards analytics aware ontology based access to static and streaming data; automatic classification of Springer nature proceedings with smart topic miner; semantic technologies for data analysis in health care and extending SPARQL for data analytic tasks.",Final,
García-Godoy M.J.; López-Camacho E.; Navas-Delgado I.; Aldana-Montes J.F.,"García-Godoy, María Jesús (55169317400); López-Camacho, Esteban (55788851600); Navas-Delgado, Ismael (6508304108); Aldana-Montes, José F. (6507036317)",55169317400; 55788851600; 6508304108; 6507036317,Re-constructing hidden semantic data models by querying SPARQL endpoints,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981250166&doi=10.1007%2f978-3-319-44403-1_25&partnerID=40&md5=aac78cc291a4c17155d8a6755c033494,"Linked Open Data community is constantly producing new repositories that store information from different domains. The data included in these repositories follow the rules proposed by the W3C community, based on standards such as Resource Description Framework (RDF) and the SPARQL query language. The main advantage of this approach is the possibility of external developers accessing the data from their applications. This advantage is also one of the main challenges of this new technology due to the cost of exploring how the data is structured in a given repository in order to construct SPARQL queries to retrieve useful information. According to the reviewed literature, there are no applications to reconstruct the underlying semantic data models from an SPARQL endpoint. In this paper, we present an application for the reconstruction of the data model as an OWL (Ontology Web Language) ontology. This application, available as Open Source at http://github.com/estebanpua/ontology-endpoint-extraction uses a set of SPARQL queries to discover the classes and the (object and data) properties for a given RDF database. A web application interface has also been implemented for users to browse through classes, properties of the ontology generated from the data structure (http://khaos.uma. es/oee). The ontologies generated by this application can help users to understand how the information is semantically organized, making easier the design of SPARQL queries. © Springer International Publishing Switzerland 2016.",Final,All Open Access; Green Open Access
Ciora R.A.; Simion C.M.; Cioca M.,"Ciora, Radu Adrian (57188879619); Simion, Carmen Mihaela (8670074600); Cioca, Marius (55888486300)",57188879619; 8670074600; 55888486300,Quality improvement based on big data analysis,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964026901&doi=10.1007%2f978-3-319-32942-0_7&partnerID=40&md5=73d53f75f71aa664bf68cdce391f65b8,"Big data analysis has become an important trend in computer science. Quality improvement is a constant in current industry trends. In this paper, we present an idea of quality improvement based on big data analysis with the aid of linked data and ontologies in order to implement it in the case of automotive parts production. We consider defective automotive products and try to find the best refurbishment solution for them considering their characteristics. Moreover, we propose to develop a recommender system that is able to give recommendations in order to prevent or to alleviate defects and to provide insights for possible causes that led to these defective parts. This study intends to help direct beneficiaries (public consumer, quality engineers, quality control managers), but also specialists and researchers in the NLP, software engineers, etc. © Springer International Publishing Switzerland 2016.",Final,
Michel F.; Djimenou L.; Faron-Zucker C.; Montagnat J.,"Michel, Franck (36559861300); Djimenou, Loïc (56926640900); Faron-Zucker, Catherine (55665070200); Montagnat, Johan (55887022200)",36559861300; 56926640900; 55665070200; 55887022200,"Translation of heterogeneous databases into RDF, and application to the construction of a SKOS taxonomical reference",,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961732842&doi=10.1007%2f978-3-319-30996-5_14&partnerID=40&md5=8c369779274fa6b4b8b43cb81fc3a994,"While the data deluge accelerates, most of the data produced remains locked in deep Web databases. For the linked open data to benefit from the potential represented by this huge amount of data, it is crucial to come up with solutions to expose heterogeneous databases as linked data. The xR2RML mapping language is an endeavor towards this goal: it is designed to map various types of databases to RDF, by flexibly adapting to heterogeneous query languages and data models while remaining free from any specific language. It extends R2RML, the W3C recommendation for the mapping of relational databases to RDF, and relies on RML for the handling of various data formats. In this paper we present xR2RML, we analyse data models of several modern databases as well as the format in which query results are returned, and we show how xR2RML translates any result data element into RDF, relying on existing languages such as XPath and JSONPath when necessary. We illustrate some features of xR2RML such as the generation of RDF collections and containers, and the ability to deal with mixed data formats. We also describe a real-world use case in which we applied xR2RML to build a SKOS thesaurus aimed at supporting studies on History of Zoology, Archaeozoology and Conservation Biology. © Springer International Publishing Switzerland 2016.",Final,All Open Access; Green Open Access
Vasudevan M.; Tripathy B.K.,"Vasudevan, Magesh (56765513600); Tripathy, B.K. (7006285374)",56765513600; 7006285374,A constraint based question answering over semantic knowledge base,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951994403&doi=10.1007%2f978-81-322-2731-1_11&partnerID=40&md5=077d61049bcb89f069d2d2e5b9809cbe,The proposed system aims at extracting meaning from the natural language query for querying the semantic knowledge sources. Semantic knowledge sources are systems conceptualized with Ontology. Characterization of a concept is through other concepts as a constraint over other. This very method to extract meaning from the natural language query has been experimented in this system. Constraints and entities from the query and the relationship between the entities is capable of transforming natural language query to a SPARQL (a query language for Semantic Knowledge sources). Further the SPARQL query is generated through recursive procedure from the intermediate query which is more efficient that mapping with patterns of the question. The system is compared with other systems of QALD (Question Answering over Linked Data) standard. © Springer India 2016.,Final,
Diana T.; Gîfu D.,"Diana, Trandabăţ (57188875002); Gîfu, Daniela (42661254500)",57188875002; 42661254500,"Linguistic Linked Open Data: 12th EUROLAN 2015 summer school and RUMOUR 2015 workshop Sibiu, Romania, july 13-25, 2015 revised selected papers",,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963997708&partnerID=40&md5=f7ecfcac299364fab5f5b4d73338c78d,[No abstract available],Final,
,,,"12th Summer School on Linguistic Linked Open Data, EUROLAN 2015 and Workshop on Social Media and the Web of Linked Data, RUMOUR-2015",,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964048312&partnerID=40&md5=2a3f1c1c6344e62598e8073eeff67e1c,"The proceedings contain 23 papers. The special focus in this conference is on Ontological Modeling of Social Media Data, Application of Social Media, Linked Data Methodologies in Real-Life Scenarios, User Profiling, Assessing the Suitability of Content from Social Media and Linking Content. The topics include: Towards creating an ontology of social media texts; towards social data analytics for smart tourism; a mixed approach in recognising geographical entities in texts; image and user profile-based recommendation system; discovering semantic relations within nominals; quality improvement based on big data analysis; projects of digitization and linked data and extracting features from social media networks using semantics.",Final,
Zhu C.; Ren K.; Liu X.; Wang H.; Tian Y.; Yu Y.,"Zhu, Chenhao (57188548927); Ren, Kan (57188557037); Liu, Xuan (57188566810); Wang, Haofen (23399118800); Tian, Yiding (57188554784); Yu, Yong (8723751600)",57188548927; 57188557037; 57188566810; 23399118800; 57188554784; 8723751600,A graph traversal based approach to answer non-aggregation questions over DBpedia,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961659466&doi=10.1007%2f978-3-319-31676-5_16&partnerID=40&md5=6c4b6393117d1d076dc7c8e551da18d3,"We present a question answering system over DBpedia, filling the gap between user information needs expressed in natural language and a structured query interface expressed in SPARQL over the underlying knowledge base (KB). Given the KB, our goal is to comprehend a natural language query and provide corresponding accurate answers. Focusing on solving the non-aggregation questions, in this paper, we construct a subgraph of the knowledge base from the detected entities and propose a graph traversal method to solve both the semantic item mapping problem and the disambiguation problem in a joint way. Compared with existing work, we simplify the process of query intention understanding and pay more attention to the answer path ranking. We evaluate our method on a non-aggregation question dataset and further on a complete dataset. Experimental results show that our method achieves best performance compared with several state-of-the-art systems. © Springer International Publishing Switzerland 2016.",Final,All Open Access; Green Open Access
Del Gratta R.; Boschetti F.; Del Grosso A.; Khan F.; Monachini M.,"Del Gratta, Riccardo (34976432900); Boschetti, Federico (36081634700); Del Grosso, Angelo (56319538600); Khan, Fahad (56643810600); Monachini, Monica (23397766600)",34976432900; 36081634700; 56319538600; 56643810600; 23397766600,Cooperative philology on the way to web services: The case of the cophiWordNet platform,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961744725&doi=10.1007%2f978-3-319-31468-6_13&partnerID=40&md5=ae430864e4034e75a90df3969f28570b,"In this paper we present ongoing research carried out at the Institute for Computational Linguistics “A. Zampolli” (ILC) in Pisa. The institute has been active since many years in the field of Digital Humanities providing resources, tools and solutions to address issues of the to digital humanists. Starting from those previous initiatives, we show how to re-engineer them as Web Services in order to make connections between lexicons, semantic resources and a fine grained text management. Linked Open Data is chosen as the paradigm used to link the different resources as well as the modality of data presentation. © Springer International Publishing Switzerland 2016.",Final,
Bertola F.; Patti V.,"Bertola, Federico (56519658300); Patti, Viviana (6506947801)",56519658300; 6506947801,Ontology-based affective models to organize artworks in the social semantic web,,-1,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949057679&doi=10.1016%2fj.ipm.2015.10.003&partnerID=40&md5=2a832477ded6d78c25131d9c23221d5d,"In this paper, we focus on applying sentiment analysis to resources from online art collections, by exploiting, as information source, tags intended as textual traces that visitors leave to comment artworks on social platforms. We present a framework where methods and tools from a set of disciplines, ranging from Semantic and Social Web to Natural Language Processing, provide us the building blocks for creating a semantic social space to organize artworks according to an ontology of emotions. The ontology is inspired by the Plutchik's circumplex model, a well-founded psychological model of human emotions. Users can be involved in the creation of the emotional space, through a graphical interactive interface. The development of such semantic space enables new ways of accessing and exploring art collections. The affective categorization model and the emotion detection output are encoded into W3C ontology languages. This gives us the twofold advantage to enable tractable reasoning on detected emotions and related artworks, and to foster the interoperability and integration of tools developed in the Semantic Web and Linked Data community. The proposal has been evaluated against a real-word case study, a dataset of tagged multimedia artworks from the ArsMeteo Italian online collection, and validated through a user study. © 2015 Elsevier Ltd. All rights reserved.",Final,
Bosch T.; Acar E.; Nolle A.; Eckert K.,"Bosch, Thomas (55030381500); Acar, Erman (57209068452); Nolle, Andreas (55783320900); Eckert, Kai (24070419400)",55030381500; 57209068452; 55783320900; 24070419400,The role of reasoning for RDF validation,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962622204&doi=10.1145%2f2814864.2814867&partnerID=40&md5=2c6abd92305cb7a5fb4540f0195a554c,"For data practitioners embracing the world of RDF and Linked Data, the openness and flexibility is a mixed blessing. For them, data validation according to predefined constraints is a much sought-after feature, particularly as this is taken for granted in the XML world. Based on our work in the DCMI RDF Application Profiles Task Group and in cooperation with the W3C Data Shapes Working Group, we published by today 81 types of constraints that are required by various stakeholders for data applications. These constraint types form the basis to investigate the role that reasoning and different semantics play in practical data validation, why reasoning is beneficial for RDF validation, and how to overcome the major shortcomings when validating RDF data by performing reasoning prior to validation. For each constraint type, we examine (1) if reasoning may improve data quality, (2) how efficient in terms of runtime validation is performed with and without reasoning; and (3) if validation results depend on underlying semantics which differs between reasoning and validation. Using these findings, we determine for the most common constraint languages which constraint types they enable to express and give directions for the further development of constraint languages.",Final,All Open Access; Green Open Access
Mackellar B.; Schweikert C.,"Mackellar, Bonnie (6508128713); Schweikert, Christina (35146659300)",6508128713; 35146659300,Analyzing conflicts between Clinical Trials from a patient perspective,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966585932&doi=10.1109%2fHealthCom.2015.7454550&partnerID=40&md5=e05c86144e8d1a763f08c684cf445855,"Patients with serious long-term disease often search for clinical trial information on their own, using sites such as ClinicalTrials.gov. We are developing a patient-focused search tool for clinical trials. Since patients are often concerned that participation in one clinical trial may preclude their participation in other trials, one of the planned features of this system will be the ability to analyze whether treatments in one trial will prevent a patient from participating in another. This paper describes an approach to this task. Eligibility criteria are classified according to linguistic pattern, UMLS concepts, content, and time. The criteria are then compared with treatments and side effects in other trials relevant to a patient, in order to identify potential conflicts. © 2015 IEEE.",Final,
Boella G.; Di Caro L.; Graziadei M.; Cupi L.; Salaroglio C.E.; Humphreys L.; Konstantinov H.; Marko K.; Robaldo L.; Ruffini C.; Simov K.; Violato A.; Stroetmann V.,"Boella, Guido (7007108372); Di Caro, Luigi (57207954874); Graziadei, Michele (31267544500); Cupi, Loredana (57140586200); Salaroglio, Carlo Emilio (57140717400); Humphreys, Llio (54784731500); Konstantinov, Hristo (57140502500); Marko, Kornel (6701790915); Robaldo, Livio (15045771000); Ruffini, Claudio (55538061600); Simov, Kiril (8835805500); Violato, Andrea (54785591100); Stroetmann, Veli (6506633799)",7007108372; 57207954874; 31267544500; 57140586200; 57140717400; 54784731500; 57140502500; 6701790915; 15045771000; 55538061600; 8835805500; 54785591100; 6506633799,Linking legal open data: Breaking the accessibility and language barrier in European legislation and case law,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959111435&doi=10.1145%2f2746090.2746106&partnerID=40&md5=4d7b0fd8da1aab6bdaf0267610c8ce6a,"In this paper we describe how the EUCases FP7 project is addressing the problem of lifting Legal Open Data to Linked Open Data to develop new applications for the legal information provision market by enriching structurally the documents (first of all with navigable references among legal texts) and semantically (with concepts from ontologies and classification). First we describe the social and economic need for breaking the accessibility barrier in legal information in the EU, then we describe the technological challenges and finally we explain how the EUCases project is addressing them by a combination of Human Language Technologies. © 2015 ACM.",Final,
Sateli B.; Witte R.,"Sateli, Bahar (39062011400); Witte, René (23010981400)",39062011400; 23010981400,"Semantic representation of scientific literature: Bringing claims, contributions and named entities onto the Linked Open Data cloud",,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992468702&doi=10.7717%2fpeerj-cs.37&partnerID=40&md5=2edca2e31c66fdab4fe8baa573e7e3c5,"Motivation. Finding relevant scientific literature is one of the essential tasks researchers are facing on a daily basis. Digital libraries and web information retrieval techniques provide rapid access to a vast amount of scientific literature. However, no further automated support is available that would enable fine-grained access to the knowledge 'stored' in these documents. The emerging domain of Semantic Publishing aims at making scientific knowledge accessible to both humans and machines, by adding semantic annotations to content, such as a publication's contributions, methods, or application domains. However, despite the promises of better knowledge access, the manual annotation of existing research literature is prohibitively expensive for wide-spread adoption.We argue that a novel combination of three distinct methods can significantly advance this vision in a fully-automated way: (i) Natural Language Processing (NLP) for Rhetorical Entity (RE) detection; (ii) Named Entity (NE) recognition based on the Linked Open Data (LOD) cloud; and (iii) automatic knowledge base construction for both NEs and REs using semantic web ontologies that interconnect entities in documents with the machine-readable LODcloud. Results. We present a complete workflow to transform scientific literature into a semantic knowledge base, based on the W3C standards RDF and RDFS. A text mining pipeline, implemented based on the GATE framework, automatically extracts rhetorical entities of type Claims and Contributions fromfull-text scientific literature. These REs are further enriched with named entities, represented as URIs to the linked open data cloud, by integrating the DBpedia Spotlight tool into our workflow. Text mining results are stored in a knowledge base through a flexible export process that provides for a dynamic mapping of semantic annotations to LOD vocabularies through rules stored in the knowledge base. We created a gold standard corpus from computer science conference proceedings and journal articles, where Claim and Contribution sentences are manually annotated with their respective types using LOD URIs. The performance of the RE detection phase is evaluated against this corpus, where it achieves an average F-measure of 0.73. We further demonstrate a number of semantic queries that show how the generated knowledge base can provide support for numerous use cases in managing scientific literature. © 2015 Sateli and Witte.",Final,All Open Access; Gold Open Access; Green Open Access
Ciobanu G.; Horne R.; Sassone V.,"Ciobanu, Gabriel (7003872401); Horne, Ross (55249833700); Sassone, Vladimiro (6603781028)",7003872401; 55249833700; 6603781028,Minimal type inference for Linked Data consumers,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938700088&doi=10.1016%2fj.jlamp.2014.12.005&partnerID=40&md5=456b64f0d70b5ab98831f150bb32e1e0,"Abstract We provide an introduction to the Web of Linked Data from the perspective of a Web developer who would like to build an application using Linked Data. We identify a weakness in the development stack, namely a lack of domain specific scripting languages for designing background processes that consume Linked Data. To address this weakness, we design a scripting language with a simple but appropriate type system. In our proposed architecture, some data is consumed from sources outside of the control of the system and some data is held locally. Stronger type assumptions can be made about the local data than about external data, hence our type system mixes static and dynamic typing. We prove that our type system is algorithmic; and can therefore be used for minimal type inference. We also prove subject reduction and type safety results, which justify our claim that our language is statically type checked and does not throw basic runtime type errors. Throughout, we relate our work to the W3C recommendations that drive Linked Data, so that our syntax is accessible to Web developers. © 2014 Elsevier Inc.",Final,All Open Access; Bronze Open Access; Green Open Access
Huang J.-Y.; Lange C.; Auer S.,"Huang, Jyun-Yao (55268432200); Lange, Christoph (55709348200); Auer, Sören (23391879500)",55268432200; 55709348200; 23391879500,Streaming transformation of XML to RDF using XPath-based mappings,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962623818&doi=10.1145%2f2814864.2814880&partnerID=40&md5=c06608c433930bbfc8514c7e38051edb,"The Extensible Markup Language (XML) has become a widely adopted data interchange format. With the rise of Linked Data published using the Resource Description Framework (RDF), a number of tools for transforming XML to RDF have been developed. Specifying XML→RDF mappings for these tools often requires skills in programming languages such as XSLT or XQuery. Moreover, these tools are rarely able to deal with large XML inputs. We introduce an XML to RDF transformation approach, which is based on map- pings comprising RDF triple templates that employ sim- ple XPath expressions. Thanks to the restricted XPath expressions, which can be evaluated against a stream of XML data, our implementation can handle extremely large input XML files. To process the XML input efficiently, we employ XML filtering techniques and a strategy for selecting relevant XML nodes to generate RDF triples from. We show that the time complexity of our mapping algorithm is linear in the size of the XML input and also prove its practical efficiency with an evaluation on large real-world data.",Final,
,,,Proceedings of the 2015 ACM Web Science Conference,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978066697&partnerID=40&md5=4ec9f14fc7e205826b0d61849bb376a1,The proceedings contain 67 papers. The topics discussed include: predicting political polarization from cyberbalkanization: time series analysis of Facebook pages and opinion poll during the Hong Kong occupy movement; automatic identification of personal life events in twitter; cross-social network collaborative recommendation; a values and psychological attribute analysis of the Scottish independence referendum context in Twitter; what do academics ask their online networks? an analysis of questions posed via academia.edu; diversity analysis of web search results; the web practice of mathematicians on the web: an insight into significant but neglected web groups; real-time social media analytics through semantic annotation and linked open data; webscraping as an investigation tool to identify potential human trafficking operations in Romania; supply and demand of independent UK music artists on the web; twitter as a political network - predicting the following and unfollowing behavior of German politicians; and linguistic influence patterns within the global network of Wikipedia language editions.,Final,
Zheng W.; Zou L.; Lian X.; Yu J.X.; Song S.; Zhao D.,"Zheng, Weiguo (7403566336); Zou, Lei (8359099800); Lian, Xiang (23392904500); Yu, Jeffrey Xu (57203435589); Song, Shaoxu (13610279900); Zhao, Dongyan (55387416000)",7403566336; 8359099800; 23392904500; 57203435589; 13610279900; 55387416000,How to build templates for RDF question/answering - An uncertain graph similarity join approach,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957575023&doi=10.1145%2f2723372.2747648&partnerID=40&md5=d6b0b8cd083030b7def968255e60b954,"A challenging task in the natural language question answering (Q/A for short) over RDF knowledge graph is how to bridge the gap between unstructured natural language questions (NLQ) and graph-structured RDF data (G). One of the effective tools is the ""template"", which is often used in many existing RDF Q/A systems. However, few of them study how to generate templates automatically. To the best of our knowledge, we are the first to propose a join approach for template generation. Given a workload D of SPARQL queries and a set N of natural language questions, the goal is to find some pairs 〈q, n〉, for q ∈ D∧ n ∈ N, where SPARQL query q is the best match for natural language question n. These pairs provide promising hints for automatic template generation. Due to the ambiguity of the natural languages, we model the problem above as an uncertain graph join task. We propose several structural and probability pruning techniques to speed up joining. Extensive experiments over real RDF Q/A benchmark datasets confirm both the effectiveness and efficiency of our approach. Copyright © 2015 ACM.",Final,
Ardalan Z.; Martín C.; Padró L.,"Ardalan, Zagros (57190944285); Martín, Carme (55483453100); Padró, Lluís (36725767000)",57190944285; 55483453100; 36725767000,AETAS: A system for semanticizing temporal expressions from unstructured contents,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984617560&doi=10.1007%2f978-3-319-22363-6_26&partnerID=40&md5=61c2cd89c3a0087ffce40fd8b7d60f2b,"AETAS is an online tool for converting text into RDF linked data with resolution of temporal expressions. AETAS follows fully SOA architecture and is accessible via web-service. It implements a novel approach for semantic representation and linked temporal graphs built from natural language sentences. In this paper, we present a demonstration tool, which combines the normalized temporal expressions with linguistic semantic frames and creates a linked RDF graph where time is defined as an individual dimension. The tool is based on SUTime which identifies and normalizes the temporal expressions and on FreeLing, a linguistic processor which extracts the semantics of sentences. The output of AETAS is a set of time-enriched triples that can be stored in a RDF database for later τ-SPARQL querying. © Springer International Publishing Switzerland 2015.",Final,
Diaz E.; Kumar B.N.; Engedal K.,"Diaz, Esperanza (23099990200); Kumar, Bernadette N. (9738429400); Engedal, Knut (34975080000)",23099990200; 9738429400; 34975080000,Immigrant patients with dementia and memory impairment in primary health care in Norway: A national registry study,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926139601&doi=10.1159%2f000375526&partnerID=40&md5=f8e420296925cf79e88a7fdc0bf32274,"Immigrants comprise a growing proportion of the elderly population. However, knowledge about the diagnosis and management of dementia and memory impairment among immigrants is scarce in Norway and elsewhere. Aims: To compare proportions of Norwegians and immigrants aged ≥50 years with a diagnosis of dementia or memory impairment in primary health care and to study the demographic characteristics, utilization of primary health care services and pharmacological treatment of Norwegians and immigrants with either of the two diagnoses in 2008. Method: This is a registry-based study using linked data at the individual level from 4 national Norwegian registers. Results: A significantly lower proportion of immigrants, especially those from other than high-income countries, had a diagnosis of dementia or memory impairment. Among patients with such diagnoses, anti-dementia medication was purchased 20-50% more often by Norwegians than by immigrants, although the differences remained significant only for immigrants from other than high-income countries after adjustment for several variables. Conclusion: The lower proportions of immigrants with a dementia diagnosis and lower proportions of patients receiving treatment might indicate a lower prevalence or milder forms of dementia among immigrants. However, the cultural validity of the assessment tools, linguistic barriers and challenges for general practitioners should be further investigated. © 2015 S. Karger AG, Basel.",Final,
Ayvaz S.; Horn J.; Hassanzadeh O.; Zhu Q.; Stan J.; Tatonetti N.P.; Vilar S.; Brochhausen M.; Samwald M.; Rastegar-Mojarad M.; Dumontier M.; Boyce R.D.,"Ayvaz, Serkan (56676074300); Horn, John (7203079889); Hassanzadeh, Oktie (22937276200); Zhu, Qian (35520461100); Stan, Johann (58713108400); Tatonetti, Nicholas P. (35604787200); Vilar, Santiago (9332633100); Brochhausen, Mathias (23388655700); Samwald, Matthias (55876919000); Rastegar-Mojarad, Majid (55995663400); Dumontier, Michel (6701759312); Boyce, Richard D. (17343699800)",56676074300; 7203079889; 22937276200; 35520461100; 58713108400; 35604787200; 9332633100; 23388655700; 55876919000; 55995663400; 6701759312; 17343699800,Toward a complete dataset of drug-drug interaction information from publicly available sources,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930706290&doi=10.1016%2fj.jbi.2015.04.006&partnerID=40&md5=09fb29e2c9f2e32459d11a23d56114f8,"Although potential drug-drug interactions (PDDIs) are a significant source of preventable drug-related harm, there is currently no single complete source of PDDI information. In the current study, all publically available sources of PDDI information that could be identified using a comprehensive and broad search were combined into a single dataset. The combined dataset merged fourteen different sources including 5 clinically-oriented information sources, 4 Natural Language Processing (NLP) Corpora, and 5 Bioinformatics/Pharmacovigilance information sources. As a comprehensive PDDI source, the merged dataset might benefit the pharmacovigilance text mining community by making it possible to compare the representativeness of NLP corpora for PDDI text extraction tasks, and specifying elements that can be useful for future PDDI extraction purposes.An analysis of the overlap between and across the data sources showed that there was little overlap. Even comprehensive PDDI lists such as DrugBank, KEGG, and the NDF-RT had less than 50% overlap with each other. Moreover, all of the comprehensive lists had incomplete coverage of two data sources that focus on PDDIs of interest in most clinical settings. Based on this information, we think that systems that provide access to the comprehensive lists, such as APIs into RxNorm, should be careful to inform users that the lists may be incomplete with respect to PDDIs that drug experts suggest clinicians be aware of. In spite of the low degree of overlap, several dozen cases were identified where PDDI information provided in drug product labeling might be augmented by the merged dataset. Moreover, the combined dataset was also shown to improve the performance of an existing PDDI NLP pipeline and a recently published PDDI pharmacovigilance protocol. Future work will focus on improvement of the methods for mapping between PDDI information sources, identifying methods to improve the use of the merged dataset in PDDI NLP algorithms, integrating high-quality PDDI information from the merged dataset into Wikidata, and making the combined dataset accessible as Semantic Web Linked Data. © 2015 The Authors.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Trinh T.-D.; Wetz P.; Do B.-L.; Kiesling E.; Tjoa A.M.,"Trinh, Tuan-Dat (56083046800); Wetz, Peter (55990706600); Do, Ba-Lam (56083650000); Kiesling, Elmar (29067925200); Tjoa, A. Min (6701811086)",56083046800; 55990706600; 56083650000; 29067925200; 6701811086,Semantic mashup composition from natural language expressions: Preliminary results,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967333834&doi=10.1145%2f2837185.2837194&partnerID=40&md5=3c8bdc1e7f317a0d72312cdba6cea616,"Despite an abundance of data available on the web today, satisfying users' complex information needs intelligently by automatically integrating and processing data from various sources remains challenging. In recent years, a large stream of research into mashups as a paradigm of end user development has emerged. These mashups foster combination and reuse of data and services and thereby allow end users to create novel applications. Developing such mashups efficiently and effectively, however, is still dificult for users that lack technical expertise. To address this issue, we extend a mashup platform with automatic mashup composition mechanisms and an agent that assists users in mashup design. To this end, we leverage semantics to simplify the mashup composition process on multiple levels. We associate each widget (i.e., mashup component) with a semantic model of inputs and outputs. These semantic models are helpful for identifying appropriate widgets in a given context and allow us to validate the links between widgets in a mashup. These validations provide the foundation for an advanced composition algorithm that automatically creates meaningful mashups from a given set of widgets. Finally, we develop an agent that leverages the semantic annotations to allow users to automatically compose mashups by entering natural-language text. © 2015 ACM.",Final,
Kumamoto K.; Amagasa T.; Kitagawa H.,"Kumamoto, Kazumasa (57189052191); Amagasa, Toshiyuki (7006482993); Kitagawa, Hiroyuki (7402625746)",57189052191; 7006482993; 7402625746,A system for querying RDF data using LINQ,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964940019&doi=10.1109%2fNBiS.2015.69&partnerID=40&md5=0fbaa01d2b8ec507395a2a529174b3bd,"Linked Open Data (LOD) is a principle to publish machine readable data on the Web, and has been gaining growing attention owing to the recent upsurge of open data movement. For this reason, there are strong demands to develop applications that utilize LOD. To develop such an application, developers need to use SPARQL, a query language for RDF data, to access LOD, but there are several barriers: 1) to write an appropriate query, one needs to know the precise graph structure of RDF data being queried, although the graph structure of LOD datasets is in many cases very complicated and therefore hard to learn, and 2) it is hard for many users to learn SPARQL. To cope with this problem, in this paper, we propose a system for users to be able to query RDF data without learning SPARQL. Instead, we introduce JSON-style view on top of SPARQL endpoints. Having defined JSON-style views, ordinary users can issue queries against the views using LINQ, a structured query language similar to SQL. The system translates LINQ queries to corresponding SPARQL queries according to the view definition, and send the translated query to the SPARQL endpoint. The resulting data returned by SPARQL endpoints are processed and returned back to the user. We conduct experiments to show the feasibility of the proposed system. © 2015 IEEE.",Final,
Perera R.; Nand P.,"Perera, Rivindu (56425389400); Nand, Parma (6506991350)",56425389400; 6506991350,Selecting contextual peripheral information for answer presentation: The need for pragmatic models,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967225608&partnerID=40&md5=845c03a65806e4b2fa4e7b6aa0d72038,"This paper explores the possibility of presenting additional contextual information as a method of answer presentation Question Answering. In particular the paper discusses the result of employing Bag of Words (BoW) and Bag of Concepts (BoC) models to retrieve contextual information from a Linked Data resource, DBpedia. DBpedia provides structured information on wide variety of entities in the form of triples. We utilize the QALD question sets consisting of a 100 instances in the training set and another 100 in the testing set. The questions are categorized into single entity and multiple entity questions based on the number of entities mentioned in the question. The results show that both BoW (syntactic models) and BoC (semantic models) are not capable enough to select contextual information for answer presentation. The results further reveals that pragmatic aspects, in particular, pragmatic intent and pragmatic inference play a crucial role in contextual information selection in the answer presentation.",Final,
Rehman Z.; Kifor S.,"Rehman, Zobia (57212035458); Kifor, Stefania (36806036300)",57212035458; 36806036300,Teaching Natural Language Processing (NLP) Using Ontology Based Education Design,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072863412&doi=10.1515%2fcplbu-2015-0024&partnerID=40&md5=3de499b138966a2c5f0bff5d699d76ee,"It often happens in teaching that due to complexity of a subject or unavailability of an expert instructor the subject undergoes in a situation that not only affects its outcome but the involvement and learning development of students also. Although contents are covered even in such a situation but their inadequate explanation leaves many question marks in students' mind. Artificial Intelligence helps represent knowledge graphically and symbolically which can be logically inferred. Visual and symbolic representation of knowledge is easy to understand for both teachers and students. To facilitate students understanding teachers often structure domain knowledge in a visual form where all important contents of a subject can be seen along with their relation to each other. These structures are called ontology which is an important aspect of knowledge engineering. Teaching via ontology is in practice since last two decades. Natural Language Processing (NLP) is a combination of computation and linguistic and is often hard to teach. Its contents are apparently not tied together in a reasonable way which makes it difficult for a teacher that where to start with. In this article we will discuss the design of ontology to support rational learning and efficient teaching of NLP at introductory level.  © 2015 Quality Research Centre, Lucian Blaga University.",Final,All Open Access; Hybrid Gold Open Access
Sateli B.; Witte R.,"Sateli, Bahar (39062011400); Witte, René (23010981400)",39062011400; 23010981400,What's in this paper? combining rhetorical entities with linked open data for semantic literature querying,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968616004&doi=10.1145%2f2740908.2742022&partnerID=40&md5=3b47d379311b6a2535b125d9852dcedb,"Finding research literature pertaining to a task at hand is one of the essential tasks that scientists face on daily basis. Standard information retrieval techniques allow to quickly obtain a vast number of potentially relevant documents. Unfortunately, the search results then require significant effort for manual inspection, where we would rather select relevant publications based on more fine-grained, semantically rich queries involving a publication's contributions, methods, or application domains. We argue that a novel combination of three distinct methods can significantly advance this vision: (i) Natural Language Processing (NLP) for Rhetorical Entity (RE) detection; (ii) Named Entity (NE) recognition based on the Linked Open Data (LOD) cloud; and (iii) automatic generation of RDF triples for both NEs and REs using semantic web ontologies to interconnect them. Combined in a single workflow, these techniques allow us to automatically construct a knowledge base that facilitates numerous advanced use cases for managing scientific documents.",Final,
Kurz T.; Schlegel K.; Kosch H.,"Kurz, Thomas (34771675500); Schlegel, Kai (55786958900); Kosch, Harald (6701736254)",34771675500; 55786958900; 6701736254,Enabling access to linked media with SPARQL-MM,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968583568&doi=10.1145%2f2740908.2742914&partnerID=40&md5=9a8d3662e0f7449e556d15221ec2d908,"The amount of audio, video and image data on the web is immensely growing, which leads to data management problems based on the hidden character of multimedia. Therefore the interlinking of semantic concepts and media data with the aim to bridge the gap between the document web and the Web of Data has become a common practice and is known as Linked Media. However, the value of connecting media to its semantic meta data is limited due to lacking access methods specialized for media assets and fragments as well as to the variety of used description models. With SPARQL-MM we extend SPARQL, the standard query language for the Semantic Web with media specific concepts and functions to unify the access to Linked Media. In this paper we describe the motivation for SPARQL-MM, present the State of the Art of Linked Media description formats and Multimedia query languages, and outline the specification and implementation of the SPARQL-MM function set.",Final,
,,,CEUR Workshop Proceedings,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962318030&partnerID=40&md5=1af0144547a91e2750a8e39e0850d4f1,The proceedings contain 6 papers. The topics discussed include: a language-aware web will give us a bigger and better semantic web; roadmap for a multilingual BioPortal; applying the OntoLex model to a multilingual terminological resource; one ontology to bind them all: the METASHARE OWL ontology for the interoperability of linguistic datasets on the web; towards multilingual elexicography by means of linked (open) data; and introducing FREME: deploying linguistic linked data.,Final,
Haag F.; Lohmann S.; Siek S.; Ertl T.,"Haag, Florian (55338756700); Lohmann, Steffen (23397425600); Siek, Stephan (57031999600); Ertl, Thomas (7004765655)",55338756700; 23397425600; 57031999600; 7004765655,Visual querying of linked data with QueryVOWL,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964483243&partnerID=40&md5=3fff65cca9da06aa1ab2ad158ac255e8,"In order to enable users without any knowledge of RDF and SPARQL to query Linked Data, visual approaches can be helpful by providing graphical support for query building. We present QueryVOWL, a visual query language that is based upon the ontology visualization VOWL and defines mappings to SPARQL. We aim for a language that is intuitive and easy to use, while remaining flexible and preserving most of the expressiveness of SPARQL. In contrast to related work, the queries can be created entirely with visual elements, taking into account RDFS and OWL concepts often used to structure Linked Data. This paper introduces the QueryVOWL notation and illustrates the approach with example queries. The queries have been created with two prototypical implementations that demonstrate the general applicability of the approach. The comprehensibility and usability of the approach have been evaluated in a qualitative user study, indicating that lay users are able to construct and interpret QueryVOWL graphs.",Final,
Marko N.; Leitner A.; Herbst B.; Wallner A.,"Marko, Nadja (36699867400); Leitner, Andrea (37102046000); Herbst, Beate (57119357000); Wallner, Alfred (57119296900)",36699867400; 37102046000; 57119357000; 57119296900,Combining Xtext and OSLC for Integrated Model-Based Requirements Engineering,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958237425&doi=10.1109%2fSEAA.2015.11&partnerID=40&md5=8486ef62cd51dc7053167fe84798738d,"Requirements engineering is still a very challenging issue. This is true for most embedded systems and especially for safety-critical ones. A good requirements engineering process is vital for the development of high quality products, but these systems are often highly complex which complicates the respective activities. The use of natural language requirements is common practice, because they are easy to use and understand for people working in different engineering disciplines. However, natural language is ambiguous and vague and may lead to misunderstandings and incorrect implementations. Another big challenge is the often loose coupling of requirements and other development artifacts which hinders traceability and thus impact analysis. This paper presents an approach based on the Xtext framework for the implementation of a restricted requirements language to support engineers in writing requirements with higher quality. In order to improve tool integration, the approach supports OSLC (Open Services for Lifecycle Collaboration), which is a promising method to better support traceability using linked data principles. By using OSLC it is possible to easily extend existing requirements management tools with our proposed implementation for requirements semi-formalization as long as requirements management tools provide the respective OSLC interface. Finally, we will demonstrate our concepts using an example from the automotive domain. The example shows how the tool implementation can be integrated in a tool chain. © 2015 IEEE.",Final,
Hixon B.; Clark P.; Hajishirzi H.,"Hixon, Ben (55351459600); Clark, Peter (7402579556); Hajishirzi, Hannaneh (23008126600)",55351459600; 7402579556; 23008126600,Learning knowledge graphs for question answering through conversational dialog,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959088414&doi=10.3115%2fv1%2fn15-1086&partnerID=40&md5=064a06b29ed8bf9c581f48ad5a1a98aa,"We describe how a question-answering system can learn about its domain from conversational dialogs. Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions. We are the first to acquire knowledge for question-answering from open, natural language dialogs without a fixed ontology or domain model that predetermines what users can say. Our relation-based strategies complete more successful dialogs than a query expansion baseline, our taskdriven relations are more effective for solving science questions than relations from general knowledge sources, and our method is practical enough to generalize to other domains. © 2015 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
Heyvaert P.; Dimou A.; Verborgh R.; Mannens E.; Van De Walle R.,"Heyvaert, Pieter (56912288000); Dimou, Anastasia (55236344100); Verborgh, Ruben (36716974600); Mannens, Erik (24464045700); Van De Walle, Rik (7005287415)",56912288000; 55236344100; 36716974600; 24464045700; 7005287415,Towards a uniform user interface for editing mapping definitions,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954526572&partnerID=40&md5=70c0564a67693f0a35bb44db60369720,"Modeling domain knowledge as Linked Data is not straightforward for data publishers, because they are domain experts and not Semantic Web specialists. Most approaches that map data to its semantic representation still require users to have knowledge of the underlying implementations, as the mapping definitions remained, so far, tight to their execution. Defining mapping languages enables to decouple the mapping definitions from the implementation that executes them. However, user interfaces that enable domain experts to model knowledge and, thus, intuitively define such mapping definitions, based on available input sources, were not thoroughly investigated yet. This paper introduces a non-exhaustive list of desired features to be supported by such a mapping editor, independently of the underlying mapping language; and presents the RMLEditor as prototype interface that implements these features with RML as its underlying mapping language.",Final,
Bottoni P.; Ceriani M.,"Bottoni, Paolo (7006566346); Ceriani, Miguel (55787561400)",7006566346; 55787561400,Linked data queries as jigsaw puzzles: A visual interface for SPARQL based on blockly library,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979671207&doi=10.1145%2f2808435.2808467&partnerID=40&md5=61ce3a97e4b686359f7d713736ef712e,"SPARQL is a powerful query language for Semantic Web data sources but it is quite complex to master. The jigsaw puzzle methaphor has been succesfully used in Blockly to teach programming to kids. We discuss its applicability to the problem of building SPARQL queries, through the presentation of a dedicated Blockly-based visual user interface. © 2015 ACM.",Final,
Han L.; Finin T.; Joshi A.; Cheng. D.,"Han, Lushan (15055924300); Finin, Tim (7003679538); Joshi, Anupam (7402452908); Cheng., Doreen (57213574938)",15055924300; 7003679538; 7402452908; 57213574938,Querying RDF data with text annotated graphs,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959493061&doi=10.1145%2f2791347.2791381&partnerID=40&md5=7e1418b3678b6565a98fafec09746b53,"Scientists and casual users need better ways to query RDF databases or Linked Open Data. Using the SPARQL query language requires not only mastering its syntax and seman-Tics but also understanding the RDF data model, the on-Tology used, and URIs for entities of interest. Natural lan-guage query systems are a powerful approach, but current techniques are brittle in addressing the ambiguity and com-plexity of natural language and require expensive labor to supply the extensive domain knowledge they need. We in-Troduce a compromise in which users give a graphical ""skele-Ton"" for a query and annotates it with freely chosen words, phrases and entity names. We describe a framework for in-Terpreting these ""schema-Agnostic queries""over open domain RDF data that automatically translates them to SPARQL queries. The framework uses semantic textual similarity to find mapping candidates and uses statistical approaches to learn domain knowledge for disambiguation, thus avoiding expensive human efforts required by natural language inter-face systems. We demonstrate the feasibility of the approach with an implementation that performs well in an evaluation on DBpedia data. © 2015 ACM.",Final,
Kim E.-K.; Nam S.; Woo J.; Nam S.; Choi K.-S.,"Kim, Eun-Kyung (55705515700); Nam, Sangha (57077587500); Woo, Jongseong (57188755187); Nam, Sejin (55561208600); Choi, Key-Sun (7403949200)",55705515700; 57077587500; 57188755187; 55561208600; 7403949200,Triple-based similarity propagation for linked data matching,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962878690&partnerID=40&md5=03e9fdc02c82e2c63dae5df5570ff9ca,"In this paper, we propose an approach for mapping properties in two RDF datasets between different languages, using a triplebased similarity propagation that can be adapted to find potential property matches. This approach does not need any language dependent information during the process, and thus can be applied to arbitrary languages without requiring translation. Copyright © 2015 for the individual papers by the papers' authors.",Final,
Jiang B.; Xun E.; Qi J.,"Jiang, Birong (56649617800); Xun, Endong (6506210169); Qi, Jianzhong (53878392800)",56649617800; 6506210169; 53878392800,A domain independent approach for extracting terms from research papers,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959350961&doi=10.1007%2f978-3-319-19548-3_13&partnerID=40&md5=a2301ab86584de7eb02a8ac5c4edd18f,"We study the problem of extracting terms from research papers, which is an important step towards building knowledge graphs in research domain. Existing terminology extraction approaches are mostly domain dependent. They use domain specific linguistic rules, supervised machine learning techniques or a combination of the two to extract the terms. Using domain knowledge requires much human effort, e.g., manually composing a set of linguistic rules or labeling a large corpus, and hence limits the applicability of the existing approaches. To overcome this limitation, we propose a new terminology extraction approach that makes use of no knowledge from any specific domain. In particular, we use the title words and the keywords in research papers as the seeding terms and word2vec to identify similar terms from an open-domain corpus as the candidate terms, which are then filtered by checking their occurrence in the research papers. We repeat this process using the newly found terms until no new candidate term can be found. We conduct extensive experiments on the proposed approach. The results show that our approach can extract the terms effectively, while being domain independent. © Springer International Publishing Switzerland 2015.",Final,
Fatima A.; Luca C.; Wilson G.,"Fatima, Arooj (58587124600); Luca, Cristina (55329325500); Wilson, George (7404530373)",58587124600; 55329325500; 7404530373,User queries for semantic search engine,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961820438&doi=10.5013%2fIJSSST.a.16.04.11&partnerID=40&md5=143c6376ef330b97394e133544c42e49,"The amount of linked open data stored on the internet is increasing hugely, yet it is difficult for non-expert users to access the semantic data without having knowledge of SPARQL language. Whilst the modern semantic search engines tackled the problem with standard user interfaces, these interfaces are not very usable for the users with no or little knowledge of semantic web technologies. One way to achieve a user friendly interface is the use of an effective tool to convert a natural language query into a standard SPARQL query. This paper introduces an efficient way of information retrieval from online repositories and a system to match user entered keywords with related ontologies to format a query. This paper proposes a solution based on a previously modelled framework and introduces algorithms for query tagging and keyword mapping in order to formulate SPARQL queries. Finally, the paper describes examples using prototype user interface. © 2015, UK Simulation Society. All rights reserved.",Final,All Open Access; Green Open Access
Rajabi E.; Marenzi I.,"Rajabi, Enayat (42862135700); Marenzi, Ivana (35092974800)",42862135700; 35092974800,Linking a community platform to the linked open data cloud,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968677696&doi=10.1145%2f2740908.2741742&partnerID=40&md5=f26310a3493631a165d34e3b9d3dfbd8,"Linked Data promises access to a vast amount of resources for learners and teachers. Various research projects have focused on providing educational resources as Linked Data. In many of these projects the focus has been on interoperability of metadata and on linking them into the linked data cloud. In this paper we focus on the community aspect. We start from the observation that sharing data is most valuable within communities of practice with common interests and goals, and community members are interested in suitable resources to be used in specific learning scenarios. The community of practice we are focusing on is an English language teaching and learning community, which we have been supporting through the LearnWeb2.0 platform for the last two years. We analyse the requirements of this specific community as a basis to enrich the current collected materials with open educational resources taken from the Linked Data Cloud. To this aim, we performed an interlinking approach in order to enrich the learning resources exposed as RDF (Resource Description Framework) in the LearnWeb2.0 platform with additional information taken from the Web.",Final,
,,,"Proceedings of the 4th Workshop on Linked Data in Linguistics: Resources and Applications, LDL 2015 - collocated with 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2015",,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122948637&partnerID=40&md5=9ce385f273e53c3ba6fde8d9b5281c39,The proceedings contain 9 papers. The topics discussed include: from DBpedia and WordNet hierarchies to LinkedIn and twitter; a linked data model for multimodal sentiment and emotion analysis; seeing is correcting: curating lexical resources using social interfaces; Sar-graphs: a linked linguistic knowledge resource connecting facts with language; reconciling heterogeneous descriptions of language resources; digital representation of rights for language resources; linking four heterogeneous language resources as linked data; EVALution 1.0: an evolving semantic dataset for training and evaluation of distributional semantic models; and linguistic linked data in Chinese: the case of Chinese WordNet.,Final,
Bano M.; Ferrari A.; Zowghi D.; Gervasi V.; Gnesi S.,"Bano, Muneera (36661996700); Ferrari, Alessio (55765001561); Zowghi, Didar (6602925723); Gervasi, Vincenzo (6602711200); Gnesi, Stefania (6603718373)",36661996700; 55765001561; 6602925723; 6602711200; 6603718373,Automated service selection using natural language processing,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983347911&doi=10.1007%2f978-3-662-48634-4_1&partnerID=40&md5=b9d8c4e6221aa1565bc91fbbae4418cb,"With the huge number of services that are available online, requirements analysts face an overload of choice when they have to select the most suitable service that satisfies a set of customer requirements. Both service descriptions and requirements are often expressed in natural language (NL), and natural language processing (NLP) tools that can match requirements and service descriptions, while filtering out irrelevant options, might alleviate the problem of choice overload faced by analysts. In this paper, we propose a NLP approach based on Knowledge Graphs that automates the process of service selection by ranking the service descriptions depending on their NL similarity with the requirements. To evaluate the approach, we have performed an experiment with 28 customer requirements and 91 service descriptions, previously ranked by a human assessor. We selected the top-15 services, which were ranked with the proposed approach, and found 53% similar results with respect to top-15 services of the manual ranking. The same task, performed with the traditional cosine similarity ranking, produces only 13% similar results. The outcomes of our experiment are promising, and new insights have also emerged for further improvement of the proposed technique. © Springer-Verlag Berlin Heidelberg 2015.",Final,All Open Access; Green Open Access
Patti V.; Bertola F.; Lieto A.,"Patti, Viviana (6506947801); Bertola, Federico (56519658300); Lieto, Antonio (36782747200)",6506947801; 56519658300; 36782747200,ArsEmotica for arsmeteo.org: Emotion-driven exploration of online art collections,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958167525&partnerID=40&md5=7baafbd191249550e5891ed2f994c201,"In this paper, we present an application framework, ArsEmotica 2.0, where semantic technologies, linked data and natural language processing techniques are exploited for investigating the emotional aspects of cultural heritage artifacts, based on user generated contents collected in art social platforms. We rely on affective categorization models expressed by an ontology well grounded in psychology and encoded in W3C standard specification languages.We present the implementation and exploitation of the framework on a real dataset, the ArsMeteo online collection, aiming to adapt human access to cultural heritage collections by visualising emotions detected in artworks, and to let computer access by means of Linked Open Data. The use of semantic technologies enables both automatic reasoning on the elicited affective information, and interoperability or integration of tools developed within the Semantic Web and Linked Data Community. Copyright © 2015, Association for the Advancement of Artificial Intelligence. All rights reserved.",Final,
Bakal G.; Kavuluru R.,"Bakal, Gokhan (57074041500); Kavuluru, Ramakanth (23467019200)",57074041500; 23467019200,Predicting treatment relations with semantic patterns over biomedical knowledge graphs,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955261391&doi=10.1007%2f978-3-319-26832-3_55&partnerID=40&md5=86debef068d0584c18a2729309881de3,"Identifying new potential treatment options (say, medications and procedures) for known medical conditions that cause human disease burden is a central task of biomedical research. Since all candidate drugs cannot be tested with animal and clinical trials, in vitro approaches are first attempted to identify promising candidates. Even before this step, due to recent advances, in silico or computational approaches are also being employed to identify viable treatment options. Generally, natural language processing (NLP) and machine learning are used to predict specific relations between any given pair of entities using the distant supervision approach. In this paper, we report preliminary results on predicting treatment relations between biomedical entities purely based on semantic patterns over biomedical knowledge graphs. As such, we refrain from explicitly using NLP, although the knowledge graphs themselves may be built from NLP extractions. Our intuition is fairly straightforward - entities that participate in a treatment relation may be connected using similar path patterns in biomedical knowledge graphs extracted from scientific literature. Using a dataset of treatment relation instances derived from the well known Unified Medical Language System (UMLS), we verify our intuition by employing graph path patterns from a well known knowledge graph as features in machine learned models. We achieve a high recall (92%) but precision, however, decreases from 95% to an acceptable 71% as we go from uniform class distribution to a ten fold increase in negative instances. We also demonstrate models trained with patterns of length ≤ 3 result in statistically significant gains in F-score over those trained with patterns of length ≤ 2. Our results show the potential of exploiting knowledge graphs for relation extraction and we believe this is the first effort to employ graph patterns as features for identifying biomedical relations. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
,,,Linked Data in Linguistics 2015. Introduction and Overview,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122927781&partnerID=40&md5=d26a2187edfad33374a1709e58bbfaab,[No abstract available],Final,
Gao S.; Scharrenbach T.; Kietz J.-U.; Bernstein A.,"Gao, Shen (56209261800); Scharrenbach, Thomas (25825630500); Kietz, Jörg-Uwe (6507575238); Bernstein, Abraham (57212626682)",56209261800; 25825630500; 6507575238; 57212626682,Running out of bindings? Integrating facts and events in linked data stream processing,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955602764&partnerID=40&md5=e7783adb383f1468d80dd3214c308302,"Processing streams of linked data has gained increased importance over the past years. In many cases the streams contain events generated by sensors such as traffic control systems or news releases. As a reaction to this increased need, a number of languages and systems were developed that are aimed at processing linked data streams. These systems/languages follow one of two pertinent traditions: either they perform complex event processing or stream reasoning. However, both kinds of systems only support simulating system states as a sequence of events. This paper proposes to model a new kind of data - Facts. Facts are temporal states stored in systems that combine events. Essentially, they trade space complexity for time complexity and reduce the intermediate variable bindings compared to other approaches. They also have the advantage of keeping queries relatively simple. In our evaluation, we compile queries for typical sensor-based use-cases in TEF-SPARQL, our SPARQL extension supporting Facts, C-SPARQL, and EP-SPARQL to the well-established Event Processing Language (EPL) running on the Esper complex event processing engine. Compared to simulate Facts, we show that modeling Facts directly only creates less than 1% of intermediate bindings and improves the throughput by up to 4 times.",Final,
Zhu G.; Iglesias C.A.,"Zhu, Ganggao (57188974782); Iglesias, Carlos A. (56357213400)",57188974782; 56357213400,Sematch: Semantic entity search from knowledge graph,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964417432&partnerID=40&md5=272af308b0b35a7d840f7fd7aa67a194,"As an increasing amount of the knowledge graph is published as Linked Open Data, semantic entity search is required to develop new applications. However, the use of structured query languages such as SPARQL is challenging for non-skilled users who need to master the query language as well as acquiring knowledge of the underlying ontology of Linked Data knowledge bases. In this article, we propose the Sematch framework for entity search in the knowledge graph that combines natural language query processing, entity linking, entity type linking and semantic similarity based query expansion. The system has been validated in a dataset and a prototype has been developed that translates natural language queries into SPARQL.",Final,
Seyler D.; Yahya M.; Berberich K.,"Seyler, Dominic (57189296543); Yahya, Mohamed (57197692817); Berberich, Klaus (55953919200)",57189296543; 57197692817; 55953919200,Generating quiz questions from knowledge graphs,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968649103&doi=10.1145%2f2740908.2742722&partnerID=40&md5=0a3a854ea52ec07596c1efae8764d0af,"We propose an approach to generate natural language ques- tions from knowledge graphs such as DBpedia and YAGO. We stage this in the setting of a quiz game. Our approach, though, is general enough to be applicable in other set- tings. Given a topic of interest (e.g., Soccer) and a dificulty (e.g., hard), our approach selects a query answer, generates a SPARQL query having the answer as its sole result, before verbalizing the question.",Final,
Torvik V.I.,"Torvik, Vetle I. (6506300146)",6506300146,MapAffil: A bibliographic tool for mapping author affiliation strings to cities and their geocodes worldwide,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957096646&doi=10.1045%2fnovember2015-torvik&partnerID=40&md5=81edd1d71d052b244a9929fe0ef15b13,"Bibliographic records often contain author affiliations as free-form text strings. Ideally one would be able to automatically identify all affiliations referring to any particular country or city such as Saint Petersburg, Russia. That introduces several major linguistic challenges. For example, Saint Petersburg is ambiguous (it refers to multiple cities worldwide and can be part of a street address) and it has spelling variants (e.g., St. Petersburg, Sankt-Peterburg, and Leningrad, USSR). We have designed an algorithm that attempts to solve these types of problems. Key components of the algorithm include a set of 24,000 extracted city, state, and country names (and their variants plus geocodes) for candidate look-up, and a set of 1.1 million extracted word n-grams, each pointing to a unique country (or a US state) for disambiguation. When applied to a collection of 12.7 million affiliation strings listed in PubMed, ambiguity remained unresolved for only 0.1%. For the 4.2 million mappings to the USA, 97.7% were complete (included a city), 1.8% included a state but not a city, and 0.4% did not include a state. A random sample of 300 manually inspected cases yielded six incompletes, none incorrect, and one unresolved ambiguity. The remaining 293 (97.7%) cases were unambiguously mapped to the correct cities, better than all of the existing tools tested: GoPubMed got 279 (93.0%) and GeoMaker got 274 (91.3%) while MediaMeter CLIFF and Google Maps did worse. In summary, we find that incorrect assignments and unresolved ambiguities are rare (< 1%). The incompleteness rate is about 2%, mostly due to a lack of information, e.g. the affiliation simply says ""University of Illinois"" which can refer to one of five different campuses. A search interface called MapAffil has been developed at the University of Illinois in which the longitude and latitude of the geographical city-center is displayed when a city is identified. This not only helps improve geographic information retrieval but also enables global bibliometric studies of proximity, mobility, and other geo-linked data. © 2015 Vetle I. Torvik.",Final,All Open Access; Bronze Open Access; Green Open Access
Ismail A.S.; Al-Feel H.; Mokhtar H.M.O.,"Ismail, Ahmed Salama (57169473000); Al-Feel, Haytham (36805605400); Mokhtar, Hoda M. O. (36775353700)",57169473000; 36805605400; 36775353700,Bridging the gap for retrieving DBpedia data,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960933472&doi=10.1109%2fICeND.2015.7328537&partnerID=40&md5=efab3d7ab3f619288cbe2a966e0f105d,"DBpedia is nowadays considered one of the main projects in the World Wide Web that extracts and enriches Wikipedia data in a structured form. Also, it is considered the central hub for the Linked Open Data. Querying DBpedia using big data approaches such as Hive-QL is regarded as one of the new techniques to solve the shortcomings of SPARQL; the main query language of DBpedia and the Semantic Web. Nevertheless, despite the speed of Hive-QL compared to SPARQL, it has a stability problem. Our paper presents a new architecture and implementation for querying DBpedia using Shark query language in addition to Hive-QL. As a result of this work, An obvious decrease in execution time, as well as, an increase in the degree of stability have been attained. © 2015 IEEE.",Final,
Ingvaldsen J.E.; Özgöbek Ö.; Gulla J.A.,"Ingvaldsen, Jon Espen (10440722200); Özgöbek, Özlem (56204406900); Gulla, Jon Atle (6603727055)",10440722200; 56204406900; 6603727055,Context-aware user-driven news recommendation,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964063207&partnerID=40&md5=723ec3aa9bae1cce210f7b863926d87a,"Recommender systems match available contents with users' contexts and interests. With linked data knowledge bases we can build recommender systems where user interests, their context and available contents are modeled in terms of real world entities. In this demo paper we will describe existing academic news recommender systems and the Smartmedia prototype in particular. This prototype shows how we can combine available technologies like semantics, natural language processing and information retrieval to construct personalized and location aware recommendations on a continuous stream of news information. Copyright © 2015 for the individual papers by the papers' authors.",Final,
Jurczyk T.; Choi J.D.,"Jurczyk, Tomasz (57216441971); Choi, Jinho D. (55151206000)",57216441971; 55151206000,Semantics-based graph approach to complex question-answering,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093129374&partnerID=40&md5=2400b8f1db2850418960e6b8dee57d5f,"This paper suggests an architectural approach of representing knowledge graph for complex question-answering. There are four kinds of entity relations added to our knowledge graph: syntactic dependencies, semantic role labels, named entities, and coreference links, which can be effectively applied to answer complex questions. As a proof of concept, we demonstrate how our knowledge graph can be used to solve complex questions such as arithmetics. Our experiment shows a promising result on solving arithmetic questions, achieving the 3-folds cross-validation score of 71.75%. © NAACL-HLT 2015 - 2015 Student Research Workshop (SRW) at the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings. All rights reserved.",Final,
Hartig O.,"Hartig, Olaf (19638345600)",19638345600,LDQL: A language for linked data queries,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937458525&partnerID=40&md5=52d24c87fcf2cea9253e2a28d42532be,"In this paper, we propose LDQL, that is, a language to query Linked Data on the Web. The novelty of LDQL is that it enables a user to express separately (i) patterns that describe the expected query result, and (ii) Web navigation paths that select the data sources to be used for computing the result. As a downside of this expressiveness, we find that for some LDQL queries, a complete execution is not possible in practice. To address this issue, we show a syntactic property based on which systems can identify queries that do not have this limitation.",Final,
Sánchez-Cervantes J.L.; Rodríguez-Mazahua L.; Alor-Hernández G.; Sánchez-Ramírez C.; García-Alcaráz J.L.; Jimenez-Macias E.,"Sánchez-Cervantes, José Luis (36976388800); Rodríguez-Mazahua, Lisbeth (56436822300); Alor-Hernández, Giner (17433252100); Sánchez-Ramírez, Cuauhtémoc (57190882674); García-Alcaráz, Jorge Luis (55616966800); Jimenez-Macias, Emilio (57200162568)",36976388800; 56436822300; 17433252100; 57190882674; 55616966800; 57200162568,Benchmarking applied to semantic conceptual models of linked financial data,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951120411&doi=10.1007%2f978-3-319-26138-6_32&partnerID=40&md5=328384d31ee2e4a161c1baa4b37cb2e6,"Semantic modeling plays a central role in knowledge-based systems where information sharing and integration is a primary objective. Ontology and metadata description languages such as OWL (Web Ontology Language) and RDF(S) (Resource Description Framework Schema) are commonly the most used for representing semantic models and data. The graph-like structure adopted for semantic metadata representation allows simple and expressive queries by using SPARQL-based subgraph matching. While performance of such knowledgebased systems depends on multiple factors, in this work we present a mechanism to properly choice a semantic modeling pattern in order to significantly reduce the data query execution time. Based on this understanding, this work proposes a comparative analysis of different conceptual modeling approaches on the basis of financial domain. In order to show the efficiency/accuracy of our approach, an evaluation of SPARQL-based queries was performed against different modeled datasets. © Springer International Publishing Switzerland 2015.",Final,
,,,"16th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing 2015",,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942523425&partnerID=40&md5=e87411dc04000f565ffb5a5926a21f7c,"The proceedings contain 50 papers. The special focus in this conference is on Sentiment Analysis, Emotion Detection, Social Network Analysis and Natural Language Generation. The topics include: Building large Arabic multi-domain resources for sentiment analysis; modelling public sentiment in twitter; trending sentiment-topic detection on twitter; feature selection for twitter sentiment analysis; an iterative emotion classification approach for microblogs; aspect-based sentiment analysis using tree kernel based relation extraction; sentiment classification with graph sparsity regularization; detecting emotion stimuli in emotion-bearing sentences; sentiment-bearing new words mining; exploiting emoticons and latent polarities; identifying temporal information and tracking sentiment in cancer patients’ interviews; using stylometric features for sentiment classification; automated linguistic personalization of targeted marketing messages mining user-generated text on social media; inferring aspect-specific opinion structure in product reviews using co-training; summarizing customer reviews through aspects and contexts; twitter recommendation based on users#x2019; personal interests; detection of opinion spam with character n-grams; content-based recommender system enriched with WordNet synsets; active learning based weak supervision for textual survey response classification; detecting and disambiguating locations mentioned in twitter messages; satisfying poetry properties using constraint handling rules; a multi-strategy approach for lexicalizing linked open data; enhancing graph-based techniques for summary extraction with sentiment polarity; experiments with query expansion for entity finding; improving cross language information retrieval using corpus based query suggestion approach and information extraction with active learning.",Final,
Peñas A.; Unger C.; Paliouras G.; Kakadiaris I.,"Peñas, Anselmo (35619424200); Unger, Christina (42862497400); Paliouras, Georgios (6602657411); Kakadiaris, Ioannis (35600180100)",35619424200; 42862497400; 6602657411; 35600180100,Overview of the CLEF question answering track 2015,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945977145&doi=10.1007%2f978-3-319-24027-5_50&partnerID=40&md5=1664e0aefdb6b1f7233aec1f40396f2d,"This paper describes the CLEF QA Track 2015. Following the scenario stated last year for the CLEF QA Track, the starting point for accessing information is always a Natural Language question. However, answering some questions may need to query Linked Data (especially if aggregations or logical inferences are required), some questions may need textual inferences and querying free-text, and finally, answering some queries may require both sources of information. In this edition, the Track was divided into four tasks: (i) QALD: focused on translating natural language questions into SPARQL; (ii) Entrance Exams: focused on answering questions to assess machine reading capabilities; (iii) BioASQ1 focused on large-scale semantic indexing and (iv) BioASQ2 for Question Answering in the biomedical domain. © Springer International Publishing Switzerland 2015.",Final,
Frontini F.; Brando C.; Ganascia J.-G.,"Frontini, Francesca (55162070400); Brando, Carmen (23388106100); Ganascia, Jean-Gabriel (6603992288)",55162070400; 23388106100; 6603992288,Domain-adapted named-entity linker using Linked Data,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937122779&partnerID=40&md5=101ec538aaf72888f606323955a9c6d6,"We present REDEN, a tool for graph-based Named Entity Linking that allows for the disambiguation of entities using domain-specific Linked Data sources and different configurations (e.g. context size). It takes TEI-annotated texts as input and outputs them enriched with external references (URIs). The possibility of customizing indexes built from various knowledge sources by defining temporal and spatial extents makes REDEN particularly suited to handle domain-specific corpora such as enriched digital editions in the Digital Humanities.",Final,
Guo S.; Wang Q.; Wang B.; Wang L.; Guo L.,"Guo, Shu (55515151500); Wang, Quan (55584980300); Wang, Bin (55584805140); Wang, Lihong (57007714500); Guo, Li (56564475400)",55515151500; 55584980300; 55584805140; 57007714500; 56564475400,Semantically smooth knowledge graph embedding,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943760568&doi=10.3115%2fv1%2fp15-1009&partnerID=40&md5=8364da8101b18b0d32ecdd7be5311f0f,"This paper considers the problem of embedding Knowledge Graphs (KGs) consisting of entities and relations into lowdimensional vector spaces. Most of the existing methods perform this task based solely on observed facts. The only requirement is that the learned embeddings should be compatible within each individual fact. In this paper, aiming at further discovering the intrinsic geometric structure of the embedding space, we propose Semantically Smooth Embedding (SSE). The key idea of SSE is to take full advantage of additional semantic information and enforce the embedding space to be semantically smooth, i.e., entities belonging to the same semantic category will lie close to each other in the embedding space. Two manifold learning algorithms Laplacian Eigenmaps and Locally Linear Embedding are used to model the smoothness assumption. Both are formulated as geometrically based regularization terms to constrain the embedding task. We empirically evaluate SSE in two benchmark tasks of link prediction and triple classification, and achieve significant and consistent improvements over state-of-The-Art methods. Furthermore, SSE is a general framework. The smoothness assumption can be imposed to a wide variety of embedding models, and it can also be constructed using other information besides entities' semantic categories. © 2015 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
Marczak S.,"Marczak, Sylwia (56946598300)",56946598300,Possibility of using GDELT to research on the spatial portrait of country – Example of Poland,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946410181&partnerID=40&md5=79a672009facf34e3e1f80df40807803,"GDELT – Global Data of Events, Language and Tone is the free and open dataset containing over 250 million geolocated events mentioned by media since 1979 to present. The GDELT project might be considered as a global catalogue of the human society; it is scooping up all the world’s news media – published on the web, printed and broadcasted in over 100 languages from every country. It processes them and provides data in real time (updated daily). Within GDELT two datasets are created. The first one, the Event Database is recording over 300 CAMEO categories of physical activities georeferenced to the city - geolocation is specified in the columns of “longtitude” and “latitude” for each event. the second one, the Global Knowledge Graph is recording people, organizations, locations and over 230 themes underlying those events. The results can be displayed as a georeferenced network diagram over the entire world and it may present not only the event itself, but also its participants and its context. The basic objective of this paper was the examination of GDELT data in the context of using it in GIS software. The RAW GDELT data was downloaded and the database structure was analyzed using the R environment. Except the data, the GDELT project also provides tools to visualize it (the Analysis Service), or to analyze it at the limitless scale using the Google BigQuery. The paper describes these tools and analyzes the results in the context of their use in making the spatial portrait of Poland. GDELT data, the open spatial data provided by the Head Office of Geodesy and Cartography and statistical data related to economy and demography was harmonized and aggregated into NUTS4 units of Poland. Finally, the prototype of the spatial portrait of Poland was created using spatial analysis tools of GIS software. © SGEM2015.",Final,
Du Y.J.; Hu Q.; Li X.L.; Chen X.L.; Li C.X.,"Du, Ya Jun (7402893744); Hu, Qiang (56146632100); Li, Xiao Lei (55951842600); Chen, Xiao Liang (55908009800); Li, Chen Xing (56937260700)",7402893744; 56146632100; 55951842600; 55908009800; 56937260700,Ranking web page with path trust knowledge graph,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945914748&doi=10.1007%2f978-3-319-23862-3_7&partnerID=40&md5=ff4d050e383d9cf5286fb680d58b0b61,"How to find and discover useful information from Internet is a real challenge in information retrieval (IR) and search engines (SE). In this paper, we propose and construct Path Trust Knowledge Graph PTKGmodel for assigning priority values to the unvisited web pages. For a given user specific topic t, its PTKGcontains five parts: (1) The context graph G(t) = (V, E), where V is the crawled history web page set and E includes the hyper link set among the history web pages; (2) Retrieving knowledge implied in the paths among these web pages and finding their lengths; (3) Building the trust degrees among the web pages; (4) Constructing topic specific language model and general language model by using the trust degrees; (5) Assigning the priority values of web pages for ranking them. Finally, we perform an experimental comparison among our proposed PTKG approach with the classic LCG and RCG. As a result, our method outperforms LCG and RCG. © Springer International Publishing Switzerland 2015.",Final,
Hartig O.; Pirrò G.,"Hartig, Olaf (19638345600); Pirrò, Giuseppe (19638901800)",19638345600; 19638901800,A context-based semantics for SPARQL property paths over the web,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937409214&doi=10.1007%2f978-3-319-18818-8_5&partnerID=40&md5=71d20e0e45af43c64f516ff9f6d659e0,"As of today, there exists no standard language for querying Linked Data on the Web, where navigation across distributed data sources is a key feature. A natural candidate seems to be SPARQL, which recently has been enhanced with navigational capabilities thanks to the introduction of property paths (PPs). However, the semantics of SPARQL restricts the scope of navigation via PPs to single RDF graphs. This restriction limits the applicability of PPs on the Web. To fill this gap, in this paper we provide formal foundations for evaluating PPs on the Web, thus contributing to the definition of a query language for Linked Data. In particular, we introduce a query semantics for PPs that couples navigation at the data level with navigation on the Web graph. Given this semantics we find that for some PP-based SPARQL queries a complete evaluation on the Web is not feasible. To enable systems to identify queries that can be evaluated completely, we establish a decidable syntactic property of such queries. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Bronze Open Access; Green Open Access
Li J.; Pan J.; Ye C.; Huang Y.; Wen D.; Wang Z.,"Li, Jun (57016037500); Pan, Jinxian (57015913100); Ye, Chen (57203615648); Huang, Yong (57015725700); Wen, Danlu (57016150200); Wang, Zhichun (55211881600)",57016037500; 57015913100; 57203615648; 57015725700; 57016150200; 55211881600,Linking entities in chinese queries to knowledge graph,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951293515&doi=10.1007%2f978-3-319-25207-0_56&partnerID=40&md5=ef22d88bc3766aad129b969a1a547380,"This paper presents our approach for NLPCC 2015 shared task, Entity Recognition and Linking in Chinese Search Queries. The proposed approach takes a query as input, and generates a ranked mentionentity links as results. It combines several different metrics to evaluate the probability of each entity link, including entity relatedness in the given knowledge graph, document similarity between query and the virtual document of entity in the knowledge graph. In the evaluation, our approach gets 33.2% precision and 65.2% recall, and ranks the 6th among all the 14 teams according to the average F1-measure. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Hybrid Gold Open Access
Fionda V.; Pirro G.; Gutierrez C.,"Fionda, Valeria (23472585900); Pirro, Giuseppe (19638901800); Gutierrez, Claudio (7202545224)",23472585900; 19638901800; 7202545224,Nautilod: A Formal language for the web of data graph,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921920911&doi=10.1145%2f2697393&partnerID=40&md5=97471116ad5825bdf8566b0f4d0be7be,"The Web of Linked Data is a huge graph of distributed and interlinked datasources fueled by structured information. This new environment calls for formal languages and tools to automatize navigation across datasources (nodes in such graph) and enable semantic-Aware and Web-scale search mechanisms. In this article we introduce a declarative navigational language for theWeb of Linked Data graph called NAUTILOD. NAUTILOD enables one to specify datasources via the intertwining of navigation and querying capabilities. It also features a mechanism to specify actions (e.g., send notification messages) that obtain their parameters from datasources reached during the navigation. We provide a formalization of the NAUTILOD semantics, which captures both nodes and fragments of the Web of Linked Data. We present algorithms to implement such semantics and study their computational complexity. We discuss an implementation of the features of NAUTILOD in a tool called swget, which exploits current Web technologies and protocols. We report on the evaluation of swget and its comparison with related work. Finally, we show the usefulness of capturing Web fragments by providing examples in different knowledge domains.",Final,All Open Access; Green Open Access
Park J.-R.; Brenza A.,"Park, Jung-Ran (8248562400); Brenza, Andrew (56879159800)",8248562400; 56879159800,Semi-automatic metadata generation workflow for developing a continuing education resource repository,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951959732&doi=10.1007%2f978-3-319-27974-9_24&partnerID=40&md5=58d1c99c550ee25124c83ae73a18e013,"This paper presents a high-level conceptualized workflow for the development of a repository related to continuing educational resources for the metadata professions. One of the major challenges facing cataloging and metadata communities concerns current developments and emerging trends in standards and technologies for managing digital information. Through utilization and integration of available open-source (semi)automatic metadata generation tools, we attempted to design a repository that maximizes the selfsufficiency of the system components while also generating high quality metadata records for metadata resources. We also attempted to design a workflow that will permit the repository to serve its primary function as a continually updated warehouse of material that will constitute a centralized resource of continuing education needs of metadata. © Springer International Publishing Switzerland 2015.",Final,
,,,"9th Research Conference on Metadata and Semantics Research, MTSR 2015",,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974534&partnerID=40&md5=5ebcfadc9eb91d0d7570bd9aa542018d,"The proceedings contain 40 papers. The special focus in this conference is on Ontology Evolution, Engineering, Frameworks, and Semantic Web, Metadata Extraction, Modelling, Interoperability and Exploratory Search. The topics include: An orchestration framework for linguistic task ontologies; on the preservation of evolving digital content - the continuum approach and relevant metadata models; challenges for ontological engineering in the humanities; threshold determination and engaging materials scientists in ontology design; what are information security ontologies useful for interoperable multimedia annotation and retrieval for the tourism sector; species identification through preference-enriched faceted search; an expert system for water quality monitoring based on ontology; discovering the topical evolution of the digital library evaluation community; application of metadata standards for interoperability between species distribution models; majority voting re-ranking algorithm for content based-image retrieval; narrative analysis for hypergraph ontology of movies using plot units; vocabularies for resource description in the semantic web; metadata for scientific audiovisual media; metadata interoperability and ingestion of learning resources into a modern LMS; clustering learning objects for improving their recommendation via collaborative filtering algorithms; conceptualization of personalized privacy preserving algorithms; evaluation of metadata in research data repositories; software applications ecosystem for authority control; measuring europeana’s usability; usability testing of an annotation tool in a cultural heritage context; an exploration of users’ needs for multilingual information retrieval and access and mapping large scale research metadata to linked data.",Final,
Chen Y.-N.; Wang W.Y.; Gershman A.; Rudnicky A.I.,"Chen, Yun-Nung (47061006000); Wang, William Yang (57233559700); Gershman, Anatole (56279059600); Rudnicky, Alexander I. (6602574360)",47061006000; 57233559700; 56279059600; 6602574360,Matrix factorization with knowledge graph propagation for unsupervised spoken language understanding,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943809524&doi=10.3115%2fv1%2fp15-1047&partnerID=40&md5=ced451fd4d69f3a5fae48f44dd33ac73,"Spoken dialogue systems (SDS) typically require a predefined semantic ontology to train a spoken language understanding (SLU) module. In addition to the annotation cost, a key challenge for designing such an ontology is to define a coherent slot set while considering their complex relations. This paper introduces a novel matrix factorization (MF) approach to learn latent feature vectors for utterances and semantic elements without the need of corpus annotations. Specifically, our model learns the semantic slots for a domain-specific SDS in an unsupervised fashion, and carries out semantic parsing using latent MF techniques. To further consider the global semantic structure, such as inter-word and inter-slot relations, we augment the latent MF-based model with a knowledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner. © 2015 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Jain K.; Khatri P.; Indolia G.,"Jain, Kush (56900598100); Khatri, Priya (56900836400); Indolia, Garima (56901216300)",56900598100; 56900836400; 56901216300,Chunked N-Grams for Sentence Validation,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944046952&doi=10.1016%2fj.procs.2015.07.433&partnerID=40&md5=d7ac8a1256c434b25d00946124ece3f6,"This paper deals with Sentence Validation - a sub-field of Natural Language Processing. Sentence Validation refers to verification of ""Natural Language"" sentence on basis of its syntax and semantics. Sentence Validation is usually carried either via Statistical Means (n-grams) or by Semantic Means (by constructing some kind of Knowledge graph). We have tried to integrate the two approaches. Instead of directly using statistical methods, our sentences under-went semantic pre-processing before applying standard Statistical Means. The results for direct Statistical approach is compared with semantically pre-processed statistical approach. © 2015 Published by Elsevier Ltd.",Final,All Open Access; Gold Open Access
Gupta M.; Bendersky M.,"Gupta, Manish (57203756586); Bendersky, Michael (23994792700)",57203756586; 23994792700,Information retrieval with verbose queries,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938590660&doi=10.1561%2f1500000050&partnerID=40&md5=c8dce439ac7e0488fff988c6728adf49,"Recently, the focus of many novel search applications has shifted from short keyword queries to verbose natural language queries. Examples include question answering systems and dialogue systems, voice search on mobile devices and entity search engines like Facebook's Graph Search or Google's Knowledge Graph. However the performance of textbook information retrieval techniques for such verbose queries is not as good as that for their shorter counterparts. Thus, effective handling of verbose queries has become a critical factor for adoption of information retrieval techniques in this new breed of search applications. Over the past decade, the information retrieval community has deeply explored the problem of transforming natural language verbose queries using operations like reduction, weighting, expansion, reformulation and segmentation into more effective structural representations. However, thus far, there was not a coherent and organized survey on this topic. In this survey, we aim to put together various research pieces of the puzzle, provide a comprehensive and structured overview of various proposed methods, and also list various application scenarios where effective verbose query processing can make a significant difference. © 2015 M. Gupta and M. Bendersky.",Final,
Baudiš P.; Šedivý J.,"Baudiš, Petr (54416895900); Šedivý, Jan (7004344600)",54416895900; 7004344600,Modeling of the question answering task in the YodaQA system,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945919776&doi=10.1007%2f978-3-319-24027-5_20&partnerID=40&md5=299a134b77b0817c3bc800dccc4c0919,"We briefly survey the current state of art in the field of Question Answering and present the YodaQA system, an open source framework for this task and a baseline pipeline with reasonable performance. We take a holistic approach, reviewing and aiming to integrate many different question answering task definitions and approaches concerning classes of knowledge bases, question representation and answer generation. To ease performance comparisons of general-purpose QA systems, we also propose an effort in building a new reference QA testing corpus which is a curated and extended version of the TREC corpus. © Springer International Publishing Switzerland 2015.",Final,
Gao J.; Mazumdar S.,"Gao, Jie (57015819300); Mazumdar, Suvodeep (36696771100)",57015819300; 36696771100,Exploiting linked open data to uncover entity types,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951279084&doi=10.1007%2f978-3-319-25518-7_5&partnerID=40&md5=ceccc88c7b2b1594879b85e062c70c82,"Extracting structured information from text plays a crucial role in automatic knowledge acquisition and is at the core of any knowledge representation and reasoning system. Traditional methods rely on hand-crafted rules and are restricted by the performance of various linguistic pre-processing tools. More recent approaches rely on supervised learning of relations trained on labelled examples, which can be manually created or sometimes automatically generated (referred as distant supervision). We propose a supervised method for entity typing and alignment. We argue that a rich feature space can improve extraction accuracy and we propose to exploit Linked Open Data (LOD) for feature enrichment. Our approach is tested on task-2 of the Open Knowledge Extraction challenge, including automatic entity typing and alignment. Our approach demonstrate that by combining evidences derived from LOD (e.g. DBpedia) and conventional lexical resources (e.g. WordNet) (i) improves the accuracy of the supervised induction method and (ii) enables easy matching with the Dolce+DnS Ultra Lite ontology classes. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Green Open Access
Ji G.; He S.; Xu L.; Liu K.; Zhao J.,"Ji, Guoliang (56898499600); He, Shizhu (56021680600); Xu, Liheng (55843856700); Liu, Kang (55729555700); Zhao, Jun (57190004147)",56898499600; 56021680600; 55843856700; 55729555700; 57190004147,Knowledge graph embedding via dynamic mapping matrix,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943792156&doi=10.3115%2fv1%2fp15-1067&partnerID=40&md5=601f4a29fe876438fd3ada2e11814eac,"Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-The-Art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms stateof-the-Art methods. © 2015 Association for Computationl Linguisticss.",Final,All Open Access; Hybrid Gold Open Access
Haag F.; Siek S.; Lohmann S.; Ertl T.,"Haag, Florian (55338756700); Siek, Stephan (57031999600); Lohmann, Steffen (23397425600); Ertl, Thomas (7004765655)",55338756700; 57031999600; 23397425600; 7004765655,QueryVOWL: A visual query notation for linked data,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952690646&doi=10.1007%2f978-3-319-25639-9_51&partnerID=40&md5=f1d647e551c6376e44bace93c50aa4f4,"In order to enable users without any knowledge of RDF and SPARQL to query Linked Data, visual approaches can be helpful by providing graphical support for query building. We present QueryVOWL, a visual query language that is based upon the ontology visualization VOWL and defines mappings to SPARQL. We aim for a language that is intuitive and easy to use, while remaining flexible and preserving most of the expressiveness of SPARQL. In contrast to related work, the queries can be created entirely with visual elements, taking into account RDFS and OWL concepts often used to structure Linked Data. This paper is a revised version of a workshop paper where we first introduced QueryVOWL. We present the query notation, some example queries, and two prototypical implementations of QueryVOWL. Also, we report on a qualitative user study that indicates lay users are able to construct and interpret QueryVOWL graphs. © Springer International Publishing Switzerland 2015.",Final,All Open Access; Hybrid Gold Open Access
Selmer P.; Poulovassilis A.; Wood P.T.,"Selmer, Petra (36946463100); Poulovassilis, Alexandra (7003984218); Wood, Peter T. (7402902051)",36946463100; 7003984218; 7402902051,Implementing flexible operators for regular path queries,,-1,-1,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925015159&partnerID=40&md5=8fb75e1287fd2cc6ab05cdc4889490dc,"Given the heterogeneity of complex graph data on the web, such as RDF linked data, a user wishing to query such data may lack full knowledge of its structure and irregularities. Hence, providing users with exible querying capabilities can be beneficial. The query language we adopt comprises conjunctions of regular path queries, thus including extensions proposed for SPARQL 1.1 to allow for querying paths using regular expressions. To this language we add two operators: APPROX, supporting standard notions of approximation based on edit distance, and RELAX, which performs query relaxation based on RDFS inference rules. We describe our techniques for implementing the extended language and present a performance study undertaken on two real-world data sets. Our baseline implementation performs competitively with other automaton-based approaches, and we demonstrate empirically how various optimisations can decrease execution times of queries containing APPROX and RELAX, sometimes by orders of magnitude. © 2015, Copyright is with the authors.",Final,
Sekhavat Y.A.; Di Paolo F.; Barbosa D.; Merialdo P.,"Sekhavat, Yoones A. (24538194900); Di Paolo, Francesco (56478861100); Barbosa, Denilson (14027953400); Merialdo, Paolo (6602539867)",24538194900; 56478861100; 14027953400; 6602539867,Knowledge base augmentation using tabular data,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920829984&partnerID=40&md5=5835e45cdf6d157f937682b6f3b9ff81,"Large linked data repositories have been built by leveraging semi-structured data in Wikipedia (e.g., DBpedia) and through extracting information from natural language text (e.g., YAGO). However, the Web contains many other vast sources of linked data, such as structured HTML tables and spreadsheets. Often, the semantics in such tables is hidden, preventing one from extracting triples from them directly. This paper describes a probabilistic method that augments an existing knowledge base with facts from tabular data by leveraging a Web text corpus and natural language patterns associated with relations in the knowledge base. A preliminary evaluation shows high potential for this technique in augmenting linked data repositories. © LDOW2014, April 8, 2014, Seoul, Korea.",Final,
Tymoshenko K.; Moschitti A.; Severyn A.,"Tymoshenko, Kateryna (36163592300); Moschitti, Alessandro (6507876429); Severyn, Aliaksei (36562482900)",36163592300; 6507876429; 36562482900,Encoding semantic resources in syntactic structures for passage reranking,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905674833&doi=10.3115%2fv1%2fe14-1070&partnerID=40&md5=6db11fd0c552ccad6642f2b7269093ad,"In this paper, we propose to use semantic knowledge from Wikipedia and large-scale structured knowledge datasets available as Linked Open Data (LOD) for the answer passage reranking task. We represent question and candidate answer passages with pairs of shallow syntactic/semantic trees, whose constituents are connected using LOD. The trees are processed by SVMs and tree kernels, which can automatically exploit tree fragments. The experiments with our SVM rank algorithm on the TREC Question Answering (QA) corpus show that the added relational information highly improves over the state of the art, e.g., about 15.4% of relative improvement in P@1. © 2014 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Akbacak M.; Hakkani-Tür D.; Tur G.,"Akbacak, Murat (6507059325); Hakkani-Tür, Dilek (6603261445); Tur, Gokhan (15060858000)",6507059325; 6603261445; 15060858000,Rapidly building domain-specific entity-centric language models using semantic web knowledge sources,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910092848&partnerID=40&md5=5f6811ff2776d11de3d9cda022c2837f,"For domain-specific speech recognition tasks, it is best if the statistical language model component is trained with text data that is content-wise and style-wise similar to the targeted domain for which the application is built. For state-of-the-art language modeling techniques that can be used in real-time within speech recognition engines during first-pass decoding (e.g., N-gram models), the above constraints have to be fulfilled in the training data. However collecting such data, even through crowd sourcing, is expensive and time consuming, and can still be not representative of how a much larger user population would interact with the recognition system. In this paper, we address this problem by employing several semantic web sources that already contain the domain-specific knowledge, such as query click logs and knowledge graphs. We build statistical language models that meet the requirements listed above for domain-specific recognition tasks where natural language is used and the user queries are about name entities in a specific domain. As a case study, in the movies domain where users' voice queries are movie related, compared to a generic web language model, a language model trained with the above resources not only yields significant perplexity and word-errorrate improvements, but also presents an approach where such language models can be rapidly developed for other domains. Copyright © 2014 ISCA.",Final,
,,,"Proceedings of the Workshop on Lexical and Grammatical Resources for Language Processing, LG-LP 2014 - in conjunction with 25th International Conference on Computational Linguistics, COLING 2014",,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123862293&partnerID=40&md5=74bba2f2b8918da0f4417161aff01e8b,The proceedings contain 18 papers. The topics discussed include: paraphrasing of italian support verb constructions based on lexical and grammatical resources; using language technology resources and tools to construct Swedish FrameNet; harmonizing lexical data for their linking to knowledge objects in the linked data framework; SentiMerge: combining sentiment lexicons in a Bayesian framework; using morphosemantic information in construction of a pilot lexical semantic resource for Turkish; linguistically motivated language resources for sentiment analysis; acquisition and enrichment of morphological and morphosemantic knowledge from the French Wiktionary; and the fuzzy boundaries of operator verb and support verb constructions with dar ‘give’ and ter ‘have’ in Brazilian Portuguese.,Final,
Xu K.; Feng Y.; Zhao D.,"Xu, Kun (55712650500); Feng, Yansong (55387599700); Zhao, Dongyan (55387416000)",55712650500; 55387599700; 55387416000,Xser@QALD-4: Answering natural language questions via phrasal semantic parsing,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981234303&partnerID=40&md5=ffe859d77ece8524f717de1474bd8b2f,"We present a question answering system (Xser) over Linked Data(DBpedia), converting users' natural language questions into structured queries. There are two challenges involved: recognizing users' query intention and mapping the involved semantic items against a given knowledge base (KB), which will be in turn assembled into a structured query. In this paper, we propose an efficient pipeline framework to model a user's query intention as a phrase level dependency DAG which is then instantiated according to a given KB to construct the final structured query. We evaluate our approach on the QALD-4 test dataset and achieve an F-measure score of 0.72, an average precision of 0.72 and an average recall of 0.71 over 50 questions.",Final,
Gesmundo A.; Hall K.B.,"Gesmundo, Andrea (51664973400); Hall, Keith B. (36028055700)",51664973400; 36028055700,Projecting the Knowledge Graph to Syntactic Parsing,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040308049&partnerID=40&md5=fa8906886a4e73fceb94a1e889162352,"We present a syntactic parser training paradigm that learns from large scale Knowledge Bases. By utilizing the Knowledge Base context only during training, the resulting parser has no inference-time dependency on the Knowledge Base, thus not decreasing the speed during prediction. Knowledge Base information is injected into the model using an extension to the Augmented-loss training framework. We present empirical results that show this approach achieves a significant gain in accuracy for syntactic categories such as coordination and apposition. © 2014 Association for Computational Linguistics",Final,
Lämmel R.; Varanovich A.,"Lämmel, Ralf (7004269252); Varanovich, Andrei (36653300200)",7004269252; 36653300200,Interpretation of linguistic architecture,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958554403&doi=10.1007%2f978-3-319-09195-2_5&partnerID=40&md5=820cf9ff818c906280815bd900c76336,"The megamodeling language MegaL is designed to model the linguistic architecture of software systems: the relationships between software artifacts (e.g., files), software languages (e.g., programming languages), and software technologies (e.g., code generators) used in a system. The present paper delivers a form of interpretation for such megamodels: resolution of megamodel elements to resources (e.g., system artifacts) and evaluation of relationships, subject to designated programs (such as pluggable 'tools' for checking). Interpretation reduces concerns about the adequacy and meaning of megamodels, as it helps to apply the megamodels to actual systems. We leverage Linked Data principles for surfacing resolved megamodels by linking, for example, artifacts to GitHub repositories or concepts to DBpedia resources. We provide an executable specification (i.e., semantics) of interpreted megamodels and we discuss an implementation in terms of an object-oriented framework with dynamically loaded plugins. © 2014 Springer International Publishing Switzerland.",Final,
,,,"15th International Conference on Web Information Systems Engineering, WISE 2014",,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030312312&partnerID=40&md5=71349e3647de14df1457fdd9d0f99273,"The proceedings contain 81 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: Coupled item-based matrix factorization; a lot of slots – outliers confinement in review-based system; a unified model for community detection of multiplex networks; mining domain-specific dictionaries of opinion words; a community detection algorithm based on the similarity sequence; a self-learning clustering algorithm based on clustering coefficient; detecting hierarchical structure of community members by link pattern expansion method; automatically annotating structured web data using a svm-based multiclass classifier; mining discriminative itemsets in data streams; a supervised approach; an efficient algorithm for mining frequent unordered induced subtrees; ranking based activity trajectory search; topical pattern based document modelling and relevance ranking; a decremental search approach for large scale dynamic ridesharing; model-based search and ranking of web apis across multiple repositories; common neighbor query-friendly triangulation-based large-scale graph compression; keyword search over web documents based on earth mover’s distance; automatic polling using online search; comparing the predictive capability of social and interest affinity for recommendations; end-user browser-side modification of web pages and mobile phone recommendation based on phone interest; identifying explicit features for sentiment analysis in consumer reviews; facet tree for personalized web documents organization; mobile web user behavior modeling; effect of mood, social connectivity and age in online depression community via topic and linguistic analysis; a review selection method using product feature taxonomy and exploiting semantic result clustering to support keyword search on linked data.",Final,
Wright J.D.,"Wright, Jonathan D. (57188571779)",57188571779,RESTful annotation and efficient collaboration,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037072753&partnerID=40&md5=2ac2b35aa510a19db6142b66a9e63f34,"As linguistic collection and annotation scale up and collaboration across sites increases, novel technologies are necessary to support projects. Recent events at LDC, namely the move to a web-based infrastructure, the formation of the Software Group, and our involvement in the NSF LAPPS Grid project, have converged on concerns of efficient collaboration. The underlying design of the Web, typically referred to as RESTful principles, is crucial for collaborative annotation, providing data and processing services, and participating in the Linked Data movement. This paper outlines recommendations that will facilitate such collaboration.",Final,
Kotoulas S.; Sedlazek W.; Lopez V.; Sbodio M.; Stephenson M.; Tommasi P.; Mac Aonghusa P.,"Kotoulas, Spyros (16238993900); Sedlazek, Walter (56649354600); Lopez, Vanessa (8928407100); Sbodio, Marco (55886127400); Stephenson, Martin (55232883500); Tommasi, Pierpaolo (56104140600); Mac Aonghusa, Pol (55232189100)",16238993900; 56649354600; 8928407100; 55886127400; 55232883500; 56104140600; 55232189100,Enabling Person-Centric Care using Linked Data Technologies,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929501599&doi=10.3233%2f978-1-61499-432-9-692&partnerID=40&md5=e4161241a0873a193e39747da655d762,"Patient-Centric Care requires comprehensive visibility into the strengths and vulnerabilities of individuals and populations. The systems involved in Patient-Centric Care are numerous and heterogeneous, span medical, behavioral and social domains and must be coordinated across government and NGO stakeholders in Health Care, Social Care and more. We present a system, based on Linked Data technologies, taking first steps in making this cross-domain information accessible and fit-for-use, using minimal structure and open vocabularies. We evaluate our system through user studies. © 2014 European Federation for Medical Informatics and IOS Press.",Final,
Chen Y.-N.; Hakkani-Tur D.; Tur G.,"Chen, Yun-Nung (47061006000); Hakkani-Tur, Dilek (6603261445); Tur, Gokan (15060858000)",47061006000; 6603261445; 15060858000,Deriving local relational surface forms from dependency-based entity embeddings for unsupervised spoken language understanding,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943747009&doi=10.1109%2fSLT.2014.7078581&partnerID=40&md5=eb52f2ee9d50bc4e75f679c19e6ad053,"Recent works showed the trend of leveraging web-scaled structured semantic knowledge resources such as Freebase for open domain spoken language understanding (SLU). Knowledge graphs provide sufficient but ambiguous relations for the same entity, which can be used as statistical background knowledge to infer possible relations for interpretation of user utterances. This paper proposes an approach to capture the relational surface forms by mapping dependency-based contexts of entities from the text domain to the spoken domain. Relational surface forms are learned from dependency-based entity embeddings, which encode the contexts of entities from dependency trees in a deep learning model. The derived surface forms carry functional dependency to the entities and convey the explicit expression of relations. The experiments demonstrate the efficiency of leveraging derived relational surface forms as local cues together with prior background knowledge. © 2014 IEEE.",Final,
,,,Frontiers in Artificial Intelligence and Applications,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182321946&partnerID=40&md5=707926dfd9324d07a302b0fe9bdd4f5f,The proceedings contain 30 papers. The topics discussed include: argumentation schemes for statutory interpretation: a logical analysis; interpretative argumentation schemes; on the interactional meaning of fundamental legal concepts; a model of air transport passenger incidents and rights; abstract dialectical frameworks for legal reasoning; extracting legal arguments from forensic Bayesian networks; managing motivation at the workplace through negotiation; extracting scenarios from a Bayesian network as explanations for legal evidence; facilitating re-use of legal data in applications - Finnish law as a linked open data service; open-access grant data: towards meta-research innovation; mining information from statutory texts in multi-jurisdictional settings; legislation as a complex network: modelling and analysis of European union legal sources; towards measures of complexity: applying structural and linguistic metrics to German laws; and towards graph-based and semantic search in legal information access systems.,Final,
Dimou A.; Sande M.V.; Colpaert P.; Verborgh R.; Mannens E.; Van De Walle R.,"Dimou, Anastasia (55236344100); Sande, Miel Vander (55883893100); Colpaert, Pieter (56208754400); Verborgh, Ruben (36716974600); Mannens, Erik (24464045700); Van De Walle, Rik (7005287415)",55236344100; 55883893100; 56208754400; 36716974600; 24464045700; 7005287415,RML: A generic language for integrated RDF mappings of heterogeneous data,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920771184&partnerID=40&md5=30b3a55835aad496749f1e01699d03a2,"Despite the significant number of existing tools, incorporating data from multiple sources and different formats into the Linked Open Data cloud remains complicated. No mapping formalisation exists to define how to map such heterogeneous sources into rdf in an integrated and interoperable fashion. This paper introduces the rml mapping language, a generic language based on an extension over r2rml, the w3c standard for mapping relational databases into rdf. Broadening r2rml's scope, the language becomes source-Agnostic and extensible, while facilitating the definition of mappings of multiple heterogeneous sources. This leads to higher integrity within datasets and richer interlinking among resources. © LDOW2014, April 8, 2014, Seoul, Korea.",Final,
Song W.; Xu Z.; Tang Y.; Lin L.; Ni L.,"Song, Wanli (55608284400); Xu, Zhuoming (55613796500); Tang, Yan (57193127623); Lin, Lili (55202918000); Ni, Lixian (56127017900)",55608284400; 55613796500; 57193127623; 55202918000; 56127017900,Towards a lay-user interface for querying DBpedia,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946688284&doi=10.1109%2fWISA.2014.11&partnerID=40&md5=2e4e2e8027072afaea45eeda030e299a,"As an RDF representation of information extracted from Wikipedia, DBpedia has been serving as an interlinking hub for many other RDF data sets in the Linked Open Data cloud on the Web of Data. Therefore, accessing the DBpedia data set is a common task for various Semantic Web applications. Given the fact that DBpedia is currently accessed through public SPARQL endpoints, which requires the users to know and understand the vocabularies of the DBpedia ontology and to master the complicated syntax and semantics for the SPARQL language. This is a tough task for the querying users, especially for lay-users without sufficient knowledge of Semantic Web techniques. The goal of this paper is to provide the users, especially lay-users, with a friendly, easy-to-use interface for querying the DBpedia dataset. Such a user interface can create a visual class hierarchy of the DBpedia ontology for the users to browse and let the users specify query conditions by means of simple form-based operations. We design a group of algorithms for the lay-user interface, implement a prototype, LUQI-DBpedia, of the interface, and use LUQI-DBpedia to carry out query experiments. The implementation and experimental results indicate that the proposed approach is achievable using Java programming language and Apache Jena framework for Java. © 2014 IEEE.",Final,
Yu D.; Huang H.; Cassidy T.; Ji H.; Wang C.; Zhi S.; Han J.; Voss C.; Magdon-Ismail M.,"Yu, Dian (57216703846); Huang, Hongzhao (56349648700); Cassidy, Taylor (55286664500); Ji, Heng (35240121900); Wang, Chi (55893752800); Zhi, Shi (57052551000); Han, Jiawei (24325399900); Voss, Clare (7004570831); Magdon-Ismail, Malik (6701757209)",57216703846; 56349648700; 55286664500; 35240121900; 55893752800; 57052551000; 24325399900; 7004570831; 6701757209,The wisdom of minority: Unsupervised slot filling validation based on multi-dimensional truth-finding,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959925878&partnerID=40&md5=90f28cb8be63c97f482b727a68d32de7,"Information Extraction using multiple information sources and systems is beneficial due to multisource/ system consolidation and challenging due to the resulting inconsistency and redundancy. We integrate IE and truth-finding research and present a novel unsupervised multi-dimensional truth finding framework which incorporates signals from multiple sources, multiple systems and multiple pieces of evidence by knowledge graph construction through multi-layer deep linguistic analysis. Experiments on the case study of Slot Filling Validation demonstrate that our approach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding 90% truths with only one half the cost of a baseline without credibility estimation).",Final,
Kontokostas D.; Brümmer M.; Hellmann S.; Lehmann J.; Ioannidis L.,"Kontokostas, Dimitris (54396973500); Brümmer, Martin (55995213500); Hellmann, Sebastian (35199882400); Lehmann, Jens (35229806900); Ioannidis, Lazaros (35812016800)",54396973500; 55995213500; 35199882400; 35229806900; 35812016800,NLP data cleansing based on linguistic ontology constraints,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902603108&doi=10.1007%2f978-3-319-07443-6_16&partnerID=40&md5=a8e3a81ed91a9d39d8e5d8d7093ecdba,"Linked Data comprises of an unprecedented volume of structured data on the Web and is adopted from an increasing number of domains. However, the varying quality of published data forms a barrier for further adoption, especially for Linked Data consumers. In this paper, we extend a previously developed methodology of Linked Data quality assessment, which is inspired by test-driven software development. Specifically, we enrich it with ontological support and different levels of result reporting and describe how the method is applied in the Natural Language Processing (NLP) area. NLP is - compared to other domains, such as biology - a late Linked Data adopter. However, it has seen a steep rise of activity in the creation of data and ontologies. NLP data quality assessment has become an important need for NLP datasets. In our study, we analysed 11 datasets using the lemon and NIF vocabularies in 277 test cases and point out common quality issues. © 2014 Springer International Publishing.",Final,All Open Access; Green Open Access
,,,"8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, LaTeCH 2014 at the 14th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2014",,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119280458&partnerID=40&md5=f5047a042f24f8a110652562c56c2d89,The proceedings contain 18 papers. The topics discussed include: a new implementation for canonical text services; how to semantically relate dialectal dictionaries in the linked data framework; bootstrapping a historical commodities lexicon with SKOS and DBpedia; new technologies for old germanic. resources and research on parallel bibles in older continental western Germanic; a multilingual evaluation of three spelling normalisation methods for historical text; enhancing the possibilities of corpus-based investigations: word sense disambiguation on query results of large text corpora; a hybrid disambiguation measure for inaccurate cultural heritage data; and developing a tagalog linguistic inquiry and word count (LIWC) ‘disaster’ dictionary for understanding mixed language social media: a work-in-progress paper.,Final,
,,,"EACL 2014 - 14th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference",,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122003990&partnerID=40&md5=ed0846e259cb82d219151edb3df88de5,The proceedings contain 46 papers. The topics discussed include: easy web search results clustering: when baselines can reach state-of-the-art algorithms; propagation strategies for building temporal ontologies; Chinese open relation extraction for knowledge acquisition; temporal text ranking and automatic dating of texts; measuring the similarity between automatically generated topics; projecting the knowledge graph to syntactic parsing; a vague sense classifier for detecting vague definitions in ontologies; chasing hypernyms in vector spaces with entropy; tight integration of speech disfluency removal into SMT; non-monotonic parsing of fluent umm i mean disfluent sentences; lightly-supervised word sense translation error detection for an interactive conversational spoken language translation system; and map translation using geo-tagged social media.,Final,
Varanovich A.; Lämmel R.; Leinberger M.; Favre J.-M.; Schmorleiz T.,"Varanovich, Andrei (36653300200); Lämmel, Ralf (7004269252); Leinberger, Martin (55555466700); Favre, Jean-Marie (8412823400); Schmorleiz, Thomas (55249992400)",36653300200; 7004269252; 55555466700; 8412823400; 55249992400,Declarative software development: Distilled tutorial,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968883490&doi=10.1145%2f2643135.2643163&partnerID=40&md5=7ce0388573f7ef8bdc83140ace03595a,"Software development could be said to be declarative, if declarative programming languages were used significantly in the development of a software system. Software development could also be said to be declarative, if lightweight or heavyweight formal methods or model-driven engineering and model transformation were used as the primary development methods. This tutorial discusses another view on 'declarative software development'. That is, we promote the use of declarative methods for understanding software systems, software languages, software technologies, and software concepts. More specifically, we discuss a method package of a software ontology, automated software analysis, a modeling approach for software technologies, and Linked Data-based publication and exploration of software data. © Copyright 2014 ACM.",Final,
Wang Z.; Zhang J.; Feng J.; Chen Z.,"Wang, Zhen (56393607000); Zhang, Jianwen (55904683400); Feng, Jianlin (55468540400); Chen, Zheng (55574827100)",56393607000; 55904683400; 55468540400; 55574827100,Knowledge graph and text jointly embedding,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926065966&doi=10.3115%2fv1%2fd14-1167&partnerID=40&md5=eb21d9b18f85533cd6ff04cbef47a079,"We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram). © 2014 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Grunwald D.; Gladisch C.; Liu T.; Taghdiri M.; Tyszberowicz S.,"Grunwald, Daniel (56487271500); Gladisch, Christoph (23389119700); Liu, Tianhai (55253523800); Taghdiri, Mana (55909402400); Tyszberowicz, Shmuel (6602980514)",56487271500; 23389119700; 55253523800; 55909402400; 6602980514,Generating JML specifications from Alloy expressions,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921329924&doi=10.1007%2f978-3-319-13338-6_9&partnerID=40&md5=26344c1c198107f3a3c2face59c88a19,"Java Modeling Language (JML) is a specification language for Java programs, that follows the design by contract paradigm. However, it is not always easy to use JML, for example when specifying properties of linked data structures. Alloy, on the other hand, is a relational specification language with a built-in transitive closure operator, which makes it particularly suitable for writing concise specifications of linked data structures. This paper presents Alloy2JML, a tool that generates JML specifications from Alloy expression, in order to support both Alloy and JML specifications in the KeY verification engine. This translation allows Java programs with Alloy specifications to be fully verified for correctness. Moreover, Alloy2JML lets Alloy specifications be employed in a variety of tools that accept only JML as their specification language. Supporting Alloy has the additional advantage that users can validate the specifications beforehand using the Alloy Analyzer. © Springer International Publishing Switzerland 2014.",Final,
Rettingerf A.; Hagemann A.; Nickles M.,"Rettingerf, Achim (23092350400); Hagemann, Alexander (57189711536); Nickles, Matthias (6602772470)",23092350400; 57189711536; 6602772470,Learning an optimal sequence of questions for the disambiguation of queries over structured data,,-1,-1,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974806554&partnerID=40&md5=c90319d646a5a11fd05d15a973dca9ab,"Intelligent systems interacting with users often need to relate ambiguous natural language phrases lo formal entities which can be further processed. This work strives for learning an optimal sequence of disambiguation questions asked by an agent in order to achieve a perfect interactive disambiguation, setting itself off against previous work on interactive and adaptive dialogue systems for disambiguation in question answering. To this aim, we built a hybrid system that exhibits deductive and statistical inference capabilities by combining techniques from natural language processing, information retrieval, answer set programming and relational reinforcement learning. © Copyright 2014, Association for the Advancement of Artificial Intelligence (www.aaia.org). All rights reserved.",Final,
,,,"2nd Symposium on Languages, Applications and Technologies, SLATE 2013",,-1,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893323722&partnerID=40&md5=e29642104d3e833e4288245c4580e89a,The proceedings contain 18 papers. The topics discussed include: software languages: the linguistic continuum; or-parallel prolog execution on clusters of multicores; NESSy: a new evaluator for software development tools; supporting separate compilation in a defunctionalizing compiler; towards automated program abstraction and language enrichment; publishing linked data with DaPress; Seqins - a sequencing tool for educational resources; retreading dictionaries for the 21st century; a flexible dynamic system for automatic grading of programming exercises; CodeSkelGen - a program skeleton generator; choosing grammars to support language processing courses; role of patterns in automated task-driven grammar refactoring; defining domain language of graphical user interfaces; dictionary alignment by rewrite-based entry translation; and combining language independent part-of-speech tagging tools.,Final,
,,,"Semantic Technology - Second Joint International Conference, JIST 2012, Proceedings",,-1,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892956998&partnerID=40&md5=299e91463558d0101e48c51824929bcc,The proceedings contain 33 papers. The topics discussed include: A resolution procedure for description logics with nominal schemas; ontological modeling of interoperable abnormal states; active learning of domain-specific distances for link discovery; interlinking linked data sources using a domain-independent system; instance coreference resolution in multi-ontology linked data resources; the dynamic generation of refining categories in ontology-based search; keyword-driven resource disambiguation over RDF knowledge bases; an automated template selection framework for keyword query over linked data; leveraging the crowdsourcing of lexical resources for bootstrapping a linguistic data cloud; navigation-induced knowledge engineering by example; an ontological framework for decision support; and development of the method for the appropriate selection of the successor by applying metadata to the standardization reports and members.,Final,
,,,"4th Biennial International Workshop on Balto-Slavic Natural Language Processing, BSNLP 2013 at the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013 - Proceedings",,-1,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149129051&partnerID=40&md5=b6948045349807f30c0d1e0a5a681bea,The proceedings contain 17 papers. The topics discussed include: ontologies and linked open data for acquisition and exploitation of language resources; a comparison of approaches for sentiment classification on Lithuanian internet comments; evaluating sentiment analysis systems in Russian; aspect-oriented opinion mining from user reviews in Croatian; frequently asked questions retrieval for Croatian based on semantic textual similarity; parsing Russian: a hybrid approach; GPKEX: genetically programmed keyphrase extraction from Croatian texts; lemmatization and morphosyntactic tagging of Croatian and Serbian; modernizing historical Slovene words with character-based SMT; and improving English-Russian sentence alignment through POS tagging and Damerau-Levenshtein distance.,Final,
Xie B.; Ma X.; Wu J.; Yang J.; Fan H.,"Xie, Bingbing (57216406371); Ma, Xiaoxiao (57224937615); Wu, Jia (23971568900); Yang, Jian (35304034500); Fan, Hao (57216407011)",57216406371; 57224937615; 23971568900; 35304034500; 57216407011,Knowledge Graph Enhanced Heterogeneous Graph Neural Network for Fake News Detection,-1,Maria Angela PELLEGRINO Forse ti torna utile per l'altro lavoro che stai facendo,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174836201&doi=10.1109%2fTCE.2023.3324661&partnerID=40&md5=85d93641df6700710b048dc1a1517aad,"The rapid proliferation of online fake news has caused confusion and social panic, underscoring the urgency of effective detection. Although tremendous research effort has been devoted to extracting semantic information from news pieces and detecting fake news regarding their linguistic characteristics, the abundant factual information in Knowledge graphs (KGs) has yet to be explored. There remain two significant challenges to utilizing KGs for fake news detection: 1) The unknown relation between existing knowledge and news content, and 2) fusing characters of fake news from both KGs and news content inherently requires balancing the contributions of these resources, but no prior domain knowledge is available. Therefore, we propose KEHGNN-FD, a novel KG-enhanced Heterogeneous Graph Neural Network, to unleash the power of KGs for fake news detection. We model news content, topics, and entities as a heterogeneous graph and use graph attention to learn high-level news representations by adaptively aggregating neighboring information from the heterogeneous graph and ground-truth KG entities (i.e., Wikidata). Finally, we train a semi-supervised detector to label news as fake or true. Extensive experiments on four fake news datasets show the superiority of KEHGNN-FD over seven baselines regarding accuracy, precision, recall, F1-score, and ROC. The ablation study further validates the efficacy of the KG for fake news detection as well as KEHGNN-FD&#x2019;s components. IEEE",Article in press,
Zhang H.; Li Z.; Liu S.; Huang T.; Ni Z.; Zhang J.; Lv Z.,"Zhang, Hao (57276621800); Li, Zonglin (58350149000); Liu, Sanya (24481510400); Huang, Tao (56658903200); Ni, Zhouwei (58350781800); Zhang, Jian (58348257400); Lv, Zhihan (55925162500)",57276621800; 58350149000; 24481510400; 56658903200; 58350781800; 58348257400; 55925162500,Do Sentence-Level Sentiment Interactions Matter? Sentiment Mixed Heterogeneous Network for Fake News Detection,-1,Maria Angela PELLEGRINO può tornarti utile,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162932140&doi=10.1109%2fTCSS.2023.3269090&partnerID=40&md5=5cfb25435cdb2a0cc2f8170c1712857f,"With the proliferation of fake news, the spread of misleading information can easily cause social panic and group polarization. Many existing methods for detecting fake news rely on linguistic and semantic features extracted from the content of the news. Some existing approaches focus on sentiment analysis for fake news detection, but the sentiment changes and sentence-level emotional interactions in news classification are not fully analyzed. Fortunately, we observe that in long-form news, the change and mutual influence of sentiment between sentences are different. To extract the features of sentiment interaction between sentences in the article, we propose a graph attention network-based model that combines both sentiment and external knowledge comparison to meet the needs of fake news classification. We obtain the contextual sentiment representation and entity representation of the sentence through the heterogeneous network and the emotion interaction network and obtain the change of the sentiment vector through the emotion comparison network. We compare the entity vectors in the context with those corresponding knowledge base (KB)-based, combine them with the contextual semantic representation of the sentence, and finally input them into the classifier. In experiments, our model performs well in both single and multiclass classification, achieving the state-of-the-art accuracy on existing datasets. IEEE",Article in press,
Sharma A.; Jain S.; Jain N.K.; Bhargava B.,"Sharma, Abhisek (57217481852); Jain, Sarika (57203018058); Jain, Naveen Kumar (58587117200); Bhargava, Bharat (7103137823)",57217481852; 57203018058; 58587117200; 7103137823,A Research Agenda Towards Culturally Aware Information Systems,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174534979&doi=10.1007%2f978-981-99-5085-0_35&partnerID=40&md5=e4a2b726a5b3b2559ee2dced0f60b3be,"Our world is not homogeneous in nature, it has multiple languages, ethnic groups, culture, beliefs, and varying perceptions of things. There is development towards catering experiences based on these varying dimensions by utilizing the available cultural models (such as Trompenaars, Hofstede, and Deal and Kennedy). Though these models can help in the development of globalized information systems that can be adapted for a particular locale (location/language/culture-specific), we don’t have these dimensions in a dereferenceable form. This paper is an attempt to put some light on the possible solution for the problems discussed. Here, we discuss research questions that should be addressed while incorporating cultural representation. We also discuss various cultural models, and available usages and probable usecases. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.",Final,
Ahmed A.F.; Firmansyah A.F.; Sherif M.A.; Moussallem D.; Ngonga Ngomo A.-C.,"Ahmed, Abdullah Fathi (57188732238); Firmansyah, Asep Fajar (56580147400); Sherif, Mohamed Ahmed (55901643100); Moussallem, Diego (57079181300); Ngonga Ngomo, Axel-Cyrille (23397850200)",57188732238; 56580147400; 55901643100; 57079181300; 23397850200,Explainable Integration of Knowledge Graphs Using Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164721228&doi=10.1007%2f978-3-031-35320-8_9&partnerID=40&md5=d3d1c0f1395ceb90c4ce001e09fbac4a,"Linked knowledge graphs build the backbone of many data-driven applications such as search engines, conversational agents and e-commerce solutions. Declarative link discovery frameworks use complex link specifications to express the conditions under which a link between two resources can be deemed to exist. However, understanding such complex link specifications is a challenging task for non-expert users of link discovery frameworks. In this paper, we address this drawback by devising NMV-LS, a language model-based verbalization approach for translating complex link specifications into natural language. NMV-LS relies on the results of rule-based link specification verbalization to apply continuous training on T5, a large language model based on the Transformer architecture. We evaluated NMV-LS on English and German datasets using well-known machine translation metrics such as BLUE, METEOR, ChrF++ and TER. Our results suggest that our approach achieves a verbalization performance close to that of humans and outperforms state of the art approaches. Our source code and datasets are publicly available at https://github.com/dice-group/NMV-LS. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Qu X.; Gu Y.; Xia Q.; Li Z.; Wang Z.; Huai B.,"Qu, Xiaoye (57204328498); Gu, Yingjie (57198896537); Xia, Qingrong (57192309417); Li, Zechang (58119455800); Wang, Zhefeng (56285986500); Huai, Baoxing (55959581300)",57204328498; 57198896537; 57192309417; 58119455800; 56285986500; 55959581300,"A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends",-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167803285&doi=10.1109%2fTKDE.2023.3303136&partnerID=40&md5=0c25330cdf480e7c941a15993d52ddab,"As more and more Arabic texts emerged on the Internet, extracting important information from these Arabic texts is especially useful. As a fundamental technology, Named entity recognition (NER) serves as the core component in information extraction technology, while also playing a critical role in many other Natural Language Processing (NLP) systems, such as question answering and knowledge graph building. In this paper, we provide a comprehensive review of the development of Arabic NER, especially the recent advances in deep learning and pre-trained language model. Specifically, we first introduce the background of Arabic NER, including the characteristics of Arabic and existing resources for Arabic NER. Then, we systematically review the development of Arabic NER methods. Traditional Arabic NER systems focus on feature engineering and designing domain-specific rules. In recent years, deep learning methods achieve significant progress by representing texts via continuous vector representations. With the growth of pre-trained language model, Arabic NER yields better performance. Finally, we conclude the method gap between Arabic NER and NER methods from other languages, which helps outline future directions for Arabic NER.  © 1989-2012 IEEE.",Final,All Open Access; Green Open Access
Sewunetie W.T.; Kovacs L.,"Sewunetie, Walelign Tewabe (57934333100); Kovacs, Laszlo (7201471183)",57934333100; 7201471183,A Comparative Study of ChatGPT-Based and Hybrid Parser-based Sentence Parsing Methods for Semantic Graph-Based Induction,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184341595&doi=10.1109%2fACCESS.2024.3360480&partnerID=40&md5=bda6db3b468106aeee60a9d2c813239b,"Sentence parsing is a fundamental step in the conversion of a text document into semantic graphs. In this research, novel phrase parsing techniques for semantic graph-based induction are presented, namely the ChatGPT-based and Hybrid Parser-based approaches. The performance of these two approaches in the context of inducing semantic networks from textual data is assessed through a comprehensive analysis in this study. The primary purpose is to enhance the construction of semantic graphs, specifically focusing on capturing detailed event descriptions and relationships within text. The research finds that the Hybrid Parser-Based approach exhibits a slight advantage in accuracy (acc&#x005F;hybrid = 0.87) compared to ChatGPT (acc&#x005F;GPT = 0.85) in sentence parsing tasks. Furthermore, the efficiency analysis reveals that ChatGPT&#x2019;s response quality varies with different prompt sizes, while the Hybrid Parser-Based method consistently maintains an ""excellent"" response quality rating. Authors",Article in press,All Open Access; Gold Open Access
Canabal-Juanatey M.; Alonso-Moral J.M.; Catala A.; Bugarín-Diz A.,"Canabal-Juanatey, Mariña (58852515900); Alonso-Moral, Jose M. (58725423700); Catala, Alejandro (23974472900); Bugarín-Diz, Alberto (58531191800)",58852515900; 58725423700; 23974472900; 58531191800,Enriching interactive explanations with fuzzy temporal constraint networks,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183564390&doi=10.1016%2fj.ijar.2024.109128&partnerID=40&md5=1893a8e3ba386505acd17702ffe81fa6,"Humans often use expressions with vague terms which play a fundamental role for effective communication. These expressions are successfully modeled with fuzzy technology, but they are not usually integrated yet with Natural Language Processing models and techniques. Large-scale pre-trained language models yield excellent results in many language tasks, but they have some drawbacks such as their lack of transparency and thorough temporal reasoning capabilities. Therefore, the use of such models may provoke inconsistent or incorrect dialogues in the context of conversational agents which were aimed at providing users of intelligent systems with interactive explanations. In this paper, we propose a model for fuzzy temporal reasoning to overcome some inconsistencies detected in pre-trained language models in a specific application domain of a conversational agent carefully designed for providing users with explanations which are endowed with a good balance between naturalness and fidelity. More precisely, starting from a knowledge graph that provides an intuitive representation of the entities and relations in the application domain, we describe how to map the temporal information onto a fuzzy temporal constraint network. This formalism allows to represent imprecise temporal information and provides mechanisms for checking consistency in conversations. In addition, as a proof of concept, we have developed TimeVersa, a conversational agent which integrates the proposed model into an application domain (i.e., a virtual assistant for tourists) that requires handling imprecise temporal constraints. We illustrate in a use case how the agent can identify temporal inconsistencies and answer queries related to temporal information properly. Results after a user study report that users' perception of consistency is significantly higher in a conversation with TimeVersa than in a similar conversation using the well-known GPT-3 Large Language Model, when vague temporal information is involved. The proposed approach is a step forward for developing conversational agents operating in application domains that require temporal reasoning under uncertainty. © 2024 The Author(s)",Article in press,All Open Access; Hybrid Gold Open Access
Buehler M.J.,"Buehler, Markus J. (7102467930)",7102467930,"MechGPT, a Language-Based Strategy for Mechanics and Materials Modeling That Connects Knowledge Across Scales, Disciplines, and Modalities",-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184374431&doi=10.1115%2f1.4063843&partnerID=40&md5=084eb60d2696016fb425056f373995e0,"For centuries, researchers have sought out ways to connect disparate areas of knowledge. While early scholars (Galileo, da Vinci, etc.) were experts across fields, specialization took hold later. With the advent of Artificial Intelligence, we can now explore relationships across areas (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-art). To achieve this, we use a fine-tuned large language model (LLM), here for a subset of knowledge in multiscale materials failure. The approach includes the use of a general-purpose LLM to distill question-answer pairs from raw sources followed by LLM fine-tuning. The resulting MechGPTLLMfoundation model is used in a series of computational experiments to explore its capacity for knowledge retrieval, various language tasks, hypothesis generation, and connecting knowledge across disparate areas. While the model has some ability to recall knowledge from training, we find that LLMs are particularly useful for extracting structural insights through Ontological Knowledge Graphs. These interpretable graph structures provide explanatory insights, frameworks for new research questions, and visual representations of knowledge that also can be used in retrieval-augmented generation. Three versions of MechGPT are discussed, featuring different sizes from 13×109 to 70×109 parameters, and reaching context lengths of more than 10,000 tokens. This provides ample capacity for sophisticated retrieval augmented strategies, as well as agentbased modeling where multiple LLMs interact collaboratively and/or adversarially, the incorporation of new data from the literature or web searches, as well as multimodality.  Copyright © 2024 by ASME.",Final,All Open Access; Green Open Access
Yang L.; Chen H.; Li Z.; Ding X.; Wu X.,"Yang, Linyao (58372747500); Chen, Hongyang (24829367600); Li, Zhao (57191700056); Ding, Xiao (56375894000); Wu, Xindong (55533800700)",58372747500; 24829367600; 57191700056; 56375894000; 55533800700,Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184341387&doi=10.1109%2fTKDE.2024.3360454&partnerID=40&md5=c37d0dfe482955bf0fc907793183278a,"Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention. Due to their powerful emergent abilities, recent LLMs are considered as a possible alternative to structured knowledge bases like knowledge graphs (KGs). However, while LLMs are proficient at learning probabilistic language patterns and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance in generating texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-trained language models (KGPLMs) as well as their applications. Inspired by existing studies on KGPLM, this paper proposes enhancing LLMs with KGs by developing knowledge graph-enhanced large language models (KGLLMs). KGLLM provides a solution to enhance LLMs&#x2019; factual reasoning ability, opening up new avenues for LLM research. IEEE",Article in press,
Zafar A.; Sahoo S.K.; Varshney D.; Das A.; Ekbal A.,"Zafar, Aizan (58081132400); Sahoo, Sovan Kumar (57220039065); Varshney, Deeksha (57217702734); Das, Amitava (55628533537); Ekbal, Asif (23093674100)",58081132400; 57220039065; 57217702734; 55628533537; 23093674100,KIMedQA: towards building knowledge-enhanced medical QA models,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182984493&doi=10.1007%2fs10844-024-00844-1&partnerID=40&md5=5e78ada8318e277f1115085bdf3b5f7d,"Medical question-answering systems require the ability to extract accurate, concise, and comprehensive answers. They will better comprehend the complex text and produce helpful answers if they can reason on the explicit constraints described in the question’s textual context and the implicit, pertinent knowledge of the medical world. Integrating Knowledge Graphs (KG) with Language Models (LMs) is a common approach to incorporating structured information sources. However, effectively combining and reasoning over KG representations and language context remains an open question. To address this, we propose the Knowledge Infused Medical Question Answering system (KIMedQA), which employs two techniques viz. relevant knowledge graph selection and pruning of the large-scale graph to handle Vector Space Inconsistent (VSI) and Excessive Knowledge Information (EKI). The representation of the query and context are then combined with the pruned knowledge network using a pre-trained language model to generate an informed answer. Finally, we demonstrate through in-depth empirical evaluation that our suggested strategy provides cutting-edge outcomes on two benchmark datasets, namely MASH-QA and COVID-QA. We also compared our results to ChatGPT, a robust and very powerful generative model, and discovered that our model outperforms ChatGPT according to the F1 Score and human evaluation metrics such as adequacy. © 2024, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article in press,
Sun K.; Yu J.; Li J.; Hou L.,"Sun, Kai (57336681500); Yu, Jifan (57205103754); Li, Juanzi (8304332600); Hou, Lei (56622056400)",57336681500; 57205103754; 8304332600; 56622056400,Exploring sequence-to-sequence taxonomy expansion via language model probing[Formula presented],-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176085077&doi=10.1016%2fj.eswa.2023.122321&partnerID=40&md5=793037ff81ecb6c63e2cdcda9c7de6c9,"Taxonomy is a knowledge graph of concept hierarchy which plays a significant role in semantic entailment and is widely used in many downstream natural language processing tasks. Distinct from building a taxonomy from scratch, the task of taxonomy expansion aims at enriching an existing taxonomy by adding new concepts. However, existing methods often construct only part of semantic relationships for representing the taxonomy, which may ignore sufficient features. Meanwhile, as many recent models usually take this task in insertion-only manner, they preserve limitations when the new concept is not an insertion to taxonomy. Therefore, we propose TaxoSeq, a method that converts the task of taxonomy expansion into a sequence to sequence setting, thereby effectively exploiting the entire structural features and naturally dealing with more expansion cases. Empowered by pre-trained language models such as T5, our approach is shown to achieve significant progress over other methods in SemEval's three publicly benchmark datasets. © 2023 Elsevier Ltd",Final,
Sovrano F.; Palmirani M.; Sapienza S.; Pistone V.,"Sovrano, Francesco (57200161563); Palmirani, Monica (57193195959); Sapienza, Salvatore (57203765882); Pistone, Vittoria (58771001500)",57200161563; 57193195959; 57203765882; 58771001500,DiscoLQA: zero-shot discourse-based legal question answering on European Legislation,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182201407&doi=10.1007%2fs10506-023-09387-2&partnerID=40&md5=019d39006337820a1befbdcf1f34013b,"The structures of discourse used by legal and ordinary languages share differences that foster technical issues when applying or fine-tuning general-purpose language models for open-domain question answering on legal resources. For example, longer sentences may be preferred in European laws (i.e., Brussels I bis Regulation EU 1215/2012) to reduce potential ambiguities and improve comprehensibility, distracting a language model trained on ordinary English. In this article, we investigate some mechanisms to isolate and capture the discursive patterns of legalese in order to perform zero-shot question answering, i.e., without training on legal documents. Specifically, we use pre-trained open-domain answer retrieval systems and study what happens when changing the type of information to consider for retrieval. Indeed, by selecting only the important parts of discourse (e.g., elementary units of discourse, EDU for short, or abstract representations of meaning, AMR for short), we should be able to help the answer retriever identify the elements of interest. Hence, with this paper, we publish Q4EU, a new evaluation dataset that includes more than 70 questions and 200 answers on 6 different European norms, and study what happens to a baseline system when only EDUs or AMRs are used during information retrieval. Our results show that the versions using EDUs are overall the best, leading to state-of-the-art F1, precision, NDCG and MRR scores. © 2024, The Author(s).",Article in press,All Open Access; Hybrid Gold Open Access
Chaudhary A.; Milios E.; Rajabi E.,"Chaudhary, Akhil (58753869100); Milios, Evangelos (7006232899); Rajabi, Enayat (42862135700)",58753869100; 7006232899; 42862135700,Top2Label: Explainable zero shot topic labelling using knowledge graphs,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179127787&doi=10.1016%2fj.eswa.2023.122676&partnerID=40&md5=7ce94a6afb50aaece0258d5e01a0d955,"Automatic topic labelling aims to generate coherent, interpretable, and meaningful labels to facilitate the interpretation of various topics within a corpus of documents. Typically, we represent a topic as a list of terms and documents ranked according to probability. In our research, we employ Top2Vec for topic modelling. We propose a novel three-phase, zero-shot topic labelling framework leveraging the ConceptNet knowledge graph (a comprehensive semantic network of words and phrases) and pre-trained language models as external sources of information. The first phase enriches the top n words of a given topic (based on probability) by expanding their neighbourhood in ConceptNet, bridging missing connections and information gaps, and subsequently yielding a semantically enhanced set of potential labels through the generation of a sub-graph. The second phase constructs a neighbourhood graph (organized as a subgraph of ConceptNet) for each candidate label, evaluating each node's semantic similarity to the topic and retaining the best sub-graph according to semantic similarity. In this phase, a one-word label is extracted from the final graph, concisely representing the topic. In the third phase, we use the language model to derive the final labels by taking the optimal graph as input. In the third phase, we utilize the language model to derive the sentence and summary labels using the optimal graph as input. These additional labels offer more comprehensive and contextually rich topic representations, facilitating more profound understanding and interpretation. By harnessing the power of knowledge graphs and language models, our framework expands the knowledge beyond the topic documents, optimizing the discovered topics with more representative terms while preserving the topic information. The proposed zero-shot approach (employing pre-trained language models and the ConceptNet knowledge graph without additional training) alleviates computational burdens. It reduces the cognitive and interpretative load on end-users by generating three types of labels for each topic: a one-word, sentence, and summary. Experimental results demonstrate that our model significantly surpasses unsupervised baselines and traditional topic labelling models while remaining competitive with supervised baselines in topic labelling performance. © 2023 Elsevier Ltd",Final,
Fan Z.; Chen C.,"Fan, Zhanling (56305281500); Chen, Chongcheng (11940377800)",56305281500; 11940377800,CuPe-KG: Cultural perspective–based knowledge graph construction of tourism resources via pretrained language models,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183365319&doi=10.1016%2fj.ipm.2024.103646&partnerID=40&md5=ceeffbb4b5094f5c22a42ff38f9b5de5,"Tourism knowledge graphs lack cultural content, limiting their usefulness for cultural tourists.This paper presents the development of a cultural perspective-based knowledge graph (CuPe-KG). We evaluated fine-tuning ERNIE 3.0 (FT-ERNIE) and ChatGPT for cultural type recognition to strengthen the relationship between tourism resources and cultures. Our investigation used an annotated cultural tourism resource dataset containing 2,745 items across 16 cultural types. The results showed accuracy scores for FT-ERNIE and ChatGPT of 0.81 and 0.12, respectively, with FT-ERNIE achieving a micro-F1 score of 0.93, a 26 percentage point lead over ChatGPT's score of 0.67. These underscore FT-ERNIE's superior performance (the shortcoming is the need to annotate data) while highlighting ChatGPT's limitations because of insufficient Chinese training data and lower identification accuracy in professional knowledge. A novel ontology was designed to facilitate the construction of CuPe-KG, including elements such as cultural types, historical figures, events, and intangible cultural heritage. CuPe-KG effectively addresses cultural tourism visitors’ information retrieval needs. © 2024",Final,
Li X.; Henriksson A.; Duneld M.; Nouri J.; Wu Y.,"Li, Xiu (57258078100); Henriksson, Aron (52463615100); Duneld, Martin (56176877300); Nouri, Jalal (36608737900); Wu, Yongchao (57257970000)",57258078100; 52463615100; 56176877300; 36608737900; 57257970000,Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183383290&doi=10.3390%2ffi16010012&partnerID=40&md5=231bde85581487531725e5cab3b471df,"Educational content recommendation is a cornerstone of AI-enhanced learning. In particular, to facilitate navigating the diverse learning resources available on learning platforms, methods are needed for automatically linking learning materials, e.g., in order to recommend textbook content based on exercises. Such methods are typically based on semantic textual similarity (STS) and the use of embeddings for text representation. However, it remains unclear what types of embeddings should be used for this task. In this study, we carry out an extensive empirical evaluation of embeddings derived from three different types of models: (i) static embeddings trained using a concept-based knowledge graph, (ii) contextual embeddings from a pre-trained language model, and (iii) contextual embeddings from a large language model (LLM). In addition to evaluating the models individually, various ensembles are explored based on different strategies for combining two models in an early vs. late fusion fashion. The evaluation is carried out using digital textbooks in Swedish for three different subjects and two types of exercises. The results show that using contextual embeddings from an LLM leads to superior performance compared to the other models, and that there is no significant improvement when combining these with static embeddings trained using a knowledge graph. When using embeddings derived from a smaller language model, however, it helps to combine them with knowledge graph embeddings. The performance of the best-performing model is high for both types of exercises, resulting in a mean Recall@3 of 0.96 and 0.95 and a mean MRR of 0.87 and 0.86 for quizzes and study questions, respectively, demonstrating the feasibility of using STS based on text embeddings for educational content recommendation. The ability to link digital learning materials in an unsupervised manner—relying only on readily available pre-trained models—facilitates the development of AI-enhanced learning. © 2023 by the authors.",Final,All Open Access; Gold Open Access
Yang T.; Mei Y.; Xu L.; Yu H.; Chen Y.,"Yang, Tian (58786146700); Mei, Yupeng (57301911900); Xu, Ling (58373084800); Yu, Huihui (55934197600); Chen, Yingyi (24079892700)",58786146700; 57301911900; 58373084800; 55934197600; 24079892700,Application of question answering systems for intelligent agriculture production and sustainable management: A review,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185550710&doi=10.1016%2fj.resconrec.2024.107497&partnerID=40&md5=dfafd31e61cbb849ff97cf0d5062e5bd,"The increasing application of artificial intelligence in agriculture production and management has generated a large amount of data, leading to a demand for processing this data. This review focuses on the knowledge storage approaches in agricultural question answering systems, namely corpora, knowledge graphs, and large language models. These systems are built on massive amounts of data and aim to process and retrieve information effectively in the context of sustainable agriculture. Corpora refer to large collections of diverse documents that serve as foundational resources for training and fine-tuning question answering systems. Knowledge graphs capture structured and interconnected knowledge by representing entities, relationships, and attributes, enabling efficient organization and querying of information. Large language models, such as GPT-4, enhance the capacity of question answering systems to provide accurate and relevant responses. By exploring these three prominent knowledge storage approaches, this review analyses the methodology and impact of agricultural question answering systems, highlighting their applications in the production process. The findings provide important implications for future research in agriculture, and potential directions for further exploration. © 2024",Final,
Zhou B.; Li X.; Liu T.; Xu K.; Liu W.; Bao J.,"Zhou, Bin (57209908256); Li, Xinyu (56455381400); Liu, Tianyuan (57205137997); Xu, Kaizhou (57212003322); Liu, Wei (57211158398); Bao, Jinsong (7201398425)",57209908256; 56455381400; 57205137997; 57212003322; 57211158398; 7201398425,CausalKGPT: Industrial structure causal knowledge-enhanced large language model for cause analysis of quality problems in aerospace product manufacturing,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182431911&doi=10.1016%2fj.aei.2023.102333&partnerID=40&md5=2f365deef6c65220d929f6f986acbf99,"The whole cycle for manufacturing aerospace thin-walled shells is a lengthy and sophisticated process. A large amount of quality-related data exists within and between processes, involving many types of quality defects and influencing factors. However, there are ambiguous causal associations among quality-related data affecting the shape-properties of the shell. Also, the coupling of long processes and multiple factors makes it hard to analyze the main factors that affect the quality defects in shell manufacturing. In this paper, taking into account the advantages of causal Scientology and the large language model (LLM), we propose an industrial structure causal knowledge-enhanced large language model for the cause analysis of quality defects in aerospace product manufacturing. To reinforce the causal associations among quality-related data deriving from manufacturing documents (product defect survey sheets, quality inspection, and maintenance reports), a structure causal graph-based sum-product network (SCG-SPN) model is designed to model machining quality-related knowledge and eliminate pseudo-association confounding factors by doing an intervention. Thus, a causal quality-related knowledge graph (CQKG) with high-quality causal associations is constructed. With this, to provide a trustworthy guarantee in responding to quality problem solving, we construct a quality-related prompt dataset with multi-round conversations based on CQKG. Then, a novel P-tuning that adapts to utilize external CQKG instructions is designed to fine-tune an open-source ChatGLM base model. Based on this, a causal knowledge graph-augmented LLM, named CausalKGPT, is developed to enable reasoning and responding to quality defects in both Chinese and English. It uses natural text descriptions related to quality defects as input and takes a quality-related causal knowledge graph as an additional corpus. Finally, the case study shows that the CausalKGPT performs with more expertise and reliability in responding to quality question solving of aerospace shell manufacturing than the classic commercial models like ChatGPT and GPT4. The results indicate that the proposed method may provide a trustworthy guide in assisting workers to analyze quality defects in aerospace products. © 2023 Elsevier Ltd",Final,
Meng X.; Jing B.; Wang S.; Pan J.; Huang Y.; Jiao X.,"Meng, Xiangzhen (58664948400); Jing, Bo (57203233056); Wang, Shenglong (57215311241); Pan, Jinxin (57218215517); Huang, Yifeng (40661233500); Jiao, Xiaoxuan (55943363700)",58664948400; 57203233056; 57215311241; 57218215517; 40661233500; 55943363700,Fault Knowledge Graph Construction and Platform Development for Aircraft PHM,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181974214&doi=10.3390%2fs24010231&partnerID=40&md5=aab96b5669c0fd75ecb47e50617914d5,"To tackle the problems of over-reliance on traditional experience, poor troubleshooting robustness, and slow response by maintenance personnel to changes in faults in the current aircraft health management field, this paper proposes the use of a knowledge graph. The knowledge graph represents troubleshooting in a new way. The aim of the knowledge graph is to improve the correlation between fault data by representing experience. The data source for this study consists of the flight control system manual and typical fault cases of a specific aircraft type. A knowledge graph construction approach is proposed to construct a fault knowledge graph for aircraft health management. Firstly, the data are classified using the ERNIE model-based method. Then, a joint entity relationship extraction model based on ERNIE-BiLSTM-CRF-TreeBiLSTM is introduced to improve entity relationship extraction accuracy and reduce the semantic complexity of the text from a linguistic perspective. Additionally, a knowledge graph platform for aircraft health management is developed. The platform includes modules for text classification, knowledge extraction, knowledge auditing, a Q&A system, and graph visualization. These modules improve the management of aircraft health data and provide a foundation for rapid knowledge graph construction and knowledge graph-based fault diagnosis. © 2023 by the authors.",Final,All Open Access; Gold Open Access
Ong M.; Gordin S.,"Ong, Matthew (58898327200); Gordin, Shai (55546456300)",58898327200; 55546456300,A Survey of Body Part Construction Metaphors in the Neo-Assyrian Letter Corpus,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185609603&doi=10.5334%2fjohd.142&partnerID=40&md5=c3aa15845d255966c0f2ef5219dd67a7,"The dataset consists of approximately 2,400 examples of metaphors in Akkadian of what we term Body Part Constructions (BPCs) within the letter sub-corpus of the State Archives of Assyria online (SAAo). The dataset was generated by a multi-step process involving the training and application of a language model to the SAAo letter sub-corpus, converting the resulting annotations to linked open data format amenable to searching for BPCs, and manually adding metalinguistic data to the search results; these files, in CONLLU and TTL formats, are also made available in this publication. The BPC dataset is stored as a CSV file, and can serve as an easy starting place for other scholars interested in finding socio-linguistic usage patterns of this construction. © 2024 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.",Final,All Open Access; Gold Open Access
You Z.,"You, Zhuomei (58752832200)",58752832200,Research on English Foreign Propaganda Translation and External Communication Paths Based on Multimodal Analysis Approach,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179035747&doi=10.2478%2famns.2023.2.01257&partnerID=40&md5=548f81111553f88b0aa36e96a50c7954,"In this paper, a multimodal phrase corpus is created, enabling phrases to be searched automatically. The phrase structure is constructed through phrase centroids, and multilevel linguistic measurements are obtained for vocabulary, syntax, and parts of speech styles. A joint feature analysis model for the automatic conversion of English-Chinese machine translation is constructed through distributed feature fusion and joint parameter analysis. Linear statistical features and feature analysis detection are utilized to compute the optimal solution for English-Chinese machine automatic translation text. The graph embedding technique was used to pretrain the knowledge graph and obtain information about the network structure. Combined with the graph convolution technique, deep semantic information mining was carried out to achieve efficient content matching and cultural dissemination. It has been proved that the method of this paper has an AUC value of 0.921 and a satisfaction rate between 80% and 95% in English-translated movie data. The proposed method can accurately translate information from English to foreign propaganda content, which further promotes the development of international cultural exchange and communication. © 2024 Zhuomei You, published by Sciendo.",Final,All Open Access; Gold Open Access
Zafar A.; Sahoo S.K.; Bhardawaj H.; Das A.; Ekbal A.,"Zafar, Aizan (58031569400); Sahoo, Sovan Kumar (57220039065); Bhardawaj, Harsh (57201946729); Das, Amitava (55628533537); Ekbal, Asif (23093674100)",58031569400; 57220039065; 57201946729; 55628533537; 23093674100,KI-MAG: A knowledge-infused abstractive question answering system in medical domain,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181014592&doi=10.1016%2fj.neucom.2023.127141&partnerID=40&md5=176e9e04431a6574787ad71dc2e87e4c,"Abstractive question-answering (QA) has emerged as a prominent area in Natural Language Processing (NLP) due to its ability to produce concise and human-like responses, particularly with the advancement of Large Language Models. Despite its potential, abstractive QA suffers from challenges like the need for extensive training data and the generation of incorrect entities and out-of-context words in the responses. In safety–critical domains like medical and clinical settings, such issues are unacceptable and may compromise the accuracy and reliability of generated answers. We proposed KI-MAG (Knowledge-Infused Medical Abstractive Generator) model, a novel Knowledge-Infused Abstractive Question Answering System specifically designed for the medical domain. KI-MAG aims to address the aforementioned limitations and enhance the correctness of generated responses while mitigating data sparsity concerns. The KI-MAG system produces more precise and informative answers by incorporating relevant medical entities into the model's generation process. Furthermore, we adopt a synthetic data generation approach using question–answer pairs to overcome the challenge of limited training data in the medical domain. These synthetic pairs augment the original dataset, resulting in better model generalization and improved performance. Our extensive experimental evaluations demonstrate the effectiveness of the KI-MAG system. Compared to traditional abstractive QA models, our approach exhibits a substantial increase of approximately 15% in Blue-1, Blue-2, Blue-3, and Blue-4 scores, indicating a remarkable improvement in answer accuracy and overall quality of responses. Overall, our Knowledge-Infused Abstractive Question Answering System in the Medical Domain (KI-MAG) presents a promising solution to enhance the performance and reliability of abstractive QA models in safety–critical medical applications where precision and correctness of answers are of utmost importance. © 2023 Elsevier B.V.",Final,
Xie J.; Li X.; Yuan Y.; Guan Y.; Jiang J.; Guo X.; Peng X.,"Xie, Jing (57200535026); Li, Xin (56386356300); Yuan, Ye (58843749600); Guan, Yi (7202924009); Jiang, Jingchi (56376858400); Guo, Xitong (24777794600); Peng, Xin (58843749700)",57200535026; 56386356300; 58843749600; 7202924009; 56376858400; 24777794600; 58843749700,Knowledge-based dynamic prompt learning for multi-label disease diagnosis,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183152181&doi=10.1016%2fj.knosys.2024.111395&partnerID=40&md5=40e9df30142d9599cd697c16381731ba,"Pretrained language models (PLMs) have been developed rapidly which establish impressive performance on many open-domain downstream tasks. However, conducting these pretrained models directly without additional network architectures on special domain tasks like multi-label disease diagnosis cannot perform well. Recently, prompt learning has been a new paradigm in PLM field which is more convenient and well-performed than the traditional fine-tuning approach for different domain tasks. However, prompt engineering is challenging because it takes time and experience. In this paper, we propose a new prompt learning method named Knowledge-based Dynamic PrompT (KBDPT) to deal with these problems. Firstly, we import medical knowledge into PLMs by prompt templates which make results of the disease diagnosis more reasonable and qualified. Compared with the fine-tuning approach, this method needs fewer trainable parameters and less training data but achieve better performance. Secondly, unlike most existing pre-defined prompt methods, KBDPT dynamically generates prompts based on personal medical information and a large-scale medical knowledge graph, which can provide more valuable guidance information for disease diagnosis. Lastly, the proposed model also ensembles multiple prompts from all possible diseases to introduce more knowledge and obtain differential diagnosis results. Experiments of multi-label disease diagnosis are conduct on three real-world EMR datasets. Results demonstrate that our model can be used in various pretrained models and outperform both classical deep learning methods and fine-tuning PLMs. The source code of our proposed model has been released at: https://github.com/loxs123/KBDPT. © 2024",Final,
Wang Q.; Cao X.; Wang J.; Zhang W.,"Wang, Quanxiu (58534307300); Cao, Xinlei (57487079200); Wang, Jianyong (57208873256); Zhang, Wei (57775688000)",58534307300; 57487079200; 57208873256; 57775688000,Knowledge-Aware Collaborative Filtering With Pre-Trained Language Model for Personalized Review-Based Rating Prediction,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167819218&doi=10.1109%2fTKDE.2023.3301884&partnerID=40&md5=05c99653ec921ee3fbd9631c06e0b39c,"Personalized review-based rating prediction aims at leveraging existing reviews to model user interests and item characteristics for rating prediction. Most of the existing studies mainly encounter two issues. First, the rich knowledge contained in the fine-grained aspects of each review and the knowledge graph is rarely considered to complement the pure text for better modeling user-item interactions. Second, the power of pre-trained language models is not carefully studied for personalized review-based rating prediction. To address these issues, we propose an approach named Knowledge-aware Collaborative Filtering with Pre-trained Language Model (KCF-PLM). For the first issue, to utilize rich knowledge, KCF-PLM develops a transformer network to model the interactions of the extracted aspects w.r.t. a user-item pair. For the second issue, to better represent users and items, KCF-PLM takes all the historical reviews of a user or an item as input to pre-trained language models. Moreover, KCF-PLM integrates the transformer network and the pre-trained language models through representation propagation on the knowledge graph and user-item guided attention of the aspect representations. Thus KCF-PLM combines review text, aspect, knowledge graph, and pre-trained language models together for review-based rating prediction. We conduct comprehensive experiments on several public datasets, demonstrating the effectiveness of KCF-PLM.  © 1989-2012 IEEE.",Final,All Open Access; Green Open Access
Ni P.; Okhrati R.; Guan S.; Chang V.,"Ni, Pin (57251100100); Okhrati, Ramin (36198696600); Guan, Steven (7101750605); Chang, Victor (56926234700)",57251100100; 36198696600; 7101750605; 56926234700,Knowledge Graph and Deep Learning-based Text-to-GraphQL Model for Intelligent Medical Consultation Chatbot,-1,,-1,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133582660&doi=10.1007%2fs10796-022-10295-0&partnerID=40&md5=e2587be69746ef9265930546d1a334ce,"Text-to-GraphQL (Text2GraphQL) is a task that converts the user's questions into Graph + QL (Query Language) when a graph database is given. That is a task of semantic parsing that transforms natural language problems into logical expressions, which will bring more efficient direct communication between humans and machines. The existing related work mainly focuses on Text-to-SQL tasks, and there is no available semantic parsing method and data set for the graph database. In order to fill the gaps in this field to serve the medical Human–Robot Interactions (HRI) better, we propose this task and a pipeline solution for the Text2GraphQL task. This solution uses the Adapter pre-trained by “the linking of GraphQL schemas and the corresponding utterances” as an external knowledge introduction plug-in. By inserting the Adapter into the language model, the mapping between logical language and natural language can be introduced faster and more directly to better realize the end-to-end human–machine language translation task. In the study, the proposed Text2GraphQL task model is mainly constructed based on an improved pipeline composed of a Language Model, Pre-trained Adapter plug-in, and Pointer Network. This enables the model to copy objects' tokens from utterances, generate corresponding GraphQL statements for graph database retrieval, and builds an adjustment mechanism to improve the final output. And the experiments have proved that our proposed method has certain competitiveness on the counterpart datasets (Spider, ATIS, GeoQuery, and 39.net) converted from the Text2SQL task, and the proposed method is also practical in medical scenarios. © 2022, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Ashby T.; Webb B.K.; Knapp G.; Searle J.; Fulda N.,"Ashby, Trevor (58285340800); Webb, Braden K. (58285446800); Knapp, Gregory (58285135400); Searle, Jackson (58285289200); Fulda, Nancy (6507317548)",58285340800; 58285446800; 58285135400; 58285289200; 6507317548,Personalized Quest and Dialogue Generation in Role-Playing Games: A Knowledge Graph- and Language Model-based Approach,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160003028&doi=10.1145%2f3544548.3581441&partnerID=40&md5=36e297b8626119ae106733703502f7bd,"Procedural content generation (PCG) in video games offers unprecedented opportunities for customization and user engagement. Working within the specialized context of role-playing games (RPGs), we introduce a novel framework for quest and dialogue generation that places the player at the core of the generative process. Drawing on a hand-crafted knowledge base, our method grounds generated content with in-game context while simultaneously employing a large-scale language model to create fluent, unique, accompanying dialogue. Through human evaluation, we confirm that quests generated using this method can approach the performance of hand-crafted quests in terms of fluency, coherence, novelty, and creativity; demonstrate the enhancement to the player experience provided by greater dynamism; and provide a novel, automated metric for the relevance between quest and dialogue. We view our contribution as a critical step toward dynamic, co-creative narrative frameworks in which humans and AI systems jointly collaborate to create unique and user-specific playable experiences. © 2023 ACM.",Final,
Argüelles Terrón G.; Martín Chozas P.; Rodríguez Doncel V.,"Argüelles Terrón, Gabriela (58789692000); Martín Chozas, Patricia (57210581382); Rodríguez Doncel, Víctor (35204031900)",58789692000; 57210581382; 35204031900,Event Extraction and Semantic Representation from Spanish Workers Statute Using Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181171854&doi=10.3233%2fFAIA230983&partnerID=40&md5=f4287ea7c6437c9bc7ec8f285f538910,"This work uses Large Language Models to process an important piece of Spanish legislation: the Workers' Statute. The proposed method extracts the relevant events in its articles using a GPT-3.5 model and represents the entities involved in the events and the relationships between them as RDF triples. The experiments carried out to select a high-performance strategy include both zero- and few-shot learning tests. Finally, this work proposes a strategy to uplift the extracted legal relations into a legal knowledge graph.  © 2023 The Authors.",Final,All Open Access; Hybrid Gold Open Access
Zhang Z.-B.; Zhong Z.-M.; Yuan P.-P.; Jin H.,"Zhang, Zhao-Bo (57228034800); Zhong, Zhi-Man (57202982213); Yuan, Ping-Peng (12762118900); Jin, Hai (56434989100)",57228034800; 57202982213; 12762118900; 56434989100,Improving Entity Linking in Chinese Domain by Sense Embedding Based on Graph Clustering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151409491&doi=10.1007%2fs11390-023-2835-4&partnerID=40&md5=2920f4baf570bf08a34e632f12de572f,"Entity linking refers to linking a string in a text to corresponding entities in a knowledge base through candidate entity generation and candidate entity ranking. It is of great significance to some NLP (natural language processing) tasks, such as question answering. Unlike English entity linking, Chinese entity linking requires more consideration due to the lack of spacing and capitalization in text sequences and the ambiguity of characters and words, which is more evident in certain scenarios. In Chinese domains, such as industry, the generated candidate entities are usually composed of long strings and are heavily nested. In addition, the meanings of the words that make up industrial entities are sometimes ambiguous. Their semantic space is a subspace of the general word embedding space, and thus each entity word needs to get its exact meanings. Therefore, we propose two schemes to achieve better Chinese entity linking. First, we implement an n-gram based candidate entity generation method to increase the recall rate and reduce the nesting noise. Then, we enhance the corresponding candidate entity ranking mechanism by introducing sense embedding. Considering the contradiction between the ambiguity of word vectors and the single sense of the industrial domain, we design a sense embedding model based on graph clustering, which adopts an unsupervised approach for word sense induction and learns sense representation in conjunction with context. We test the embedding quality of our approach on classical datasets and demonstrate its disambiguation ability in general scenarios. We confirm that our method can better learn candidate entities’ fundamental laws in the industrial domain and achieve better performance on entity linking through experiments. © 2023, Institute of Computing Technology, Chinese Academy of Sciences.",Final,All Open Access; Bronze Open Access
Di Porto F.,"Di Porto, Fabiana (57168852100)",57168852100,Algorithmic disclosure rules,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118673342&doi=10.1007%2fs10506-021-09302-7&partnerID=40&md5=033949916d249e41901d2ba251dda318,"During the past decade, a small but rapidly growing number of Law&Tech scholars have been applying algorithmic methods in their legal research. This Article does it too, for the sake of saving disclosure regulation failure: a normative strategy that has long been considered dead by legal scholars, but conspicuously abused by rule-makers. Existing proposals to revive disclosure duties, however, either focus on the industry policies (e.g. seeking to reduce consumers’ costs of reading) or on rulemaking (e.g. by simplifying linguistic intricacies). But failure may well depend on both. Therefore, this Article develops a `comprehensive approach', suggesting to use computational tools to cope with linguistic and behavioral failures at both the enactment and implementation phases of disclosure duties, thus filling a void in the Law & Tech scholarship. Specifically, it outlines how algorithmic tools can be used in a holistic manner to address the many failures of disclosures from the rulemaking in parliament to consumer screens. It suggests a multi-layered design where lawmakers deploy three tools in order to produce optimal disclosure rules: machine learning, natural language processing, and behavioral experimentation through regulatory sandboxes. To clarify how and why these tasks should be performed, disclosures in the contexts of online contract terms and privacy online are taken as examples. Because algorithmic rulemaking is frequently met with well-justified skepticism, problems of its compatibility with legitimacy, efficacy and proportionality are also discussed. © 2021, The Author(s).",Final,All Open Access; Hybrid Gold Open Access
Blin I.; Stork L.; Spillner L.; Santagiustina C.,"Blin, Inès (57822229500); Stork, Lise (57202773210); Spillner, Laura (57299173600); Santagiustina, Carlo (57219757849)",57822229500; 57202773210; 57299173600; 57219757849,OKG: A Knowledge Graph for Fine-grained Understanding of Social Media Discourse on Inequality,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180361840&doi=10.1145%2f3587259.3627557&partnerID=40&md5=13a8943deff7c7e4e53202976ed132e2,"In recent years, social media platforms such as Twitter have allowed people to voice their opinions by engaging in online discussions. The availability of such discussions has garnered interest amongst researchers in analyzing the dynamics on critical topics, such as inequality. Most of the current strategies are, however, limited with respect to conveying the fine-grained opinions of users, focusing on tasks such as sentiment analysis or topic modeling that extract coarse categorizations. In this work, we address this challenge by integrating a Twitter corpus with the output of finer-grained semantic parsing for the analysis of social media discourse. To do so, we first introduce the OBservatory Integrated Ontology (OBIO) that integrates social media metadata with various types of linguistic knowledge. We then present the Observatory Knowledge Graph (OKG), a knowledge graph in terms of the ontology, populated with tweets on inequality. We lastly provide use cases showing how the knowledge graph can be used as the backbone of a social media observatory, to facilitate a deeper understanding of social media discourse. © 2023 Owner/Author.",Final,All Open Access; Hybrid Gold Open Access
Piché D.; Font L.; Zouaq A.; Gagnon M.,"Piché, Dominique (57217028610); Font, Ludovic (57189225314); Zouaq, Amal (14049497000); Gagnon, Michel (15050256600)",57217028610; 57189225314; 14049497000; 15050256600,Comparing Heuristic Rules and Masked Language Models for Entity Alignment in the Literature Domain,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176739806&doi=10.1145%2f3606699&partnerID=40&md5=cf0578ad159c0f5d63a332bb227fdac7,"The cultural world offers a staggering amount of rich and varied metadata on cultural heritage, accumulated by governmental, academic, and commercial players. However, the variety of involved institutions means that the data are stored in as many complex and often incompatible models and standards, which limits its availability and explorability by the greater public. The adoption of Linked Open Data technologies allows a strong interlinking of these various databases as well as external connections with existing knowledge bases. However, as they often contain references to the same entities, the delicate issue of entity alignment becomes the central challenge, especially in the absence or scarcity of unique global identifiers. To tackle this issue, we explored two approaches, one based on a set of heuristic rules and one based on masked language models, or masked language models (MLMs). We compare these two approaches, as well as different variations of MLMs, including some models trained on a different language, and various levels of data cleaning and labeling. Our results show that heuristics are a solid approach but also that MLM-based entity alignment obtains better performance coupled with the fact that it is robust to the data format and does not require any form of data preprocessing, which was not the case of the heuristic approach in our experiments. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,
Yu W.; Tong L.; Shi W.; Peng N.; Jiang M.,"Yu, Wenhao (57209227271); Tong, Lingbo (57234152400); Shi, Weijia (57225007353); Peng, Nanyun (57204466260); Jiang, Meng (36179647500)",57209227271; 57234152400; 57225007353; 57204466260; 36179647500,The Second Workshop on Knowledge-Augmented Methods for Natural Language Processing,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171361925&doi=10.1145%2f3580305.3599233&partnerID=40&md5=300157e122369aab12fea3d0f05b1d33,"Language models are being developed and deployed in many applications, ""small""-scale and large-scale, generic and specialized, text-only and multimodal, etc. Meanwhile, the missingness of important knowledge causes limitations and safety challenges. The knowledge includes commonsense, world facts, domain expertise, personalization, and especially the unique patterns that need to be discovered from big data applications. Training and inference processes of the language models can be and should be augmented with the knowledge. The first KnowledgeNLP at AAAI 2023 attracted scientists on knowledge augmentation methods towards higher language intelligence. This workshop offers a broad platform to share ideas and discuss various topics, such as (1) synergy between knowledge and language model, (2) scalable architectures that integrate NLP, knowledge graph, and graph learning technologies, (3) KnowledgeNLP for e-commerce, education, and healthcare, (4) human factors and social good in KnowledgeNLP.  © 2023 Owner/Author.",Final,
Gao Y.; Wang L.; Chen X.; Du Y.; Wang B.,"Gao, Yang (57213345459); Wang, Ludi (57193205545); Chen, Xueqing (58163816500); Du, Yi (35791161600); Wang, Bin (55584805036)",57213345459; 57193205545; 58163816500; 35791161600; 55584805036,Revisiting Electrocatalyst Design by a Knowledge Graph of Cu-Based Catalysts for CO2 Reduction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163537344&doi=10.1021%2facscatal.3c00759&partnerID=40&md5=6c53c0c324cdc290c90f5ecb1ce5a3a7,"Electrocatalysis takes a significant role in the production of sustainable fuels and chemicals. The combination of artificial intelligence and catalytic science is exhibiting great potential to extract, analyze, and predict electrocatalysts. However, the currently developed machine learning approach usually requires a mass of data from density functional theory calculations to train and optimize models. In contrast, a knowledge graph has the potential to extract useful information from a large amount of the literature without referring to density functional theory. Herein, a knowledge graph of Cu-based electrocatalysts for electrocatalytic CO2 reduction is constructed based on a linguistically enriched SciBERT-based framework. This framework retrieves multiple types of entities including material, regulation method, product, Faradaic efficiency, etc. from 757 scientific literature, generates representations with abundant domain-specific semantic information, and exhibits the capability to deal with electrocatalysts for CO2 reduction. The obtained graph shows the development history of related catalysts, builds relationships between the factors associated with catalysis, and provides intuitive charts for researchers to gain useful information. Furthermore, we propose a deep learning-based prediction model, which integrates the semantic information from the scientific literature (word embedding) with the correlation of knowledge triples (graph embedding) and realizes the prediction of the Faradaic efficiency for a targeted case. This work paves the way for catalyst design in the manner of merging artificial intelligence with catalytic science. © 2023 American Chemical Society",Final,
Ye Q.; Cao B.; Chen N.; Xu W.; Zou Y.,"Ye, Qichen (57988214100); Cao, Bowen (58127169800); Chen, Nuo (57221907210); Xu, Weiyuan (57340007000); Zou, Yuexian (7402166847)",57988214100; 58127169800; 57221907210; 57340007000; 7402166847,FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167976837&partnerID=40&md5=f9e835dac8a68b85c25f84899d2caa41,"Knowledge-aware question answering (KAQA) requires the model to answer questions over a knowledge base, which is essential for both open-domain QA and domain-specific QA, especially when language models alone cannot provide all the knowledge needed. Despite the promising result of recent KAQA systems which tend to integrate linguistic knowledge from pre-trained language models (PLM) and factual knowledge from knowledge graphs (KG) to answer complex questions, a bottleneck exists in effectively fusing the representations from PLMs and KGs because of (i) the semantic and distributional gaps between them, and (ii) the difficulties in joint reasoning over the provided knowledge from both modalities. To address the above two problems, we propose a Fine-grained Two-stage training framework (FiTs) to boost the KAQA system performance: The first stage aims at aligning representations from the PLM and the KG, thus bridging the modality gaps between them, named knowledge adaptive post-training. The second stage, called knowledge-aware fine-tuning, aims to improve the model's joint reasoning ability based on the aligned representations. In detail, we finetune the post-trained model via two auxiliary self-supervised tasks in addition to the QA supervision. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMILE) domains. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Xu B.; Zhang C.; Liu W.; Huang J.; Su Y.; Yang Y.; Jiang W.; Sun W.,"Xu, Bing (58492485500); Zhang, Chunju (35757236800); Liu, Wencong (57226884790); Huang, Jianwei (56660043200); Su, Yujiao (58492000400); Yang, Yucheng (57226889322); Jiang, Weijie (58598745200); Sun, Wenhao (58595990900)",58492485500; 35757236800; 57226884790; 56660043200; 58492000400; 57226889322; 58598745200; 58595990900,Landslide Identification Method Based on the FKGRNet Model for Remote Sensing Images,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165080901&doi=10.3390%2frs15133407&partnerID=40&md5=af5b243bbc2f91e27a0ea977d38a6133,"Currently, researchers commonly use convolutional neural network (CNN) models for landslide remote sensing image recognition. However, with the increase in landslide monitoring data, the available multimodal landslide data contain rich feature information, and existing landslide recognition models have difficulty utilizing such data. A knowledge graph is a linguistic network knowledge base capable of storing and describing various entities and their relationships. A landslide knowledge graph is used to manage multimodal landslide data, and by integrating this graph into a landslide image recognition model, the given multimodal landslide data can be fully utilized for landslide identification. In this paper, we combine knowledge and models, introduce the use of landslide knowledge graphs in landslide identification, and propose a landslide identification method for remote sensing images that fuses knowledge graphs and ResNet (FKGRNet). We take the Loess Plateau of China as the study area and test the effect of the fusion model by comparing the baseline model, the fusion model and other deep learning models. The experimental results show that, first, with ResNet34 as the baseline model, the FKGRNet model achieves 95.08% accuracy in landslide recognition, which is better than that of the baseline model and other deep learning models. Second, the FKGRNet model with different network depths has better landslide recognition accuracy than its corresponding baseline model. Third, the FKGRNet model based on feature splicing outperforms the fused feature classifier in terms of both accuracy and F1-score on the landslide recognition task. Therefore, the FKGRNet model can make fuller use of landslide knowledge to accurately recognize landslides in remote sensing images. © 2023 by the authors.",Final,All Open Access; Gold Open Access
Abdul Rahim R.; Pilkington R.; Procter A.M.; Montgomerie A.; Mittinty M.N.; D'Onise K.; Lynch J.,"Abdul Rahim, Razlyn (57666475400); Pilkington, Rhiannon (36617616400); Procter, Alexandra M (57211583517); Montgomerie, Alicia (55877756500); Mittinty, Murthy N (35848848200); D'Onise, Katina (14420735800); Lynch, John (57221617326)",57666475400; 36617616400; 57211583517; 55877756500; 35848848200; 14420735800; 57221617326,Child protection contact among children of culturally and linguistically diverse backgrounds: A South Australian linked data study,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147513765&doi=10.1111%2fjpc.16364&partnerID=40&md5=77a96ab081ff7225a88729042828547d,"Aim: To describe the cumulative incidence of child protection (CP) system contact, maltreatment type, source of reports to age 7 years, and socio-demographic characteristics for culturally and linguistically diverse (CALD) Australian children. Methods: We used CP, education, health, and birth registrations data for children followed from birth up to age 7 from the South Australian Better Evidence, Better Outcomes, Linked Data (SA BEBOLD) platform. Participants: SA born children enrolled in their first year of school from 2009 to 2015 (n = 76 563). CALD defined as non-Aboriginal or Torres Strait Islander, spoken language other than English, Indigenous or Sign, or had at least one parent born in a non-English speaking country. Outcomes measures: For CALD and non-CALD children, we estimated the cumulative incidence (risk) of CP contacts up to age 7, relative risk and risk differences for all levels of CP contact from notification to out-of-home care (OOHC), primary maltreatment type, reporter type, and socio-economic characteristics. Sensitivity analyses explored different population selection criteria and CALD definitions. Results: By age 7, 11.2% of CALD children had ‘screened-in’ notifications compared to 18.8% of non-CALD (risk difference [RD] 7.6 percentage points (95% confidence interval: 6.9–8.3)), and 0.6% of CALD children experienced OOHC compared to 2.2% of non-CALD (RD 1.6 percentage points (95% confidence interval: 1.3–1.8)). Emotional abuse was the most common substantiated maltreatment type for CALD and neglect for non-CALD. Among both groups, the most common reporter sources were police and education sector. Socio-economic characteristics were broadly similar. Sensitivity analyses results were consistent with primary analyses. Conclusion: By age 7, CALD children had lower risk of contact with all levels of CP. Estimates based on primary and sensitivity analyses suggested CALD children were 5–9 percentage points less likely to have a report screened-in, and from 1.0 to 1.7 percentage points less likely to have experienced OOHC. © 2023 The Authors. Journal of Paediatrics and Child Health published by John Wiley & Sons Australia, Ltd on behalf of Paediatrics and Child Health Division (The Royal Australasian College of Physicians).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Corrado M.; Giliberti V.; Gozzi M.; Lanzolla V.; Vetere G.; Zurlo D.,"Corrado, Mario (58593098300); Giliberti, Vincenzo (57751827800); Gozzi, Manuel (58590873700); Lanzolla, Vincenzo (58589984700); Vetere, Guido (22434365100); Zurlo, Domenico (58593098400)",58593098300; 57751827800; 58590873700; 58589984700; 22434365100; 58593098400,Assisting the Assistant: obot for Voice Customer Support,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171471256&doi=10.3233%2fFAIA230096&partnerID=40&md5=66974f1548cd6fcd1112724d7c8b70c7,"Despite recent advances in automation, customer support still requires a substantial amount of human intervention through voice channels. With the aim of improving the work of human assistants, we developed a collaborative bot (cobot) to help them in the process of handling customer voice interactions. The cobot is a reasoning agent that starts from loading background customer data into a dynamic knowledge graph. Then it captures the audio stream of the conversation, converts it to text in real time, analyzes the blocks of conversation with neural technologies and 'thinks' about the results. Assistants can also supply data to the cobot, based on the information they gather from the ongoing conversation. The reasoning agent provides information and action suggestions to the human assistant by applying heuristics on data collected from both automatic and human sources, based on a task and domain-specific conceptual models (ontologies). While designing a prototypical solution for utility services in Italy, we are faced with many problems, including spontaneous speech understanding, factual and linguistic knowledge representation, and efficient heuristic reasoning. We adopted a standards-based approach and experimented with open source reasoners and publicly available language models. The paper presents preliminary findings and outlines the system design, with focus on the interplay of neural language processing and logic reasoning. © 2023 The Authors.",Final,All Open Access; Hybrid Gold Open Access
Tyagi N.; Sarkar S.; Gaur M.,"Tyagi, Nancy (58570792800); Sarkar, Surjodeep (58257693500); Gaur, Manas (57204944466)",58570792800; 58257693500; 57204944466,Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178146475&doi=10.1145%2f3583780.3615273&partnerID=40&md5=302a5aedb302d234d9e65e8329bc479c,"The Natural Language Processing (NLP) community has been using crowd-sourcing techniques to create benchmark datasets such as General Language Understanding and Evaluation (GLUE) for training modern Language Models (LMs) such as BERT. GLUE tasks measure the reliability scores using inter-annotator metrics - Cohen's Kappa (k). However, the reliability aspect of LMs has often been overlooked. To counter this problem, we explore a knowledge-guided LM ensembling approach that leverages reinforcement learning to integrate knowledge from ConceptNet and Wikipedia as knowledge graph embeddings. This approach mimics human annotators resorting to external knowledge to compensate for information deficits in the datasets. Across nine GLUE datasets, our research shows that ensembling strengthens reliability and accuracy scores, outperforming state-of-the-art. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,All Open Access; Green Open Access
Duan L.; Wang J.; Luo B.; Sun Q.,"Duan, Li (55729337600); Wang, Jing (58463521300); Luo, Bing (39762069900); Sun, Qiao (57710138600)",55729337600; 58463521300; 39762069900; 57710138600,Simple Knowledge Graph Completion Model Based on Differential Negative Sampling and Prompt Learning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168774624&doi=10.3390%2finfo14080450&partnerID=40&md5=3dbd03fa809bad90353b301a1c132464,"Knowledge graphs (KGs) serve as a crucial resource for numerous artificial intelligence tasks, significantly contributing to the advancement of the AI field. However, the incompleteness of existing KGs hinders their effectiveness in practical applications. Consequently, researchers have proposed the task of KG completion. Currently, embedding-based techniques dominate the field as they leverage the structural information within KGs to infer and complete missing parts. Nonetheless, these methods exhibit limitations. They are limited by the quality and quantity of structural information and are unable to handle the missing entities in the original KG. To overcome these challenges, researchers have attempted to integrate pretrained language models and textual data to perform KG completion. This approach utilizes the definition statements and description text of entities within KGs. The goal is to compensate for the latent connections that are difficult for traditional methods to obtain. However, text-based methods still lag behind embedding-based models in terms of performance. Our analysis reveals that the critical issue lies in the selection process of negative samples. In order to enhance the performance of the text-based methods, various types of negative sampling methods are employed in this study. We introduced prompt learning to fill the gap between the pre-training language model and the knowledge graph completion task, and to improve the model reasoning level. Simultaneously, a ranking strategy based on KG structural information is proposed to utilize KG structured data to assist reasoning. The experiment results demonstrate that our model exhibits strong competitiveness and outstanding inference speed. By fully exploiting the internal structural information of KGs and external relevant descriptive text resources, we successfully elevate the performance levels of KG completion tasks across various metrics. © 2023 by the authors.",Final,All Open Access; Gold Open Access
Zhang J.; Ilievski F.; Ma K.; Kollaa A.; Francis J.; Oltramari A.,"Zhang, Jiarui (57712448200); Ilievski, Filip (57188757237); Ma, Kaixin (57219619491); Kollaa, Aravinda (58032693600); Francis, Jonathan (57194176946); Oltramari, Alessandro (6506019992)",57712448200; 57188757237; 57219619491; 58032693600; 57194176946; 6506019992,A Study of Situational Reasoning for Traffic Understanding,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171324019&doi=10.1145%2f3580305.3599246&partnerID=40&md5=f11530083e23f3e434260a12bc17c452,"Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work, based on natural language inference, commonsense knowledge-graph self-supervision, multi-QA joint training, and dense retrieval of domain information. We associate each method with a relevant knowledge source, including knowledge graphs, relevant benchmarks, and driving manuals. In extensive experiments, we benchmark various knowledge-aware methods against the three datasets, under zero-shot evaluation; we provide in-depth analyses of model performance on data partitions and examine model predictions categorically, to yield useful insights on traffic understanding, given different background knowledge and reasoning strategies.  © 2023 ACM.",Final,All Open Access; Green Open Access
Lu J.; Ma W.; Shen J.; Staab S.; Xiong B.; Yang C.,"Lu, Jiaying (57219628325); Ma, Wenjing (57250629600); Shen, Jiaming (57200213994); Staab, Steffen (7004053291); Xiong, Bo (57221322184); Yang, Carl (57203495794)",57219628325; 57250629600; 57200213994; 7004053291; 57221322184; 57203495794,HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167949945&doi=10.1145%2f3539618.3591997&partnerID=40&md5=0d973112a706c900bdc875a59bbd8c1f,"Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a supervision-efficient knowledge fusion framework that elicits the few-shot reasoning ability of large language models through hierarchy-oriented prompts. Empirical results on the collected KG-Hi-BKF benchmark datasets demonstrate the effectiveness of HiPrompt. © 2023 Copyright held by the owner/author(s).",Final,All Open Access; Green Open Access
Zhang Y.; Zhang Y.; Han J.,"Zhang, Yu (57196201561); Zhang, Yunyi (57217171173); Han, Jiawei (24325399900)",57196201561; 57217171173; 24325399900,Mining Structures from Massive Texts by Exploring the Power of Pre-trained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165033832&doi=10.48786%2fedbt.2023.81&partnerID=40&md5=6658f7de6d0bd73216edc6cbbc22fd78,"Technologies for handling massive structured or semi-structured data have been researched extensively in database communities. However, the real-world data are largely in the form of unstructured text, posing a great challenge to their management and analysis as well as their integration with semi-structured databases. Recent developments of deep learning methods and large pre-trained language models (PLMs) have revolutionized text mining and processing and shed new light on structuring massive text data and building a framework for integrated (i.e., structured and unstructured) data management and analysis. In this tutorial, we will focus on the recently developed text mining approaches empowered by PLMs that can work without relying on heavy human annotations. We will present an organized picture of how a set of weakly supervised methods explore the power of PLMs to structure text data, with the following outline: (1) an introduction to pre-trained language models that serve as new tools for our tasks, (2) mining topic structures: unsupervised and seed-guided methods for topic discovery from massive text corpora, (3) mining document structures: weakly supervised methods for text classification, (4) mining entity structures: distantly supervised and weakly supervised methods for phrase mining, named entity recognition, taxonomy construction, and structured knowledge graph construction, and (5) towards an integrated information processing paradigm. © 2023 Copyright held by the owner/author(s)",Final,
Liu B.; Lin T.; Li M.,"Liu, Bin (57477382300); Lin, Tao (57095282700); Li, Ming (56994248900)",57477382300; 57095282700; 56994248900,Enhancing aspect-category sentiment analysis via syntactic data augmentation and knowledge enhancement,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147855140&doi=10.1016%2fj.knosys.2023.110339&partnerID=40&md5=3f89cfad1f70734140170d3cbd6fab86,"The goal of aspect-category sentiment analysis (ACSA) is to predict the sentiment polarity toward a specific aspect category from reviewers’ expressed opinions in a sentence. With the boom of pretrained language models, various relative methods have achieved significant improvements in ACSA. However, two major issues still remain to be solved. First, most of these studies usually follow the canonical method of fine-tuning on limited labeled data, neglecting to leverage external knowledge to further enhance ACSA performance. Second, aspect categories are usually abstract concepts that are mentioned explicitly or implicitly, and the corresponding different sentiment polarities are not easy to accurately recognize. To address these issues, we first transform the ACSA task into a sentence-pair classification task with natural language inference, constructing synthetic sentences as hypotheses based on the predefined aspect categories and the prompt-generation sentence template. Then the model applies a passivization transformation to the synthetic sentences and generates more syntactic data to augment the limited training data. Furthermore, we enhance ACSA with curated knowledge from a common sense knowledge graph. Finally, different representations are synergistically fused with a gating mechanism to output richer sentiment features and enable context-, syntax-, and knowledge-aware predictions. Experimental results on three challenging benchmark datasets show that the proposed model outperforms some competitive baselines. © 2023 Elsevier B.V.",Final,
Yao Y.; Mao S.; Zhang N.; Chen X.; Deng S.; Chen X.; Chen H.,"Yao, Yunzhi (57225213006); Mao, Shengyu (57236852700); Zhang, Ningyu (55923601900); Chen, Xiang (57247642100); Deng, Shumin (57201556430); Chen, Xi (57218347633); Chen, Huajun (35268022500)",57225213006; 57236852700; 55923601900; 57247642100; 57201556430; 57218347633; 35268022500,Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168698471&doi=10.1145%2f3539618.3591763&partnerID=40&md5=ba620b7e32458423d39c214b982f99a0,"With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supervised data as a prompt for each sample, which is model-agnostic and can be plugged into widespread existing approaches. Experimental results demonstrate that previous methods integrated with RAP can achieve impressive performance gains in low-resource settings on five datasets of relational triple extraction and event extraction for knowledge graph construction. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,All Open Access; Green Open Access
Jovanovic M.; Campbell M.,"Jovanovic, Mladan (57214836766); Campbell, Mark (57211137983)",57214836766; 57211137983,Connecting AI: Merging Large Language Models and Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175178826&doi=10.1109%2fMC.2023.3305206&partnerID=40&md5=d0d2046c97d741103e27573fb236b498,Combining the generative abilities of large language models with the logical and factual coherence of knowledge graphs using a connected artificial intelligence architecture minimizes each system's shortcomings and amplifies their strengths across many real-world domains. © 1970-2012 IEEE.,Final,All Open Access; Bronze Open Access
Yang L.; Chen J.; Wang Z.; Shang F.,"Yang, Luheng (58069255900); Chen, Jianrui (36350603500); Wang, Zhihui (57215539107); Shang, Fanhua (36716893400)",58069255900; 36350603500; 57215539107; 36716893400,Subgraph-aware virtual node matching Graph Attention Network for entity alignment[Formula presented],-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163751095&doi=10.1016%2fj.eswa.2023.120694&partnerID=40&md5=0da468edd51d1fc35c16ec2bbb50ba39,"With the vigorous development of knowledge graph, its construction has become a hot issue recently. However, most knowledge graphs are incomplete, and it is worthwhile to devote much effort to further fuse the knowledge of different entities. Hence, entity alignment has surprisingly emerged as a key step of knowledge fusion to tackle the above issue. The existing GNN-based models simply aggregate entity embeddings, or incorporate auxiliary information of entities (e.g., relationship, time, etc.), which frustratingly fail to consider neighborhood structure of entities and the cross-graph matching information of the nodes between two knowledge graphs. Thus, to overcome the two challenges, we propose a novel Subgraph-aware Virtual Node Matching Graph Attention neTwork for entity alignment, named SVNM-GAT. Specifically, to strikingly capture the cross-graph matching interaction information of entities, we propose a new virtual node matching mechanism, which can obtain the long-range dependencies between virtual nodes and holistic nodes by scale-dot attention. Additionally, a subgraph discriminator is presented in SVNM-GAT to identify the subgraph structure and obtain weighted adjacent matrix by calculating subgraph structure coefficients. Finally, we adopt experiments to verify the effectiveness of our model on the cross-linguistic and temporal datasets, and all the results indicate that SVNM-GAT considerably outperforms the state-of-the-art methods. © 2023 Elsevier Ltd",Final,
Zhang X.; Xin X.; Li D.; Liu W.; Ren P.; Chen Z.; Ma J.; Ren Z.,"Zhang, Xiaoyu (58450257800); Xin, Xin (57214436254); Li, Dongdong (57224731589); Liu, Wenxuan (58033935300); Ren, Pengjie (56181249600); Chen, Zhumin (15749859500); Ma, Jun (56440424700); Ren, Zhaochun (53985046100)",58450257800; 57214436254; 57224731589; 58033935300; 56181249600; 15749859500; 56440424700; 53985046100,Variational Reasoning over Incomplete Knowledge Graphs for Conversational Recommendation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149628005&doi=10.1145%2f3539597.3570426&partnerID=40&md5=f8b63115b8ee6ae1413dbf08607c5a76,"Conversational recommender systems (CRSs) often utilize external knowledge graphs (KGs) to introduce rich semantic information and recommend relevant items through natural language dialogues. However, original KGs employed in existing CRSs are often incomplete and sparse, which limits the reasoning capability in recommendation. Moreover, only few of existing studies exploit the dialogue context to dynamically refine knowledge from KGs for better recommendation. To address the above issues, we propose the Variational Reasoning over Incomplete KGs Conversational Recommender (VRICR). Our key idea is to incorporate the large dialogue corpus naturally accompanied with CRSs to enhance the incomplete KGs; and perform dynamic knowledge reasoning conditioned on the dialogue context. Specifically, we denote the dialogue-specific subgraphs of KGs as latent variables with categorical priors for adaptive knowledge graphs refactor. We propose a variational Bayesian method to approximate posterior distributions over dialogue-specific subgraphs, which not only leverages the dialogue corpus for restructuring missing entity relations but also dynamically selects knowledge based on the dialogue context. Finally, we infuse the dialogue-specific subgraphs to decode the recommendation and responses. We conduct experiments on two benchmark CRSs datasets. Experimental results confirm the effectiveness of our proposed method. © 2023 ACM.",Final,All Open Access; Green Open Access
De Luca E.W.; Fiorelli M.; Picca D.; Stellato A.; Wehnert S.,"De Luca, Ernesto William (14026533600); Fiorelli, Manuel (55389632500); Picca, Davide (34772021800); Stellato, Armando (23393619500); Wehnert, Sabine (57210978233)",14026533600; 55389632500; 34772021800; 23393619500; 57210978233,Legal Information Retrieval meets Artificial Intelligence (LIRAI),-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174262477&doi=10.1145%2f3603163.3610575&partnerID=40&md5=1843a572dd8c55b1ff7df9f02a3dd975,"The Legal Information Retrieval meets Artificial Intelligence (LIRAI) workshop series aims to provide a venue hosting discussion of novel ideas, evaluations, and success stories concerning the application of Artificial Intelligence (AI) and Information Retrieval (IR) to the legal domain. All around the world, lawmakers, legal professionals, and citizens must cope with the sheer amount of legal knowledge present in legal documents. These documents can be norms, regulations, directives, legal cases, and other relevant material for legal practitioners, such as legal commentary. The continuous evolution of legal documents is a challenging setting, with implicit relationships playing an important role beyond explicit references. Recently, the adoption of shared machine-readable formats and FAIR principles, as well as methods and practices from the Semantic Web, have certainly improved the accessibility of legal knowledge and its interoperability. Still, retrieving legal knowledge and making sense of it are not solved problems. The legal community often has special requirements for retrieval systems (e.g., high recall, explainability). Artificial Intelligence (AI) is positioned as a lever to enhance our ability to find, understand, and correlate legal information, and to comprehend its relationship to reality, in terms of compliance evaluation and risk/benefit analysis. We call contributions on these topics in the form of papers, which will be collected in an open-access proceedings published on CEURWS.org and thus indexed by Scopus, DBLP, Google Scholar, and other citation databases. © 2023 Owner/Author.",Final,
Cao X.; Liu Y.; Sun F.,"Cao, Xing (57290601400); Liu, Yun (55960857900); Sun, Feng (57210860333)",57290601400; 55960857900; 57210860333,"Predict, pretrained, select and answer: Interpretable and scalable complex question answering over knowledge bases",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167787606&doi=10.1016%2fj.knosys.2023.110820&partnerID=40&md5=a89d0d4f016fa1d9a5a772f0b128c1bd,"Complex question answering (CQA) over knowledge bases(KB) is a challenging task that has attracted increasing attention in recent years. Semantic parsing-based methods face challenges such as poor adaptability for incomplete KB, large search spaces, and high costs to label logic forms. The gap between knowledge graph representations and question token embeddings leads to poor generalizability and uninterpretable reasoning of information retrieval-based methods. We propose an interpretable and scalable system called Predict, Pretrained, Select and Answer (PPSA) to solve CQA tasks over KB. Our system first trains a language model to predict the reasoning paths required to answer questions. We select only the entities that the predicted reasoning paths pass through in the knowledge graph as candidate entities to reduce the amount of distracting information. The paths that connect the topic entity and the selected candidate entity along with the question are then fed into another language model for answer prediction. The answer prediction module loads the parameters of the trained path prediction module before training to improve accuracy. The system reduces the search space by predicting the path and does not need expensive logic forms annotation. The textual path is the input to the language model, which bridges the gap between the graph representations and token embeddings. We analyse the system reasoning ability over knowledge graphs with different degrees of sparseness, and evaluate the system generalizability. The results of experiments performed with the Complex WebQuestions and WebQuestionsSP datasets demonstrate the effectiveness of our approach for CQA task. © 2023 Elsevier B.V.",Final,
Gupta R.; Srinivasa S.,"Gupta, Rajeev (57214908904); Srinivasa, Srinath (6602084314)",57214908904; 6602084314,Workshop on Enterprise Knowledge Graphs using Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178136348&doi=10.1145%2f3583780.3615301&partnerID=40&md5=91e170f4c1c67028abf9b3e763520795,"Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types-static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving -information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., - is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes-whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc. © 2023 Copyright is held by the owner/author(s). Publication rights licensed to ACM.",Final,
Zhang Y.; Jiang Y.; Alireza J.,"Zhang, Yuanpeng (36773940100); Jiang, Yizhang (55437846600); Alireza, Jolfaei (58316164800)",36773940100; 55437846600; 58316164800,Mutual Supervised Fusion & Transfer Learning with Interpretable Linguistic Meaning for Social Data Analytics,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162120141&doi=10.1145%2f3568675&partnerID=40&md5=111c40ed1d21bc6d8a1dc6aa43bd1e8a,"Social data analytics is often taken as the most commonly used method for community discovery, product recommendations, knowledge graph, and so on. In this study, social data are firstly represented in different feature spaces by using various feature extraction algorithms. Then we build a transfer learning model to leverage knowledge from multiple feature spaces. During modeling, since the assumption that the training and the testing data have the same distribution is always true, we give a theorem and its proof which asserts the necessary and sufficient condition for achieving a minimum testing error. We also theoretically demonstrate that maximizing the classification error consistency across different feature spaces can improve the classification performance. Additionally, the cluster assumption derived from semi-supervised learning is introduced to enhance knowledge transfer. Finally, a Tagaki-Sugeno-Kang (TSK) fuzzy system-based learning algorithm is proposed, which can generate interpretable fuzzy rules. Experimental results not only demonstrate the promising social data classification performance of our proposed approach but also show its interpretability which is missing in many other models.  © 2023 Association for Computing Machinery.",Final,
Zhao Z.; Lin S.,"Zhao, Zhen (57193540820); Lin, Shuo (58289596400)",57193540820; 58289596400,A cross-linguistic entity alignment method based on graph convolutional neural network and graph attention network,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160258689&doi=10.1007%2fs00607-023-01178-6&partnerID=40&md5=77216aae8b043808a5bdaa47f165fc11,"Cross-language entity alignment forms an important component of building a Knowledge Graph. The task of cross-lingual entity alignment is to match entities in a source language with their counterparts in target languages. In practice, there is an imbalance of attribute information in corresponding entities at the same level, and the problem of neighboring point weight assignment is not considered, which not only loses the association information between entities but also limits the utilization of entity attributes in the alignment process, making this task challenging. In this paper, we propose a cross-lingual entity alignment method based on Graph convolutinal neural network and Graph attention network. Specifically, it can capture more spatial information by assigning respective weights to the neighbors of different nodes through multi-level learning of entity structure, attributes, and attention. In addition, the weights of neighboring node features depend entirely on the node features, which gets rid of the dependence on the graph. The experiments show that our models outperform state-of-the-art methods at a fraction of the cost. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.",Final,
Palma C.,"Palma, Cosimo (58209074000)",58209074000,Neurosymbolic Narrative Generation for Cultural Heritage,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171446260&doi=10.3233%2fFAIA230129&partnerID=40&md5=b882d5bee468483fbf05d8756db5dd7d,"Aim of my research is to exploit Linguistic Linked Open Data (LLOD) as base for advanced Cultural Heritage (CH) fruition by means of Automatic Story Generation (ASG). Following the rationale that discovering and reviving already existing (yet latent) narratives is worthier than automatically generating them from anew in eliciting the user's interest, the input-2-graph and the graph-2-sequence ASG-pipeline phases, heavily relying on LLOD, will be given a deeper focus, whereby the final Natural Language Generation (NLG) module will be constrained by the entities and relations established in the Knowledge Graph (KG) generation modules (a configuration typical of the neurosymbolic approach). In order to enhance possibilities of implementation in real-life contexts, the elaborated pipeline will be modular, i.e. self-sufficient in its constituent parts. Beyond the countless possible application scenarios ranging from education to entertainment, this solution detangles the user from his role of mere consumer, and empowers him not only to control the creation process [3.1], but also to find already within it, and not necessarily in the final outcome, a valuable source for intellectual growth. This work intends the addressing of a specific societal need as an avalanche to simultaneously fill knowledge gaps identified in and among the related scientific domains. © 2023 The Authors.",Final,All Open Access; Hybrid Gold Open Access
Zhang J.; Huang B.; Fujita H.; Zeng G.; Liu J.,"Zhang, Jiahao (57970940100); Huang, Bo (57207403484); Fujita, Hamido (35611951900); Zeng, Guohui (35750794700); Liu, Jin (26652771400)",57970940100; 57207403484; 35611951900; 35750794700; 26652771400,FeQA: Fusion and enhancement of multi-source knowledge on question answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158037925&doi=10.1016%2fj.eswa.2023.120286&partnerID=40&md5=cdcc0c0bb917d8ef029a50c74ed65aed,"In the question answering task, we usually need to reason the answer according to the question. Question answering tasks mostly use the pretrained language model to obtain the semantic embedding of questions and choices to predict answers, while the pretrained language model cannot accurately represent the potential relationship between entities in the question. Therefore, researchers introduce knowledge graph to realize the reasoning from question entity to answer entity. However, the limitation of knowledge graph lies in the lack of background information of entities, which may lead to wrong reasoning. To solve the above problems, a new question answering system model FeQA is proposed, which adopts large-scale pretrained language model and knowledge graph. The former uses dual-attention mechanism to enhance the semantics of questions by using Wiktionary and other question answering datasets, while the latter uses graph neural network to infer entities. During the interaction of two modal knowledge, the former provides the basis for the reasoning of nodes in the latter, and the latter provides structured knowledge for the former. After several reasoning iterations, the final answer is obtained by using the knowledge of the two modes. The experimental results on the CommonsenseQA and OpenBookQA datasets show that the performance of this model is better than that of the baseline models. Ablation experiments show that the components and knowledge sources included in this model play an important role in the effect of question and answering task. Extended experiments show the model has good application capability. © 2023 Elsevier Ltd",Final,
Adjali O.; Grimal P.; Ferret O.; Ghannay S.; Le Borgne H.,"Adjali, Omar (56780391200); Grimal, Paul (58406004100); Ferret, Olivier (14832680800); Ghannay, Sahar (57028272700); Le Borgne, Hervé (55882534700)",56780391200; 58406004100; 14832680800; 57028272700; 55882534700,Explicit Knowledge Integration for Knowledge-Aware Visual Question Answering about Named Entities,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163586772&doi=10.1145%2f3591106.3592227&partnerID=40&md5=3ad52ba87eedb7c1a6d068aed0883d27,"Recent years have shown unprecedented growth of interest in Vision-Language related tasks, with the need to address the inherent challenges of integrating linguistic and visual information to solve real-world applications. Such a typical task is Visual Question Answering (VQA), which aims to answer questions about visual content. The limitations of the VQA task in terms of question redundancy and poor linguistic variability encouraged researchers to propose Knowledge-aware Visual Question Answering tasks as a natural extension of VQA. In this paper, we tackle the KVQAE (Knowledge-based Visual Question Answering about named Entities) task, which proposes to answer questions about named entities defined in a knowledge base and grounded in visual content. In particular, besides the textual and visual information, we propose to leverage the structural information extracted from syntactic dependency trees and external knowledge graphs to help answer questions about a large spectrum of entities of various types. Thus, by combining contextual and graph-based representations using Graph Convolutional Networks (GCNs), we are able to learn meaningful embeddings for Information Retrieval tasks. Experiments on the ViQuAE public dataset show how our approach improves the state-of-the-art baselines while demonstrating the interest of injecting external knowledge to enhance multimodal information retrieval.  © 2023 ACM.",Final,All Open Access; Green Open Access
Zhang G.,"Zhang, Gangyi (57218843840)",57218843840,User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174537606&doi=10.1145%2f3604915.3608885&partnerID=40&md5=686b2c3e964314d6b0f89f3b28bece13,"Conversational recommender systems (CRS) promise to provide a more natural user experience for exploring and discovering items of interest through ongoing conversation. However, effectively modeling and adapting to users' complex and changing preferences remains challenging. This research develops user-centric methods that focus on understanding and adapting to users throughout conversations to provide the most helpful recommendations. First, a graph-based Conversational Path Reasoning (CPR) framework is proposed that represents dialogs as interactive reasoning over a knowledge graph to capture nuanced user interests and explain recommendations. To further enhance relationship modeling, graph neural networks are incorporated for improved representation learning. Next, to address uncertainty in user needs, the Vague Preference Multi-round Conversational Recommendation (VPMCR) scenario and matching Adaptive Vague Preference Policy Learning (AVPPL) solution are presented using reinforcement learning to tailor recommendations to evolving preferences. Finally, opportunities to leverage large language models are discussed to further advance user experiences via advanced user modeling, policy learning, and response generation. Overall, this research focuses on designing conversational recommender systems that continuously understand and adapt to users' ambiguous, complex and changing needs during natural conversations. © 2023 Owner/Author.",Final,
Zhou J.; Zhan Y.; Chen S.,"Zhou, Jinming (57193493889); Zhan, Yuanyuan (58750980800); Chen, Sibo (57214793130)",57193493889; 58750980800; 57214793130,Multi-Dimensional Cloud Model-Based Assessment and Its Application to the Risk of Supply Chain Financial Companies,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178995882&doi=10.4018%2fIJFSA.333863&partnerID=40&md5=022444674bcb8183b55ad4e40a545837,"The multi-dimensional cloud model is proposed as the expansion of the one-dimensional cloud model. The features of ambiguity and stochasticity in complex information situations are considered; thus, this optimized model can be utilized upon multiple value classifications and ordering via which the objects’ attributes of physical and social can be reflected. Therefore, this promoted model is wildly used. This paper provides a knowledge graph by reviewing the theoretical research of the multi-dimensional cloud model and its related bibliographies, and Cite Space is applied here to give a visualization conclusion. In recent years, a multitude of theories and methods have emerged to address the challenges posed by fuzzy and stochastic uncertainty in various domains, such as image segmentation, data mining, prediction techniques, and comprehensive evaluation of multiple metrics and dimensions using uncertain linguistic variables. © 2023 IGI Global. All rights reserved.",Final,All Open Access; Hybrid Gold Open Access
Oduro-Afriyie J.; Jamil H.M.,"Oduro-Afriyie, Joel (57211168878); Jamil, Hasan M (57207601856)",57211168878; 57207601856,Enabling the Informed Patient Paradigm with Secure and Personalized Medical Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175859728&doi=10.1145%2f3584371.3613016&partnerID=40&md5=ee953356ef7f31dbf974e9c67dcfe914,"Quality patient care is a complex and multifaceted problem requiring the integration of data from multiple sources. We propose Medicient, a knowledge-graph-based question answering system that processes heterogeneous data sources, including patient health records, drug databases, and medical literature, into a unified knowledge graph with zero training. The knowledge graph is then utilized to provide personalized recommendations for treatment or medication. The system leverages the power of large language models for question understanding and natural language response generation, while hiding sensitive patient information. We compare our system to a large language model (ChatGPT), which does not have access to patient health records, and show that our system provides better recommendations. This study contributes to a growing body of research on knowledge graphs and their applications in healthcare. © 2023 ACM.",Final,All Open Access; Bronze Open Access
Chen J.; He Y.; Geng Y.; Jiménez-Ruiz E.; Dong H.; Horrocks I.,"Chen, Jiaoyan (55827415100); He, Yuan (57372933500); Geng, Yuxia (57219622057); Jiménez-Ruiz, Ernesto (15136001900); Dong, Hang (57209220354); Horrocks, Ian (20734105100)",55827415100; 57372933500; 57219622057; 15136001900; 57209220354; 20734105100,Contextual semantic embeddings for ontology subsumption prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156109122&doi=10.1007%2fs11280-023-01169-9&partnerID=40&md5=ee5a034982cc79c5204f3c98fc8e7925,"Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of the templates and that BERTSubs can dramatically outperform the baselines that use (literal-aware) knowledge graph embeddings, non-contextual word embeddings and the state-of-the-art OWL ontology embeddings. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,All Open Access; Green Open Access
Zhong Q.; Ding L.; Liu J.; Du B.; Jin H.; Tao D.,"Zhong, Qihuang (57217065019); Ding, Liang (57219499270); Liu, Juhua (37076076900); Du, Bo (57217375214); Jin, Hua (54927577000); Tao, Dacheng (7102600334)",57217065019; 57219499270; 37076076900; 57217375214; 54927577000; 7102600334,Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-Based Sentiment Analysis,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149357653&doi=10.1109%2fTKDE.2023.3250499&partnerID=40&md5=3125561c4405af3f511795d525769efc,"Aspect-based sentiment analysis (ABSA) is a fine-grained task of sentiment analysis. To better comprehend long complicated sentences and obtain accurate aspect-specific information, linguistic and commonsense knowledge are generally required in this task. However, most current methods employ complicated and inefficient approaches to incorporate external knowledge, e.g., directly searching the graph nodes. Additionally, the complementarity between external knowledge and linguistic information has not been thoroughly studied. To this end, we propose a knowledge graph augmented network (KGAN), which aims to effectively incorporate external knowledge with explicitly syntactic and contextual information. In particular, KGAN captures the sentiment feature representations from multiple different perspectives, i.e., context-, syntax- and knowledge-based. First, KGAN learns the contextual and syntactic representations in parallel to fully extract the semantic features. Then, KGAN integrates the knowledge graphs into the embedding space, based on which the aspect-specific knowledge representations are further obtained via an attention mechanism. Last, we propose a hierarchical fusion module to complement these multi-view representations in a local-to-global manner. Extensive experiments on five popular ABSA benchmarks demonstrate the effectiveness and robustness of our KGAN. Notably, with the help of the pretrained model of RoBERTa, KGAN achieves a new record of state-of-the-art performance among all datasets.  © 1989-2012 IEEE.",Final,All Open Access; Green Open Access
Choi B.; Ko Y.,"Choi, Bonggeun (57263655600); Ko, Youngjoong (8082612400)",57263655600; 8082612400,Knowledge graph extension with a pre-trained language model via unified learning method,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146055694&doi=10.1016%2fj.knosys.2022.110245&partnerID=40&md5=b326af28109bf807e245f085abdcedce,"Knowledge graphs (KGs) are collections of real-world knowledge that is represented by a structured form of triples. Since they are manually built in their nascent stage, there is a common problem that some links (triples) are missing. Knowledge graph completion (KGC) aims to find those missing links and thereby complete the KGs. However, as knowledge increases through diverse sources, new entities have explosively emerged and they are needed to be connected to existing KGs. Thus, open-world KGC is targeted on extending KGs to those new entities. Dealing with those new entities is challenging because they do not have any connection with entities in the existing KGs. One way to handle the new ones is to embed them with their textual descriptions with pre-trained word embeddings and score them in the graph-vector space with the existing typical KGC models. These models have resulted in meaningful results but there is still a lack of studies on utilizing the latest neural networks, such as pre-trained language models which are known to be better at capturing contexts than pre-trained word embeddings. This paper proposes a novel model that effectively connects new entities and existing KGs through a pre-trained language model. To effectively handle the problem, we utilize two learning methods; one is the classification method of the masked language model (MLM) that predicts a word among a huge vocabulary set with a given context, and the other is multi-task learning based on the Multi-Task for Deep Neural Networks (MT-DNN). Based on the methods, the model first generates an embedding of a new entity using its textual description and then uses the embedding to find one of the existing entities from a KG where the new entity can be connected. The experimental results on three benchmark datasets, DBPedia50k, FB15k-237-OWE, and FB20k, show that the proposed model improves performances by 9.2%p, 4.4%p, and 11.1%p, respectively, and achieves new state-of-the-art performance for all datasets. © 2022 Elsevier B.V.",Final,
Cui W.; Shang M.,"Cui, Wei (57220007512); Shang, Mingsheng (12761788400)",57220007512; 12761788400,KAGN:knowledge-powered attention and graph convolutional networks for social media rumor detection,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153262960&doi=10.1186%2fs40537-023-00725-4&partnerID=40&md5=596edb982dc3922fbfc7cfac96256f15,"Rumor posts have received substantial attention with the rapid development of online and social media platforms. The automatic detection of rumor from posts has emerged as a major concern for the general public, the government, and social media platforms. Most existing methods focus on the linguistic and semantic aspects of posts content, while ignoring knowledge entities and concepts hidden within the article which facilitate rumor detection. To address these limitations, in this paper, we propose a novel end-to-end attention and graph-based neural network model (KAGN), which incorporates external knowledge from the knowledge graphs to detect rumor. Specifically, given the post's sparse and ambiguous semantics, we identify entity mentions in the post’s content and link them to entities and concepts in the knowledge graphs, which serve as complementary semantic information for the post text. To effectively inject external knowledge into textual representations, we develop a knowledge-aware attention mechanism to fuse local knowledge. Additionally, we construct a graph consisting of posts texts, entities, and concepts, which is fed to graph convolutional networks to explore long-range knowledge through graph structure. Our proposed model can therefore detect rumor by combining semantic-level and knowledge-level representations of posts. Extensive experiments on four publicly available real-world datasets show that KAGN outperforms or is comparable to other state-of-the-art methods, and also validate the effectiveness of knowledge. © 2023, The Author(s).",Final,All Open Access; Gold Open Access; Green Open Access
Hertling S.; Paulheim H.,"Hertling, Sven (55583440200); Paulheim, Heiko (35095438500)",55583440200; 35095438500,OLaLa: Ontology Matching with Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180367190&doi=10.1145%2f3587259.3627571&partnerID=40&md5=7b017e0ca919f17ccea79a17288582bb,"Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth. © 2023 Owner/Author.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Atif F.; El Khatib O.; Difallah D.,"Atif, Farah (57213145511); El Khatib, Ola (58547763900); Difallah, Djellel (55001800900)",57213145511; 58547763900; 55001800900,BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168675722&doi=10.1145%2f3539618.3591698&partnerID=40&md5=f77b7db65791b8aab4ee054ed768af3e,"Knowledge Graph Question Answering (KGQA) is a task that aims to answer natural language queries by extracting facts from a knowledge graph. Current state-of-the-art techniques for KGQA rely on text-based information from graph entity and relations labels, as well as external textual corpora. By reasoning over multiple edges in the graph, these can accurately rank and return the most relevant entities. However, one of the limitations of these methods is that they cannot handle the inherent incompleteness of real-world knowledge graphs and may lead to inaccurate answers due to missing edges. To address this issue, recent advances in graph representation learning have led to the development of systems that can use link prediction techniques to handle missing edges probabilistically, allowing the system to reason with incomplete information. However, existing KGQA frameworks that use such techniques often depend on learning a transformation from the query representation to the graph embedding space, which requires access to a large training dataset. We present BeamQA, an approach that overcomes these limitations by combining a sequence-to-sequence prediction model with beam search execution in the embedding space. Our model uses a pretrained large language model and synthetic question generation. Our experiments demonstrate the effectiveness of BeamQA when compared to other KGQA methods on two knowledge graph question-answering datasets. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,
Wang T.; Shen B.; Zhang J.; Zhong Y.,"Wang, Tao (56135273700); Shen, Bo (57051936000); Zhang, Jinglin (58249993300); Zhong, Yu (58249286000)",56135273700; 57051936000; 58249993300; 58249286000,Improving PLMs for Graph-to-Text Generation by Relational Orientation Attention,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159274034&doi=10.1007%2fs11063-023-11292-3&partnerID=40&md5=d9061c1fd7a7e83c772204502fb5d860,"Pretrained language models (PLMs) with impressive performances in graph-to-text generation have recently been employed. However, linearized graph data will lead to the loss of triplet structure information and the problem of insufficient syntactic information when graph data are converted into sequence data by PLMs. These defects prevent PLMs from absorbing all the information that knowledge graphs hold and exerting their full potential in graph-to-text generation. To address these issues, we propose two targeted solutions. First, a relational orientation attention (ROA) module is proposed to incorporate triplet structure information into knowledge graph representations. During graph encoding, ROA establishes structural associations between entities and relations by fusing relevant relation information into entity representations. Second, the (knowledge subgraph, text) pairs are used to pretrain PLMs in text and triplet reconstruction tasks. Pretraining tasks with linearized graph data will enable PLMs to transfer learning more seamlessly between graphs and texts. The experiments with the WebNLG, WebQuestions, and PathQuestions datasets demonstrate that relational orientation attention and pretraining tasks (text and triplet reconstruction) can be implemented to capture triplet structure information and boost the learning ability of PLMs on structured data. Additional research reveals that PLMs equipped with designed approaches have superior few-shot learning capability. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,
Zhai J.; Zheng X.; Wang C.-D.; Li H.; Tian Y.,"Zhai, Jianyang (58546649700); Zheng, Xiawu (57204472355); Wang, Chang-Dong (55157826700); Li, Hui (57211503963); Tian, Yonghong (7402840445)",58546649700; 57204472355; 55157826700; 57211503963; 7402840445,Knowledge Prompt-tuning for Sequential Recommendation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546267&doi=10.1145%2f3581783.3612252&partnerID=40&md5=91e1b02330b6e9a47915ca5a84301335,"Pre-trained language models (PLMs) have demonstrated strong performance in sequential recommendation (SR), which are utilized to extract general knowledge. However, existing methods still lack domain knowledge and struggle to capture users' fine-grained preferences. Meanwhile, many traditional SR methods improve this issue by integrating side information while suffering from information loss. To summarize, we believe that a good recommendation system should utilize both general and domain knowledge simultaneously. Therefore, we introduce an external knowledge base and propose Knowledge Prompt-tuning for Sequential Recommendation (KP4SR). Specifically, we construct a set of relationship templates and transform a structured knowledge graph (KG) into knowledge prompts to solve the problem of the semantic gap. However, knowledge prompts disrupt the original data structure and introduce a significant amount of noise. We further construct a knowledge tree and propose a knowledge tree mask, which restores the data structure in a mask matrix form, thus mitigating the noise problem. We evaluate KP4SR on three real-world datasets, and experimental results show that our approach outperforms state-of-the-art methods on multiple evaluation metrics. Specifically, compared with PLM-based methods, our method improves NDCG@5 and HR@5 by 40.65% and 36.42% on the books dataset, 11.17% and 11.47% on the music dataset, and 22.17% and 19.14% on the movies dataset, respectively. Our code is publicly available at the link: https://github.com/zhaijianyang/KP4SR. © 2023 ACM.",Final,All Open Access; Green Open Access
Hu N.; Wu Y.; Qi G.; Min D.; Chen J.; Pan J.Z.; Ali Z.,"Hu, Nan (58278625700); Wu, Yike (57547104200); Qi, Guilin (56393840100); Min, Dehai (57996415000); Chen, Jiaoyan (55827415100); Pan, Jeff Z (8856621200); Ali, Zafar (57220705145)",58278625700; 57547104200; 56393840100; 57996415000; 55827415100; 8856621200; 57220705145,An empirical study of pre-trained language models in simple knowledge graph question answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159595670&doi=10.1007%2fs11280-023-01166-y&partnerID=40&md5=70884daa18e729e7028ad0df77729e77,"Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT (https://chat.openai.com/), which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA (https://github.com/aannonymouuss/PLMs-in-Practical-KBQA). © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,All Open Access; Green Open Access
Cao X.; Liu Y.,"Cao, Xing (57290601400); Liu, Yun (55960857900)",57290601400; 55960857900,ReLMKG: reasoning with pre-trained language models and knowledge graphs for complex question answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138383289&doi=10.1007%2fs10489-022-04123-w&partnerID=40&md5=a1d057879be442f1ad8f8789e41b2ed3,"The goal of complex question answering over knowledge bases (KBQA) is to find an answer entity in a knowledge graph. Recent information retrieval-based methods have focused on the topology of the knowledge graph, ignoring inconsistencies between knowledge graph embeddings and natural language embeddings, and cannot effectively utilize both implicit and explicit knowledge for reasoning. In this paper, we propose a novel model, ReLMKG, to address this challenge. This approach performs joint reasoning on a pre-trained language model and the associated knowledge graph. The complex question and textual paths are encoded by the language model, bridging the gap between the question and the knowledge graph and exploiting implicit knowledge without introducing additional unstructured text. The outputs of different layers in the language model are used as instructions to guide a graph neural network to perform message propagation and aggregation in a step-by-step manner, which utilizes the explicit knowledge contained in the structured knowledge graph. We analyse the reasoning ability of the ReLMKG model for knowledge graphs with different degrees of sparseness and evaluate the generalizability of the model. Experiments conducted on the Complex WebQuestions and WebQuestionsSP datasets demonstrate the effectiveness of our approach on KBQA tasks. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,
Liu R.; Fang Y.; Yu F.; Tian R.; Ren T.; Wu G.,"Liu, Runze (58759557800); Fang, Yaqun (57417172200); Yu, Fan (57220866028); Tian, Ruiqi (58759484700); Ren, Tongwei (25423101300); Wu, Gangshan (8247435800)",58759557800; 57417172200; 57220866028; 58759484700; 25423101300; 8247435800,Deep Video Understanding with Video-Language Model,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179555254&doi=10.1145%2f3581783.3612863&partnerID=40&md5=5c79ef818575be8cfa487ff3be9be292,"Pre-trained video-language models (VLMs) have shown superior performance in high-level video understanding tasks, analyzing multi-modal information, aligning with Deep Video Understanding Challenge (DVUC) requirements.In this paper, we explore pre-trained VLMs' potential in multimodal question answering for long-form videos. We propose a solution called Dual Branches Video Modeling (DBVM), which combines knowledge graph (KG) and VLMs, leveraging their strengths and addressing shortcomings.The KG branch recognizes and localizes entities, fuses multimodal features at different levels, and constructs KGs with entities as nodes and relationships as edges.The VLM branch applies a selection strategy to adapt input movies into acceptable length and a cross-matching strategy to post-process results providing accurate scene descriptions.Experiments conducted on the DVUC dataset validate the effectiveness of our DBVM. © 2023 ACM.",Final,
Nguyen Quang T.; Nguyen T.-O.,"Nguyen Quang, Tung (58778349800); Nguyen, Thi-Oanh (57212284010)",58778349800; 57212284010,Language Knowledge-Assisted in Topology Construction for Skeleton-Based Action Recognition,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180548900&doi=10.1145%2f3628797.3629008&partnerID=40&md5=59096c6db04472a87245754d081d5860,"Skeleton-based action recognition is a challenging problem due to the high dimensionality and noisy nature of skeleton data. Graph convolution networks (GCNs), which use graph topology to extract representative features, have been effective for skeleton-based action recognition in recent years. However, effectively learning and aggregating topology information is challenging problem. In this work, we propose a strategy to construct topology representation to skeleton-based action recognition that combines language knowledge to learn the topology. Specifically, borrows the idea from Language Knowledge-Assisted Representation Learning (LAGCN) [20], which uses a large-scale language model (LLM) to learn a priori global relationship (GPR) topology that captures the global structural relationships between the joints and a priori category relationship (CPR) topology between nodes in the skeleton graph to capture the category-specific relationships between the joints. We propose to apply the GPR topology as a prior topology, provide significant momentum to learn the model along with the CPR which is used to learn the class-distinguishable features into the Channel-wise Topology Refinement Graph Convolution (CTRGCN) [4]. The proposed approach is evaluated on the NTU RGB+D and NW-UCLA datasets. The results show that the proposed approach achieves promising results with 96.76% on the NW-UCLA dataset and 97% on the NTU dataset with the cross-view benchmark along with 92.8% on NTU cross-subject benchmark.  © 2023 ACM.",Final,
Feng X.; Zhang Y.; Meng M.H.; Li Y.; Joe C.E.; Wang Z.; Bai G.,"Feng, Xinguo (58035022400); Zhang, Yanjun (57202793122); Meng, Mark Huasong (57204462857); Li, Yansong (58447927100); Joe, Chegne Eu (58242403400); Wang, Zhe (24385743300); Bai, Guangdong (55954311500)",58035022400; 57202793122; 57204462857; 58447927100; 58242403400; 24385743300; 55954311500,Detecting contradictions from IoT protocol specification documents based on neural generated knowledge graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158817992&doi=10.1016%2fj.isatra.2023.04.025&partnerID=40&md5=3c5e03fdd9e95774de6bc841a05a4ea9,"Due to the boom of Internet of Things (IoT) in recent years, various IoT devices are connected to the Internet and communicate with each other through network protocols such as the Constrained Application Protocol (CoAP). These protocols are typically defined and described in specification documents, such as Request for Comments (RFC), which are written in natural or semi-formal languages. Since developers largely follow the specification documents when implementing web protocols, they have become the de facto protocol specifications. Therefore, it must be ensured that the descriptions in them are consistent to avoid technological issues, incompatibility, security risks, or even legal concerns. In this work, we propose Neural RFC Knowledge Graph (NRFCKG), a neural network-generated knowledge graph based contradictions detection tool for IoT protocol specification documents. Our approach can automatically parse the specification documents and construct knowledge graphs from them through entity extraction, relation extraction, and rule extraction with large language models. It then conducts an intra-entity and inter-entity contradiction detection over the generated knowledge graph. We implement NRFCKG and apply it to the most extensively used messaging protocols in IoT, including the main RFC (RFC7252) of CoAP, the specification document of MQTT, and the specification document of AMQP. Our evaluation shows that NRFCKG generalizes well to other specification documents and it manages to detect contradictions from these IoT protocol specification documents. © 2023 ISA",Final,
Tan J.; Hu J.; Dong S.,"Tan, Jiajie (57812027800); Hu, Jinlong (35100245500); Dong, Shoubin (7402016703)",57812027800; 35100245500; 7402016703,Incorporating entity-level knowledge in pretrained language model for biomedical dense retrieval,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173559854&doi=10.1016%2fj.compbiomed.2023.107535&partnerID=40&md5=946c352e5c757104c074459c77941f03,"In recent years, pre-trained language models (PLMs) have dominated natural language processing (NLP) and achieved outstanding performance in various NLP tasks, including dense retrieval based on PLMs. However, in the biomedical domain, the effectiveness of dense retrieval models based on PLMs still needs to be improved due to the diversity and ambiguity of entity expressions caused by the enrichment of biomedical entities. To alleviate the semantic gap, in this paper, we propose a method that incorporates external knowledge at the entity level into a dense retrieval model to enrich the dense representations of queries and documents. Specifically, we first add additional self-attention and information interaction modules in the Transformer layer of the BERT architecture to perform fusion and interaction between query/document text and entity embeddings from knowledge graphs. We then propose an entity similarity loss to constrain the model to better learn external knowledge from entity embeddings, and further propose a weighted entity concatenation mechanism to balance the impact of entity representations when matching queries and documents. Experiments on two publicly available biomedical retrieval datasets show that our proposed method outperforms state-of-the-art dense retrieval methods. In term of NDCG metrics, the proposed method (called ELK) improves the ranking performance of coCondenser by at least 5% on both two datasets, and also obtains further performance gain over state-of-the-art EVA methods. Though having a more sophisticated architecture, the average query latency of ELK is still within the same order of magnitude as that of other efficient methods. © 2023 Elsevier Ltd",Final,
Maillot P.; Corby O.; Faron C.; Gandon F.; Michel F.,"Maillot, Pierre (56203583800); Corby, Olivier (6602312177); Faron, Catherine (57541989800); Gandon, Fabien (12242656500); Michel, Franck (36559861300)",56203583800; 6602312177; 57541989800; 12242656500; 36559861300,IndeGx: A model and a framework for indexing RDF knowledge graphs with SPARQL-based test suits,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147247408&doi=10.1016%2fj.websem.2023.100775&partnerID=40&md5=a86ead9f0788df247a0536a2378ef37e,"In recent years, a large number of RDF datasets have been built and published on the Web in fields as diverse as linguistics or life sciences, as well as general datasets such as DBpedia or Wikidata. The joint exploitation of these datasets requires specific knowledge about their content, access points, and commonalities. However, not all datasets contain a self-description, and not all access points can handle the complex queries used to generate such a description. In this article, we provide a standard-based approach to generate the description of a dataset. The generated descriptions as well as the process of their computation are expressed using standard vocabularies and languages. We implemented our approach into a framework, called IndeGx, where each indexing feature and its computation is collaboratively and declaratively defined in a GitHub repository. We have experimented IndeGx on a set of 339 RDF datasets with endpoints listed in public catalogs, over 8 months. The results show that we can collect, as much as possible, important characteristics of the datasets depending on their availability and capacities. The resulting index captures the commonalities, variety and disparity in the offered content and services and it provides an important support to any application designed to query RDF datasets. © 2023 Elsevier B.V.",Final,All Open Access; Green Open Access
Tebaldi C.,"Tebaldi, Catherine (56997033600)",56997033600,Granola Nazis and the great reset,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175490859&doi=10.1075%2flcs.00036.teb&partnerID=40&md5=3e4089a25f9a43f5389a9feb934ee709,"This paper analyzes the naturalization of Nazism, through semiotic processes of enregisterment, circulation, and regimentation of the register “nature-tradition” associated with a characterological figure I term the Granola Nazi. Granola Nazi is assembled through a rhematized set of semiotic elements, images, practices and forms of talk, which have come to indicate socially typified personae – strong virile white farmers, traditional earthy homesteading moms – and the moral order they embody. Using linguistic anthropological and digital methods, this analysis draws on 885 Instagram accounts as well as linked data from YouTube and print media (i.e. cookbooks, diet advice), to explore how the worlds of far right neofolkish movement intersect with discourses of health and wellness, creating moralized discourses of “natural beauty” and “folk vitality” which naturalize far- right racial hierarchies. This is at once a co-option of discourses of health and environment, but also one which reveals the how the naturalization of Nazism is made possible by racism and sexism in long present in liberal talk about nature, beauty or wellness. © 2023 John Benjamins Publishing Company.",Final,
Wang T.; Shen B.; Zhong Y.,"Wang, Tao (56135273700); Shen, Bo (57051936000); Zhong, Yu (58249286000)",56135273700; 57051936000; 58249286000,SSKGE: a time-saving knowledge graph embedding framework based on structure enhancement and semantic guidance,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166678834&doi=10.1007%2fs10489-023-04896-8&partnerID=40&md5=d5c092926b3a57521b574347c44abaea,"In knowledge graph embedding, an attempt is made to embed the objective facts and relationships expressed in the form of triplets into multidimensional vector space, facilitating various applications, such as link prediction and question answering. Structure embedding models focus on the graph structure while the importance of language semantics in inferring similar entities and relations is ignored. Semantic embedding models use pretrained language models to learn entity and relation embeddings based on text information, but they do not fully exploit graph structures that reflect relation patterns and mapping attributes. Structure and semantic information in knowledge graphs represent different hierarchical properties that are indispensable for comprehensive knowledge representation. In this paper, we propose a general knowledge graph embedding framework named SSKGE, which considers both the graph structure and language semantics and learns these two complementary characteristics to integrate entity and relation representations. To compensate for semantic embedding approaches that ignore the graph structure, we first design a structure loss function to explicitly model the graph structure attributes. Second, we leverage a pretrained language model that has been fine-tuned by the structure loss to guide the structure embedding approaches in enhancing the semantic information they lack and obtaining universal knowledge representations. Specifically, guidance is provided by a distance function that makes the spatial distribution of the two types of graph embeddings have a certain similarity. SSKGE significantly reduces the time cost of using a pretrained language model to complete a knowledge graph. Common knowledge graph embedding models such as TransE, DistMult, ComplEx, RotatE, PairRE, and HousE have achieved better results with multiple datasets, including FB15k, FB15k-237, WN18, and WN18RR, using the SSKGE framework. Extensive experiments and analyses have verified the effectiveness and practicality of SSKGE. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,
Fan L.; Lafia S.; Li L.; Yang F.; Hemphill L.,"Fan, Lizhou (57549267200); Lafia, Sara (57190124857); Li, Lingyao (57218382490); Yang, Fangyuan (58344987800); Hemphill, Libby (35772520500)",57549267200; 57190124857; 57218382490; 58344987800; 35772520500,DataChat: Prototyping a Conversational Agent for Dataset Search and Visualization,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174518185&doi=10.1002%2fpra2.820&partnerID=40&md5=f76c4aba8ca96fb51a32be437f0f7799,"Data users need relevant context and research expertise to effectively search for and identify relevant datasets. Leading data providers, such as the Inter-university Consortium for Political and Social Research (ICPSR), offer standardized metadata and search tools to support data search. Metadata standards emphasize the machine-readability of data and its documentation. There are opportunities to enhance dataset search by improving users' ability to learn about, and make sense of, information about data. Prior research has shown that context and expertise are two main barriers users face in effectively searching for, evaluating, and deciding whether to reuse data. In this paper, we propose a novel chatbot-based search system, DataChat, that leverages a graph database and a large language model to provide novel ways for users to interact with and search for research data. DataChat complements data archives' and institutional repositories' ongoing efforts to curate, preserve, and share research data for reuse by making it easier for users to explore and learn about available research data.  Annual Meeting of the Association for Information Science & Technology | Oct. 27 – 31, 2023 | London, United Kingdom. Author(s) retain copyright, but ASIS&T receives an exclusive publication license.",Final,All Open Access; Green Open Access
Dong X.L.; Moon S.; Xu Y.E.; Malik K.; Yu Z.,"Dong, Xin Luna (55800289000); Moon, Seungwhan (57216616433); Xu, Yifan Ethan (57216202489); Malik, Kshitiz (57225354727); Yu, Zhou (57205750897)",55800289000; 57216616433; 57216202489; 57225354727; 57205750897,Towards Next-Generation Intelligent Assistants Leveraging LLM Techniques,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171379652&doi=10.1145%2f3580305.3599572&partnerID=40&md5=90f11a7b4c098b19ed719d98e734f91e,"Virtual Intelligent Assistants take user requests in the voice form, perform actions such as setting an alarm, turning on a light, and answering a question, and provide answers or confirmations in the voice form or through other channels such as a screen. Assistants have become prevalent in the past decade, and users have been taking services from assistants like Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana. The emergence of AR/VR devices raised many new challenges for building intelligent assistants. The unique requirements have inspired new research directions such as (a) understanding users' situated multi-modal contexts (e.g. vision, sensor signals) as well as language-oriented conversational contexts, (b) personalizing the assistant services by grounding interactions on growing public and personal knowledge graphs and online search engines, and (c) on- device model inference and training techniques that satisfy strict resource and privacy constraints. In this tutorial, we will provide an in-depth walk-through of techniques in the afore-mentioned areas in the recent literature. We aim to introduce techniques for researchers and practitioners who are building intelligent assistants, and inspire research that will bring us one step closer to realizing the dream of building an all-day accompanying assistant. Additionally, we will highlight the significant role that Large Language Models (LLMs) play in enhancing these strategies, underscoring their potential to reshape the future landscape of intelligent assistance.  © 2023 Owner/Author.",Final,
Wawrzik F.; Rafique K.A.; Rahman F.; Grimm C.,"Wawrzik, Frank (56811646200); Rafique, Khushnood Adil (57835699600); Rahman, Farin (58581447400); Grimm, Christoph (35247954100)",56811646200; 57835699600; 58581447400; 35247954100,Ontology Learning Applications of Knowledge Base Construction for Microelectronic Systems Information,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151097377&doi=10.3390%2finfo14030176&partnerID=40&md5=2a2a2ea1ec00e5f38c4e81c206f806fc,"Knowledge base construction (KBC) using AI has been one of the key goals of this highly popular technology since its emergence, as it helps to comprehend everything, including relations, around us. The construction of knowledge bases can summarize a piece of text in a machine-processable and understandable way. This can prove to be valuable and assistive to knowledge engineers. In this paper, we present the application of natural language processing in the construction of knowledge bases. We demonstrate how a trained bidirectional long short-term memory or bi-LSTM neural network model can be used to construct knowledge bases in accordance with the exact ISO26262 definitions as defined in the GENIAL! Basic Ontology. We provide the system with an electronic text document from the microelectronics domain and the system attempts to create a knowledge base from the available information in textual format. This information is then expressed in the form of graphs when queried by the user. This method of information retrieval presents the user with a much more technical and comprehensive understanding of an expert piece of text. This is achieved by applying the process of named entity recognition (NER) for knowledge extraction. This paper provides a result report of the current status of our knowledge construction process and knowledge base content, as well as describes our challenges and experiences. © 2023 by the authors.",Final,All Open Access; Gold Open Access
Liu Q.; Zhang L.; Ren G.; Zou B.,"Liu, Qingping (58604585800); Zhang, Lunlun (58604585900); Ren, Gao (58604905800); Zou, Beiji (8553584700)",58604585800; 58604585900; 58604905800; 8553584700,Research on named entity recognition of Traditional Chinese Medicine chest discomfort cases incorporating domain vocabulary features,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171625175&doi=10.1016%2fj.compbiomed.2023.107466&partnerID=40&md5=fdd243e0b0921709fc1d58dcfae4299f,"Objective: To promote research on knowledge extraction and knowledge graph construction of chest discomfort medical cases in Traditional Chinese Medicine (TCM), this paper focuses on their named entity recognition (NER). The recognition task includes six entity types: “syndrome”, “symptom”, “etiology and pathogenesis”, “treatment method”, “medication”, and “prescription”. Methods: We annotated data in a BIO (B-begin, I-inside, O-outside) manner. For the characteristics of medical case texts, we proposed a custom dictionary method that can be dynamically updated for word segmentation. To compare the effect of the method on the experimental results, we applied the method in the BiLSTM-CRF model and IDCNN-CRF model, respectively. Results: The models using custom dictionaries (BiLSTM-CRF-Loaded and IDCNN-CRF-Loaded) outperformed the models without custom dictionaries (BiLSTM-CRF and IDCNN-CRF) in accuracy, precision, recall, and F1 score. The BiLSTM-CRF-Loaded model yielded F1 scores of 92.59% and 93.23% on the test set and validation set, respectively, surpassing the BERT-BiLSTM-CRF model by 3.59% and 4.87%. Furthermore, when analyzing the results for the six entity categories separately, we found that the use of custom dictionaries has a marked impact, with the categories of “etiology and pathogenesis” and “syndrome” demonstrating the most noticeable improvements. By comparing the F1 scores, we observed that the entity category “medication” yielded the highest performance, reaching F1 scores of 96.04% and 96.48% on the test set and validation set, respectively. Conclusion: We propose a word segmentation method based on a dynamically updated custom dictionary. The method is combined with the BILSTM-CRF and the IDCNN-CRF models, which enhances the model to recognize domain-specific terms and new entities. It can be widely applied in dealing with complex text structures and texts containing domain-specific terms. © 2023 The Author(s)",Final,All Open Access; Hybrid Gold Open Access
Sekar A.; Chakraborti S.,"Sekar, Anbarasu (57193892915); Chakraborti, Sutanu (24831430300)",57193892915; 24831430300,Modeling Tradeoffs Using Preference-Based Feedback in Session-Based Recommender Systems,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140795105&doi=10.1109%2fTAI.2022.3214801&partnerID=40&md5=ecd63c0819a9bff6ead4baab6d07ae47,"Cold-start is a challenge in most data-driven approaches across various paradigms of recommender systems research. Knowledge integration is becoming essential to alleviate the problem. Despite the availability of knowledge representations like the knowledge graph, there is a need for a richer semantic model to capture relationships among products in a domain. Recommender systems inspired by case-based reasoning uses rich domain knowledge in their recommendation process. Conversational case-based reasoning recommender systems (CCBR-RS) are session-based recommender systems that operate under cold-start assumptions. User preferences in such scenarios can only be learned based on the context of the current session. Tradeoffs have been used in literature to model the relationship among products in recommending appropriate products. The models in earlier works have been based on crisp sets, which lack flexibility in capturing varying degrees of tradeoffs, which is a more natural way of dealing with tradeoffs. This work proposes a flexible tradeoff representation scheme based on fuzzy sets to model tradeoffs in terms of linguistic terms and a fuzzy inference system that measures the similarity among tradeoffs represented in linguistic terms. We demonstrate the performance improvement in utilizing a more flexible model of tradeoffs by evaluating the methods on three datasets in a CCBR-RS framework.  © 2020 IEEE.",Final,
Chiarcos C.; Silvano P.; Damova M.; Oleškeviciene G.V.; Liebeskind C.; Trajanov D.; Truică C.-O.; Apostol E.-S.; Bączkowska A.,"Chiarcos, Christian (22333764800); Silvano, Purificação (55453450500); Damova, Mariana (36615168000); Oleškeviciene, Giedre Valunaite (57194015310); Liebeskind, Chaya (55761687500); Trajanov, Dimitar (8206057700); Truică, Ciprian-Octavian (56331462000); Apostol, Elena-Simona (55365937600); Bączkowska, Anna (57197523089)",22333764800; 55453450500; 36615168000; 57194015310; 55761687500; 8206057700; 56331462000; 55365937600; 57197523089,"Building an OWL-Ontology for Representing, Linking and Querying SemAF Discourse Annotations; [Izrada OWL ontologije za prikaz, povezivanje i pretraživanje SemAF diskursnih oznaka]",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177056570&doi=10.31724%2frihjj.49.1.6&partnerID=40&md5=4c397a60df12a842eea493028d2ecefc,"Linguistic Linked Open Data (LLOD) are technologies that provide a powerful instrument for representing and interpreting language phenomena on a web-scale. The main objective of this paper is to demonstrate how LLOD technologies can be applied to represent and annotate a corpus composed of multiword discourse markers, and what the effects of this are. In particular, it is our aim to apply semantic web standards such as RDF and OWL for publishing and integrating data. We present a novel scheme for discourse annotation that combines ISO standards describing discourse relations and dialogue acts – ISO DR-Core (ISO 24617-8) and ISO-Dialogue Acts (ISO 24617-2) in 9 languages (cf. Silvano and Damova 2022; Silvano et al. 2022). We develop an OWL ontology to formalize that scheme, provide a newly annotated dataset and link its RDF edition with the ontology. Consequently, we describe the conjoint querying of the ontology and the annotations by means of SPARQL, the standard query language for the web of data. The ultimate result is that we are able to perform queries over multiple, interlinked datasets with complex internal structure. This is a first, but essential step, in developing novel, powerful, and groundbreaking means for the corpus-based study of multilingual discourse, communication analysis, or attitudes discovery. © 2023, Institute of Croatian Language and Linguistics. All rights reserved.",Final,All Open Access; Gold Open Access
Taunk D.; Khanna L.; Kandru S.V.P.K.; Varma V.; Sharma C.; Tapaswi M.,"Taunk, Dhaval (57867271200); Khanna, Lakshya (58161432300); Kandru, Siri Venkata Pavan Kumar (58259141600); Varma, Vasudeva (16053729400); Sharma, Charu (56508977400); Tapaswi, Makarand (26637560200)",57867271200; 58161432300; 58259141600; 16053729400; 56508977400; 26637560200,GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159637178&doi=10.1145%2f3543873.3587651&partnerID=40&md5=34edc684b7665c4b026d5fd02500e7ed,"Commonsense question-answering (QA) methods combine the power of pre-trained Language Models (LM) with the reasoning provided by Knowledge Graphs (KG). A typical approach collects nodes relevant to the QA pair from a KG to form a Working Graph (WG) followed by reasoning using Graph Neural Networks (GNNs). This faces two major challenges: (i) it is difficult to capture all the information from the QA in the WG, and (ii) the WG contains some irrelevant nodes from the KG. To address these, we propose GrapeQA with two simple improvements on the WG: (i) Prominent Entities for Graph Augmentation identifies relevant text chunks from the QA pair and augments the WG with corresponding latent representations from the LM, and (ii) Context-Aware Node Pruning removes nodes that are less relevant to the QA pair. We evaluate our results on OpenBookQA, CommonsenseQA and MedQA-USMLE and see that GrapeQA shows consistent improvements over its LM + KG predecessor (QA-GNN in particular) and large improvements on OpenBookQA.  © 2023 ACM.",Final,All Open Access; Green Open Access
Chuang Y.-N.; Wang G.; Chang C.-Y.; Lai K.-H.; Zha D.; Tang R.; Yang F.; Reyes A.C.; Zhou K.; Jiang X.; Hu X.,"Chuang, Yu-Neng (57766024000); Wang, Guanchu (57201529169); Chang, Chia-Yuan (57732728000); Lai, Kwei-Herng (57206726892); Zha, Daochen (56579935400); Tang, Ruixiang (57218847353); Yang, Fan (57209528035); Reyes, Alfredo Costilla (58621487800); Zhou, Kaixiong (57194203961); Jiang, Xiaoqian (24479530900); Hu, Xia (35114937200)",57766024000; 57201529169; 57732728000; 57206726892; 56579935400; 57218847353; 57209528035; 58621487800; 57194203961; 24479530900; 35114937200,DiscoverPath: A Knowledge Refinement and Retrieval System for Interdisciplinarity on Biomedical Research,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178144147&doi=10.1145%2f3583780.3614739&partnerID=40&md5=9cdccf5c107f852f82526d20b86736c3,"The exponential growth in scholarly publications necessitates advanced tools for efficient article retrieval, especially in interdisciplinary fields where diverse terminologies are used to describe similar research. Traditional keyword-based search engines often fall short in assisting users who may not be familiar with specific terminologies. To address this, we present a knowledge graph based paper search engine for biomedical research to enhance the user experience in discovering relevant queries and articles. The system, dubbed DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS) tagging to extract terminologies and relationships from article abstracts to create a KG. To reduce information overload, DiscoverPath presents users with a focused subgraph containing the queried entity and its neighboring nodes and incorporates a query recommendation system enabling users to iteratively refine their queries. The system is equipped with an accessible Graphical User Interface that provides an intuitive visualization of the KG, query recommendations, and detailed article information, enabling efficient article retrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath is open-sourced at https://github.com/ynchuang/DiscoverPath with an online demo at discoverpath.top and a video at Youtube. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,All Open Access; Green Open Access
Rawsthorne H.M.; Abadie N.; Kergosien E.; Duchêne C.; Saux E.,"Rawsthorne, Helen Mair (57977002100); Abadie, Nathalie (55453960900); Kergosien, Eric (55625321100); Duchêne, Cécile (6602190150); Saux, Éric (6603279144)",57977002100; 55453960900; 55625321100; 6602190150; 6603279144,Automatic Nested Spatial Entity and Spatial Relation Extraction From Text for Knowledge Graph Creation: A Baseline Approach and a Benchmark Dataset,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180129015&doi=10.1145%2f3615887.3627754&partnerID=40&md5=37f7fdae7d1b57dfce6806c47854b8f3,"Automatically extracting geographic information from text is the key to harnessing the vast amount of spatial knowledge that only exists in this unstructured form. The fundamental elements of spatial knowledge include spatial entities, their types and the spatial relations between them. Structuring the spatial knowledge contained within text as a geospatial knowledge graph, and disambiguating the spatial entities, significantly facilitates its reuse. The automatic extraction of geographic information from text also allows the creation or enrichment of gazetteers. We propose a baseline approach for nested spatial entity and binary spatial relation extraction from text, a new annotated French-language benchmark dataset on the maritime domain that can be used to train algorithms for both extraction tasks, and benchmark results for the two tasks carried out individually and end-to-end. Our approach involves applying the Princeton University Relation Extraction system (PURE), made for flat, generic entity extraction and generic binary relation extraction, to the extraction of nested, spatial entities and spatial binary relations. By extracting nested spatial entities and the spatial relations between them, we have more information to aid entity disambiguation. In our experiments we compare the performance of a pretrained monolingual French BERT language model with that of a pretrained multilingual BERT language model, and study the effect of including cross-sentence context. Our results reveal very similar results for both models, although the multilingual model performs slightly better in entity extraction, and the monolingual model has slightly better relation extraction and end-to-end performances. We observe that increasing the amount of cross-sentence context improves the results for entity extraction whereas it has the opposite effect on relation extraction.  © 2023 ACM.",Final,
Chakraborty C.; Wan S.; Khosravi M.R.,"Chakraborty, Chinmay (7005340424); Wan, Shaohua (35190004700); Khosravi, Mohammad R. (57189501555)",7005340424; 35190004700; 57189501555,Editorial: Ontology-based Knowledge Presentation and Computational Linguistics for Semantic Big Social Data Analytics in Asian Social Networks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162181474&doi=10.1145%2f3594719&partnerID=40&md5=d4cfc689af9f40dd960260f2ff644c19,"Data-driven ontology-based knowledge (OK) presentation and computational linguistics for evolving semantic Asian social networks (ASNs) can make one of the most important platforms that provide robust and real-time data mapping in massive access across the heterogeneous big data sources in the web that is named OK-ASN. It benefits from computational intelligence, web-of-things (WoT) architecture, semantic features, statistical learning and pattern recognition, database management, computer vision, cyber-security, and language processing. OK-ASN is a critical strategy for WoT big data mining and enterprises from social media to medical and industrial sectors.  © 2023 Copyright held by the owner/author(s).",Final,
Lehmann J.; Gattogi P.; Bhandiwad D.; Ferré S.; Vahdati S.,"Lehmann, Jens (35229806900); Gattogi, Preetam (58682826600); Bhandiwad, Dhananjay (58682137000); Ferré, Sébastien (8974579900); Vahdati, Sahar (56204337200)",35229806900; 58682826600; 58682137000; 8974579900; 56204337200,Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175792468&doi=10.3233%2fFAIA230411&partnerID=40&md5=65f6a98a35646164cc55e51d710f465d,"We propose the use of controlled natural language as a target for knowledge graph question answering (KGQA) semantic parsing via language models as opposed to using formal query languages directly. Controlled natural languages are close to (human) natural languages, but can be unambiguously translated into a formal language such as SPARQL. Our research hypothesis is that the pre-training of large language models (LLMs) on vast amounts of textual data leads to the ability to parse into controlled natural language for KGQA with limited training data requirements. We devise an LLM-specific approach for semantic parsing to study this hypothesis. To conduct our study, we created a dataset that allows the comparison of one formal and two different controlled natural languages. Our analysis shows that training data requirements are indeed substantially reduced when using controlled natural languages, which is relevant since collecting and maintaining high-quality KGQA semantic parsing training data is very expensive and time-consuming. © 2023 The Authors.",Final,All Open Access; Hybrid Gold Open Access
Feng J.; Tao C.; Shen T.; Liu C.; Zhao D.,"Feng, Jiazhan (57216614370); Tao, Chongyang (57204468075); Shen, Tao (57210531549); Liu, Chang (57221259090); Zhao, Dongyan (55387416000)",57216614370; 57204468075; 57210531549; 57221259090; 55387416000,Dimension-Prompts Boost Commonsense Consolidation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168695263&doi=10.1145%2f3539618.3591973&partnerID=40&md5=f1bdffef4fcb5fdb6cec679d8479449f,"Neural knowledge models emerged and advanced common-sense-centric knowledge grounding. They parameterize a small seed curated commonsense knowledge graph (CS-KG) in a language model to generalize more. A current trend is to scale the seed up by directly mixing multiple sources of CS-KG (e.g., ATOMIC, ConceptNet) into one model. But, such brute-force mixing inevitably hinders effective knowledge consolidation due to i) ambiguous, polysemic, and/or inconsistent relations across sources and ii) knowledge learned in an entangled manner despite distinct types (e.g., causal, temporal). To mitigate this, we adopt a concept of commonsense knowledge dimension and propose a brand-new dimension-disentangled knowledge model (D2KM) learning paradigm with multiple sources. That is, a generative language model with dimension-specific soft prompts is trained to disentangle knowledge acquisitions along with different dimensions and facilitate potential intra-dimension consolidation across CS-KG sources. Experiments show our knowledge model outperforms its baselines in both standard and zero-shot scenarios. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Final,
Sivakumar N.; Srinivasan P.; Kannan M.; Vijayalakshmi P.; Nagarajan T.,"Sivakumar, Nethraa (57670990800); Srinivasan, Pooja (58166178100); Kannan, Mrinalini (57425962600); Vijayalakshmi, P. (9269557900); Nagarajan, T. (57191859542)",57670990800; 58166178100; 57425962600; 9269557900; 57191859542,PooRaa-Agri KG: An agricultural knowledge graph-based simplified multilingual query system,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169140315&doi=10.1111%2fexsy.13434&partnerID=40&md5=2cbf288bc8851d071fd2a365abcd4187,"The current work proposes PooRaa-Agri KG, an agricultural knowledge graph-based simplified multilingual query system that works in real time to provide concise answers for agriculture-based queries. The proposed approach accommodates real-time and low-resource queries in English and Hindi with a novel multi-stage solution consisting of data pre-processing, sentence simplification, triplet extraction, knowledge graph generation, sentence reconstruction, query-to-reconstructed sentence matching, and machine translation as its sub-modules. In this work, a novel combination of rule-based sentence simplification and triplet extraction is carried out resulting in a triplet similarity score of 86.56% for the extracted triplets. This method is superior to the existing triplet extraction method whose triplet similarity score was found to be 60.65%. Further, the proposed work makes use of heuristic rules to reconstruct sentences which when evaluated by human evaluators for meaningfulness and grammar resulted in a score of 3.09/4 and 2.95/4 respectively. To complete end-to-end communication in the proposed system, a similarity-based query answer system is proposed in this work. © 2023 John Wiley & Sons Ltd.",Final,
Li D.; Zhu B.; Yang S.; Xu K.; Yi M.; He Y.; Wang H.,"Li, Da (57421478700); Zhu, Boqing (57204110244); Yang, Sen (57188971330); Xu, Kele (56413567000); Yi, Ming (57421588000); He, Yukai (57753518700); Wang, Huaimin (15838322600)",57421478700; 57204110244; 57188971330; 56413567000; 57421588000; 57753518700; 15838322600,Multi-task Pre-training Language Model for Semantic Network Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179131594&doi=10.1145%2f3627704&partnerID=40&md5=9ba5db82e76dc9fee84090e699296b97,"Semantic networks, exemplified by the knowledge graph, serve as a means to represent knowledge by leveraging the structure of a graph. While the knowledge graph exhibits promising potential in the field of natural language processing, it suffers from incompleteness. This article focuses on the task of completing knowledge graphs by predicting linkages between entities, which is fundamental yet critical. Traditional methods based on translational distance struggle when dealing with unseen entities. In contrast, semantic matching presents itself as a potential solution due to its ability to handle such cases. However, semantic matching-based approaches necessitate large-scale datasets for effective training, which are typically unavailable in practical scenarios, hindering their competitive performance. To address this challenge, we propose a novel architecture for knowledge graphs known as LP-BERT, which incorporates a language model. LP-BERT consists of two primary stages: multi-task pre-training and knowledge graph fine-tuning. During the pre-training phase, the model acquires relationship information from triples by predicting either entities or relations through three distinct tasks. In the fine-tuning phase, we introduce a batch-based triple-style negative sampling technique inspired by contrastive learning. This method significantly increases the proportion of negative sampling while maintaining a nearly unchanged training time. Furthermore, we propose a novel data augmentation approach that leverages the inverse relationship of triples to enhance both the performance and robustness of the model. To demonstrate the effectiveness of our proposed framework, we conduct extensive experiments on three widely used knowledge graph datasets: WN18RR, FB15k-237, and UMLS. The experimental results showcase the superiority of our methods, with LP-BERT achieving state-of-the-art performance on the WN18RR and FB15k-237 datasets.  © 2023 held by the owner/author(s). Publication rights licensed to ACM.",Final,All Open Access; Green Open Access
Wei Y.; Huang Q.; Zhang Y.; Kwok J.T.,"Wei, Yanbin (58846644100); Huang, Qiushi (57226336495); Zhang, Yu (55740056300); Kwok, James T. (58883124300)",58846644100; 57226336495; 55740056300; 58883124300,KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183311284&partnerID=40&md5=879a60839ce7bc963a3ce78363db489e,"Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC. They can be categorized into two main classes: triple-based and text-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced entity distributions. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate these limitations, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever. It alleviates the long-tail problem without incurring additional training overhead. KICGPT uses an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide the LLM. Empirical results on benchmark datasets demonstrate the effectiveness of KICGPT with smaller training overhead and no finetuning. © 2023 Association for Computational Linguistics.",Final,
Naseem U.; Thapa S.; Zhang Q.; Hu L.; Masood A.; Nasim M.,"Naseem, Usman (57212385431); Thapa, Surendrabikram (57218940311); Zhang, Qi (57199111398); Hu, Liang (57188765841); Masood, Anum (57213374479); Nasim, Mehwish (35795750500)",57212385431; 57218940311; 57199111398; 57188765841; 57213374479; 35795750500,Reducing Knowledge Noise for Improved Semantic Analysis in Biomedical Natural Language Processing Applications,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175429068&partnerID=40&md5=1ad8578ccd3103b410f7fec5f5c87822,"Graph-based techniques have gained traction for representing and analyzing data in various natural language processing (NLP) tasks. Knowledge graph-based language representation models have shown promising results in leveraging domain-specific knowledge for NLP tasks, particularly in the biomedical NLP field. However, such models have limitations, including knowledge noise and neglect of contextual relationships, leading to potential semantic errors and reduced accuracy. To address these issues, this paper proposes two novel methods. The first method combines knowledge graphbased language model with nearest-neighbor models to incorporate semantic and category information from neighboring instances. The second method involves integrating knowledge graph-based language model with graph neural networks (GNNs) to leverage feature information from neighboring nodes in the graph. Experiments on relation extraction (RE) and classification tasks in English and Chinese language datasets demonstrate significant performance improvements with both methods, highlighting their potential for enhancing the performance of language models and improving NLP applications in the biomedical domain.  © 2023 Association for Computational Linguistics.",Final,
Frey J.; Meyer L.-P.; Arndt N.; Brei F.; Bulert K.,"Frey, Johannes (57201725937); Meyer, Lars-Peter (56103867800); Arndt, Natanael (42461015000); Brei, Felix (58621475600); Bulert, Kirill (56584463500)",57201725937; 56103867800; 42461015000; 58621475600; 56584463500,Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596343&partnerID=40&md5=e04931624848f328aa2c4965169f67e2,"Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within RDF knowledge graph engineering workflows utilizing Turtle representation. While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context. © 2023 Copyright for this paper by its authors.",Final,
Liu Y.; Zhang J.; Hu F.; Li T.; Wang Z.,"Liu, Yibo (57217315826); Zhang, Jian (58748701900); Hu, Fanghuai (53363727500); Li, Taowei (58064856300); Wang, Zhaolei (58698443700)",57217315826; 58748701900; 53363727500; 58064856300; 58698443700,A Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176916152&doi=10.1007%2f978-981-99-7224-1_27&partnerID=40&md5=4bc6b156789c8b7211965b8047dfbc0f,"With the rise of big language model technology, the application of big models in the military field is increasingly being valued. How to combine big language models with knowledge graph technology to improve the effectiveness of knowledge Q&A is currently a key research direction for improving military knowledge services. Based on the big language model technology, this paper implements knowledge Q&A in the military field by using template learning and template matching methods. For the key steps of knowledge linking and template matching, this paper uses the knowledge linking and semantic matching technology enhanced by the big language model. Finally, experimental verification was conducted in the test set provided by the CCKS (China Conference on Knowledge Graph and Semantic Computing) conference, and F1 reached 0.869. In summary, this paper provides a new solution for natural language Q&A in the military field using a large language model. This method achieves high accuracy while reducing dependence on training corpus data. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Yu S.; Huang T.; Liu M.; Wang Z.,"Yu, Shuang (57218824197); Huang, Tao (58732362200); Liu, Mingyi (57208466945); Wang, Zhongjie (14009001300)",57218824197; 58732362200; 57208466945; 14009001300,BEAR: Revolutionizing Service Domain Knowledge Graph Construction with LLM,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178217581&doi=10.1007%2f978-3-031-48421-6_23&partnerID=40&md5=9b4d7b798f33cf50d88b98d1d42b0663,"Knowledge graph (KG), as a novel knowledge storage approach, has been widely used in various domains. In the service computing community, researchers tried to harness the enormous potential of KG to tackle domain-specific tasks. However, the lack of an openly available service domain KG limits the in-depth exploration of KGs in domain-specific applications. Building a service domain KG primarily faces two challenges: first, the diversity and complexity of service domain knowledge, and second, the dispersion of domain knowledge and the lack of annotated data. These challenges discouraged costly investment in large, high-quality domain-specific KGs by researchers. In this paper, we present the construction of a service domain KG called BEAR. We design a comprehensive service domain knowledge ontology to automatically generate the prompts for the Large Language Model (LLM) and employ LLM to implement a zero-shot method to extract high-quality knowledge. A series of experiments are conducted to demonstrate the feasibility of graph construction process and showcase the richness of content available from BEAR. Currently, BEAR includes 133, 906 nodes, 169, 159 relations, and about 424, 000 factual knowledge as attributes, which is available through github.com/HTXone/BEAR. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Gupta R.; Srinivasa S.,"Gupta, Rajeev (57214908904); Srinivasa, Srinath (6602084314)",57214908904; 6602084314,Workshop on Enterprise Knowledge Graphs using Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177552958&partnerID=40&md5=7dcc29452ef0615d132885bad768ccc4,"Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types—static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving –information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., – is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes—whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175420251&partnerID=40&md5=d3481577748387760fc6c19a0c97f0db,The proceedings contain 12 papers. The topics discussed include: knowledge graph-augmented language models for complex question answering; exploring the curious case of code prompts; a smashed glass cannot be full: generation of commonsense explanations through prompt-based few-shot learning; saliency map verbalization: comparing feature importance representations from model-free and instruction-based methods; using planning to improve semantic parsing of instructional texts; reasoning circuits: few-shot multi-hop question generation with structured rationales; knowledge-augmented language model prompting for zero-shot knowledge graph question answering; can in-context learners learn a reasoning concept from demonstrations?; effect graph: effect relation extraction for explanation generation; and OPT-R: exploring the role of explanations in finetuning and prompting for reasoning skills of large language models.,Final,
,,,"3rd International Conference on Artificial Intelligence Logic and Applications, AILA 2023",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177873945&partnerID=40&md5=216b25bf97b84a148407676448fc2c08,The proceedings contain 36 papers. The special focus in this conference is on Artificial Intelligence Logic and Applications. The topics include: An Abstraction Neural Network Generator for Efficient Formal Verification; a Fault Diagnosis Method of Discrete Event System Based on Binary Decision Diagram; Comparison and Implementation of ROS-Based SLAM and Path Planning Methods; a Diagnostic Model Generation Method Based on Clustering; a Heterogeneous Multicore Co-scheduling Algorithm Based on Multi-characteristic Fuzzy Cluster; conceptual Clustering Based on Linguistic-Valued Layered Concept Lattice; clause and Literal Selection Strategies Based on Complementary Pair Distribution for Contradiction Separation Deduction; an Improved Genetic Programming Based Factor Construction for Stock Price Prediction; dual Channel Graph Neural Network for Fraud Detection; non-negative Matrix Factorization Method Based on Mixed Gaussian Kernels; satisfiability Verification of Integrity Constraints for Spatial Linked Data; Direct Limits of EMV-Algebras; weighted Consistent Multi-view Discriminant Analysis in Unreliable Labeling Environment; nonlinear Manifold Learning via Graph Curvature; cross-Lingual Entity Alignment via Two-Hop Neighbour Sampling and Distinguishable Relation Embedding; GRU-Attention Interpretable Knowledge Tracking Model with Forgetting Law for Intelligent Education System; a Multi-Label Feature Selection Method Based on Label Granulation; regularized Loose Coupled Deep Non-negative Basis Matrix Factorization for Low-Resolution Face Image Recognition; CDFSIP Feature Selection Algorithm Based on ADA-DPC; person Re-identification Based on Fusion of Shared Feature Branches; granular Computing Measures for the Classical Formal Concepts and Intuitionistic Fuzzy Formal Concepts; fine-Grained Mushroom Image Classification by Resnet Combined with Attention Mechanism; link Prediction Based on Pairwise Proximity Preserving Graph Neural Networks; hierarchical Time Series Forecasting Based on Temporal Convolution and Attention Mechanism; CKKP: Chinese-Korean Text Classification via Knowledge Base and Prompt Learning.,Final,
Liu A.; Wang B.; Tan Y.; Zhao D.; Huang K.; He R.; Hou Y.,"Liu, Anqi (58676090200); Wang, Bo (56949454300); Tan, Yue (58506099900); Zhao, Dongming (7403490494); Huang, Kun (57614133600); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",58676090200; 56949454300; 58506099900; 7403490494; 57614133600; 19835197000; 7402198932,MTGP: Multi-turn Target-oriented Dialogue Guided by Generative Global Path with Flexible Turns,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175443764&partnerID=40&md5=ca8959923d56f43e648dc2428fddd644,"Target-oriented dialogue guides the dialogue to a target quickly and smoothly. The latest approaches focus on global planning, which plans toward the target before the conversation instead of adopting a greedy strategy during the conversation. However, the global plan in existing works is fixed to certain turns by generating paths with certain nodes, which limits the optimization of turns and coherence of the target-oriented process. Toward flexible global planning, we propose to generate a global path as a natural language sentence instead of a sequence of nodes. With this path, the dialog is guided to the target with flexible turns of dialog. For model training, we also extract target-oriented dialogues from the chit-chat corpus with a knowledge graph. We conduct experiments on three datasets and simulate scenarios with and without user participation. The results show that our method has fewer turns, more coherent semantics, and a higher success rate in reaching the target than baselines. © 2023 Association for Computational Linguistics.",Final,
Wold S.; Øvrelid L.; Velldal E.,"Wold, Sondre (57933865400); Øvrelid, Lilja (52864533500); Velldal, Erik (49964845000)",57933865400; 52864533500; 49964845000,Text-To-KG Alignment: Comparing Current Methods on Classification Tasks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175400756&partnerID=40&md5=951292112a161488476b1bf0337cd36e,"In contrast to large text corpora, knowledge graphs (KG) provide dense and structured representations of factual information. This makes them attractive for systems that supplement or ground the knowledge found in pre-trained language models with an external knowledge source. This has especially been the case for classification tasks, where recent work has focused on creating pipeline models that retrieve information from KGs like ConceptNet as additional context. Many of these models consist of multiple components, and although they differ in the number and nature of these parts, they all have in common that for some given text query, they attempt to identify and retrieve a relevant subgraph from the KG. Due to the noise and idiosyncrasies often found in KGs, it is not known how current methods compare to a scenario where the aligned subgraph is completely relevant to the query. In this work, we try to bridge this knowledge gap by reviewing current approaches to text-to-KG alignment and evaluating them on two datasets where manually created graphs are available, providing insights into the effectiveness of current methods. We release our code for reproducibility.  © 2023 Association for Computational Linguistics.",Final,
Xiao L.; Zhang R.; Chen Z.; Chen J.,"Xiao, Likang (58655822100); Zhang, Richong (23669861200); Chen, Zijie (58655977800); Chen, Junfan (57214236442)",58655822100; 23669861200; 58655977800; 57214236442,Tucker Decomposition with Frequency Attention for Temporal Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174495033&partnerID=40&md5=04c66aa345a994677ead042e20e95295,"Temporal Knowledge Graph Completion aims to complete missing entities or relations under temporal constraints. Previous tensor decomposition-based models for TKGC only independently consider the combination of one single relation with one single timestamp, ignoring the global nature of the embedding. We propose a Frequency Attention (FA) model to capture the global temporal dependencies between one relation and the entire timestamp. Specifically, we use Discrete Cosine Transform (DCT) to capture the frequency of the timestamp embedding and further compute the frequency attention weight to scale embedding. Meanwhile, the previous temporal tucker decomposition method uses a simple norm regularization to constrain the core tensor, which limits the optimization performance. Thus, we propose Orthogonal Regularization (OR) variants for the core tensor, which can limit the non-superdiagonal elements of the 3-rd core tensor. Experiments on three standard TKGC datasets demonstrate that our method outperforms the state-of-the-art results on several metrics. The results suggest that the direct-current component is not the best feature for TKG representation learning. Additional analysis shows the effectiveness of our FA and OR models, even with smaller embedding dimensions. © 2023 Association for Computational Linguistics.",Final,
Misra K.; dos Santos C.N.; Shakeri S.,"Misra, Kanishka (57207312560); dos Santos, Cicero Nogueira (55665418300); Shakeri, Siamak (57207856389)",57207312560; 55665418300; 57207856389,Triggering Multi-Hop Reasoning for Question Answering in Language Models using Soft Prompts and Random Walks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175421299&partnerID=40&md5=a21daf4aa8e1b7b440851f4280cc5e43,"Despite readily memorizing world knowledge about entities, pre-trained language models (LMs) struggle to compose together two or more facts to perform multi-hop reasoning in question-answering tasks. In this work, we propose techniques that improve upon this limitation by relying on random walks over structured knowledge graphs. Specifically, we use soft prompts to guide LMs to chain together their encoded knowledge by learning to map multi-hop questions to random walk paths that lead to the answer. Applying our methods on two T5 LMs shows substantial improvements over standard tuning approaches in answering questions that require 2-hop reasoning. © 2023 Association for Computational Linguistics.",Final,
Xu W.; Liu B.; Peng M.; Jia X.; Peng M.,"Xu, Wenjie (57385295700); Liu, Ben (57937723800); Peng, Miao (57938314000); Jia, Xu (57286063600); Peng, Min (7202484705)",57385295700; 57937723800; 57938314000; 57286063600; 7202484705,Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175229573&partnerID=40&md5=95047250895593d6e6eb64fd9b1c6053,"Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models. The code of PPT is available at https://github.com/JaySaligia/PPT. © 2023 Association for Computational Linguistics.",Final,
Youn J.; Tagkopoulos I.,"Youn, Jason (57312221700); Tagkopoulos, Ilias (14025920800)",57312221700; 14025920800,KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175398242&partnerID=40&md5=33de752a15e729a5273132f2f2ade071,"The ability of knowledge graphs to represent complex relationships at scale has led to their adoption for various needs including knowledge representation, question-answering, and recommendation systems. Knowledge graphs are often incomplete in the information they represent, necessitating the need for knowledge graph completion tasks. Pre-trained and finetuned language models have shown promise in these tasks although these models ignore the intrinsic information encoded in the knowledge graph, namely the entity and relation types. In this work, we propose the Knowledge Graph Language Model (KGLM) architecture, where we introduce a new entity/relation embedding layer that learns to differentiate distinctive entity and relation types, therefore allowing the model to learn the structure of the knowledge graph. In this work, we show that further pretraining the language models with this additional embedding layer using the triples extracted from the knowledge graph, followed by the standard fine-tuning phase sets a new state-of-the-art performance for the link prediction task on the benchmark datasets. © 2023 Association for Computational Linguistics.",Final,
Chen Y.; Cui S.; Huang K.; Wang S.; Tang C.; Liu T.; Fang B.,"Chen, Yilong (55549619900); Cui, Shiyao (57219687444); Huang, Kun (58698728500); Wang, Shicheng (58161022900); Tang, Chuanyu (58698728600); Liu, Tingwen (35956637400); Fang, Binxing (58385170700)",55549619900; 57219687444; 58698728500; 58161022900; 58698728600; 35956637400; 58385170700,Improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176947983&doi=10.1007%2f978-981-99-7224-1_21&partnerID=40&md5=2d9e80284861c6c8d9d65311bfc04c8a,"Knowledge graph construction (KGC) aims to build the semantic network which expresses the relationship between named entities. Despite the success of prior studies, it is struggling to accommodate existing KGC models with evolving entity-relation knowledge schema. In this paper, we propose a schema-adaptive KGC method driven by the instruction-tuning large language models (LLM). We fine-tune a LLM with tailored KGC corpus, through which the generalization ability of LLMs are transfered for KGC with evolving schema. To alleviate the bias of a single LLM, we integrate the superiority of several expert models to derive credible results from multiple perspectives. We further boost KGC performances via an elaborately designed schema-constrained decoding strategy and a LLM-guided correction module. Experimental results validate the advantages of our proposed method. Besides, our method achieved the first place in the first task of CCKS-2023 Knowledge Graph Construction. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Salmas K.; Pantazi D.-A.; Koubarakis M.,"Salmas, Konstantinos (58759425600); Pantazi, Despina-Athanasia (57204938232); Koubarakis, Manolis (55872674100)",58759425600; 57204938232; 55872674100,Extracting Geographic Knowledge from Large Language Models: An Experiment,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546460&partnerID=40&md5=0fd90a6d6edc446515886a7202960882,"We perform an experimental analysis of how the inner architecture of large language models behaves whilst extracting geographic knowledge. Our aim is to conclude on whether models actually incorporate geospatial information or simply follow statistical patterns in the data; hence to contribute to the research area of creating knowledge graphs from large language models. To achieve this, we study one specific geospatial relation and explore different techniques that leverage the masked language modeling abilities of BERT and RoBERTa. Our study should be construed as a stepping stone to the general study of the ways large language models encapsulate geospatial knowledge. In addition, it has allowed us to observe important points one should focus on when querying language models, which we discuss in detail. © 2023 CEUR-WS. All rights reserved.",Final,
Markowitz E.S.; Galstyan A.,"Markowitz, Elan S. (57130686500); Galstyan, Aram (7003679856)",57130686500; 7003679856,StATIK+: Structure and Text for Inductive Knowledge Graph Modeling and Paths towards Enterprise Implementations,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177571183&partnerID=40&md5=58aed3de71133c386241f9588b93c273,"While many enterprise knowledge Graphs (KGs) are updated frequently, most KG models require retraining to incorporate these updates. Inductive models are able to adapt to new edges and entities in the KG. This extended abstract presents a prior work StATIK–Structure And Text for Inductive Knowledge Completion– and a roadmap towards industry implementations. StATIK uses a Language Model to extract the semantic information from text descriptions, while using Message Passing Neural Networks to capture the structural information in the graph. While StATIK was evaluated for inductive knowledge graph completion, many applications have different end tasks. This work provides background and a roadmap of some of the opportunities in applying StATIK to industry tasks. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Li S.; Gao Y.; Jiang H.; Yin Q.; Li Z.; Yan X.; Zhang C.; Yin B.,"Li, Shiyang (57214680329); Gao, Yifan (57211752080); Jiang, Haoming (57210643061); Yin, Qingyu (57462087800); Li, Zheng (57196124633); Yan, Xifeng (36083601600); Zhang, Chao (56192792200); Yin, Bing (57210637479)",57214680329; 57211752080; 57210643061; 57462087800; 57196124633; 36083601600; 56192792200; 57210637479,Graph Reasoning for Question Answering with Triplet Retrieval,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174784554&partnerID=40&md5=f93d6e420b37c436d147fa0bc66e6ed3,"Answering complex questions often requires reasoning over knowledge graphs (KGs). State-of-the-art methods often utilize entities in questions to retrieve local subgraphs, which are then fed into KG encoder, e.g. graph neural networks (GNNs), to model their local structures and integrated into language models for question answering. However, this paradigm constrains retrieved knowledge in local subgraphs and discards more diverse triplets buried in KGs that are disconnected but useful for question answering. In this paper, we propose a simple yet effective method to first retrieve the most relevant triplets from KGs and then rerank them, which are then concatenated with questions to be fed into language models. Extensive results on both CommonsenseQA and OpenbookQA datasets show that our method can outperform state-of-the-art up to 4.6% absolute accuracy. © 2023 Association for Computational Linguistics.",Final,
Feng G.; Zhu G.; Shi S.; Sun Y.; Fan Z.; Gao S.; Hu J.,"Feng, Guandong (58698728700); Zhu, Guoliang (58698603100); Shi, Shengze (58549273900); Sun, Yue (58106379100); Fan, Zhongyi (58698728900); Gao, Sulin (58697920900); Hu, Jun (57219759997)",58698728700; 58698603100; 58549273900; 58106379100; 58698728900; 58697920900; 57219759997,Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176966002&doi=10.1007%2f978-981-99-7224-1_25&partnerID=40&md5=4f7d467cbd1641549620e23d2d2dc46e,"Knowledge Base Question Answering (KBQA) is a significant task in natural language processing, aiming to retrieve answers from structured knowledge bases in response to natural language questions. NL2Cypher is crucial for accurately querying answers from knowledge bases, but there is limited research in this area or the results are unsatisfactory. Our work explores the convergence of advanced natural language processing techniques with knowledge base question answering (KBQA), focusing on the automated generation of Cypher queries from natural language queries. By leveraging the capabilities of large language model (LLM), our approach bridges the gap between textual questions and structured knowledge representations. The proposed methodology showcases promising results in accurately formulating Cypher queries. We achieved substantial performance in the CCKS2023 Foreign Military Unmanned Systems Knowledge Graph Reasoning Question-Answering Evaluation Task. Our method achieved an F1 score of 0.94269 on the final testing dataset. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Liu X.; Zhang K.; Liu Y.; Chen E.; Huang Z.; Yue L.; Yan J.,"Liu, Xukai (58676297000); Zhang, Kai (58376409600); Liu, Ye (57221998149); Chen, Enhong (35228685900); Huang, Zhenya (57192675168); Yue, Linan (57226475441); Yan, Jiaxian (57759744600)",58676297000; 58376409600; 57221998149; 35228685900; 57192675168; 57226475441; 57759744600,RHGN: Relation-gated Heterogeneous Graph Network for Entity Alignment in Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175456858&partnerID=40&md5=49d357d57a4f2b3496ff0f655ad9e168,"Entity Alignment, which aims to identify equivalent entities from various Knowledge Graphs (KGs), is a fundamental and crucial task in knowledge graph fusion. Existing methods typically use triples or neighbor information to represent entities, and then align those entities using similarity matching. Most of them, however, fail to account for the heterogeneity among KGs and the distinction between KG entities and relations. To better solve these problems, we propose a Relation-gated Heterogeneous Graph Network (RHGN) for entity alignment in knowledge graphs. Specifically, RHGN contains a relation-gated convolutional layer to distinguish relations and entities in the KG. In addition, RHGN adopts a cross-graph embedding exchange module and a soft relation alignment module to address the neighbor heterogeneity and relation heterogeneity between different KGs, respectively. Extensive experiments on four benchmark datasets demonstrate that RHGN is superior to existing state-of-the-art entity alignment methods. © 2023 Association for Computational Linguistics.",Final,
Mohanty A.,"Mohanty, Anurag (58706276200)",58706276200,EduEmbedd – A Knowledge Graph Embedding for Education,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177600940&partnerID=40&md5=57b001fdc0dc598036196e6031f0d44d,"Motivated by emerging strength of Knowledge graphs as an integrated information representation and repository that interlinks heterogeneous data from different domains and the growing adoption and application of artificial intelligence for various use-cases on education domain. We propose EduEmbedd, a framework to develop an Embedding (Knowledge Graph Embedding) for the education domain and demonstrate the usefulness of such embedding. We understand that in the emerging era of Large Language Model (LLMs), domain specific embeddings based on Knowledge Graph has the potential to aid the LLMs to overcome some of the most pressing challenges like hallucinations along with improving its interpretability. The knowledge held up in the education domain is an assimilation of information from multiple contexts. EduEmbedd leverages all these different contexts into one to learn an effective embedding which can be used for various upstream machine learning tasks. The heterogeneous data from different contexts is often related to each other. In order to derive value, the data should be integrated, structured and the relationships should be made explicit. Knowledge Graphs (KG) can play a key role in achieving these goals and gives us an opportunity to assimilate information from these multiple contexts into a single unified structure and semantic form. We also understand that several novel enhancements would be required on top of this base idea to ensure that we are able to deal with the nuances of the domain for which we are creating the embedding. EduEmbedd is a step towards this direction where we introduce a systematic framework to create an Embedding for the education domain by leveraging Knowledge Graph Embedding (KGE) approaches. We also demonstrate how these embeddings are useful in terms of its ability in representing the composite knowledge being held up in them along with the efficacy it brings to machine learning using this approach. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Yu C.; Wang W.; Liu X.; Bai J.; Song Y.; Li Z.; Gao Y.; Cao T.; Yin B.,"Yu, Changlong (57211937170); Wang, Weiqi (57222025650); Liu, Xin (57206739249); Bai, Jiaxin (57211989884); Song, Yangqiu (14039604300); Li, Zheng (57196124633); Gao, Yifan (57211752080); Cao, Tianyu (57225220598); Yin, Bing (57210637479)",57211937170; 57222025650; 57206739249; 57211989884; 14039604300; 57196124633; 57211752080; 57225220598; 57210637479,FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175070179&partnerID=40&md5=fdafe65bb81fbc3aaf6a626b20a06b21,"Understanding users' intentions in e-commerce platforms requires commonsense knowledge. In this paper, we present FolkScope, an intention knowledge graph construction framework to reveal the structure of humans' minds about purchasing items. As commonsense knowledge is usually ineffable and not expressed explicitly, it is challenging to perform information extraction. Thus, we propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph. LLMs first generate intention assertions via e-commerce-specific prompts to explain shopping behaviors, where the intention can be an open reason or a predicate falling into one of 18 categories aligning with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility and typicality labels of sampled intentions as training data in order to populate human judgments to all automatic generations. Last, to structurize the assertions, we propose pattern mining and conceptualization to form more condensed and abstract knowledge. Extensive evaluations and studies demonstrate that our constructed knowledge graph can well model e-commerce knowledge and have many potential applications. Our codes and datasets are publicly available at https://github.com/HKUSTKnowComp/FolkScope. © 2023 Association for Computational Linguistics.",Final,
Zou J.; Xie Z.; Chen J.; Hou J.; Yan Q.; Zheng H.-T.,"Zou, Jiaxin (57945864700); Xie, Zuotong (58482266700); Chen, Junhua (58657522100); Hou, Jiawei (58560730400); Yan, Qiang (57217028802); Zheng, Hai-Tao (57203433967)",57945864700; 58482266700; 58657522100; 58560730400; 57217028802; 57203433967,K-DLM: A Domain-Adaptive Language Model Pre-Training Framework with Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174589030&doi=10.1007%2f978-3-031-44216-2_37&partnerID=40&md5=d02259ac4a595014aadc5f840e83eaf8,"Despite the excellent performance of pre-trained language models, such as BERT, on various natural language processing tasks, they struggle with tasks that require domain-specific knowledge. Integrating information from knowledge graphs through pre-training tasks is a common approach. However, existing models tend to focus on entity information at the word level and fail to capture the rich information in knowledge graphs. To address this issue, we propose a domain-adaptive language model pre-training framework with a knowledge graph (K-DLM). K-DLM can learn both word and lexical-semantic level entity information and relationships from the knowledge graph. It predicts entity categories and sememes for masked phrases, replaces entities in sentences according to the knowledge graph, and learns relationship information via contrastive learning. The evaluation on open-domain and domain-specific tasks demonstrates that K-DLM outperforms previous models, particularly in domain-specific contexts. Our findings highlight K-DLM as an excellent pre-training framework for knowledge-driven problems that leverage domain knowledge graphs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Han Z.; Liao R.; Gu J.; Zhang Y.; Ding Z.; Gu Y.; Koeppl H.; Schütze H.; Tresp V.,"Han, Zhen (57219766233); Liao, Ruotong (57566178900); Gu, Jindong (57209291895); Zhang, Yao (57219556126); Ding, Zifeng (57260888700); Gu, Yujia (57260779700); Koeppl, Heinz (6603491586); Schütze, Hinrich (7003432991); Tresp, Volker (6603805670)",57219766233; 57566178900; 57209291895; 57219556126; 57260888700; 57260779700; 6603491586; 7003432991; 6603805670,ECOLA: Enhancing Temporal Knowledge Embeddings with Contextualized Language Representations,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175467105&partnerID=40&md5=6ad5287c3ffde024b9d194e379d742cc,"Since conventional knowledge embedding models cannot take full advantage of the abundant textual information, there have been extensive research efforts in enhancing knowledge embedding using texts. However, existing enhancement approaches cannot apply to temporal knowledge graphs (tKGs), which contain time-dependent event knowledge with complex temporal dynamics. Specifically, existing enhancement approaches often assume knowledge embedding is time-independent. In contrast, the entity embedding in tKG models usually evolves, which poses the challenge of aligning temporally relevant texts with entities. To this end, we propose to study enhancing temporal knowledge embedding with textual data in this paper. As an approach to this task, we propose Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations (ECOLA), which takes the temporal aspect into account and injects textual information into temporal knowledge embedding. To evaluate ECOLA, we introduce three new datasets for training and evaluating ECOLA. Extensive experiments show that ECOLA significantly enhances temporal KG embedding models with up to 287% relative improvements regarding Hits@1 on the link prediction task. The code and models are publicly available. © 2023 Association for Computational Linguistics.",Final,
Saratoon K.; Chutiporn A.; Nuttapong S.,"Saratoon, K. (58759266500); Chutiporn, A. (58759175400); Nuttapong, S. (58759046400)",58759266500; 58759175400; 58759046400,Knowledge Graph for Deriving Insights on The Thai Government Dataset,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179507146&doi=10.1109%2fTENCON58879.2023.10322344&partnerID=40&md5=643ec158eff3f8659cf879165a985089,"Natural language processing (NLP) is mandatory in working with text. There are many tools and applications that are based on it. However, most of those tools are often operated in, or only, the English language. In recent years, there has been a continuing development for NLP tools to support other languages or creating a specific tool for certain language for simple NLP tasks, but for some of the advanced tasks, the advancement is still behind that of the English language, Thai language is also one of them. So, in this research, the capabilities of the currently existing Thai NLP tools are explored and evaluated, with the tasks of extracting text from the Thai government dataset (eMENSCR) and creating the knowledge graph from it to improve data interpretability and gain more insight from the data, by utilizing queries that are exclusive, or less complex to execute, when the data is stored in the graph database such as performing a path traversal or relationship counting on the data. Natural language processing's part of speech tagging and named entity tagging is used to perform entity and relation extraction after filtering the unneeded data fields. Then the extracted information will be formulated into the format of 'triple', which is in the form of (head, relation, tail). After the process of triple construction is finished, The triples are evaluated by Precision, recall, and F1 in order to measure the pipeline's performance and import to the Neo4j for query testing. The obtained results show that there is still room for improvement for both the tools and the methodology itself.  © 2023 IEEE.",Final,
Qiao Z.; Ye W.; Yu D.; Mo T.; Li W.; Zhang S.,"Qiao, Zile (57885433300); Ye, Wei (57202350940); Yu, Dingyao (58071387700); Mo, Tong (36632540700); Li, Weiping (35229637800); Zhang, Shikun (7409376421)",57885433300; 57202350940; 58071387700; 36632540700; 35229637800; 7409376421,Improving Knowledge Graph Completion with Generative Hard Negative Mining,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175454560&partnerID=40&md5=9220c8f0bd8b8a012939bfbe5610e878,"Contrastive learning has recently shown great potential to improve text-based knowledge graph completion (KGC). In this paper, we propose to learn a more semantically structured entity representation space in text-based KGC via hard negatives mining. Specifically, we novelly leverage a sequence-to-sequence architecture to generate high-quality hard negatives. These negatives are sampled from the same decoding distributions as the anchor (or correct entity), inherently being semantically close to the anchor and thus enjoying good hardness. A self-information-enhanced contrasting strategy is further incorporated into the Seq2Seq generator to systematically diversify the produced negatives. Extensive experiments on three KGC benchmarks demonstrate the sound hardness and diversity of our generated negatives and the resulting performance superiority on KGC. © 2023 Association for Computational Linguistics.",Final,
Huang Q.; Wan Z.; Xing Z.; Wang C.; Chen J.; Xu X.; Lu Q.,"Huang, Qing (57195682681); Wan, Zhenyu (58640674900); Xing, Zhenchang (8347413500); Wang, Changjing (55766590100); Chen, Jieshan (57196018877); Xu, Xiwei (55706225900); Lu, Qinghua (56431802100)",57195682681; 58640674900; 8347413500; 55766590100; 57196018877; 55706225900; 56431802100,"Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179009379&doi=10.1109%2fASE56229.2023.00075&partnerID=40&md5=35cece058bfbbaa7bde6961be86dd4e3,"API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.  © 2023 IEEE.",Final,All Open Access; Green Open Access
Sewak M.; Emani V.; Naresh A.,"Sewak, Mohit (56572829400); Emani, Vamsi (58705984500); Naresh, Annam (57195391390)",56572829400; 58705984500; 57195391390,CRUSH: Cybersecurity Research using Universal LLMs and Semantic Hypernetworks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177576385&partnerID=40&md5=04f2785cc3dcf4e0b6b5f0334048b0fa,"Enterprise Knowledge Graphs (EKG) are powerful tools for representing and reasoning about complex and dynamic domains, such as cyber threat intelligence. However, designing and constructing such graphs can be challenging, especially when dealing with heterogeneous and noisy data sources. This paper presents our novel approach to using Large Language Models (LLM) for EKG design and development based on our experience building a Threat Intelligence Graph (TIG) using GPT3.5/ GPT4/ ChatGPT. We show how LLMs can automatically extract, infer, validate, and summarize information from various sources, such as threat reports, literature, scripts, etc., and populate the EKG with relevant entities, relationships, and properties. We also demonstrate how LLMs can identify malicious intents in any script file and map it to the TIG to detect any malicious techniques linked to the script. We demonstrate that an LLM-EKG-based approach could deliver up to 99% recall on the task of detection of malicious scripts and a consistent 90%+ recall on the task of detection of specific threat types across all script-based cybersecurity threats. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Soriano M.; Berlanga R.; Lanza-Cruz I.,"Soriano, Mario (58684675200); Berlanga, Rafael (6701785415); Lanza-Cruz, Indira (57203941883)",58684675200; 6701785415; 57203941883,On the Problem of Automatically Aligning Indicators to SDGs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175944113&doi=10.1007%2f978-3-031-43458-7_26&partnerID=40&md5=4b7f19d3d82b60e5d869ad34465efe4d,"In this paper we present a first approach to the application of transformer-based language models to the automatic alignment to sustainable development goals (SDGs). This task is quite relevant for the development of new tools that aim at measuring the engagement degree of the organization’s indicators to the SGDs. Our first experiments show that this task is hard, and that even powerful large language models do not achieve a high accuracy as in other NLP tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
García-Silva A.; Berrío C.; Gómez-Pérez J.M.,"García-Silva, Andrés (36718996900); Berrío, Cristian (57219692740); Gómez-Pérez, Jose Manuel (23485087500)",36718996900; 57219692740; 23485087500,Textual Entailment for Effective Triple Validation in Object Prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177231372&doi=10.1007%2f978-3-031-47240-4_5&partnerID=40&md5=f1ef66cface066da147061a697483939,"Knowledge base population seeks to expand knowledge graphs with facts that are typically extracted from a text corpus. Recently, language models pretrained on large corpora have been shown to contain factual knowledge that can be retrieved using cloze-style strategies. Such approach enables zero-shot recall of facts, showing competitive results in object prediction compared to supervised baselines. However, prompt-based fact retrieval can be brittle and heavily depend on the prompts and context used, which may produce results that are unintended or hallucinatory. We propose to use textual entailment to validate facts extracted from language models through cloze statements. Our results show that triple validation based on textual entailment improves language model predictions in different training regimes. Furthermore, we show that entailment-based triple validation is also effective to validate candidate facts extracted from other sources including existing knowledge graphs and text passages where named entities are recognized. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Tan Y.; Wang B.; Liu A.; Zhao D.; Huang K.; He R.; Hou Y.,"Tan, Yue (58506099900); Wang, Bo (56949454300); Liu, Anqi (58676090200); Zhao, Dongming (7403490494); Huang, Kun (57614133600); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",58506099900; 56949454300; 58676090200; 7403490494; 57614133600; 19835197000; 7402198932,Guiding Dialogue Agents to Complex Semantic Targets by Dynamically Completing Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175466823&partnerID=40&md5=95f3ae2e50dd0f5aae516612cef7d1f8,"In target-oriented dialogue, the representation and achievement of targets are two interrelated essential issues. In current approaches, the target is typically assumed to be a single object represented as a word, which makes it relatively easy to achieve through dialogue with the help of a knowledge graph (KG). However, when the target has complex semantics, the existing KG is often incomplete in tracking semantic relations. This paper studies target-oriented dialog where the target is a topic sentence. We combine the methods of knowledge retrieval and relationship prediction to construct a context-related dynamic KG, in which we can track the implicit semantic paths in the speaker's mind that may not exist in the existing KGs. In addition, we also designed a novel metric to evaluate the tracked path automatically. The experimental results show that our method can control the agent more logically and smoothly toward the complex target. © 2023 Association for Computational Linguistics.",Final,
Su X.; Zhou Y.; Shan Z.; Chen Q.,"Su, Xin (8656363400); Zhou, Yao (58279807000); Shan, Zifei (57219807524); Chen, Qian (58547892300)",8656363400; 58279807000; 57219807524; 58547892300,MeKB-Rec: Personal Knowledge Graph Learning for Cross-Domain Recommendation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179009938&partnerID=40&md5=2b4ceba8b65328c7e848ff19cbb09beb,"It is a long-standing challenge in modern recommender systems to make recommendations for new users, namely the cold-start problem. Cross-Domain Recommendation (CDR) has been proposed to address this challenge, but current ways to represent users’ interests across systems are still severely limited. We introduce Personal Knowledge Graph (PKG) as a domain-invariant interest representation, and propose a novel CDR paradigm named MeKB-Rec. We first link users and entities in a knowledge base to construct a PKG of users’ interests, named MeKB. Then we learn a semantic representation of MeKB for the cross-domain recommendation. Beyond most existing systems, our approach builds a semantic mapping across domains using Pretrained Language Models which breaks the requirement for in-domain user behaviors, enabling zero-shot recommendations for new users in a low-resource domain. We experiment MeKB-Rec on well-established public CDR datasets, and demonstrate that the new formulation achieves a new state-of-the-art that significantly improves HR@10 and NDCG@10 metrics over best previous approaches by 24%–91%, with a 105% improvement for HR@10 of zero-shot users with no behavior in the target domain. We deploy MeKB-Rec in WeiXin recommendation scenarios and achieve significant gains in core online metrics. MeKB-Rec is now serving hundreds of millions of users in real-world products. © 2023 Copyright for this paper by its authors.",Final,
Axelsson A.; Skantze G.,"Axelsson, Agnes (57292133300); Skantze, Gabriel (6505943187)",57292133300; 6505943187,Using Large Language Models for Zero-Shot Natural Language Generation from Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175688234&partnerID=40&md5=37361e3fb8b3742b856f2f071d7c6c5d,"In any system that uses structured knowledge graph (KG) data as its underlying knowledge representation, KG-to-text generation is a useful tool for turning parts of the graph data into text that can be understood by humans. Recent work has shown that models that make use of pretraining on large amounts of text data can perform well on the KG-to-text task, even with relatively little training data on the specific graph-to-text task. In this paper, we build on this concept by using large language models to perform zero-shot generation based on nothing but the model’s understanding of the triple structure from what it can read. We show that ChatGPT achieves near state-of-the-art performance on some measures of the WebNLG 2020 challenge, but falls behind on others. Additionally, we compare factual, counter-factual and fictional statements, and show that there is a significant connection between what the LLM already knows about the data it is parsing and the quality of the output text. © 2023 Association for Computational Linguistics.",Final,
Soares F.M.; Bergier I.; Coradini M.C.; Ferreira A.P.L.; Telles M.A.; dos Santos Maculan B.C.M.; de Cléofas Faggion Alencar M.; Simão V.P.M.; de Almeida B.T.; Drucker D.P.; Machado Vieira M.S.; da Cruz S.M.S.,"Soares, Filipi Miranda (57722637400); Bergier, Ivan (50461023200); Coradini, Maria Carolina (57214185181); Ferreira, Ana Paula Lüdtke (8299784300); Telles, Milena Ambrosio (58701830400); dos Santos Maculan, Benildes Coura Moreira (58699630900); de Cléofas Faggion Alencar, Maria (57209441602); Simão, Victor Paulo Marques (58701164100); de Almeida, Bibiana Teixeira (58701164200); Drucker, Debora Pignatari (14062915000); Machado Vieira, Marcia dos Santos (58701666800); da Cruz, Sérgio Manuel Serra (24821242900)",57722637400; 50461023200; 57214185181; 8299784300; 58701830400; 58699630900; 57209441602; 58701164100; 58701164200; 14062915000; 58701666800; 24821242900,Unveiling Knowledge Organization Systems’ Artifacts for Digital Agriculture with Lexical Network Analysis,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177186632&doi=10.1007%2f978-3-031-47112-4_28&partnerID=40&md5=e3937b250f6966521372265e2b7b2f9b,"This article presents a bibliometric and terminological study of a corpus composed of abstracts and titles of 278 articles retrieved by a review protocol planned for surveying initiatives on building artifacts for modeling knowledge related to agricultural production systems. The original corpus comprised a 53,379-word linguistic extract filtered to 111 interconnected major terminologies by combining AntConc and VOSViewer tools. The reduced data were imported into the Gephi tool for analysis of lexical network graphs. Emergent clusters and their central terms underscore the thematic areas that prominently shape the landscape of agricultural Knowledge Organization Systems (KOS) and highlight the interplay between technological advancements, semantic enrichment, and domain-specific challenges. Our analysis of term occurrences and clusters contributes to a broader understanding of these concepts, inferring their significance, roles, and interconnections within the agricultural landscape. It also sheds light on the roles played by KOS in Digital Agriculture. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Cadeddu A.; Chessa A.; De Leo V.; Fenu G.; Motta E.; Osborne F.; Recupero D.R.; Salatino A.; Secchi L.,"Cadeddu, Andrea (50661090000); Chessa, Alessandro (6604050350); De Leo, Vincenzo (57201282816); Fenu, Gianni (24469552000); Motta, Enrico (7006092143); Osborne, Francesco (36675585600); Recupero, Diego Reforgiato (57206674454); Salatino, Angelo (57188026200); Secchi, Luca (6602677456)",50661090000; 6604050350; 57201282816; 24469552000; 7006092143; 36675585600; 57206674454; 57188026200; 6602677456,Enhancing Scholarly Understanding: A Comparison of Knowledge Injection Strategies in Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178584892&partnerID=40&md5=1a1e9863020e62bdd181f45745a1b8ee,"The use of transformer-based models like BERT for natural language processing has achieved remarkable performance across multiple domains. However, these models face challenges when dealing with very specialized domains, such as scientific literature. In this paper, we conduct a comprehensive analysis of knowledge injection strategies for transformers in the scientific domain, evaluating four distinct methods for injecting external knowledge into transformers. We assess these strategies in a single-label multi-class classification task involving scientific papers. For this, we develop a public benchmark based on 12k scientific papers from the AIDA knowledge graph, categorized into three fields. We utilize the Computer Science Ontology as our external knowledge source. Our findings indicate that most proposed knowledge injection techniques outperform the BERT baseline. © 2022 Copyright for this paper by its authors.",Final,
,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175417467&partnerID=40&md5=cb3ccf1e95ab49b982573a741eed8c90,The proceedings contain 9 papers. The topics discussed include: text-to-KG alignment: comparing current methods on classification tasks; identifying quantifiably verifiable statements from text; toward consistent and informative event-event temporal relation extraction; COFFEE: a contrastive oracle-free framework for event extraction; corpus-based task-specific relation discovery; on the surprising effectiveness of name matching alone in autoregressive entity linking; knowledge-augmented language model prompting for zero-shot knowledge graph question answering; knowledge base completion for long-tail entities; and CoSiNES: contrastive Siamese network for entity standardization.,Final,
Nayyeri M.; Wang Z.; Akter M.M.; Alam M.M.; Rony M.R.A.H.; Lehmann J.; Staab S.,"Nayyeri, Mojtaba (35776892400); Wang, Zihao (57202647584); Akter, Mst. Mahfuja (57852007600); Alam, Mirza Mohtashim (57202902190); Rony, Md Rashad Al Hasan (57203302415); Lehmann, Jens (35229806900); Staab, Steffen (7004053291)",35776892400; 57202647584; 57852007600; 57202902190; 57203302415; 35229806900; 7004053291,Integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177234493&doi=10.1007%2f978-3-031-47240-4_21&partnerID=40&md5=97eea61703ae1ba6e30bd3ce8eca890a,"Knowledge graphs comprise structural and textual information to represent knowledge. To predict new structural knowledge, current approaches learn representations using both types of information through knowledge graph embeddings and language models. These approaches commit to a single pre-trained language model. We hypothesize that heterogeneous language models may provide complementary information not exploited by current approaches. To investigate this hypothesis, we propose a unified framework that integrates multiple representations of structural knowledge and textual information. Our approach leverages hypercomplex algebra to model the interactions between (i) graph structural information and (ii) multiple text representations. Specifically, we utilize Dihedron models with 4*D dimensional hypercomplex numbers to integrate four different representations: structural knowledge graph embeddings, word-level representations (e.g., Word2vec and FastText), sentence-level representations (using a sentence transformer), and document-level representations (using FastText or Doc2vec). Our unified framework score the plausibility of labeled edges via Dihedron products, thus modeling pairwise interactions between the four representations. Extensive experimental evaluations on standard benchmark datasets confirm our hypothesis showing the superiority of our two new frameworks for link prediction tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Jiang P.; Agarwal S.; Jin B.; Wang X.; Sun J.; Han J.,"Jiang, Pengcheng (58342404500); Agarwal, Shivam (57219545565); Jin, Bowen (57218704108); Wang, Xuan (57203976646); Sun, Jimeng (9737233900); Han, Jiawei (24325399900)",58342404500; 57219545565; 57218704108; 57203976646; 9737233900; 24325399900,Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175438166&partnerID=40&md5=f793591ad289627c2d175dd60df87f16,"The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TAGREAL that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TAGREAL achieves state-of-the-art performance on two benchmark datasets. We find that TAGREAL has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods. © 2023 Association for Computational Linguistics.",Final,
Gupta R.; Aksitov R.; Phatale S.; Chaudhary S.; Lee H.; Rastogi A.,"Gupta, Raghav (57209831072); Aksitov, Renat (58112034800); Phatale, Samrat (57193131236); Chaudhary, Simral (58337823700); Lee, Harrison (57313869600); Rastogi, Abhinav (57193220666)",57209831072; 58112034800; 57193131236; 58337823700; 57313869600; 57193220666,"Conversational Recommendation as Retrieval: A Simple, Strong Baseline",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174503211&partnerID=40&md5=978a099124cdca32264d8901d8a1aea6,"Conversational recommendation systems (CRS) aim to recommend suitable items to users through natural language conversation. However, most CRS approaches do not effectively utilize the signal provided by these conversations. They rely heavily on explicit external knowledge e.g., knowledge graphs to augment the models’ understanding of the items and attributes, which is quite hard to scale. To alleviate this, we propose an alternative information retrieval (IR)-styled approach to the CRS item recommendation task, where we represent conversations as queries and items as documents to be retrieved. We expand the document representation used for retrieval with conversations from the training set. With a simple BM25-based retriever, we show that our task formulation compares favorably with much more complex baselines using complex external knowledge on a popular CRS benchmark. We demonstrate further improvements using user-centric modeling and data augmentation to counter the cold start problem for CRSs. © 2023 Association for Computational Linguistics.",Final,
Hu Z.; Li X.; Pan X.; Wen S.; Bao J.,"Hu, Zhiqiang (57215925897); Li, Xinyu (56455381400); Pan, Xinyu (58658033700); Wen, Sijie (58657335600); Bao, Jinsong (7201398425)",57215925897; 56455381400; 58658033700; 58657335600; 7201398425,A question answering system for assembly process of wind turbines based on multi-modal knowledge graph and large language model,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174585056&doi=10.1080%2f09544828.2023.2272555&partnerID=40&md5=d34e7e9c0bab9ed1408dd5749390ccb0,"In the field of wind power generation, wind turbines serve as the foundation for harnessing electrical energy. However, the assembly process information for wind turbines is typically dispersed among various modalities such as 3D models, natural text, and images in the form of process documents. The difficulty in effectively utilising historical process knowledge hampers the efficiency of assembly process design and subsequently affects production efficiency. To address this issue, this paper constructs a Multi-modal Process Knowledge Graph for Wind Turbines, named MPKG-WT. Additionally, a wind turbine assembly process question-answering system combining multi-modal knowledge graphs with large language models (LLMs) is proposed to enable efficient utilisation of historical assembly process knowledge. The proposed approach achieves outstanding results when compared with other state-of-the-art KBQA methods and recent LLMs using a wind turbine assembly process dataset. The effectiveness of the approach is further validated through a visualised assembly process question-answering system. The research findings demonstrate a significant improvement in assembly process design efficiency. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",Article in press,
Wang P.; Xie X.; Wang X.; Zhang N.,"Wang, Peng (58316810800); Xie, Xin (57222379771); Wang, Xiaohan (57216847319); Zhang, Ninyu (58613381500)",58316810800; 57222379771; 57216847319; 58613381500,Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174702684&doi=10.1007%2f978-3-031-44693-1_9&partnerID=40&md5=ef237fba0eb07eead68ddbd2fe0903ab,"Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory (Code is available at: https://github.com/zjunlp/KNN-KG ). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Riaz A.; Abdollahi S.; Gottschalk S.,"Riaz, Aniqa (58684373100); Abdollahi, Sara (57219024750); Gottschalk, Simon (57190496603)",58684373100; 57219024750; 57190496603,Entity Typing with Triples Using Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176001461&doi=10.1007%2f978-3-031-43458-7_32&partnerID=40&md5=cece3bb3a97dc9aaa06da199c24f643c,"Entity Typing is the task of assigning a type to an entity in a knowledge graph. In this paper, we propose ETwT (Entity Typing with Triples), which leverages the triples of an entity, namely its label, description and the property labels used on it. We analyse which language models and classifiers are best suited to this input and compare ETwT’s performance on coarse-grained and fine-grained entity typing. Our evaluation demonstrates that ETwT is able to predict coarse-grained entity types with an F $$:1$$ score of 0.994, outperforming three baselines. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
Lin C.; Zheng Z.; Cai S.; Fu L.; Xie W.; Ma T.; Zhang Z.,"Lin, Chenxiang (58284327500); Zheng, Zhou (57696467000); Cai, Shitao (58659740300); Fu, Li (58661091600); Xie, Wei (58659858700); Ma, Teng (58660906000); Zhang, Zhihong (55644004034)",58284327500; 57696467000; 58659740300; 58661091600; 58659858700; 58660906000; 55644004034,Knowledge Graph Completion for Power Grid Main Equipment Using Pretrained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174704504&doi=10.1007%2f978-981-99-4752-2_68&partnerID=40&md5=ca7c75a13ade319bceb9eb7b57585453,"The safe and stable operation of power systems relies on the timely diagnosis of defects in power grid equipment. To achieve this, knowledge graph (KG) can be used to model power grid equipment defect knowledge, and knowledge graph embedding (KGE) can be utilized to embed KG into low dimensional vector spaces for deep learning models. However, pre-trained language model-based KGE methods may not perform as well as structure-based methods due to their limitations in explicitly representing domain-specific knowledge and supplementary information about entities. In this study, a hybrid KGE model called PLMSM was proposed to address this issue. PLMSM combines pre-trained language models with structure-based models to input entities and their supplementary information into a pre-trained language model to obtain their embeddings, which are then combined with the embeddings generated by a structure-based model for entity completion tasks. The model was optimized through efficient negative sampling and addressed the issue of inaccurate predictions caused by long-tail entities in the power grid defects KG. The experimental results showed that PLMSM achieved good performance in Entity completion tasks on the power grid equipment defects KG. This proposed model has potential applications in power grid equipment defect diagnosis and maintenance. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Arachchige I.A.N.; Ha L.A.; Mitkov R.; Nahar V.,"Arachchige, Isuri Anuradha Nanomi (57712837800); Ha, Le An (13612155200); Mitkov, Ruslan (6602533142); Nahar, Vinitar (57506852900)",57712837800; 13612155200; 6602533142; 57506852900,Evaluating Large Language Models in Relationship Extraction from Unstructured Data: Empirical Study from Holocaust Testimonies,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179177996&doi=10.26615%2f978-954-452-092-2_013&partnerID=40&md5=4aa71293a35772a7c5988c15a47f2c26,"Relationship extraction from unstructured data remains one of the most challenging tasks in the field of Natural Language Processing (NLP). The complexity of relationship extraction arises from the need to comprehend the underlying semantics, syntactic structures, and contextual dependencies within the text. Unstructured data poses challenges with diverse linguistic patterns, implicit relationships, contextual nuances, complicating accurate relationship identification and extraction. The emergence of Large Language Models (LLMs), such as GPT (Generative Pre-trained Transformer), has indeed marked a significant advancement in the field of NLP.In this work, we assess and evaluate the effectiveness of LLMs in relationship extraction in the Holocaust testimonies within the context of the Historical realm. By delving into this domainspecific context, we aim to gain deeper insights into the performance and capabilities of LLMs in accurately capturing and extracting relationships within the Holocaust domain by developing a novel knowledge graph to visualise the relationships of the Holocaust. To the best of our knowledge, there is no existing study which discusses relationship extraction in Holocaust testimonies. The majority of current approaches for Information Extraction (IE) in historic documents are either manual or Optical Character Recognition (OCR) based. Moreover, in this study, we found that the Subject-Object-Verb extraction using GPT3-based relations produced more meaningful results compared to the Semantic Role labelingbased triple extraction. © 2023 Incoma Ltd. All rights reserved.",Final,All Open Access; Bronze Open Access
Yáñez-Romero F.; Montoyo A.; Muñoz R.; Gutiérrez Y.; Suárez A.,"Yáñez-Romero, Fabio (58754723400); Montoyo, Andres (8921219600); Muñoz, Rafael (7202035977); Gutiérrez, Yoan (41761666300); Suárez, Armando (8921219800)",58754723400; 8921219600; 7202035977; 41761666300; 8921219800,A Review in Knowledge Extraction from Knowledge Bases,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179177199&doi=10.26615%2f978-954-452-092-2_012&partnerID=40&md5=cec4b4e3513b360cccffa002783ca023,"Generative language models achieve the state of the art in many tasks within natural language processing (NLP). Although these models correctly capture syntactic information, they fail to interpret knowledge (semantics). Moreover, the lack of interpretability of these models promotes the use of other technologies as a replacement or complement to generative language models. This is the case with research focused on incorporating knowledge by resorting to knowledge bases mainly in the form of graphs. The generation of large knowledge graphs is carried out with unsupervised or semi-supervised techniques, which promotes the validation of this knowledge with the same type of techniques due to the size of the generated databases. In this review, we will explain the different techniques used to test and infer knowledge from graph structures with machine learning algorithms. The motivation of validating and inferring knowledge is to use correct knowledge in subsequent tasks with improved embeddings. © 2023 Incoma Ltd. All rights reserved.",Final,All Open Access; Bronze Open Access
Lippolis A.S.; Klironomos A.; Milon-Flores D.F.; Zheng H.; Jouglar A.; Norouzi E.; Hogan A.,"Lippolis, Anna Sofia (57279654900); Klironomos, Antonis (58305677900); Milon-Flores, Daniela F. (57215363484); Zheng, Heng (58733879700); Jouglar, Alexane (58682888400); Norouzi, Ebrahim (58734244400); Hogan, Aidan (57203013004)",57279654900; 58305677900; 57215363484; 58733879700; 58682888400; 58734244400; 57203013004,Enhancing Entity Alignment Between Wikidata and ArtGraph Using LLMs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178311919&partnerID=40&md5=ba7501ef8c69f4154305acfc78c3f637,"Knowledge graphs (KGs) are used in a wide variety of applications, including within the cultural heritage domain. An important prerequisite of such applications is the quality and completeness of the data. Using a single KG might not be enough to fulfill this requirement. The absence of connections between KGs complicates taking advantage of the complementary data they can provide. This paper focuses on the Wikidata and A rtG raph KGs, which exhibit gaps in content that can be filled by enriching one with data from the other. Entity alignment can help to combine data from KGs by connecting entities that refer to the same real-world entities. However, entity alignment in art-domain knowledge graphs remains under-explored. In the pursuit of entity alignment between A rtG raph and Wikidata, a hybrid approach is proposed. The first part, which we call WES (Wikidata Entity Search), utilizes traditional Wikidata SPARQL queries and is followed by a supplementary sequence-to-sequence large language model (LLM) pipeline that we denote as pArtLink. The combined approach successfully aligned artworks and artists, with WES identifying entities for 14,982 artworks and 2,029 artists, and pArtLink further aligning 76 additional artists, thus enhancing the alignment process beyond WES’ capabilities. © 2023 Copyright for this paper by its authors.",Final,
Wu S.; Shen X.; Xia R.,"Wu, Siwei (57939086600); Shen, Xiangqing (57939056400); Xia, Rui (36847284600)",57939086600; 57939056400; 36847284600,Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175453934&partnerID=40&md5=c35cb33200e532763e490c7dd6156d15,"The nodes in the commonsense knowledge graph (CSKG) are normally represented by free-form short text (e.g., word or phrase). Different nodes may represent the same concept. This leads to the problems of edge sparsity and node redundancy, which challenges CSKG representation and completion. On the one hand, edge sparsity limits the performance of graph representation learning; On the other hand, node redundancy makes different nodes corresponding to the same concept have inconsistent relations with other nodes. To address the two problems, we propose a new CSKG completion framework based on Contrastive Pretraining and Node Clustering (CPNC). Contrastive Pretraining constructs positive and negative head-tail node pairs on CSKG and utilizes contrastive learning to obtain better semantic node representation. Node Clustering aggregates nodes with the same concept into a latent concept, assisting the task of CSKG completion. We evaluate our CPNC approach on two CSKG completion benchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-art methods. Extensive experiments demonstrate that both Contrastive Pretraining and Node Clustering can significantly improve the performance of CSKG completion. The source code of CPNC is publicly available on https://github.com/NUSTM/CPNC. © 2023 Association for Computational Linguistics.",Final,
Li Q.; Joty S.; Wang D.; Feng S.; Zhang Y.; Qin C.,"Li, Qian (57199178910); Joty, Shafiq (24779447500); Wang, Daling (8543200700); Feng, Shi (36173786700); Zhang, Yifei (36618421200); Qin, Chengwei (57313726600)",57199178910; 24779447500; 8543200700; 36173786700; 36618421200; 57313726600,Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175483719&partnerID=40&md5=a2a42df5fa4fa0a84ca009c97289bbad,"With the evolution of Knowledge Graphs (KGs), new entities emerge which are not seen before. Representation learning of KGs in such an inductive setting aims to capture and transfer the structural patterns from existing entities to new entities. However, the performance of existing methods in inductive KGs are limited by sparsity and implicit transfer. In this paper, we propose VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting. We first propose representation generation to capture the encoded and generated representations of entities, where the generated variations can augment the representation space with complementary features. Then, we design two CL objectives that work across entities and meta-KGs to simulate the transfer mode. With extensive experiments we demonstrate that our proposed VMCL can significantly outperform previous state-of-the-art baselines. © 2023 Association for Computational Linguistics.",Final,
Braşoveanu A.M.P.; Nixon L.J.B.; Weichselbraun A.; Scharl A.,"Braşoveanu, Adrian M.P. (57222186167); Nixon, Lyndon J.B. (8912318900); Weichselbraun, Albert (23471068600); Scharl, Arno (36811137000)",57222186167; 8912318900; 23471068600; 36811137000,Framing Few-Shot Knowledge Graph Completion with Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175627576&partnerID=40&md5=e739d2ea8c5f81b27f25e636e20d37f8,"Knowledge Graph Completion (KGC) from text involves identifying known or unknown entities (nodes) as well as relations (edges) among these entities. Recent work has started to explore the use of Large Language Models (LLMs) for entity detection and relation extraction, due to their Natural Language Understanding (NLU) capabilities. However, LLM performance varies across models and depends on the quality of the prompt engineering. We examine specific relation extraction cases and present a set of examples collected from well-known resources in a small corpus. We provide a set of annotations and identify various issues that occur when using different LLMs for this task. As LLMs will remain a focal point of future KGC research, we conclude with suggestions for improving the KGC process. © 2023 Copyright for this paper by its authors.",Final,
Matsubara T.; Miwa M.; Sasaki Y.,"Matsubara, Takuma (58655967500); Miwa, Makoto (35208894900); Sasaki, Yutaka (35956948800)",58655967500; 35208894900; 35956948800,Distantly Supervised Document-Level Biomedical Relation Extraction with Neighborhood Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174543680&partnerID=40&md5=1aabe66c462ba0030bdf31f7f8208264,"We propose a novel distantly supervised document-level biomedical relation extraction model that uses partial knowledge graphs that include the graph neighborhood of the entities appearing in each input document. Most conventional distantly supervised relation extraction methods use only the entity relations automatically annotated by using knowledge base entries. They do not fully utilize the rich information in the knowledge base, such as entities other than the target entities and the network of heterogeneous entities defined in the knowledge base. To address this issue, our model integrates the representations of the entities acquired from the neighborhood knowledge graphs with the representations of the input document. We conducted experiments on the ChemDisGene dataset using Comparative Toxicogenomics Database (CTD) for document-level relation extraction with respect to interactions between drugs, diseases, and genes. Experimental results confirmed the performance improvement by integrating entities and their neighborhood biochemical information from the knowledge base. © 2023 Association for Computational Linguistics.",Final,
Omeliyanenko J.; Zehe A.; Hotho A.; Schlör D.,"Omeliyanenko, Janna (57220023388); Zehe, Albin (57191032011); Hotho, Andreas (8227931000); Schlör, Daniel (57205323166)",57220023388; 57191032011; 8227931000; 57205323166,CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177206539&doi=10.1007%2f978-3-031-47240-4_33&partnerID=40&md5=5bb38a514cd2113011f33c64139611bb,"Automated completion of knowledge graphs is a popular topic in the Semantic Web community that aims to automatically and continuously integrate new appearing knowledge into knowledge graphs using artificial intelligence. Recently, approaches that leverage implicit knowledge from language models for this task have shown promising results. However, by fine-tuning language models directly to the domain of knowledge graphs, models forget their original language representation and associated knowledge. An existing solution to address this issue is a trainable adapter, which is integrated into a frozen language model to extract the relevant knowledge without altering the model itself. However, this constrains the generalizability to the specific extraction task and by design requires new and independent adapters to be trained for new knowledge extraction tasks. This effectively prevents the model from benefiting from existing knowledge incorporated in previously trained adapters. In this paper, we propose to combine the benefits of adapters for knowledge graph completion with the idea of integrating capsules, introduced in the field of continual learning. This allows the continuous integration of knowledge into a joint model by sharing and reusing previously trained capsules. We find that our approach outperforms solutions using traditional adapters, while requiring notably fewer parameters for continuous knowledge integration. Moreover, we show that this architecture benefits significantly from knowledge sharing in low-resource situations, outperforming adapter-based models on the task of link prediction. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Guan Y.; Chen J.; Lecue F.; Pan J.Z.; Li J.; Li R.,"Guan, Yong (57192310879); Chen, Jiaoyan (55827415100); Lecue, Freddy (15136250600); Pan, Jeff Z. (8856621200); Li, Juanzi (8304332600); Li, Ru (57192310904)",57192310879; 55827415100; 15136250600; 8856621200; 8304332600; 57192310904,Trigger-Argument based Explanation for Event Detection,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174992103&partnerID=40&md5=4ccd52229a94c540aee24d75d95f6748,"A critical task for constructing event knowledge graphs is event detection (ED), which aims to identify events of certain types in plain text. Neural models have achieved great success on ED, thus coming with a desire for higher interpretability. Existing works mainly exploit words or phrases of the input text to explain models' inner mechanisms. However, for ED, the event structure, comprising of an event trigger and a set of arguments, provides more enlightening clues to explain model behaviors. To this end, we propose a Trigger-Argument based Explanation method (TAE), which can utilize event structure knowledge to uncover a faithful interpretation for the existing ED models at neuron level. Specifically, we design group, sparsity, support mechanisms to construct the event structure from structuralization, compactness, and faithfulness perspectives. We evaluate our model on the large-scale MAVEN and the widely-used ACE 2005 datasets, and observe that TAE is able to reveal the process by which the model predicts. Experimental results also demonstrate that TAE can not only improve the interpretability on standard evaluation metrics, but also effectively facilitate the human understanding. © 2023 Association for Computational Linguistics.",Final,
Bączkowska A.; Gromann D.,"Bączkowska, Anna (57197523089); Gromann, Dagmar (55844075500)",57197523089; 55844075500,"From knobhead to sex goddess: Swear words in English subtitles, their functions and representation as linguistic linked data; [Od šupljoglavca do božice seksa: psovke u engleskim titlovima, njihove funkcije i prikaz modelom jezičnih povezanih podataka]",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177213645&doi=10.31724%2frihjj.49.1.4&partnerID=40&md5=59297edc7fbc7948ac5891b08b396dab,"Swear words represent an important social vehicle for human communication that beyond mere insults are conventionally used for social bonding and bantering among other functions. However, to the best of our knowledge, no systematic typology of swear word functions has been proposed. In this article, such a typology is proposed in a top-down manner drawing on literature as well as bottom-up by analysing a concrete corpus of real-world sufficiently filthy dialogues. For this first case study, the analysis is limited to English and the analysis of subtitles of a single movie. We found that specific types of swear words, e.g. bodily functions, appear across functions with some preferences, e.g. body parts are particularly utilised in jocularity, criticism, and anger. Furthermore, theresulting data are represented as linguistic linked data, extolling the virtues of this format for fine-grained linguistic analyses, e.g. filtering and visualising all swear words pertaining to a specific function. © 2023, Institute of Croatian Language and Linguistics. All rights reserved.",Final,All Open Access; Gold Open Access
Song R.; He S.; Gao S.; Cai L.; Liu K.; Yu Z.; Zhao J.,"Song, Ran (57212212531); He, Shizhu (56021680600); Gao, Shengxiang (12762206800); Cai, Li (55145480500); Liu, Kang (55729555700); Yu, Zhengtao (8883303600); Zhao, Jun (57190004147)",57212212531; 56021680600; 12762206800; 55145480500; 55729555700; 8883303600; 57190004147,Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175424495&partnerID=40&md5=d328536a275ee62fc7ca6e96e0d34ad6,"Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like (h, r, ?) in different languages by reasoning a tail entity t thus improving multilingual knowledge graphs. Previous studies leverage multilingual pretrained language models (PLMs) and the generative paradigm to achieve mKGC. Although multilingual pretrained language models contain extensive knowledge of different languages, its pretraining tasks cannot be directly aligned with the mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit a pronounced English-centric bias. This makes it difficult for mKGC to achieve good results, particularly in the context of low-resource languages. To overcome previous problems, this paper introduces global and local knowledge constraints for mKGC. The former is used to constrain the reasoning of answer entities, while the latter is used to enhance the representation of query contexts. The proposed method makes the pretrained model better adapt to the mKGC task. Experimental results on public datasets demonstrate that our method outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and 16.03%, which indicates that our proposed method has significant enhancement on mKGC. © 2023 Association for Computational Linguistics.",Final,
Li F.; Huang H.; Dong R.,"Li, Fengying (55494484900); Huang, Hongfei (58658038600); Dong, Rongsheng (35107163200)",55494484900; 58658038600; 35107163200,Efficient Question Answering Based on Language Models and Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174601293&doi=10.1007%2f978-3-031-44216-2_28&partnerID=40&md5=3fd6abe51578a919281e474303cf670f,"Knowledge graph question answering (Q &A) aims to answer questions through a knowledge base (KB). When using a knowledge base as a data source for multihop Q &A, knowledge graph Q &A needs to obtain relevant entities, their relationships and the correct answer, but often the correct answer cannot be obtained through the reasoning path because of absent relationships. Currently, using pre-trained language models (PLM) and knowledge graphs (KG) has a good effect on complex problems. However, challenging problems remain; the relationships between problems and candidate entities need to be better represented, and joint reasoning must be performed in the relationship graph based on problems and entities. To solve these problems, we expand the relational graph by adding tail entities to the list of preselected entities through reverse relations and then add the processed problems and entities to the problem subgraph. To perform inference on a relational graph, we design an attention-based neural network module. To calculate the loss of the model’s inference process nodes, we use a modified Euclidean distance function as the loss function. To evaluate our model, we conducted experiments on the WebQSP and CWQ datasets, and the model obtained state-of-the-art results in both the KB-full and KB-half settings. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Thant S.; Racharak T.; Andres F.,"Thant, Shin (57216894144); Racharak, Teeradaj (56712968400); Andres, Frederic (7006587676)",57216894144; 56712968400; 7006587676,BERT Fine-Tuning the Covid-19 Open Research Dataset for Named Entity Recognition,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177820256&doi=10.1007%2f978-981-99-7969-1_19&partnerID=40&md5=daa58d05bc892480a069118e90d8af96,"This study employs the widely used Large Language Model (LLM), BERT, to implement Named Entity Recognition (NER) on the CORD-19 biomedical literature corpus. By fine-tuning the pre-trained BERT on the CORD-NER dataset, the model gains the ability to comprehend the context and semantics of biomedical named entities. The refined model is then utilized on the CORD-19 to extract more contextually relevant and updated named entities. However, fine-tuning large datasets with LLMs poses a challenge. To counter this, two distinct sampling methodologies are proposed to apply on each dataset. First, for the NER task on the CORD-19, a Latent Dirichlet Allocation (LDA) topic modeling technique is employed. This maintains the sentence structure while concentrating on related content. Second, a straightforward greedy method is deployed to gather the most informative data of 25 entity types from the CORD-NER dataset. The study realizes its goals by demonstrating the content comprehension capability of BERT-based models without the necessity of supercomputers, and converting the document-level corpus into a source for NER data, enhancing data accessibility. The outcomes of this research can shed light on the potential progression of more sophisticated NLP applications across various sectors, including knowledge graph creation, ontology learning, and conversational AI. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",Final,
Nguyen C.D.M.; French T.; Liu W.; Stewart M.,"Nguyen, Chau Duc Minh (58282242700); French, Tim (13611425300); Liu, Wei (36077178500); Stewart, Michael (57196713433)",58282242700; 13611425300; 36077178500; 57196713433,SConE: Simplified Cone Embeddings with Symbolic Operators for Complex Logical Queries,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175485370&partnerID=40&md5=f82787d8bf58c782338654253f9a3ab8,"Geometric representation of query embeddings (using points, particles, rectangles and cones) can effectively achieve the task of answering complex logical queries expressed in first-order logic (FOL) form over knowledge graphs, allowing intuitive encodings. However, current geometric-based methods depend on the neural approach to model FOL operators (conjunction, disjunction and negation), which are not easily explainable with considerable computation cost. We overcome this challenge by introducing a symbolic modeling approach for the FOL operators, emphasizing the direct calculation of the intersection between geometric shapes, particularly sector-cones in the embedding space, to model the conjunction operator. This approach reduces the computation cost as a non-neural approach is involved in the core logic operators. Moreover, we propose to accelerate the learning in the relation projection operator using the neural approach to emphasize the essential role of this operator in all query structures. Although empirical evidence for explainability is challenging, our approach demonstrates a significant improvement in answering complex logical queries (both non-negative and negative FOL forms) over previous geometric-based models. © 2023 Association for Computational Linguistics.",Final,
Banerjee D.,"Banerjee, Debayan (57204184497)",57204184497,Semantic Parsing for Knowledge Graph Question Answering with Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176013413&doi=10.1007%2f978-3-031-43458-7_42&partnerID=40&md5=20cbd9c7fa7e8a0b0b0c9008f65e33a5,"This thesis explores the topic of Knowledge Graph Question Answering with a special emphasis on semantic parsing approaches, incorporating pre-trained text-to-text language models. We use the text generation ability of these models to convert natural language questions to logical forms. We test whether correct logical forms are being generated, and if not, how to mitigate the failure cases. As a second step, we try to make the same models generate additional information to aid the process of grounding of the logical forms to entities, relations and literals in the Knowledge Graph. In experiments conducted so far, we see encouraging results on both generation of base logical forms, and grounding them to the KG elements. At the same time, we discover failure cases prompting directions in future work (The author considers himself a ‘middle-stage’ Ph.D. candidate). © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
Zhao Y.; Wu Y.; Cai X.; Zhang Y.; Zhang H.; Yuan X.,"Zhao, Yu (57909140900); Wu, Yike (57210586635); Cai, Xiangrui (55954059800); Zhang, Ying (55954386400); Zhang, Haiwei (35118347900); Yuan, Xiaojie (57218614021)",57909140900; 57210586635; 55954059800; 55954386400; 35118347900; 57218614021,From Alignment to Entailment: A Unified Textual Entailment Framework for Entity Alignment,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175475156&partnerID=40&md5=5dd4a6f41ee9dbe503b2172ea1b06b93,"Entity Alignment (EA) aims to find the equivalent entities between two Knowledge Graphs (KGs). Existing methods usually encode the triples of entities as embeddings and learn to align the embeddings, which prevents the direct interaction between the original information of the cross-KG entities. Moreover, they encode the relational triples and attribute triples of an entity in heterogeneous embedding spaces, which prevents them from helping each other. In this paper, we transform both triples into unified textual sequences, and model the EA task as a bi-directional textual entailment task between the sequences of cross-KG entities. Specifically, we feed the sequences of two entities simultaneously into a pre-trained language model (PLM) and propose two kinds of PLM-based entity aligners that model the entailment probability between sequences as the similarity between entities. Our approach captures the unified correlation pattern of two kinds of information between entities, and explicitly models the fine-grained interaction between original entity information. The experiments on five cross-lingual EA datasets show that our approach outperforms the state-of-the-art EA methods and enables the mutual enhancement of the heterogeneous information. Codes are available at https://github.com/OreOZhao/TEA. © 2023 Association for Computational Linguistics.",Final,
Abacha A.B.; Yim W.-W.; Michalopoulos G.; Lin T.,"Abacha, Asma Ben (51664696400); Yim, Wen-Wai (57191829247); Michalopoulos, George (58584898000); Lin, Thomas (57345102700)",51664696400; 57191829247; 58584898000; 57345102700,An Investigation of Evaluation Metrics for Automated Medical Note Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175452393&partnerID=40&md5=1bbd234f2cf73d27c511dcf23316656a,"Recent studies on automatic note generation have shown that doctors can save significant amounts of time when using automatic clinical note generation (Knoll et al., 2022). Summarization models have been used for this task to generate clinical notes as summaries of doctor-patient conversations (Krishna et al., 2021; Cai et al., 2022). However, assessing which model would best serve clinicians in their daily practice is still a challenging task due to the large set of possible correct summaries, and the potential limitations of automatic evaluation metrics. In this paper, we study evaluation methods and metrics for the automatic generation of clinical notes from medical conversations. In particular, we propose new task-specific metrics and we compare them to SOTA evaluation metrics in text summarization and generation, including: (i) knowledge-graph embedding-based metrics, (ii) customized model-based metrics, (iii) domain-adapted/fine-tuned metrics, and (iv) ensemble metrics. To study the correlation between the automatic metrics and manual judgments, we evaluate automatic notes/summaries by comparing the system and reference facts and computing the factual correctness, and the hallucination and omission rates for critical medical facts. This study relied on seven datasets manually annotated by domain experts. Our experiments show that automatic evaluation metrics can have substantially different behaviors on different types of clinical notes datasets. However, the results highlight one stable subset of metrics as the most correlated with human judgments with a relevant aggregation of different evaluation criteria. © 2023 Association for Computational Linguistics.",Final,
Yang D.; Wang X.; Celebi R.,"Yang, Dong (58666427900); Wang, Xu (58747254900); Celebi, Remzi (16642228900)",58666427900; 58747254900; 16642228900,Expanding the Vocabulary of BERT for Knowledge Base Construction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179556106&partnerID=40&md5=573d7d647e57f6d728e501a00a111cb5,"Knowledge base construction entails acquiring structured information to create a knowledge base of factual and relational data, facilitating question answering, information retrieval, and semantic understanding. The challenge called”Knowledge Base Construction from Pretrained Language Models” at International Semantic Web Conference 2023 defines tasks focused on constructing knowledge base using language model. Our focus was on Track 1 of the challenge, where the parameters are constrained to a maximum of 1 billion, and the inclusion of entity descriptions within the prompt is prohibited. Although the masked language model offers sufficient flexibility to extend its vocabulary, it is not inherently designed for multi-token prediction. To address this, we present Vocabulary Expandable BERT for knowledge base construction, which expand the language model’s vocabulary while preserving semantic embeddings for newly added words. We adopt task-specific re-pre-training on masked language model to further enhance the language model. Through experimentation, the results show the effectiveness of our approaches. Our framework achieves F1 score of 0.323 on the hidden test set and 0.362 on the validation set, both data set is provided by the challenge. Notably, our framework adopts a lightweight language model (BERT-base, 0.13 billion parameters) and surpasses the model using prompts directly on large language model (Chatgpt-3, 175 billion parameters). Besides, Token-Recode achieves comparable performances as Re-pretrain. This research advances language understanding models by enabling the direct embedding of multi-token entities, signifying a substantial step forward in link prediction task in knowledge graph and metadata completion in data management. 1 © 2023 CEUR-WS. All rights reserved.",Final,
Martino A.; Iannelli M.; Truong C.,"Martino, Ariana (58101457500); Iannelli, Michael (56394225400); Truong, Coleen (58684637300)",58101457500; 56394225400; 58684637300,Knowledge Injection to Counter Large Language Model (LLM) Hallucination,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175947794&doi=10.1007%2f978-3-031-43458-7_34&partnerID=40&md5=f338feecc105efe53da2e424217aa790,"A shortfall of Large Language Model (LLM) content generation is hallucination, i.e., including false information in the output. This is especially risky for enterprise use cases that require reliable, fact-based, controllable text generation at scale. To mitigate this, we utilize a technique called Knowledge Injection (KI), where contextual data about the entities relevant to a text-generation task is mapped from a knowledge graph to text space for inclusion in an LLM prompt. Using the task of responding to online customer reviews of retail locations as an example, we have found that KI increases the count of correct assertions included in generated text. In a qualitative review, fine-tuned bloom-560m with KI outperformed a non-fine-tuned text-davinci-003 model from OpenAI, though text-davinci-003 has 300 times more parameters. Thus, the KI method can increase enterprise users’ confidence leveraging LLMs to replace tedious manual text generation and enable better performance from smaller, cheaper models. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
Gao Y.; He Y.; Kan Z.; Han Y.; Qiao L.; Li D.,"Gao, Yifu (57237688500); He, Yongquan (57219876375); Kan, Zhigang (57216617055); Han, Yi (57219488645); Qiao, Linbo (55388192300); Li, Dongsheng (57204110845)",57237688500; 57219876375; 57216617055; 57219488645; 55388192300; 57204110845,Learning Joint Structural and Temporal Contextualized Knowledge Embeddings for Temporal Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175468634&partnerID=40&md5=58ccb28e6556179cae64f3e6cb71e9e9,"Temporal knowledge graph completion that predicts missing links for incomplete temporal knowledge graphs (TKG) is gaining increasing attention. Most existing works have achieved good results by incorporating time information into static knowledge graph embedding methods. However, they ignore the contextual nature of the TKG structure, i.e., query-specific subgraph contains both structural and temporal neighboring facts. This paper presents the SToKE, a novel method that employs the pre-trained language model (PLM) to learn joint Structural and Temporal Contextualized Knowledge Embeddings. Specifically, we first construct an event evolution tree (EET) for each query to enable PLMs to handle the TKG, which can be seen as a structured event sequence recording query-relevant structural and temporal contexts. We then propose a novel temporal embedding and structural matrix to learn the time information and structural dependencies of facts in EET. Finally, we formulate TKG completion as a mask prediction problem by masking the missing entity of the query to fine-tune pre-trained language models. Experimental results on three widely used datasets show the superiority of our model. © 2023 Association for Computational Linguistics.",Final,
Pei S.; Zhang Q.; Zhang X.,"Pei, Shichao (57205549229); Zhang, Qiannan (57202024870); Zhang, Xiangliang (9238032200)",57205549229; 57202024870; 9238032200,Few-shot Low-resource Knowledge Graph Completion with Reinforced Task Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175459090&partnerID=40&md5=f4acac0cbcbb080440d32c65253ff966,"Despite becoming a prevailing paradigm for organizing knowledge, most knowledge graphs (KGs) suffer from the low-resource issue due to the deficiency of data sources. The enrichment of KGs by automatic knowledge graph completion is impeded by the intrinsic long-tail property of KGs. In spite of their prosperity, existing few-shot learning-based models have difficulty alleviating the impact of the long-tail issue on low-resource KGs because of the lack of training tasks. To tackle the challenging long-tail issue on low-resource KG completion, in this paper, we propose a novel few-shot low-resource knowledge graph completion framework, which is composed of three components, i.e., few-shot learner, task generator, and task selector. The key idea is to generate and then select the beneficial few-shot tasks that complement the current tasks and enable the optimization of the few-shot learner using the selected few-shot tasks. Extensive experiments conducted on several real-world knowledge graphs validate the effectiveness of our proposed method. © 2023 Association for Computational Linguistics.",Final,
Dasoulas I.; Yang D.; Duan X.; Dimou A.,"Dasoulas, Ioannis (58635301000); Yang, Duo (58753732300); Duan, Xuemin (58753457300); Dimou, Anastasia (55236344100)",58635301000; 58753732300; 58753457300; 55236344100,TorchicTab: Semantic Table Annotation with Wikidata and Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179133798&partnerID=40&md5=3a2c12804e5395023d68961b926a484e,"An abundance of tabular data exists and is used by a wide range of applications. However, a big portion of these data lack the semantic information necessary for users and machines to properly understand them. This lack of table semantic understanding impedes their usage in data analytics pipelines. Solutions to semantically interpret tables exist but they are focused on specific annotation tasks and types of tables, and rely on large knowledge bases, making it difficult to re-use in real-world settings. Thus, more robust systems that produce more precise annotations and adapt to different table types are needed. The Semantic Web Challenge on Tabular Data to Knowledge Graph Matching (SemTab) was introduced in an effort to benchmark semantic table interpretation systems, by evaluating them over diverse datasets and tasks. In this paper, we introduce TorchicTab, a versatile semantic table interpretation system able to annotate tables with varied structures by using either an external knowledge graph, such as Wikidata, or annotated tables with pre-defined terms for training. We evaluate our proposed system according to the different annotation tasks of the SemTab challenge. The results show that our system can produce accurate annotations for different tasks across varied datasets. © 2023 CEUR-WS. All rights reserved.",Final,
Xu Z.; Yuan J.; Pan M.; Tian S.; Song L.,"Xu, Zishang (57214002013); Yuan, Jindou (57197717936); Pan, Mingming (55356337600); Tian, Shiming (7202367439); Song, Lei (57220195685)",57214002013; 57197717936; 55356337600; 7202367439; 57220195685,Analysis of Electricity Safety in Scientific Research and Production Sites: A Novel HMM-VA-based Knowledge Graph Approach,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175082872&doi=10.1109%2fICSECE58870.2023.10263563&partnerID=40&md5=5d70269d4152f89800b2ba68bb79f5d7,"The electricity load in scientific research and production sites is large, and the impact of electrical safety accidents is difficult to estimate. It is crucial to analyze the potential safety hazards and causes of safety accidents in these sites. Most of the traditional methods are generally realized through gradual troubleshooting of low-voltage terminal distribution system, power quality of electrical equipment, grounding system, but these methods are difficult to quickly and accurately determine the characteristics of hidden trouble. For this reason, this paper proposes an analysis method of potential safety hazards of power consumption in scientific research and production sites based on knowledge graph. Firstly, this paper extracts the unstructured security risk data and constructs an elastic search (ES) to store the risk data. Secondly, we utilized the Chineseword segmentation model based on self-attention mechanism-guided by syntactic dependency (AM-GSD) for word segmentation training on data within the engine and implemented the annotation of hidden entity word segmentation. Finally, this paper uses Neo4j Graph database to build a knowledge graph of power safety hazards, and realizes the analysis of power safety hazards in scientific research and production sites. The method proposed in this paper has been tested and verified by the actual data of safe power utilization in a scientific research site. The experimental results show that the proposed method can effectively display and retrieve hidden danger data.  © 2023 IEEE.",Final,
Kochsiek A.; Saxena A.; Nair I.; Gemulla R.,"Kochsiek, Adrian (57488409100); Saxena, Apoorv (57225711426); Nair, Inderjeet (57388598500); Gemulla, Rainer (9940328100)",57488409100; 57225711426; 57388598500; 9940328100,Friendly Neighbors: Contextualized Sequence-to-Sequence Link Prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174524681&partnerID=40&md5=708f582e220246f5fea4aefe9f1fb6d9,"We propose KGT5-context, a simple sequence-to-sequence model for link prediction (LP) in knowledge graphs (KG). Our work expands on KGT5, a recent LP model that exploits textual features of the KG, has small model size, and is scalable. To reach good predictive performance, however, KGT5 relies on an ensemble with a knowledge graph embedding model, which itself is excessively large and costly to use. In this short paper, we show empirically that adding contextual information—i.e., information about the direct neighborhood of the query entity—alleviates the need for a separate KGE model to obtain good performance. The resulting KGT5-context model is simple, reduces model size significantly, and obtains state-of-the-art performance in our experimental study. © 2023 Association for Computational Linguistics.",Final,
Kovriguina L.; Teucher R.; Radyush D.; Mouromtsev D.,"Kovriguina, Liubov (56119059000); Teucher, Roman (57803401500); Radyush, Daniil (58234958500); Mouromtsev, Dmitry (55575780100)",56119059000; 57803401500; 58234958500; 55575780100,SPARQLGEN: One-Shot Prompt-based Approach for SPARQL Query Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176588073&partnerID=40&md5=c408e2ce15847ce28f17e9d1edb1c112,"In this work, we present a one-shot generative approach (further referred to as SPARQLGEN) for generating SPARQL queries by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. The prompt includes heterogeneous data sources: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query for a different question. In the experiments, GPT-3, a popular pre-trained language model from OpenAI, was leveraged, but it is possible to extend the approach to any other generative LLM. We evaluate, how different types of context in the prompt influence the query generation performance on QALD-9, QALD-10 and Bestiary dataset (BESTIARY), which was created to test LLM performance on unseen data, and provide a detailed error analysis. One of the findings is that providing the model with the underlying KG and a random correct query improve the generation results. The approach shows strong results on QALD-9 dataset, but doesn’t generalize on QALD-10 and BESTIARY which can be caused by memorization problem. © 2023 CEUR-WS. All rights reserved.",Final,
Ding R.; Han X.; Wang L.,"Ding, Ruiqing (57225218588); Han, Xiao (55844318500); Wang, Leye (56404299600)",57225218588; 55844318500; 56404299600,A Unified Knowledge Graph Augmentation Service for Boosting Domain-specific NLP Tasks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175423729&partnerID=40&md5=67d897a41eaf2f48fb8b2d3fbb3f6312,"By focusing the pre-training process on domain-specific corpora, some domain-specific pre-trained language models (PLMs) have achieved state-of-the-art results. However, it is under-investigated to design a unified paradigm to inject domain knowledge in the PLM fine-tuning stage. We propose KnowledgeDA, a unified domain language model development service to enhance the task-specific training procedure with domain knowledge graphs. Given domain-specific task texts input, KnowledgeDA can automatically generate a domain-specific language model following three steps: (i) localize domain knowledge entities in texts via an embedding-similarity approach; (ii) generate augmented samples by retrieving replaceable domain entity pairs from two views of both knowledge graph and training data; (iii) select high-quality augmented samples for fine-tuning via confidence-based assessment. We implement a prototype of KnowledgeDA to learn language models for two domains, healthcare and software development. Experiments on domain-specific text classification and QA tasks verify the effectiveness and generalizability of KnowledgeDA. © 2023 Association for Computational Linguistics.",Final,
Kobbe J.; Hulpus I.; Stuckenschmidt H.,"Kobbe, Jonathan (57209539404); Hulpus, Ioana (36188149800); Stuckenschmidt, Heiner (6603168933)",57209539404; 36188149800; 6603168933,Effect Graph: Effect Relation Extraction for Explanation Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175400704&partnerID=40&md5=3a29b2de5a22558f6e75a31b4ee893c0,"Argumentation is an important means of communication. For describing especially arguments about consequences, the notion of effect relations has been introduced recently. We propose a method to extract effect relations from large text resources and apply it on encyclopedic and argumentative texts. By connecting the extracted relations, we generate a knowledge graph which we call effect graph. For evaluating the effect graph, we perform crowd and expert annotations and create a novel dataset. We demonstrate a possible use case of the effect graph by proposing a method for explaining arguments from consequences.  © 2023 Association for Computational Linguistics.",Final,
Chen C.; Wang Y.; Sun A.; Li B.; Lam K.-Y.,"Chen, Chen (58383960100); Wang, Yufei (58747837700); Sun, Aixin (7202552214); Li, Bing (57226853550); Lam, Kwok-Yan (7403657062)",58383960100; 58747837700; 7202552214; 57226853550; 7403657062,Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge Graph Completion via Conditional Soft Prompting,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174996064&partnerID=40&md5=ba58b92d176716748977b1cef3b004d3,"Knowledge Graph Completion (KGC) often requires both KG structural and textual information to be effective. Pre-trained Language Models (PLMs) have been used to learn the textual information, usually under the fine-tune paradigm for the KGC task. However, the fine-tuned PLMs often overwhelmingly focus on the textual information and overlook structural knowledge. To tackle this issue, this paper proposes CSProm-KG (Conditional Soft Prompts for KGC) which maintains a balance between structural information and textual knowledge. CSProm-KG only tunes the parameters of Conditional Soft Prompts that are generated by the entities and relations representations. We verify the effectiveness of CSProm-KG on three popular static KGC benchmarks WN18RR, FB15K-237 and Wikidata5M, and two temporal KGC benchmarks ICEWS14 and ICEWS05-15. CSProm-KG outperforms competitive baseline models and sets new state-of-the-art on these benchmarks. We conduct further analysis to show (i) the effectiveness of our proposed components, (ii) the efficiency of CSProm-KG, and (iii) the flexibility of CSProm-KG. © 2023 Association for Computational Linguistics.",Final,
Baldazzi T.; Bellomarini L.; Ceri S.; Colombo A.; Gentili A.; Sallinger E.,"Baldazzi, Teodoro (57222901657); Bellomarini, Luigi (25521393800); Ceri, Stefano (7006299676); Colombo, Andrea (58569614300); Gentili, Andrea (57219337681); Sallinger, Emanuel (37011472400)",57222901657; 25521393800; 7006299676; 58569614300; 57219337681; 37011472400,Fine-Tuning Large Enterprise Language Models via Ontological Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175989701&doi=10.1007%2f978-3-031-45072-3_6&partnerID=40&md5=c9ebc64aabb63e310c2b6e85edf9a58a,"Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Li J.; Li X.; Hu L.; Zhang Y.; Wang J.,"Li, Jie (56404475300); Li, Xuan (57216515839); Hu, Linmei (56181376700); Zhang, Yirui (58261134600); Wang, Jinrui (58315247800)",56404475300; 57216515839; 56181376700; 58261134600; 58315247800,Knowledge Graph Enhanced Language Models for Sentiment Analysis,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177198266&doi=10.1007%2f978-3-031-47240-4_24&partnerID=40&md5=c2f4ad8cc2613a8b6347bf98bfc6f2ce,"Pre-trained language models (LMs) have been widely used in sentiment analysis, and some recent works have focused on injecting sentiment knowledge from sentiment lexicons or structured commonsense knowledge from knowledge graphs (KGs) into pre-trained LMs, which have achieved remarkable success. However, these works often only obtain knowledge from a single source in either the sentiment lexicon or the KG, and only perform very shallow fusion of LM representations and external knowledge representations. Therefore, how to effectively extract multiple sources of external knowledge and fully integrate them with the LM representations is still an unresolved issue. In this paper, we propose a novel knowledge enhanced model for sentiment analysis (KSA), which simultaneously incorporates commonsense and sentiment knowledge as external knowledge, by constructing a heterogeneous Commonsense-Senti Knowledge Graph. Additionally, a separate global token and global node are added to the text sequence and constructed knowledge graph respectively, and a fusion unit is used to enable global information interaction between the different modalities, allowing them to perceive each other’s information and thereby improving the ability to perform sentiment analysis. Experiments on standard datasets show that our proposed KSA significantly outperforms the strong pre-trained baselines, and achieves new state-of-the-art results on most of the test datasets. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Chen Y.; Zhang Y.; Yu J.; Yang L.; Xia R.,"Chen, Yunlong (57221813265); Zhang, Yaming (58698196000); Yu, Jianfei (56900043100); Yang, Li (57229647200); Xia, Rui (36847284600)",57221813265; 58698196000; 56900043100; 57229647200; 36847284600,In-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176912695&doi=10.1007%2f978-981-99-7224-1_26&partnerID=40&md5=29b5937dcb0c64742c0190230ec6c29f,"Knowledge Base Question Answering (KBQA) aims to answer factoid questions based on knowledge bases. However, generating the most appropriate knowledge base query code based on Natural Language Questions (NLQ) poses a significant challenge in KBQA. In this work, we focus on the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems. Inspired by the recent success of large language models (LLMs) like ChatGPT and GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL) generation framework to generate the most appropriate CQL based on the given NLQ. Our generative framework contains six parts: an auxiliary model predicting the syntax-related information of CQL based on the given NLQ, a proper noun matcher extracting proper nouns from the given NLQ, a demonstration example selector retrieving similar examples of the input sample, a prompt constructor designing the input template of ChatGPT, a ChatGPT-based generation model generating the CQL, and an ensemble model to obtain the final answers from diversified outputs. With our ChatGPT-based CQL generation framework, we achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition, achieving an F1-score of 0.92676. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,All Open Access; Green Open Access
Xu Y.; He S.; Cai L.; Liu K.; Zhao J.,"Xu, Yao (36697356200); He, Shizhu (56021680600); Cai, Li (55145480500); Liu, Kang (55729555700); Zhao, Jun (57190004147)",36697356200; 56021680600; 55145480500; 55729555700; 57190004147,Prediction and Calibration: Complex Reasoning over Knowledge Graph with Bi-directional Directed Acyclic Graph Neural Network,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175425560&partnerID=40&md5=a3549251c505b1a77776524a40c303e2,"Answering complex logical queries is a challenging task for knowledge graph (KG) reasoning. Recently, query embedding (QE) has been proposed to encode queries and entities into the same vector space, and obtain answers based on numerical computation. However, such models obtain the node representations of a query only based on its predecessor nodes, which ignore the information contained in successor nodes. In this paper, we proposed a Bi-directional Directed Acyclic Graph neural network (BiDAG) that splits the reasoning process into prediction and calibration. The joint probability of all nodes is considered by applying a graph neural network (GNN) to the query graph in the calibration process. By the prediction in the first layer and the calibration in deep layers of GNN, BiDAG can outperform previous QE based methods on FB15k, FB15k-237, and NELL995. © 2023 Association for Computational Linguistics.",Final,
Zanella L.; Toussaint Y.,"Zanella, Laura (58655977000); Toussaint, Yannick (11839190100)",58655977000; 11839190100,How Much do Knowledge Graphs Impact Transformer Models for Extracting Biomedical Events?,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174513210&partnerID=40&md5=17dca50b23da760688dc71136bbe19ad,"Biomedical event extraction can be divided into three main subtasks; (1) biomedical event trigger detection, (2) biomedical argument identification and (3) event construction. This work focuses in the two first subtasks. For the first subtask we analyze a set of transformer language models that are commonly used in the biomedical domain to evaluate and compare their capacity for event trigger detection. We fine-tune the models using seven manually annotated corpora to assess their performance in different biomedical subdomains. SciBERT emerged as the highest performing model, presenting a slight improvement compared to baseline models. Then, for the second subtask we construct a knowledge graph (KG) from the biomedical corpora and integrate its KG embeddings to SciBERT to enrich its semantic information. We demonstrate that adding the KG embeddings to the model improves the argument identification performance by around 20 %, and by around 15 % compared to two baseline models. Our results suggest that fine-tuning a transformer model that is pretrained from scratch with biomedical and general data allows to detect event triggers and identify arguments covering different biomedical subdomains, and therefore improving its generalization. Furthermore, the integration of KG embeddings into the model can significantly improve the performance of biomedical event argument identification, outperforming the results of baseline models. © 2023 Association for Computational Linguistics.",Final,
Nayyeri M.; Xiong B.; Mohammadi M.; Akter M.; Alam M.M.; Lehmann J.; Staab S.,"Nayyeri, Mojtaba (35776892400); Xiong, Bo (57221322184); Mohammadi, Majid (58675736400); Akter, Mahfuja (57852007600); Alam, Mirza Mohtashim (57202902190); Lehmann, Jens (35229806900); Staab, Steffen (7004053291)",35776892400; 57221322184; 58675736400; 57852007600; 57202902190; 35229806900; 7004053291,Knowledge Graph Embeddings using Neural Itô Process: From Multiple Walks to Stochastic Trajectories,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175442611&partnerID=40&md5=369dd9f01cf9f181b5d9dd0b999b7c15,"Knowledge graphs mostly exhibit a mixture of branching relations, e.g., hasFriend, and complex structures, e.g., hierarchy and loop. Most knowledge graph embeddings have problems expressing them, because they model a specific relation r from a head h to tails by starting at the node embedding of h and transitioning deterministically to exactly one other point in the embedding space. We overcome this issue in our novel framework ItôE by modeling relations between nodes by relation-specific, stochastic transitions. Our framework is based on stochastic Itô processes, which operate on low-dimensional manifolds. ItôE is highly expressive and generic subsuming various state-of-the-art models operating on different, also non-Euclidean, manifolds. Experimental results show the superiority of ItôE over other deterministic embedding models with regard to the KG completion task. © 2023 Association for Computational Linguistics.",Final,
Bruno A.; Mazzeo P.L.; Chetouani A.; Tliba M.; Kerkouri M.A.,"Bruno, Alessandro (7102246682); Mazzeo, Pier Luigi (7004011845); Chetouani, Aladine (24829075700); Tliba, Marouane (57221318465); Kerkouri, Mohamed Amine (57226193942)",7102246682; 7004011845; 24829075700; 57221318465; 57226193942,Insights into Classifying and Mitigating LLMs' Hallucinations,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178666482&partnerID=40&md5=a80b8d1fe254ff592ac0b8fedd8bc186,"The widespread adoption of large language models (LLMs) across diverse AI applications is proof of the outstanding achievements obtained in several tasks, such as text mining, text generation, and question answering. However, LLMs are not exempt from drawbacks. One of the most concerning aspects regards the emerging problematic phenomena known as”Hallucinations”. They manifest in text generation systems, particularly in question-answering systems reliant on LLMs, potentially resulting in false or misleading information propagation. This paper delves into the underlying causes of AI hallucination and elucidates its significance in artificial intelligence. In particular, Hallucination classification is tackled over several tasks (Machine Translation, Question and Answer, Dialog Systems, Summarisation Systems, Knowledge Graph with LLMs, and Visual Question Answer). Additionally, we explore potential strategies to mitigate hallucinations, aiming to enhance the overall reliability of LLMs. Our research addresses this critical issue within the HeReFaNMi (Health-Related Fake News Mitigation) project, generously supported by NGI Search, dedicated to combating Health-Related Fake News dissemination on the Internet. This endeavour represents a concerted effort to safeguard the integrity of information dissemination in an age of evolving AI technologies. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Mihindukulasooriya N.; Tiwari S.; Enguix C.F.; Lata K.,"Mihindukulasooriya, Nandana (56406504100); Tiwari, Sanju (56599597000); Enguix, Carlos F. (8439182400); Lata, Kusum (57219452063)",56406504100; 56599597000; 8439182400; 57219452063,Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177480752&doi=10.1007%2f978-3-031-47243-5_14&partnerID=40&md5=1c27c2ef98334d3bf4705e71000882c4,"The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact extraction performance, ontology conformance, and hallucinations by LLMs. Furthermore, we provide results for two baseline models, Vicuna-13B and Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline results show that there is room for improvement using both Semantic Web and Natural Language Processing techniques. Resource Type: Evaluation Benchmark Source Repo: https://github.com/cenguix/Text2KGBench DOI: https://doi.org/10.5281/zenodo.7916716 License: Creative Commons Attribution (CC BY 4.0) © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Final,All Open Access; Green Open Access
Wang X.; Liu K.; Wang C.,"Wang, Xiao (58648395300); Liu, Kai (55619292137); Wang, Chunlei (58647886900)",58648395300; 55619292137; 58647886900,Knowledge-enhanced Pre-Training large language model for depression diagnosis and treatment,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174936763&doi=10.1109%2fCCIS59572.2023.10263217&partnerID=40&md5=af2d36b4525cac56d8c57c108b39b5ae,"Depression, a pervasive psychiatric disorder characterized by concealment, dependence on expert judgment, and a notable rate of misdiagnosis, poses a substantial burden on society. To enhance the diagnosis and treatment of depression, this study puts forth a proposition of employing knowledge-enhanced pre-Training technology leveraging large language models. By integrating domain knowledge and depression knowledge graph directives, the pre-Trained model undergoes optimization. Expert involvement in depression diagnosis and treatment fosters a guided learning process facilitated by expert feedback. Through the application of dialogue therapy, the efficacy of treatment is augmented. This technical approach aims to ameliorate the societal burden by improving the diagnosis and treatment of depressed individuals. © 2023 IEEE.",Final,
Wang Z.; Fei W.; Yin H.; Song Y.; Wong G.Y.; See S.,"Wang, Zihao (57202647584); Fei, Weizhi (58305083600); Yin, Hang (57274331100); Song, Yangqiu (58787931000); Wong, Ginny Y. (57938989500); See, Simon (7004029208)",57202647584; 58305083600; 57274331100; 58787931000; 57938989500; 7004029208,Wasserstein-Fisher-Rao Embedding: Logical Query Embeddings with Local Comparison and Global Transport,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175427076&partnerID=40&md5=e1ca33352d9b18704d6cce5d1c97034a,"Answering complex queries on knowledge graphs is important but particularly challenging because of the data incompleteness. Query embedding methods address this issue by learning-based models and simulating logical reasoning with set operators. Previous works focus on specific forms of embeddings, but scoring functions between embeddings are underexplored. In contrast to existing scoring functions motivated by local comparison or global transport, this work investigates the local and global trade-off with unbalanced optimal transport theory. Specifically, we embed sets as bounded measures in R endowed with a scoring function motivated by the Wasserstein-Fisher-Rao metric. Such a design also facilitates closed-form set operators in the embedding space. Moreover, we introduce a convolution-based algorithm for linear time computation and a block-diagonal kernel to enforce the trade-off. Results show that WFRE can outperform existing query embedding methods on standard datasets, evaluation sets with combinatorially complex queries, and hierarchical knowledge graphs. Ablation study shows that finding a better local and global trade-off is essential for performance improvement. © 2023 Association for Computational Linguistics.",Final,
Meyer L.-P.; Frey J.; Junghanns K.; Brei F.; Bulert K.; Gründer-Fahrer S.; Martin M.,"Meyer, Lars-Peter (56103867800); Frey, Johannes (57201725937); Junghanns, Kurt (57191845999); Brei, Felix (58621475600); Bulert, Kirill (56584463500); Gründer-Fahrer, Sabine (57191623980); Martin, Michael (57061281900)",56103867800; 57201725937; 57191845999; 58621475600; 56584463500; 57191623980; 57061281900,Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176615313&partnerID=40&md5=8bb63c61f9bb09fa2d3e4e779ce7889a,"As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance. © 2023 CEUR-WS. All rights reserved.",Final,
Liu Y.; Zhang K.; Huang Z.; Wang K.; Zhang Y.; Liu Q.; Chen E.,"Liu, Ye (57221998149); Zhang, Kai (58376409600); Huang, Zhenya (57192675168); Wang, Kehang (58310819600); Zhang, Yanghai (58675905600); Liu, Qi (56382635200); Chen, Enhong (35228685900)",57221998149; 58376409600; 57192675168; 58310819600; 58675905600; 56382635200; 35228685900,Enhancing Hierarchical Text Classification through Knowledge Graph Integration,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175436966&partnerID=40&md5=8d2bae4a38c093d955d67ea7d86fe118,"Hierarchical Text Classification (HTC) is an essential and challenging subtask of multi-label text classification with a taxonomic hierarchy. Recent advances in deep learning and pre-trained language models have led to significant breakthroughs in the HTC problem. However, despite their effectiveness, these methods are often restricted by a lack of domain knowledge, which leads them to make mistakes in a variety of situations. Generally, when manually classifying a specific document to the taxonomic hierarchy, experts make inference based on their prior knowledge and experience. For machines to achieve this capability, we propose a novel Knowledge-enabled Hierarchical Text Classification model (K-HTC), which incorporates knowledge graphs into HTC. Specifically, K-HTC innovatively integrates knowledge into both the text representation and hierarchical label learning process, addressing the knowledge limitations of traditional methods. Additionally, a novel knowledge-aware contrastive learning strategy is proposed to further exploit the information inherent in the data. Extensive experiments on two publicly available HTC datasets show the efficacy of our proposed method, and indicate the necessity of incorporating knowledge graphs in HTC tasks. © 2023 Association for Computational Linguistics.",Final,
Tang J.; Zhao K.; Li J.,"Tang, Jianheng (57216618053); Zhao, Kangfei (57016004700); Li, Jia (57203396812)",57216618053; 57016004700; 57203396812,A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175488767&partnerID=40&md5=4b0b89f060a435bb400afb20188a8431,"Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 distinct KGs across five languages. Without any supervision or hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including cutting-edge supervised entity alignment methods. Our code is available at https://github.com/squareRoot3/FusedGW-Entity-Alignment. © 2023 Association for Computational Linguistics.",Final,
Pitarch L.,"Pitarch, Lucía (58653774200)",58653774200,Metaphor Processing in the Medical Domain via Linked Data and Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175983396&doi=10.1007%2f978-3-031-43458-7_40&partnerID=40&md5=dc7cde246a02de5be71c8e0750a0067f,"This thesis proposes a hybrid approach that benefits from Natural Language Processing and Semantic Web technologies for computational metaphor processing. Metaphors are linguistic devices that enable us to perceive and express a concept in terms of another similar one. Designing systems that allow their explicit identification and interpretation can highly facilitate communication in sensitive and obscure contexts such as the medical one. This proposal seeks the identification, understanding, generation, and manipulation of metaphors while providing novel datasets and baselines to exploit Languages Models and Linked Data in the context of figurative knowledge. The developed methodologies will be validated by their application into a specific communication tool between cancer patients and healthcare professionals. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.",Final,
Banerjee D.; Nair P.A.; Usbeck R.; Biemann C.,"Banerjee, Debayan (57204184497); Nair, Pranav Ajit (57414812400); Usbeck, Ricardo (43661711000); Biemann, Chris (8538613800)",57204184497; 57414812400; 43661711000; 8538613800,The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175442200&partnerID=40&md5=78a8f96394f6ae0dd3411cd2ff674e15,"In this work, we analyse the role of output vocabulary for text-to-text (T2T) models on the task of SPARQL semantic parsing. We perform experiments within the the context of knowledge graph question answering (KGQA), where the task is to convert questions in natural language to the SPARQL query language. We observe that the query vocabulary is distinct from human vocabulary. Language Models (LMs) are pre-dominantly trained for human language tasks, and hence, if the query vocabulary is replaced with a vocabulary more attuned to the LM tokenizer, the performance of models may improve. We carry out carefully selected vocabulary substitutions on the queries and find absolute gains in the range of 17% on the GrailQA dataset. © 2023 Association for Computational Linguistics.",Final,
Cadeddu A.; Chessa A.; De Leo V.; Fenu G.; Motta E.; Osborne F.; Recupero D.R.; Salatino A.; Secchi L.,"Cadeddu, Andrea (50661090000); Chessa, Alessandro (6604050350); De Leo, Vincenzo (57201282816); Fenu, Gianni (24469552000); Motta, Enrico (7006092143); Osborne, Francesco (36675585600); Recupero, Diego Reforgiato (57206674454); Salatino, Angelo (57188026200); Secchi, Luca (6602677456)",50661090000; 6604050350; 57201282816; 24469552000; 7006092143; 36675585600; 57206674454; 57188026200; 6602677456,Leveraging Knowledge Graphs with Large Language Models for Classification Tasks in the Tourism Domain,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178565843&partnerID=40&md5=37d0529ba5c1b6aa5e9028c19fc5edb0,"Online platforms, serving as the primary conduit for travelers to seek, compare, and secure travel accommodations, require a profound understanding of user dynamics to craft competitive and enticing offerings. Concurrently, recent advancements in Natural Language Processing, particularly large language models, have made substantial strides in capturing the complexity of human language. Simultaneously, knowledge graphs have become a formidable instrument for structuring and categorizing information. This paper introduces a cutting-edge deep learning methodology integrating large language models with domain-specific knowledge graphs to classify tourism offers. It aims at aiding hospitality operators in understanding their accommodation offerings’ market positioning, taking into account the visit propensity and user review ratings, with the goal of optimizing the offers themselves and enhancing their appeal. Comparative analysis against alternative methods on two datasets of London accommodation offers attests to our approach’s effectiveness, demonstrating superior results. © 2022 Copyright for this paper by its authors.",Final,
Xie Z.; Zhang Y.; Liu J.; Zhou G.; Huang J.X.,"Xie, Zhiwen (57190001632); Zhang, Yi (57432872200); Liu, Jin (55978402400); Zhou, Guangyou (54581936100); Huang, Jimmy Xiangji (57189975304)",57190001632; 57432872200; 55978402400; 54581936100; 57189975304,Learning Query Adaptive Anchor Representation for Inductive Relation Prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175465670&partnerID=40&md5=977dac724b605bb78ad93d52980e2444,"Relation prediction on knowledge graphs (KGs) attempts to infer the missing links between entities. Most previous studies are limited to the transductive setting where all entities must be seen during the training, making them unable to perform reasoning on emerging entities. Recently, the inductive setting is proposed to handle the entities in the test phase to be unseen during training, However, it suffers from the inefficient reasoning under the enclosing subgraph extraction issue and the lack of effective entity-independent feature modeling. To this end, we propose a novel Query Adaptive Anchor Representation (QAAR) model for inductive relation prediction. First, we extract one opening subgraph and perform reasoning by one time for all candidate triples, which is more efficient when the number of candidate triples is large. Second, we define some query adaptive anchors which are independent on any specific entity. Based on these anchors, we take advantage of the transferable entity-independent features (relation-aware, structure-aware and distance features) that can be used to produce entity embeddings for emerging unseen entities. Such entity-independent features is modeled by a query-aware graph attention network on the opening subgraph. Experimental results demonstrate that our proposed QAAR outperforms state-of-the-art baselines in inductive relation prediction task. © 2023 Association for Computational Linguistics.",Final,
Ji Z.; Liu Z.; Lee N.; Yu T.; Wilie B.; Zeng M.; Fung P.,"Ji, Ziwei (57221813204); Liu, Zihan (57216696454); Lee, Nayeon (57200084084); Yu, Tiezheng (57219737095); Wilie, Bryan (57209981152); Zeng, Min (57543046600); Fung, Pascale (7101613307)",57221813204; 57216696454; 57200084084; 57219737095; 57209981152; 57543046600; 7101613307,RHO (ρ): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174885369&partnerID=40&md5=90f4657ce88d1286f077772697b2fea7,"Dialogue systems can leverage large pretrained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, which further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO (ρ) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental results on OpenDialKG (Moon et al., 2019) show that our approach significantly outperforms state-of-the-art methods on both automatic and human evaluation by a large margin, especially in hallucination reduction (17.54% in FeQA (Durmus et al., 2020)). © 2023 Association for Computational Linguistics.",Final,
D’Souza J.; Hrou M.; Auer S.,"D’Souza, Jennifer (57215346447); Hrou, Moussab (58315250000); Auer, Sören (23391879500)",57215346447; 58315250000; 23391879500,Evaluating Prompt-Based Question Answering for Object Prediction in the Open Research Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174710939&doi=10.1007%2f978-3-031-39847-6_40&partnerID=40&md5=438467ddc816151f60bcade994dbc82d,"Recent investigations have explored prompt-based training of transformer language models for new text genres in low-resource settings. This approach has proven effective in transferring pre-trained or fine-tuned models to resource-scarce environments. This work presents the first results on applying prompt-based training to transformers for scholarly knowledge graph object prediction. Methodologically, it stands out in two main ways: 1) it deviates from previous studies that propose entity and relation extraction pipelines, and 2) it tests the method in a significantly different domain, scholarly knowledge, evaluating linguistic, probabilistic, and factual generalizability of large-scale transformer models. Our findings demonstrate that: i) out-of-the-box transformer models underperform on the new scholarly domain, ii) prompt-based training improves performance by up to 40% in relaxed evaluation, and iii) tests of the models in a distinct domain reveals a gap in capturing domain knowledge, highlighting the need for increased attention and resources in the scholarly domain for transformer models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Final,All Open Access; Green Open Access
Huang Z.; Wang D.; Huang B.; Zhang C.; Shang J.; Liang Y.; Wang Z.; Li X.; Faloutsos C.; Sun Y.; Wang W.,"Huang, Zijie (57217167601); Wang, Daheng (57203400180); Huang, Binxuan (57194796590); Zhang, Chenwei (57095203500); Shang, Jingbo (56355265600); Liang, Yan (57218843495); Wang, Zhengyang (57202439077); Li, Xian (57216211250); Faloutsos, Christos (7006005166); Sun, Yizhou (25823970300); Wang, Wei (58441698500)",57217167601; 57203400180; 57194796590; 57095203500; 56355265600; 57218843495; 57202439077; 57216211250; 7006005166; 25823970300; 58441698500,Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175457891&partnerID=40&md5=ae4068ae6fab8e057869078efcd852ab,"Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box. © 2023 Association for Computational Linguistics.",Final,
Baek J.; Aji A.F.; Saffari A.,"Baek, Jinheon (57219628188); Aji, Alham Fikri (58583850200); Saffari, Amir (23490141200)",57219628188; 58583850200; 23490141200,Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174114810&partnerID=40&md5=27ac98778013092ef97f0a665256db3b,"Large Language Models (LLMs) are capable of performing zero-shot closed-book question answering tasks, based on their internal knowledge stored in parameters during pre-training. However, such internalized knowledge might be insufficient and incorrect, which could lead LLMs to generate factually wrong answers. Furthermore, fine-tuning LLMs to update their knowledge is expensive. To this end, we propose to augment the knowledge directly in the input of LLMs. Specifically, we first retrieve the relevant facts to the input question from the knowledge graph based on semantic similarities between the question and its associated facts. After that, we prepend the retrieved facts to the input question in the form of the prompt, which is then forwarded to LLMs to generate the answer. Our framework, Knowledge-Augmented language model PromptING (KAPING), requires no model training, thus completely zero-shot. We validate the performance of our KAPING framework on the knowledge graph question answering task, that aims to answer the user's question based on facts over a knowledge graph, on which ours outperforms relevant zero-shot baselines by up to 48% in average, across multiple LLMs of various sizes.  © 2023 Association for Computational Linguistics.",Final,
Kim J.; Park S.; Kwon Y.; Jo Y.; Thorne J.; Choi E.,"Kim, Jiho (58382271300); Park, Sungjin (57219684803); Kwon, Yeonsu (58078253400); Jo, Yohan (58615299200); Thorne, James (58619226800); Choi, Edward (57188811144)",58382271300; 57219684803; 58078253400; 58615299200; 58619226800; 57188811144,FACTKG: Fact Verification via Reasoning on Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174216444&partnerID=40&md5=a63c2fbbd36e03243c29b316c2ace619,"In real world applications, knowledge graphs (KG) are widely used in various domains (e.g. medical applications and dialogue agents). However, for fact verification, KGs have not been adequately utilized as a knowledge source. KGs can be a valuable knowledge source in fact verification due to their reliability and broad applicability. A KG consists of nodes and edges which makes it clear how concepts are linked together, allowing machines to reason over chains of topics. However, there are many challenges in understanding how these machine-readable concepts map to information in text. To enable the community to better use KGs, we introduce a new dataset, FACTKG: Fact Verification via Reasoning on Knowledge Graphs. It consists of 108k natural language claims with five types of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore, FACTKG contains various linguistic patterns, including colloquial style claims as well as written style claims to increase practicality. Lastly, we develop a baseline approach and analyze FACTKG over these reasoning types. We believe FACTKG can advance both reliability and practicality in KG-based fact verification. © 2023 Association for Computational Linguistics.",Final,
Lin Q.; Liu J.; Mao R.; Xu F.; Cambria E.,"Lin, Qika (57204147391); Liu, Jun (55904548100); Mao, Rui (57207859287); Xu, Fangzhi (57372934200); Cambria, Erik (56140547500)",57204147391; 55904548100; 57207859287; 57372934200; 56140547500,TECHS: Temporal Logical Graph Networks for Explainable Extrapolation Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173795521&partnerID=40&md5=336fc0e39e4ee31e95ac87e33e8d5992,"Extrapolation reasoning on temporal knowledge graphs (TKGs) aims to forecast future facts based on past counterparts. There are two main challenges: (1) incorporating the complex information, including structural dependencies, temporal dynamics, and hidden logical rules; (2) implementing differentiable logical rule learning and reasoning for explainability. To this end, we propose an explainable extrapolation reasoning framework TEemporal logiCal grapH networkS (TECHS), which mainly contains a temporal graph encoder and a logical decoder. The former employs a graph convolutional network with temporal encoding and heterogeneous attention to embed topological structures and temporal dynamics. The latter integrates propositional reasoning and first-order reasoning by introducing a reasoning graph that iteratively expands to find the answer. A forward message-passing mechanism is also proposed to update node representations, and their propositional and first-order attention scores. Experimental results demonstrate that it outperforms state-of-the-art baselines. © 2023 Association for Computational Linguistics.",Final,
Feng S.; Tan Z.; Zhang W.; Lei Z.; Tsvetkov Y.,"Feng, Shangbin (57225889811); Tan, Zhaoxuan (57266978600); Zhang, Wenqian (58373085100); Lei, Zhenyu (57609586200); Tsvetkov, Yulia (51665958500)",57225889811; 57266978600; 58373085100; 57609586200; 51665958500,"KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174409644&partnerID=40&md5=dda074f8f244408ffd02885ec379c41e,"With the advent of pretrained language models (LMs), increasing research efforts have been focusing on infusing commonsense and domain-specific knowledge to prepare LMs for downstream tasks. These works attempt to leverage knowledge graphs, the de facto standard of symbolic knowledge representation, along with pretrained LMs. While existing approaches have leveraged external knowledge, it remains an open question how to jointly incorporate knowledge graphs representing varying contexts-from local (e.g., sentence), to document-level, to global knowledge-to enable knowledge-rich exchange across these contexts. Such rich contextualization can be especially beneficial for long document understanding tasks since standard pretrained LMs are typically bounded by the input sequence length. In light of these challenges, we propose KALM, a Knowledge-Aware Language Model that jointly leverages knowledge in local, document-level, and global contexts for long document understanding. KALM first encodes long documents and knowledge graphs into the three knowledge-aware context representations. It then processes each context with context-specific layers, followed by a “context fusion” layer that facilitates knowledge exchange to derive an overarching document representation. Extensive experiments demonstrate that KALM achieves state-of-the-art performance on six long document understanding tasks and datasets. Further analyses reveal that the three knowledge-aware contexts are complementary and they all contribute to model performance, while the importance and information exchange patterns of different contexts vary with respect to different tasks and datasets. © 2023 Association for Computational Linguistics.",Final,
Yu J.; Li Z.; Wang J.; Xia R.,"Yu, Jianfei (56900043100); Li, Ziyan (57217176348); Wang, Jieming (57888759200); Xia, Rui (36847284600)",56900043100; 57217176348; 57888759200; 36847284600,Grounded Multimodal Named Entity Recognition on Social Media,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174386283&partnerID=40&md5=86477ff48e0e3d1231aa3684ef05c102,"In recent years, Multimodal Named Entity Recognition (MNER) on social media has attracted considerable attention. However, existing MNER studies only extract entity-type pairs in text, which is useless for multimodal knowledge graph construction and insufficient for entity disambiguation. To solve these issues, in this work, we introduce a Grounded Multimodal Named Entity Recognition (GMNER) task. Given a text-image social post, GMNER aims to identify the named entities in text, their entity types, and their bounding box groundings in image (i.e., visual regions). To tackle the GMNER task, we construct a Twitter dataset based on two existing MNER datasets. Moreover, we extend four well-known MNER methods to establish a number of baseline systems and further propose a Hierarchical Index generation framework named H-Index, which generates the entity-type-region triples in a hierarchical manner with a sequence-to-sequence model. Experiment results on our annotated dataset demonstrate the superiority of our H-Index framework over baseline systems on the GMNER task. Our dataset annotation and source code are publicly released at https://github.com/NUSTM/GMNER. © 2023 Association for Computational Linguistics.",Final,
Yang Z.; Li Z.; Xu Z.; Gan Z.; Cao W.,"Yang, Zhixiang (57216695066); Li, Zihang (58616352400); Xu, Ziqing (58617163100); Gan, Zaobin (14029716400); Cao, Wanhua (7402082943)",57216695066; 58616352400; 58617163100; 14029716400; 7402082943,A Joint Relation Extraction Model Based on Domain N-Gram Adapter and Axial Attention for Military Domain,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172223070&doi=10.1007%2f978-981-99-6222-8_20&partnerID=40&md5=8458474d403d246a134832eab2a14fe8,"Domain-specific relation extraction plays an important role in constructing domain knowledge graph and further analysis. In the field of military intelligence relation extraction, there are challenges such as relation overlapping and exposure bias. Therefore, on the basis of a combination of domain N-gram adapter and axial attention, this paper presents a single-step joint relation extraction model for the field of military text analysis. Considering domain-specific language structures and patterns, the domain-specific N-gram adapter is incorporated into the pre-trained language model to improve the encoding of the proposed model. Furthermore, the axial attention mechanism is applied to capture the dependencies between token pairs and their contexts, so as to enhance the encoding representation ability of the proposed model. After that, entities and relations are jointly extracted by a relation-specific decoding method. The effectiveness of the proposed model is demonstrated through experiments on a military relation extraction dataset with F1-Score 0.6690 and CMeIE with F1-Score 0.6051, which is better than existing joint relation extraction models. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Luo H.; Haihong E.; Yang Y.; Guo Y.; Sun M.; Yao T.; Tang Z.; Wan K.; Song M.; Lin W.,"Luo, Haoran (57226337519); Haihong, E. (36679915000); Yang, Yuhao (57997365300); Guo, Yikai (57997574500); Sun, Mingzhi (57713678400); Yao, Tianyu (57819884500); Tang, Zichen (57997491300); Wan, Kaiyang (57819352200); Song, Meina (8419354200); Lin, Wei (58338473200)",57226337519; 36679915000; 57997365300; 57997574500; 57713678400; 57819884500; 57997491300; 57819352200; 8419354200; 58338473200,HAHE: Hierarchical Attention for Hyper-Relational Knowledge Graphs in Global and Local Level,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169466855&partnerID=40&md5=3e977a1b9b1eb67431c062d9378ed77c,"Link Prediction on Hyper-relational Knowledge Graphs (HKG) is a worthwhile endeavor. HKG consists of hyper-relational facts (H-Facts), composed of a main triple and several auxiliary attribute-value qualifiers, which can effectively represent factually comprehensive information. The internal structure of HKG can be represented as a hypergraph-based representation globally and a semantic sequence-based representation locally. However, existing research seldom simultaneously models the graphical and sequential structure of HKGs, limiting HKGs' representation. To overcome this limitation, we propose a novel Hierarchical Attention model for HKG Embedding (HAHE), including global-level and local-level attention. The global-level attention can model the graphical structure of HKG using hypergraph dual-attention layers, while the local-level attention can learn the sequential structure inside H-Facts via heterogeneous self-attention layers. Experiment results indicate that HAHE achieves state-of-the-art performance in link prediction tasks on HKG standard datasets. In addition, HAHE addresses the issue of HKG multi-position prediction for the first time, increasing the applicability of the HKG link prediction task. Our code is publicly available. © 2023 Association for Computational Linguistics.",Final,
Li A.H.; Shang M.; Spiliopoulou E.; Ma J.; Ng P.; Wang Z.; Min B.; Wang W.; McKeown K.; Castelli V.; Roth D.; Xiang B.,"Li, Alexander Hanbo (57200533043); Shang, Mingyue (57204474234); Spiliopoulou, Evangelia (57128569600); Ma, Jie (57219736049); Ng, Patrick (57216690110); Wang, Zhiguo (53664832900); Min, Bonan (23480129200); Wang, William (57233559700); McKeown, Kathleen (56269175400); Castelli, Vittorio (7005324678); Roth, Dan (7401669040); Xiang, Bing (7005065960)",57200533043; 57204474234; 57128569600; 57219736049; 57216690110; 53664832900; 23480129200; 57233559700; 56269175400; 7005324678; 7401669040; 7005065960,Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174423667&partnerID=40&md5=180cb12d78763b3eed68aec00d11e3e6,"We present a novel approach for structured data-to-text generation that addresses the limitations of existing methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multitask training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework. © 2023 Association for Computational Linguistics.",Final,
Shen X.; Wu S.; Xia R.,"Shen, Xiangqing (57939056400); Wu, Siwei (57939086600); Xia, Rui (36847284600)",57939056400; 57939086600; 36847284600,Dense-ATOMIC: Towards Densely-connected ATOMIC with High Knowledge Coverage and Massive Multi-hop Paths,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174403787&partnerID=40&md5=be3f177eb46af67af9be92fbbe4bab9a,"ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing everyday if-then knowledge triplets, i.e., {head event, relation, tail event}. The one-hop annotation manner made ATOMIC a set of independent bipartite graphs, which ignored the numerous links between events in different bipartite graphs and consequently caused shortages in knowledge coverage and multi-hop paths. In this work, we aim to construct Dense-ATOMIC with high knowledge coverage and massive multi-hop paths. The events in ATOMIC are normalized to a consistent pattern at first. We then propose a CSKG completion method called Rel-CSKGC to predict the relation given the head event and the tail event of a triplet, and train a CSKG completion model based on existing triplets in ATOMIC. We finally utilize the model to complete the missing links in ATOMIC and accordingly construct Dense-ATOMIC. Both automatic and human evaluation on an annotated subgraph of ATOMIC demonstrate the advantage of Rel-CSKGC over strong baselines. We further conduct extensive evaluations on Dense-ATOMIC in terms of statistics, human evaluation, and simple downstream tasks, all proving Dense-ATOMIC's advantages in Knowledge Coverage and Multi-hop Paths. Both the source code of Rel-CSKGC and Dense-ATOMIC are publicly available on https://github.com/NUSTM/Dense-ATOMIC. © 2023 Association for Computational Linguistics.",Final,
Kasner Z.; Konstas I.; Dušek O.,"Kasner, Zdeněk (57219694109); Konstas, Ioannis (35229595400); Dušek, Ondřej (56075872200)",57219694109; 35229595400; 56075872200,Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159856712&partnerID=40&md5=1c737d7f80ed9511e34043817393a133,"Pretrained language models (PLMs) for data-to-text (D2T) generation can use human-readable data labels such as column headings, keys, or relation names to generalize to out-of-domain examples. However, the models are well-known in producing semantically inaccurate outputs if these labels are ambiguous or incomplete, which is often the case in D2T datasets. In this paper, we expose this issue on the task of descibing a relation between two entities. For our experiments, we collect a novel dataset for verbalizing a diverse set of 1,522 unique relations from three large-scale knowledge graphs (Wikidata, DBPedia, YAGO). We find that although PLMs for D2T generation expectedly fail on unclear cases, models trained with a large variety of relation labels are surprisingly robust in verbalizing novel, unseen relations. We argue that using data with a diverse set of clear and meaningful labels is key to training D2T generation systems capable of generalizing to novel domains. © 2023 Association for Computational Linguistics.",Final,
Zhang M.; Xia Y.; Liu Q.; Wu S.; Wang L.,"Zhang, Mengqi (57215545099); Xia, Yuwei (58109644600); Liu, Qiang (56818103100); Wu, Shu (36245362600); Wang, Liang (57218666547)",57215545099; 58109644600; 56818103100; 36245362600; 57218666547,Learning Latent Relations for Temporal Knowledge Graph Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173798879&partnerID=40&md5=3fa3618c67e952bc2cce45a9c5bbc8dc,"Temporal Knowledge Graph (TKG) reasoning aims to predict future facts based on historical data. However, due to the limitations in construction tools and data sources, many important associations between entities may be omitted in TKG. We refer to these missing associations as latent relations. Most of the existing methods have some drawbacks in explicitly capturing intra-time latent relations between co-occurring entities and inter-time latent relations between entities that appear at different times. To tackle these problems, we propose a novel Latent relations Learning method for TKG reasoning; namely L2TKG. Specifically, we first utilize a Structural Encoder (SE) to obtain representations of entities at each timestamp. We then design a Latent Relations Learning (LRL) module to mine and exploit the intra- and inter-time latent relations. Finally, we extract the temporal representations from the output of SE and LRL for entity prediction. Extensive experiments on four datasets demonstrate the effectiveness of L2TKG. © 2023 Association for Computational Linguistics.",Final,
Capshaw R.; Blomqvist E.,"Capshaw, Riley (55343041300); Blomqvist, Eva (8968017800)",55343041300; 8968017800,Towards Tailored Knowledge Base Modeling using Masked Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169151570&partnerID=40&md5=afd9b4f845701ed93b92499a46ae2a3f,"We propose a methodology for leveraging aspects of ontology design principles to guide the use of a masked language model (MLM) as a query engine over raw text documents. By using targeted fill-in-the-blank-style prompts to define relations, we show how a domain expert could use BERT, a well-known MLM, to extract triples from unseen documents without any fine-tuning. We evaluate our proposed methodology using a modified document-level relation extraction task, highlighting early successes but also numerous areas that need improvement. Despite these shortcomings, we then discuss why we are still hopeful that this paves the way toward flexible text-based query engines which use collections of unstructured documents. © 2023 CEUR-WS. All rights reserved.",Final,
Huynh V.-P.; Chabot Y.; Troncy R.,"Huynh, Viet-Phi (57211575986); Chabot, Yoan (56286988800); Troncy, Raphaël (23986650400)",57211575986; 56286988800; 23986650400,Towards Generative Semantic Table Interpretation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171281829&partnerID=40&md5=16ae0ed05db813ca4416cc870a8eca7b,"Semantic Table Interpretation (STI), or Semantic Table Annotation, is the process of understanding the semantics of tabular data with reference information identified in knowledge graphs (KG). In this paper, we first present insights gained from the design and implementation of DAGOBAH SL, a top performing STI system in state-of-the-art benchmarks, and we discuss the unsolved challenges that need to be addressed to make STI more effective in practice. Pre-trained generative Large Language Models (LLMs) have demonstrated their powerful versatility in tackling a broad spectrum of natural language understanding tasks. We envision their potential for improving STI systems. We describe several appealing research ideas that could lay the foundation for future development of Generative Semantic Table Interpretation. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Alqarni A.D.; Noaman K.M.G.; AL-Aswadi F.N.; Alshalabi H.,"Alqarni, Amani D. (57654660700); Noaman, Khaled M. G. (57700990200); AL-Aswadi, Fatima N. (56755404500); Alshalabi, Hamood (57259218800)",57654660700; 57700990200; 56755404500; 57259218800,A Bottom-Up 2-Stage Approach for Constructing Arabic Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171143773&doi=10.1007%2f978-3-031-36258-3_5&partnerID=40&md5=402eb724054b450298f38a28b1ac6884,"Since Google has coined the term ‘knowledge graph’ (KG) in 2012, it has garnered much attention from the commercial and scientific domains. This term has been applied in numerous applications, such as automated fraud detection, supply chain management, semantic search, and intelligent question-answering (QA). The KG organises and represents strands of information as a semantic graph with higher usage efficiency, better modification, and clearer comprehension. However, KG has faced multiple challenges during the construction process particularly for Arabic language. As such, this study identified the Arabic KG (AKG) construction difficulties from Arabic text in order to propose a bottom-up 2-stage approach to construct AKG from Arabic texts. This proposed approach has dual stages: linguistic-based and machine learning-based (ML-based) stages. The linguistic-based stage is based on Natural Language Processing (NLP) techniques and three main tasks are deployed: corpus analysis, term extraction, and concept conceptualisation. As for the ML-based stage, it is based on semi-supervised ML techniques and three main tasks are applied: taxonomic classification, semantic mapping, and knowledge visualisation. The proposed methodology could successfully address the complex nature of the Arabic language in an effective manner to construct AKG. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Chen Z.; Liao J.; Zhao X.,"Chen, Ziyang (58393125100); Liao, Jinzhi (57201365513); Zhao, Xiang (55598203500)",58393125100; 57201365513; 55598203500,Multi-granularity Temporal Question Answering over Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171437288&partnerID=40&md5=d4daced9d379977309b538a7f6bc81e0,"Recently, question answering over temporal knowledge graphs (i.e., TKGQA) has been introduced and investigated, in quest of reasoning about dynamic factual knowledge. To foster research on TKGQA, a few datasets have been curated (e.g., CRONQUESTIONS and Complex-CRONQUESTIONS), and various models have been proposed based on these datasets. Nevertheless, existing efforts overlook the fact that real-life applications of TKGQA also tend to be complex in temporal granularity, i.e., the questions may concern mixed temporal granularities (e.g., both day and month). To overcome the limitation, in this paper, we motivate the notion of multi-granularity temporal question answering over knowledge graphs and present a large-scale dataset for multi-granularity TKGQA, namely MULTITQ. To the best of our knowledge, MULTITQ is among the first of its kind, and compared with existing datasets on TKGQA, MULTITQ features at least two desirable aspects-ample relevant facts and multiple temporal granularities. It is expected to better reflect real-world challenges, and serve as a test bed for TKGQA models. In addition, we propose a competing baseline MultiQA over MULTITQ, which is experimentally demonstrated to be effective in dealing with TKGQA. The data and code are released at https://github.com/czy1999/MultiTQ. © 2023 Association for Computational Linguistics.",Final,
Wang Y.; Zhang H.; Liang J.; Li R.,"Wang, Yujie (57956148400); Zhang, Hu (35200191600); Liang, Jiye (55552159700); Li, Ru (57192310904)",57956148400; 35200191600; 55552159700; 57192310904,Dynamic Heterogeneous-Graph Reasoning with Language Models and Knowledge Representation Learning for Commonsense Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174410105&partnerID=40&md5=4a171bb5346129492660bff9893136cc,"Recently, knowledge graphs (KGs) have won noteworthy success in commonsense question answering. Existing methods retrieve relevant subgraphs in the KGs through key entities and reason about the answer with language models (LMs) and graph neural networks. However, they ignore (i) optimizing the knowledge representation and structure of subgraphs and (ii) deeply fusing heterogeneous QA context with subgraphs. In this paper, we propose a dynamic heterogeneous-graph reasoning method with LMs and knowledge representation learning (DHLK), which constructs a heterogeneous knowledge graph (HKG) based on multiple knowledge sources and optimizes the structure and knowledge representation of the HKG using a two-stage pruning strategy and knowledge representation learning (KRL). It then performs joint reasoning by LMs and Relation Mask Self-Attention (RMSA). Specifically, DHLK filters key entities based on the dictionary vocabulary to achieve the first-stage pruning while incorporating the paraphrases in the dictionary into the subgraph to construct the HKG. Then, DHLK encodes and fuses the QA context and HKG using LM, and dynamically removes irrelevant KG entities based on the attention weights of LM for the second-stage pruning. Finally, DHLK introduces KRL to optimize the knowledge representation and perform answer reasoning on the HKG by RMSA. We evaluate DHLK at CommonsenseQA and OpenBookQA, and show its improvement on existing LM and LM+KG methods. © 2023 Association for Computational Linguistics.",Final,
Deng Y.; Zhang W.; Yuan Y.; Lam W.,"Deng, Yang (57200607347); Zhang, Wenxuan (57217168417); Yuan, Yifei (57224852900); Lam, Wai (57203073460)",57200607347; 57217168417; 57224852900; 57203073460,Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170838970&partnerID=40&md5=3108db3a25dc7b662cb2503043137b75,"Unlike empathetic dialogues, the system in emotional support conversations (ESC) is expected to not only convey empathy for comforting the help-seeker, but also proactively assist in exploring and addressing their problems during the conversation. In this work, we study the problem of mixed-initiative ESC where the user and system can both take the initiative in leading the conversation. Specifically, we conduct a novel analysis on mixed-initiative ESC systems with a tailor-designed schema that divides utterances into different types with speaker roles and initiative types. Four emotional support metrics are proposed to evaluate the mixed-initiative interactions. The analysis reveals the necessity and challenges of building mixed-initiative ESC systems. In the light of this, we propose a knowledge-enhanced mixed-initiative framework (KEMI) for ESC, which retrieves actual case knowledge from a large-scale mental health knowledge graph for generating mixed-initiative responses. Experimental results on two ESC datasets show the superiority of KEMI in both content-preserving evaluation and mixed initiative related analyses. © 2023 Association for Computational Linguistics.",Final,
Lin W.; Wang Z.; Byrne B.,"Lin, Weizhe (57219629078); Wang, Zhilin (57219633490); Byrne, Bill (56414274500)",57219629078; 57219633490; 56414274500,FVQA 2.0: Introducing Adversarial Samples into Fact-based Visual Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159857757&partnerID=40&md5=6666853f0bc1e40f5d8fe09310f63b83,The widely used Fact-based Visual Question Answering (FVQA) dataset contains visually-grounded questions that require information retrieval using common sense knowledge graphs to answer. It has been observed that the original dataset is highly imbalanced and concentrated on a small portion of its associated knowledge graph. We introduce FVQA 2.0 which contains adversarial variants of test questions to address this imbalance. We show that systems trained with the original FVQA train sets can be vulnerable to adversarial samples and we demonstrate an augmentation scheme to reduce this vulnerability without human annotations. © 2023 Association for Computational Linguistics.,Final,
Plenz M.; Opitz J.; Heinisch P.; Cimiano P.; Frank A.,"Plenz, Moritz (57224406177); Opitz, Juri (57209542025); Heinisch, Philipp (57223089314); Cimiano, Philipp (15838793700); Frank, Anette (56254159500)",57224406177; 57209542025; 57223089314; 15838793700; 56254159500,Similarity-weighted Construction of Contextualized Commonsense Knowledge Graphs for Knowledge-intense Argumentation Tasks,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174391514&partnerID=40&md5=9e72c751fe016bc8d72da406ae761e3d,"Arguments often do not make explicit how a conclusion follows from its premises. To compensate for this lack, we enrich arguments with structured background knowledge to support knowledge-intense argumentation tasks. We present a new unsupervised method for constructing Contextualized Commonsense Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from large knowledge graphs (KGs) efficiently and at high quality. Our work goes beyond context-insensitive knowledge extraction heuristics by computing semantic similarity between KG triplets and textual arguments. Using these triplet similarities as weights, we extract contextualized knowledge paths that connect a conclusion to its premise, while maximizing similarity to the argument. We combine multiple paths into a CCKG that we optionally prune to reduce noise and raise precision. Intrinsic evaluation of the quality of our graphs shows that our method is effective for (re)constructing human explanation graphs. Manual evaluations in a large-scale knowledge selection setup confirm high recall and precision of implicit CSK in the CCKGs. Finally, we demonstrate the effectiveness of CCKGs in a knowledge-insensitive argument quality rating task, outperforming strong baselines and rivaling a GPT-3 based system. © 2023 Association for Computational Linguistics.",Final,
Li J.; Su X.; Gao G.,"Li, Jiang (58437332500); Su, Xiangdong (36613483100); Gao, Guanglai (7403171213)",58437332500; 36613483100; 7403171213,TeAST: Temporal Knowledge Graph Embedding via Archimedean Spiral Timeline,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173838737&partnerID=40&md5=bd316530ab657d66056272efd482a8ac,"Temporal knowledge graph embedding (TKGE) models are commonly utilized to infer the missing facts and facilitate reasoning and decision-making in temporal knowledge graph based systems. However, existing methods fuse temporal information into entities, potentially leading to the evolution of entity information and limiting the link prediction performance of TKG. Meanwhile, current TKGE models often lack the ability to simultaneously model important relation patterns and provide interpretability, which hinders their effectiveness and potential applications. To address these limitations, we propose a novel TKGE model which encodes Temporal knowledge graph embeddings via Archimedean Spiral Timeline (TeAST), which maps relations onto the corresponding Archimedean spiral timeline and transforms the quadruples completion to 3th-order tensor completion problem. Specifically, the Archimedean spiral timeline ensures that relations that occur simultaneously are placed on the same timeline, and all relations evolve over time. Meanwhile, we present a novel temporal spiral regularizer to make the spiral timeline orderly. In addition, we provide mathematical proofs to demonstrate the ability of TeAST to encode various relation patterns. Experimental results show that our proposed model significantly outperforms existing TKGE methods. Our code is available at https://github.com/IMU-MachineLearningSXD/TeAST. © 2023 Association for Computational Linguistics.",Final,
Xu H.; Bao J.; Liu W.,"Xu, Hongcai (57219688493); Bao, Junpeng (7201398514); Liu, Wenbo (58735770600)",57219688493; 7201398514; 58735770600,Double-Branch Multi-Attention based Graph Neural Network for Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174424597&partnerID=40&md5=c16324f3cd1022ab247f2b7aa91db5b9,"Graph neural networks (GNNs), which effectively use topological structures in the knowledge graphs (KG) to embed entities and relations in low-dimensional spaces, have shown great power in knowledge graph completion (KGC). KG has abundant global and local structural information, however, many GNN-based KGC models cannot capture these two types of information about the graph structure by designing complex aggregation schemes and are not designed well to learn representations of seen entities with sparse neighborhoods in isolated subgraphs. In this paper, we find that a simple attention-based method can outperform a general GNN-based approach for KGC. We then propose a double-branch multi-attentionbased graph neural network (MA-GNN) to learn more expressive entity representations that contain rich global-local structural information. Specifically, we first explore the graph attention network-based local aggregator to learn entity representations. Furthermore, we propose a snowball local attention mechanism by leveraging the semantic similarity between two-hop neighbors to enrich the entity embedding. Finally, we use Transformer-based self-attention to learn long-range dependence between entities to obtain richer representations with the global graph structure and entity features. Experimental results on five benchmark datasets show that MA-GNN achieves significant improvements over strong baselines for inductive KGC. © 2023 Association for Computational Linguistics.",Final,
Sola D.; van der Aa H.; Meilicke C.; Stuckenschmidt H.,"Sola, Diana (57226389317); van der Aa, Han (6604024016); Meilicke, Christian (23009400900); Stuckenschmidt, Heiner (6603168933)",57226389317; 6604024016; 23009400900; 6603168933,Activity Recommendation for Business Process Modeling with Pre-trained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163354758&doi=10.1007%2f978-3-031-33455-9_19&partnerID=40&md5=d11c30170c4f3a00e38940c966c2005a,"Activity recommendation in business process modeling is concerned with suggesting suitable labels for a new activity inserted by a modeler in a process model under development. Recently, it has been proposed to represent process model repositories as knowledge graphs, which makes it possible to address the activity-recommendation problem as a knowledge graph completion task. However, existing recommendation approaches are entirely dependent on the knowledge contained in the model repository used for training. This makes them rigid in general and even inapplicable in situations where a process model consists of unseen activities, which were not part of the repository used for training. In this paper, we avoid these issues by recognizing that the semantics contained in process models can be used to instead pose the activity-recommendation problem as a set of textual sequence-to-sequence tasks. This enables the application of transfer-learning techniques from natural language processing, which allows for recommendations that go beyond the activities contained in an available repository. We operationalize this with an activity-recommendation approach that employs a pre-trained language model at its core, and uses the representations of process knowledge as structured graphs combined with the natural-language-based semantics of process models. In an experimental evaluation, we show that our approach considerably outperforms the state of the art in terms of semantic accuracy of the recommendations and that it is able to recommend and handle activity labels that go beyond the vocabulary of the model repository used during training. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Skandan S.; Kanungo S.; Devaraj S.; Gupta S.; Narayan S.,"Skandan, Spurthy (58402522900); Kanungo, Susheen (58401151100); Devaraj, Shreyas (58403204500); Gupta, Sahil (58597760700); Narayan, Surabhi (57258297000)",58402522900; 58401151100; 58403204500; 58597760700; 57258297000,Question Answering System using Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163554264&doi=10.1109%2fICICT57646.2023.10134047&partnerID=40&md5=1f30f3f1d4fd2a7237719e1d27afbd31,"A question answering system aims to answer the asked question with relevant responses thus sufficing the requested query asked in natural language by responding in the same language. Knowledge Graph Question Answering (KGQA) aims to answer questions asked by the user on a paragraph from a knowledge graph (KG). A strongly connected KG is essential in picking out answers for the requested question. This is because the KG is traversed to select the answer. A well connected KG thus provides a relevant answer. The knowledge graph is built by identifying the subject, the object and the relation for every sentence in the input text or knowledge base. Questions are processed to identify the source-relation-target triples which are then matched with that of the triples forming the KG. The challenge is in extracting the entities and relations between them to create the KG. The model's performance is directly proportional to the strength of the KG. Hence, the presence of a well connected KG provides great accuracy while a poorly connected one would break the system.The proposed model is tested on a Multi RC dataset. Multi RC is a dataset for multi hop question answering that includes short paragraphs and multi-sentence questions. This allows catering to both single hop and multi hop questions. The primary objective was to build a question answering system with the ability to answer multi hop questions together with an efficient response time through the usage of knowledge graphs. A novel approach has been employed where natural language questions are processed into key-value pairs, by leveraging python modules whose dependencies aid in parts of speech tagging in the English language thereby mapping back to the data entities present in the KG to retrieve the correct answer. © 2023 IEEE.",Final,
Wang J.; Peng B.; Tang J.,"Wang, Juan (37003468400); Peng, Bitao (35773669200); Tang, Jing (58337226200)",37003468400; 35773669200; 58337226200,Research on Named Entity Recognition in Judicial Field Based on ERNIE-Gram,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163355687&doi=10.1109%2fCISCE58541.2023.10142258&partnerID=40&md5=ba11a105739d3d035c5b06ae7a8da8a2,"Named Entity Recognition is a key and fundamental task in natural language processing and can benefit many downstream tasks such as knowledge graph construction, question answering system, machine reading, etc. In view of the contradiction between the rapidly increasing of judgement documents and the low efficiency of manual analysis in the judicial field, we propose a NER model by using a combination of ERNIE-Gram, BiGRU, and CRF. ERNIE-Gram adopts multi-granularity n-gram language learning mechanism to learn the semantic of n-grams more adequately. Thus, we first employ the ERNIE-Gram to capture rich language representation, then we feed them into the BiGRU to obtain more important text features, finally, we use the CRF to decode and output optimal labeling sequence. We conduct experiments on an open dataset of the 2021 'Challenge of AI in Law' information extraction subtask and compare our model with currently familiar models for NER task. Experimental results demonstrate that our proposed model achieves a F1-score of 87.01%, and outperforms all the baseline models.  © 2023 IEEE.",Final,
Tang C.; Zhang H.; Loakman T.; Lin C.; Guerin F.,"Tang, Chen (57196025933); Zhang, Hongbo (58607173400); Loakman, Tyler (57473214300); Lin, Chenghua (35322970500); Guerin, Frank (23396695000)",57196025933; 58607173400; 57473214300; 35322970500; 23396695000,Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173715875&partnerID=40&md5=35389697f853890c0a8d3e4a4106fc0a,"Incorporating external graph knowledge into neural chatbot models has been proven effective for enhancing dialogue generation. However, in conventional graph neural networks (GNNs), message passing on a graph is independent from text, resulting in the graph representation hidden space differing from that of the text. This training regime of existing models therefore leads to a semantic gap between graph knowledge and text. In this study, we propose a novel framework for knowledge graph enhanced dialogue generation. We dynamically construct a multi-hop knowledge graph with pseudo nodes to involve the language model in feature aggregation within the graph at all steps. To avoid the semantic biases caused by learning on vanilla subgraphs, the proposed framework applies hierarchical graph attention to aggregate graph features on pseudo nodes and then attains a global feature. Therefore, the framework can better utilise the heterogeneous features from both the post and external graph knowledge. Extensive experiments demonstrate that our framework outperforms state-of-the-art (SOTA) baselines on dialogue generation. Further analysis also shows that our representation learning framework can fill the semantic gap by coagulating representations of both text and graph knowledge. Moreover, the language model also learns how to better select knowledge triples for a more informative response via exploiting subgraph patterns within our feature aggregation process. Our code and resources are available at https://github.com/tangg555/SaBART. © 2023 Association for Computational Linguistics.",Final,
Zhang R.; Su Y.; Trisedya B.D.; Zhao X.; Yang M.; Cheng H.; Qi J.,"Zhang, Rui (54947068500); Su, Yixin (57204649658); Trisedya, Bayu Distiawan (57216617832); Zhao, Xiaoyan (57218707688); Yang, Min (56349712700); Cheng, Hong (7404284983); Qi, Jianzhong (53878392800)",54947068500; 57204649658; 57216617832; 57218707688; 56349712700; 7404284983; 53878392800,AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172203247&doi=10.1109%2fTKDE.2023.3325484&partnerID=40&md5=e4ec8d6b46cbb1cc2c9d49e7ed3bf0fa,"The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require <italic>manually crafted</italic> seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs&#x0027; entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods. Our source code is available at ruizhang-ai/AutoAlign. IEEE",Article in press,All Open Access; Green Open Access
Badawy I.L.; Nagaty K.; Hamdy A.,"Badawy, Israa Lotfy (58162488200); Nagaty, Khaled (6506246402); Hamdy, Abeer (55160491400)",58162488200; 6506246402; 55160491400,A Comprehensive Review on Deep Learning-Based Generative Linguistic Steganography,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151147044&doi=10.1007%2f978-3-031-26876-2_61&partnerID=40&md5=83f92df0d07c3d9511cd37e185852877,"The recent development of deep learning has made a significant breakthrough in linguistic generative steganography. The text has become one of the most intensely used communication carriers on the Internet, making steganography an efficient carrier for concealing secret messages. Text steganography has long been used to protect the privacy and confidentiality of data via public transmission. Steganography utilizes a carrier to embed the data to generate a secret unnoticed and less attractive message. Different techniques have been used to improve the security of the generated text and quality of the steganographic text, such as the Markov model, Recurrent Neural Network (RNN), Long short-term memory (LSTM), Transformers, Knowledge Graph, and Variational autoencoder (VAE). Those techniques enhance the steganographic text’s language model and conditional probability distribution. This paper provides a comparative analysis to review the key contributions of generative linguistic steganographic deep learning-based methods through different perspectives such as text generation, encoding algorithm, and evaluation criteria. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Wang Y.-C.; Ge X.; Wang B.; Kuo C.-C.J.,"Wang, Yun-Cheng (57218521783); Ge, Xiou (57202498636); Wang, Bin (57209905481); Kuo, C.-C. Jay (58094912900)",57218521783; 57202498636; 57209905481; 58094912900,GreenKGC: A Lightweight Knowledge Graph Completion Method,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174402550&partnerID=40&md5=e8f87443736222c6520f25d7f4b936a5,"Knowledge graph completion (KGC) aims to discover missing relationships between entities in knowledge graphs (KGs). Most prior KGC work focuses on learning embeddings for entities and relations through a simple scoring function. Yet, a higher-dimensional embedding space is usually required for a better reasoning capability, which leads to a larger model size and hinders applicability to real-world problems (e.g., large-scale KGs or mobile/edge computing). A lightweight modularized KGC solution, called GreenKGC, is proposed in this work to address this issue. GreenKGC consists of three modules: representation learning, feature pruning, and decision learning, to extract discriminant KG features and make accurate predictions on missing relationships using classifiers and negative sampling. Experimental results demonstrate that, in low dimensions, GreenKGC can outperform SOTA methods in most datasets. In addition, low-dimensional GreenKGC can achieve competitive or even better performance against high-dimensional models with a much smaller model size. We make our code publicly available. © 2023 Association for Computational Linguistics.",Final,
Jiang C.; Jiang Y.; Wu W.; Zheng Y.; Xie P.; Tu K.,"Jiang, Chengyue (57216706766); Jiang, Yong (57195958145); Wu, Weiqi (58031352000); Zheng, Yuting (58109929900); Xie, Pengjun (57216619845); Tu, Kewei (56371222100)",57216706766; 57195958145; 58031352000; 58109929900; 57216619845; 56371222100,COMBO: A Complete Benchmark for Open KG Canonicalization,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159856213&partnerID=40&md5=c3b538d171161706c7ce8931aad8b94b,"Open knowledge graph (KG) consists of (subject, relation, object) triples extracted from millions of raw text. The subject and object noun phrases and the relation in open KG have severe redundancy and ambiguity and need to be canonicalized. Existing datasets for open KG canonicalization only provide gold entity-level canonicalization for noun phrases. In this paper, we present COMBO, a Complete Benchmark for Open KG canonicalization. Compared with existing datasets, we additionally provide gold canonicalization for relation phrases, gold ontology-level canonicalization for noun phrases, as well as source sentences from which triples are extracted. We also propose metrics for evaluating each type of canonicalization. On the COMBO dataset, we empirically compare previously proposed canonicalization methods as well as a few simple baseline methods based on pretrained language models. We find that properly encoding the phrases in a triple using pretrained language models results in better relation canonicalization and ontology-level canonicalization of the noun phrase. We release our dataset, baselines, and evaluation scripts at https://github.com/jeffchy/COMBO/tree/main. © 2023 Association for Computational Linguistics.",Final,
Jiang F.; Drummond T.; Cohn T.,"Jiang, Fan (57478027900); Drummond, Tom (56152373800); Cohn, Trevor (15043872200)",57478027900; 56152373800; 15043872200,Don't Mess with Mister-in-Between: Improved Negative Search for Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159853980&partnerID=40&md5=680d8f3a022e8099483d5d98ba1a30d8,"The best methods for knowledge graph completion use a 'dual-encoding' framework, a form of neural model with a bottleneck that facilitates fast approximate search over a vast collection of candidates. These approaches are trained using contrastive learning to differentiate between known positive examples and sampled negative instances. The mechanism for sampling negatives to date has been very simple, driven by pragmatic engineering considerations (e.g., using mismatched instances from the same batch). We propose several novel means of finding more informative negatives, based on searching for candidates with high lexical overlaps, from the dual-encoder model and according to knowledge graph structures. Experimental results on four benchmarks show that our best single model improves consistently over previous methods and obtains new state-of-the-art performance, including the challenging large-scale Wikidata5M dataset. Combing different strategies through model ensembling results in a further performance boost. © 2023 Association for Computational Linguistics.",Final,
Sharma A.; Kazemi M.; Saxena A.; Talukdar P.; Gupta C.; Chakrabarti S.,"Sharma, Aditya (57207856342); Kazemi, Mehran (58090922500); Saxena, Apoorv (57225711426); Talukdar, Partha (25652280700); Gupta, Chitrank (57244261600); Chakrabarti, Soumen (58570163200)",57207856342; 58090922500; 57225711426; 25652280700; 57244261600; 58570163200,TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159858241&partnerID=40&md5=2f758cf776a37abd77683d9a5a99e690,"Recent years have witnessed interest in Temporal Question Answering over Knowledge Graphs (TKGQA), resulting in the development of multiple methods. However, these are highly engineered, thereby limiting their generalizability, and they do not automatically discover relevant parts of the KG during multi-hop reasoning. Relational graph convolutional networks (RGCN) provide an opportunity to address both of these challenges - we explore this direction in the paper. Specifically, we propose a novel, intuitive and interpretable scheme to modulate the messages passed through a KG edge during convolution based on the relevance of its associated period to the question. We also introduce a gating device to predict if the answer to a complex temporal question is likely to be a KG entity or time and use this prediction to guide our scoring mechanism. We evaluate the resulting system, which we call TwiRGCN, on a recent challenging dataset for multi-hop complex temporal QA called TimeQuestions. We show that TwiRGCN significantly outperforms state-of-the-art models on this dataset across diverse question types. Interestingly, TwiRGCN improves accuracy by 9-10 percentage points for the most difficult ordinal and implicit question types. © 2023 Association for Computational Linguistics.",Final,
Stoikou T.; Lymperaiou M.; Stamou G.,"Stoikou, Theodoti (58146734200); Lymperaiou, Maria (57900314700); Stamou, Giorgos (7004137698)",58146734200; 57900314700; 7004137698,Knowledge-Based Counterfactual Queries for Visual Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166470179&partnerID=40&md5=b5402c921f66fc1cf85461f45ff2daf0,"Visual Question Answering (VQA) has been a popular task that combines vision and language, with numerous relevant implementations in literature. Even though there are some attempts that approach explainability and robustness issues in VQA models, very few of them employ counterfactuals as a means of probing such challenges in a model-agnostic way. In this work, we propose a systematic method for explaining the behavior and investigating the robustness of VQA models through counterfactual perturbations. For this reason, we exploit structured knowledge bases to perform deterministic, optimal and controllable word-level replacements targeting the linguistic modality, and we then evaluate the model's response against such counterfactual inputs. Finally, we qualitatively extract local and global explanations based on counterfactual responses, which are ultimately proven insightful towards interpreting VQA model behaviors. By performing a variety of perturbation types, targeting different parts of speech of the input question, we gain insights to the reasoning of the model, through the comparison of its responses in different adversarial circumstances. Overall, we reveal possible biases in the decision-making process of the model, as well as expected and unexpected patterns, which impact its performance quantitatively and qualitatively, as indicated by our analysis. © 2023 CEUR-WS. All rights reserved.",Final,
González-Gallardo C.-E.; Boros E.; Giamphy E.; Hamdi A.; Moreno J.G.; Doucet A.,"González-Gallardo, Carlos-Emiliano (57190376802); Boros, Emanuela (36605783500); Giamphy, Edward (57867076400); Hamdi, Ahmed (57201550417); Moreno, José G. (55390418200); Doucet, Antoine (23391793200)",57190376802; 36605783500; 57867076400; 57201550417; 55390418200; 23391793200,Injecting Temporal-Aware Knowledge in Historical Named Entity Recognition,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151135342&doi=10.1007%2f978-3-031-28244-7_24&partnerID=40&md5=ac9821f4dfa768f582bf664728c81144,"In this paper, we address the detection of named entities in multilingual historical collections. We argue that, besides the multiple challenges that depend on the quality of digitization (e.g., misspellings and linguistic errors), historical documents can pose another challenge due to the fact that such collections are distributed over a long enough period of time to be affected by changes and evolution of natural language. Thus, we consider that detecting entities in historical collections is time-sensitive, and explore the inclusion of temporality in the named entity recognition (NER) task by exploiting temporal knowledge graphs. More precisely, we retrieve semantically-relevant additional contexts by exploring the time information provided by historical data collections and include them as mean-pooled representations in a Transformer-based NER model. We experiment with two recent multilingual historical collections in English, French, and German, consisting of historical newspapers (19C-20C) and classical commentaries (19C). The results are promising and show the effectiveness of injecting temporal-aware knowledge into the different datasets, languages, and diverse entity types. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Hao S.; Tan B.; Tang K.; Ni B.; Shao X.; Zhang H.; Xing E.P.; Hu Z.,"Hao, Shibo (57797938300); Tan, Bowen (57215828472); Tang, Kaiwen (57797938400); Ni, Bin (58379112500); Shao, Xiyan (58500256200); Zhang, Hengzhe (58499457900); Xing, Eric P. (57685890100); Hu, Zhiting (56272615700)",57797938300; 57215828472; 57797938400; 58379112500; 58500256200; 58499457900; 57685890100; 56272615700,BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171861045&partnerID=40&md5=eb1171194b6978bd9b807ac86ac88d32,"It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore mechanism for improved efficiency and accuracy. We deploy the approach to harvest KGs of over 400 new relations from different LMs. Extensive human and automatic evaluations show our approach manages to extract diverse accurate knowledge, including tuples of complex relations (e.g., ""A is capable of but not good at B""). The resulting KGs as a symbolic interpretation of the source LMs also reveal new insights into the LMs' knowledge capacities. © 2023 Association for Computational Linguistics.",Final,
Nandi A.; Kaur N.; Singla P.; Mausam,"Nandi, Ananjan (58616484800); Kaur, Navdeep (58584909600); Singla, Parag (10244352500); Mausam (55963402300)",58616484800; 58584909600; 10244352500; 55963402300,Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172202684&partnerID=40&md5=0575602851df780e963e883f8fe5bf6e,"High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using rules without augmentations. © 2023 Association for Computational Linguistics.",Final,
Sen P.; Mavadia S.; Saffari A.,"Sen, Priyanka (57219587178); Mavadia, Sandeep (58674451800); Saffari, Amir (23490141200)",57219587178; 58674451800; 23490141200,Knowledge Graph-augmented Language Models for Complex Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173903295&partnerID=40&md5=a7c51d0a7c88c5d4577570f7e65098cb,"Large language models have shown impressive abilities to reason over input text, however, they are prone to hallucinations. On the other hand, end-to-end knowledge graph question answering (KGQA) models output responses grounded in facts, but they still struggle with complex reasoning; such as comparison or ordinal questions. In this paper, we propose a new method for complex question answering where we combine a knowledge graph retriever based on an end-to-end KGQA model with a language model that reasons over the retrieved facts to return an answer. We observe that augmenting language model prompts with retrieved KG facts improves performance over using a language model alone by an average of 83%. In particular, we see improvements on complex questions requiring count, intersection, or multi-hop reasoning operations.  © 2023 Association for Computational Linguistics.",Final,
Xiong B.; Nayyeri M.; Pan S.; Staab S.,"Xiong, Bo (57221322184); Nayyeri, Mojtaba (35776892400); Pan, Shirui (55522732400); Staab, Steffen (7004053291)",57221322184; 35776892400; 55522732400; 7004053291,Shrinking Embeddings for Hyper-Relational Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168830782&partnerID=40&md5=a42a47dddcba9e8209e312cec96d1f71,"Link prediction on knowledge graphs (KGs) has been extensively studied on binary relational KGs, wherein each fact is represented by a triple. A significant amount of important knowledge, however, is represented by hyper-relational facts where each fact is composed of a primal triple and a set of qualifiers comprising a key-value pair that allows for expressing more complicated semantics. Although some recent works have proposed to embed hyper-relational KGs, these methods fail to capture essential inference patterns of hyper-relational facts such as qualifier monotonicity, qualifier implication, and qualifier mutual exclusion, limiting their generalization capability. To unlock this, we present ShrinkE, a geometric hyper-relational KG embedding method aiming to explicitly model these patterns. ShrinkE models the primal triple as a spatial-functional transformation from the head into a relation-specific box. Each qualifier “shrinks” the box to narrow down the possible answer set and, thus, realizes qualifier monotonicity. The spatial relationships between the qualifier boxes allow for modeling core inference patterns of qualifiers such as implication and mutual exclusion. Experimental results demonstrate ShrinkE's superiority on three benchmarks of hyper-relational KGs. © 2023 Association for Computational Linguistics.",Final,
Korini K.; Bizer C.,"Korini, Keti (58061083900); Bizer, Christian (35236159100)",58061083900; 35236159100,Column Type Annotation using ChatGPT,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171297582&partnerID=40&md5=77a8d96d464a8cf27f9ba2bb9378a402,"Column type annotation is the task of annotating the columns of a relational table with the semantic type of the values contained in each column. Column type annotation is an important pre-processing step for data search and data integration in the context of data lakes. State-of-the-art column type annotation methods either rely on matching table columns to properties of a knowledge graph or fine-tune pre-trained language models such as BERT for column type annotation. In this work, we take a different approach and explore using ChatGPT for column type annotation. We evaluate different prompt designs in zero- and few-shot settings and experiment with providing task definitions and detailed instructions to the model. We further implement a two-step table annotation pipeline which first determines the class of the entities described in the table and depending on this class asks ChatGPT to annotate columns using only the relevant subset of the overall vocabulary. Using instructions as well as the two-step pipeline, ChatGPT reaches F1 scores of over 85% in zero- and one-shot setups. To reach a similar F1 score a RoBERTa model needs to be fine-tuned with 356 examples. This comparison shows that ChatGPT is able deliver competitive results for the column type annotation task given no or only a minimal amount of task-specific demonstrations. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Khorashadizadeh H.; Mihindukulasooriya N.; Tiwari S.; Groppe J.; Groppe S.,"Khorashadizadeh, Hanieh (57003403200); Mihindukulasooriya, Nandana (56406504100); Tiwari, Sanju (56599597000); Groppe, Jinghua (22979685000); Groppe, Sven (22234205300)",57003403200; 56406504100; 56599597000; 22979685000; 22234205300,Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168818600&partnerID=40&md5=f1d79f7173a4f5005baba416c9acc899,"Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. In this paper, grounded by several research questions, we explore the capabilities of foundation models such as ChatGPT to generate knowledge graphs from the knowledge it captured during pre-training as well as the new text provided to it in the prompt. The paper provides a qualitative analysis of a set of example outputs generated by a foundation model with the aim of knowledge graph construction and completion. The results demonstrate promising capabilities. Furthermore, we discuss the challenges and next steps for this research work. © 2023 CEUR-WS. All rights reserved.",Final,
Yamasaki S.; Sasaki Y.; Karras P.; Onizuka M.,"Yamasaki, Shohei (57218837018); Sasaki, Yuya (36180137700); Karras, Panagiotis (14028488200); Onizuka, Makoto (7006799026)",57218837018; 36180137700; 14028488200; 7006799026,Holistic Prediction on a Time-Evolving Attributed Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174416399&partnerID=40&md5=67b295fd30db9b6a1f96754a53d389fc,"Graph-based prediction is essential in NLP tasks such as temporal knowledge graph completion. A cardinal question in this field is, how to predict the future links, nodes, and attributes of a time-evolving attributed graph? Unfortunately, existing techniques assume that each link, node, and attribute prediction is independent, and fall short of predicting the appearance of new nodes that were not observed in the past. In this paper, we address two interrelated questions; (1) can we exploit task interdependence to improve prediction accuracy? and (2) can we predict new nodes with their attributes? We propose a unified framework that predicts node attributes and topology changes such as the appearance and disappearance of links and the emergence and loss of nodes. This framework comprises components for independent and interactive prediction and for predicting new nodes. Our experimental study using real-world data confirms that our interdependent prediction framework achieves higher accuracy than methods based on independent prediction. © 2023 Association for Computational Linguistics.",Final,
Minoli M.; Ambegoda T.D.,"Minoli, Madhupa (58535525000); Ambegoda, Thanuja D. (57219508144)",58535525000; 57219508144,Knowledge Graphs for COVID-19: A Survey,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167873892&doi=10.1007%2f978-3-031-28631-5_1&partnerID=40&md5=cf68a40004adce65ff7408e833217130,"During a short span of time, the knowledge related to COVID-19 has been evolving rapidly because of new variants and their strange behaviors. Knowledge Graphs offer a realistic and efficient way of organizing and retrieving knowledge from such massive and growing amounts of information. Since natural language is used to represent information, language models are widely used to embed textual information in dense vector spaces, which can then be used to organize and represent knowledge in the form of knowledge graphs. In recent years, transformer-based language models that adopt the mechanism of self-attention gained state-of-the-art performance in constructing knowledge graphs. This chapter presents a survey on knowledge graph creation using transformer-based language models and their applications in organizing and retrieving semantic knowledge from the increasing volume of information related to COVID-19. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Bellan P.; Dragoni M.; Ghidini C.,"Bellan, Patrizio (57204825247); Dragoni, Mauro (19638448200); Ghidini, Chiara (6701842843)",57204825247; 19638448200; 6701842843,Assisted Process Knowledge Graph Building Using Pre-trained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151059827&doi=10.1007%2f978-3-031-27181-6_5&partnerID=40&md5=a20c894229c4d2f8cff791dca8d20ab6,"The automated construction of knowledge graphs from procedural documents is a challenging research area. Here, the lack of annotated data, as well as raw text repositories describing real-world procedural documents, make it extremely difficult to adopt deep learning approaches. Pre-trained language models have shown promising results concerning the knowledge extraction tasks from the models themselves. Although several works explored this strategy to build knowledge graph, the viability of knowledge base construction by using prompt-based learning strategy from such language models has not yet been investigated deeply. In this work, we present a prompt-based in-context learning strategy to extract, from natural language process descriptions, conceptual information that can be converted into their equivalent knowledge graphs. Such a strategy is performed in a multi-turn dialog fashion. We validate the accuracy of the proposed approach from both quantitative and qualitative perspectives. The results highlight the feasibility of the proposed approach within low-resource scenarios. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Buzzega G.; Guidetti V.; Mandreoli F.; Mariotti L.; Belli A.; Lombardi P.,"Buzzega, Giovanni (57429839000); Guidetti, Veronica (57196298204); Mandreoli, Federica (6603425981); Mariotti, Luca (57893537300); Belli, Andrea (58634662900); Lombardi, Paolo (58634197400)",57429839000; 57196298204; 6603425981; 57893537300; 58634662900; 58634197400,Automated Knowledge Graph Completion for Natural Language Understanding: Known Paths and Future Directions,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173509733&partnerID=40&md5=2b085f795bbb88f3729d47198268ee32,"Knowledge Graphs (KGs) are large collections of structured data that can model real world knowledge and are important assets for the companies that employ them. KGs are usually constructed iteratively and often show a sparse structure. Also, as knowledge evolves, KGs must be updated and completed. Many automatic methods for KG Completion (KGC) have been proposed in the literature to reduce the costs associated with manual maintenance. Motivated by an industrial case study aiming to enrich a KG specifically designed for Natural Language Understanding tasks, this paper presents an overview of classical and modern deep learning completion methods. In particular, we delve into Large Language Models (LLMs), which are the most promising deep learning architectures. We show that their applications to KGC are affected by several shortcomings, namely they neglect the structure of KG and treat KGC as a classification problem. Such limitations, together with the brittleness of the LLMs themselves, stress the need to create KGC solutions at the interface between symbolic and neural approaches and lead to the way ahead for future research in intelligible corpus-based KGC. © 2023 CEUR-WS. All rights reserved.",Final,
Yang Z.; Huang Y.; Feng J.,"Yang, Zhe (58676469800); Huang, Yi (57212062827); Feng, Junlan (57190813028)",58676469800; 57212062827; 57190813028,Learning to Leverage High-Order Medical Knowledge Graph for Joint Entity and Relation Extraction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171446818&partnerID=40&md5=f00c7657aa902deb3c892888391c4f13,"Automatic medical entity and relation extraction is essential for daily electronic medical record (EMR) analysis, and has attracted a lot of academic attention. Tremendous progress has been made in recent years. However, medical terms are difficult to understand, and their relations are more complicated than general ones. Based on this situation, domain knowledge gives better background and contexts for medical terms. Despite the benefits of medical domain knowledge, the utilization way of it for joint entity and relation extraction is inadequate. To foster this line of research, in this work, we propose to leverage the medical knowledge graph for extracting entities and relations for Chinese Medical Texts in a collective way. Specifically, we propose to construct a high-order heterogeneous graph based on medical knowledge graph, which is linked to the entity mentions in the text. In this way, neighbors from the high-order heterogeneous graph can pass the message to each other for better global context representations. Our experiments on real Chinese Medical Texts show that our method is more effective than state-of-the-art methods. © 2023 Association for Computational Linguistics.",Final,
Xu Y.; Sheng S.; Qi J.; Fu L.; Lin Z.; Wang X.; Zhou C.,"Xu, Yi (55695017800); Sheng, Shuqian (58298709300); Qi, Jiexing (57712481900); Fu, Luoyi (35955852600); Lin, Zhouhan (55567081300); Wang, Xinbing (22136880500); Zhou, Chenghu (7403347013)",55695017800; 58298709300; 57712481900; 35955852600; 55567081300; 22136880500; 7403347013,Unsupervised Graph-Text Mutual Conversion with a Unified Pretrained Language Model,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174387290&partnerID=40&md5=0dc420c6abcf19fb3315f9694f77fc9b,"Graph-to-text (G2T) generation and text-to-graph (T2G) triple extraction are two essential tasks for knowledge graphs. Existing unsupervised approaches become suitable candidates for jointly learning the two tasks due to their avoidance of using graph-text parallel data. However, they adopt multiple complex modules and still require entity information or relation type for training. To this end, we propose INFINITY, a simple yet effective unsupervised method with a unified pretrained language model that does not introduce external annotation tools or additional parallel information. It achieves fully unsupervised graph-text mutual conversion for the first time. Specifically, INFINITY treats both G2T and T2G as a bidirectional sequence generation task by fine-tuning only one pretrained seq2seq model. A novel back-translation-based framework is then designed to generate synthetic parallel data automatically. Besides, we investigate the impact of graph linearization and introduce the structure-aware fine-tuning strategy to alleviate possible performance deterioration via retaining structural information in graph sequences. As a fully unsupervised framework, INFINITY is empirically verified to outperform state-of-the-art baselines for G2T and T2G tasks. Additionally, we also devise a new training setting called cross learning for low-resource unsupervised information extraction. © 2023 Association for Computational Linguistics.",Final,
Sedova A.; Roth B.,"Sedova, Anastasiia (57223729266); Roth, Benjamin (36165172500)",57223729266; 36165172500,ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172191359&partnerID=40&md5=06a04efa091b5d1ac2ac72ec5757296f,"Self-supervised knowledge-graph completion (KGC) relies on estimating a scoring model over (entity, relation, entity)-tuples, for example, by embedding an initial knowledge graph. Prediction quality can be improved by calibrating the scoring model, typically by adjusting the prediction thresholds using manually annotated examples. In this paper, we attempt for the first time cold-start calibration for KGC, where no annotated examples exist initially for calibration, and only a limited number of tuples can be selected for annotation. Our new method ACTC finds good per-relation thresholds efficiently based on a limited set of annotated tuples. Additionally to a few annotated tuples, ACTC also leverages unlabeled tuples by estimating their correctness with Logistic Regression or Gaussian Process classifiers. We also experiment with different methods for selecting candidate tuples for annotation: density-based and random selection. Experiments with five scoring models and an oracle annotator show an improvement of 7% points when using ACTC in the challenging setting with an annotation budget of only 10 tuples, and an average improvement of 4% points over different budgets. © 2023 Association for Computational Linguistics.",Final,
,,,"Proceedings of the 15th International Conference on Flexible Query Answering Systems, FQAS 2023",-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172080973&partnerID=40&md5=b033a7e91e3be04360e90c3f89515b82,"The proceedings contain 24 papers. The special focus in this conference is on Flexible Query Answering Systems. The topics include: Data as Wealth, Data Markets and Its Regulation; some Properties of the Left Recursive Form of the Convex Combination Linguistic Aggregator; automatic Generation of Coherent Natural Language Texts; methodology for Analyzing the Risk of Algorithmic Discrimination from a Legal and Technical Point of View; an Unsupervised Approach to Extracting Knowledge from the Relationships Between Blame Attribution on Twitter; a Fuzzy Approach to Detecting Suspected Disinformation in Videos; “Let It BEE”: Natural Language Classification of Arthropod Specimens Based on Their Spanish Description; interlingual Semantic Validation; diversifying Top-k Answers in a Query by Example Setting; all Trolls Have One Mission: An Entropy Analysis of Political Misinformation Spreaders; on Reducing Reasoning and Querying in Natural Logic to Database Querying; bot Detection in Twitter: An Overview; a First Evolutionary Fuzzy Approach for Change Mining with Smart Bands; Exploring Hidden Anomalies in UGR’16 Network Dataset with Kitsune; are Textual Recommendations Enough? Guiding Physicians Toward the Design of Machine Learning Pipelines Through a Visual Platform; Who Is to Blame? Responsibility Attribution in AI Systems vs Human Agents in the Field of Air Crashes; the Promise of Query Answering Systems in Sexuality Studies: Current State, Challenges and Limitations; knowledge Graph Enabled Open-Domain Conversational Question Answering; how Tasty Is This Dish? Studying User-Recipe Interactions with a Rating Prediction Algorithm and Graph Neural Networks; federated Learning in Healthcare with Unsupervised and Semi-Supervised Methods; an Orthographic Similarity Measure for Graph-Based Text Representations; preface.",Final,
Zhang R.; Li Y.; Zou L.,"Zhang, Ruoyu (57261601200); Li, Yanzeng (57814628700); Zou, Lei (8359099800)",57261601200; 57814628700; 8359099800,A Novel Table-to-Graph Generation Approach for Document-Level Joint Entity and Relation Extraction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174391788&partnerID=40&md5=711dc30ff89f585c6ffc197a9d085255,"Document-level relation extraction (DocRE) aims to extract relations among entities within a document, which is crucial for applications like knowledge graph construction. Existing methods usually assume that entities and their mentions are identified beforehand, which falls short of real-world applications. To overcome this limitation, we propose TAG, a novel table-to-graph generation model for joint extraction of entities and relations at document-level. To enhance the learning of task dependencies, TAG induces a latent graph among mentions, with different types of edges indicating different task information, which is further broadcast with a relational graph convolutional network. To alleviate the error propagation problem, we adapt the hierarchical agglomerative clustering algorithm to back-propagate task information at decoding stage. Experiments on the benchmark dataset, DocRED, demonstrate that TAG surpasses previous methods by a large margin and achieves state-of-the-art results. © 2023 Association for Computational Linguistics.",Final,
Wang S.; Wei Z.; Han M.; Fan Z.; Shan H.; Zhang Q.; Huang X.,"Wang, Siyuan (57218333522); Wei, Zhongyu (51666060600); Han, Meng (58314426400); Fan, Zhihao (57204472851); Shan, Haijun (55516124700); Zhang, Qi (57203621188); Huang, Xuanjing (8983710700)",57218333522; 51666060600; 58314426400; 57204472851; 55516124700; 57203621188; 8983710700,Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174264718&partnerID=40&md5=674a11f7d3a6b1c1f79a96ad6cca5621,"Logical reasoning over incomplete knowledge graphs to answer complex logical queries is a challenging task. With the emergence of new entities and relations in constantly evolving KGs, inductive logical reasoning over KGs has become a crucial problem. However, previous PLMs-based methods struggle to model the logical structures of complex queries, which limits their ability to generalize within the same structure. In this paper, we propose a structure-modeled textual encoding framework for inductive logical reasoning over KGs. It encodes linearized query structures and entities using pre-trained language models to find answers. For structure modeling of complex queries, we design stepwise instructions that implicitly prompt PLMs on the execution order of geometric operations in each query. We further separately model different geometric operations (i.e., projection, intersection, and union) on the representation space using a pre-trained encoder with additional attention and maxout layers to enhance structured modeling. We conduct experiments on two inductive logical reasoning datasets and three transductive datasets. The results demonstrate the effectiveness of our method on logical reasoning over KGs in both inductive and transductive settings. © 2023 Association for Computational Linguistics.",Final,
Zheng W.; Yan L.; Chen L.; Li Q.; Wang F.,"Zheng, Wenbo (57200190073); Yan, Lan (57203678797); Chen, Long (57651818100); Li, Qiang (57572827600); Wang, Fei-Yue (57211758869)",57200190073; 57203678797; 57651818100; 57572827600; 57211758869,Knowledge-Embedded Mutual Guidance for Visual Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173015690&doi=10.1109%2fTCYB.2023.3310892&partnerID=40&md5=f78dd0e04ac0ea16c36a3b99212e1495,"Visual reasoning between visual images and natural language is a long-standing challenge in computer vision. Most of the methods aim to look for answers to questions only on the basis of the analysis of the offered questions and images. Other approaches treat knowledge graphs as flattened tables to search for the answer. However, there are two major problems with these works: 1) the model disregards the fact that the world we surrounding us interlinks our hearing and speaking of natural language and 2) the model largely ignores the structure of the KG. To overcome these challenging deficiencies, a model should jointly consider two modalities of vision and language, as well as the rich structural and logical information embedded in knowledge graphs. To this end, we propose a general joint representation learning framework for visual reasoning; namely, <italic>knowledge-embedded mutual guidance</italic>. It realizes mutual guidance not only between visual data and natural language descriptions but also between knowledge graphs and reasoning models. In addition, it exploits the knowledge derived from the reasoning model to boost knowledge graphs when applying the visual relation detection task. The experimental results demonstrate that the proposed approach performs dramatically better than state-of-the-art methods on two benchmarks for visual reasoning. IEEE",Article in press,
Hu L.; Liu Z.; Zhao Z.; Hou L.; Nie L.; Li J.,"Hu, Linmei (56181376700); Liu, Zeyi (57819499800); Zhao, Ziwang (57967384600); Hou, Lei (56622056400); Nie, Liqiang (57205067955); Li, Juanzi (8304332600)",56181376700; 57819499800; 57967384600; 56622056400; 57205067955; 8304332600,A Survey of Knowledge Enhanced Pre-Trained Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170526787&doi=10.1109%2fTKDE.2023.3310002&partnerID=40&md5=bf2bf86601f890ece16e2ef6a7cb0223,"Pre-trained Language Models (PLMs) which are trained on large text corpus via self-supervised learning method, have yielded promising performance on various tasks in Natural Language Processing (NLP). However, though PLMs with huge parameters can effectively possess rich knowledge learned from massive training text and benefit downstream tasks at the fine-tuning stage, they still have some limitations such as poor reasoning ability due to the lack of external knowledge. Research has been dedicated to incorporating knowledge into PLMs to tackle these issues. In this paper, we present a comprehensive review of Knowledge Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear insight into this thriving field. We introduce appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide the types of knowledge into four categories: linguistic knowledge, text knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are categorized into KG-based and retrieval-based methods. Finally, we point out some promising future directions of KE-PLMs. IEEE",Article in press,All Open Access; Green Open Access
Pielka M.; Schmidt S.; Pucknat L.; Sifa R.,"Pielka, Maren (57211157805); Schmidt, Svetlana (58034451300); Pucknat, Lisa (57478295200); Sifa, Rafet (55546297500)",57211157805; 58034451300; 57478295200; 55546297500,Towards Linguistically Informed Multi-objective Transformer Pre-training for Natural Language Inference,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150976671&doi=10.1007%2f978-3-031-28238-6_46&partnerID=40&md5=654d754e50fd6330904146bc68155e19,"We introduce a linguistically enhanced combination of pre-training methods for transformers. The pre-training objectives include POS-tagging, synset prediction based on semantic knowledge graphs, and parent prediction based on dependency parse trees. Our approach achieves competitive results on the Natural Language Inference task, compared to the state of the art. Specifically for smaller models, the method results in a significant performance boost, emphasizing the fact that intelligent pre-training can make up for fewer parameters and help building more efficient models. Combining POS-tagging and synset prediction yields the overall best results. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Baek J.; Aji A.F.; Lehmann J.; Hwang S.J.,"Baek, Jinheon (57219628188); Aji, Alham Fikri (58583850200); Lehmann, Jens (35229806900); Hwang, Sung Ju (57687927300)",57219628188; 58583850200; 35229806900; 57687927300,Direct Fact Retrieval from Knowledge Graphs without Entity Linking,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174384507&partnerID=40&md5=a9300a3088b6f6b79e3121a92847a3bf,"There has been a surge of interest in utilizing Knowledge Graphs (KGs) for various natural language processing/understanding tasks. The conventional mechanism to retrieve facts in KGs usually involves three steps: entity span detection, entity disambiguation, and relation classification. However, this approach requires additional labels for training each of the three subcomponents in addition to pairs of input texts and facts, and also may accumulate errors propagated from failures in previous steps. To tackle these limitations, we propose a simple knowledge retrieval framework, which directly retrieves facts from the KGs given the input text based on their representational similarities, which we refer to as Direct Fact Retrieval (DiFaR). Specifically, we first embed all facts in KGs onto a dense embedding space by using a language model trained by only pairs of input texts and facts, and then provide the nearest facts in response to the input text. Since the fact, consisting of only two entities and one relation, has little context to encode, we propose to further refine ranks of top-k retrieved facts with a reranker that contextualizes the input text and the fact jointly. We validate our DiFaR framework on multiple fact retrieval tasks, showing that it significantly outperforms relevant baselines that use the three-step approach. © 2023 Association for Computational Linguistics.",Final,
Liu T.; Hu Y.; Chen P.; Sun Y.; Yin B.,"Liu, Tengfei (57220169432); Hu, Yongli (7407118245); Chen, Puman (57285820600); Sun, Yanfeng (9736644400); Yin, Baocai (8616230700)",57220169432; 7407118245; 57285820600; 9736644400; 8616230700,Zero-Shot Text Classification with Semantically Extended Textual Entailment,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169548424&doi=10.1109%2fIJCNN54540.2023.10191094&partnerID=40&md5=33c2bacec99df83a78f6292ade079d93,"Zero-shot text classification (0SHOT-TC) aims to detect classes that the model never seen in the training set, and has attracted much attention in the research community of Natural Language Processing (NLP). The emergence of pre-trained language models has fostered the progress of 0SHOT-TC, which turns the task into a textual entailment problem of binary classification. It learns an entailment relatedness (yes/no) between the given sentence (premise) and each category (hypothesis) separately. However, the hypothesis generation paradigms need to be further studied, since the label itself or the label descriptions have limited ability to fully express the category space. Conversely, humans can easily extend a set of words describing the categories to be classified. In this paper, we propose a novel zero-shot text classification method called Semantically Extended Textual Entailment (SETE), which imitates the human's ability in knowledge extension. In the proposed method, three semantic extension methods are used to enrich the categories through a combination of static knowledge (e.g. expert knowledge, knowledge graph) and dynamic knowledge (e.g. language models), and the textual entailment model is finally used for 0SHOT-TC. The experimental results on the benchmarks show that our approach significantly outperforms the current methods in both generalized and non-generalized 0SHOT-TC. © 2023 IEEE.",Final,
Saadat-Yazdi A.; Pan J.Z.; Kökciyan N.,"Saadat-Yazdi, Ameer (57274337800); Pan, Jeff Z. (8856621200); Kökciyan, Nadin (55587819200)",57274337800; 8856621200; 55587819200,Uncovering Implicit Inferences for Improved Relational Argument Mining,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159853636&partnerID=40&md5=40663f5cf7404f823d759d0cfd82c538,"Argument mining seeks to extract arguments and their structure from unstructured texts. Identifying relations (such as attack, support, and neutral) between argumentative units is a challenging task because two units may be related to each other via implicit inferences. These inferences often rely on external commonsense knowledge to discover how one argumentative unit relates to another. State-of-the-art methods, however, rely on predefined knowledge graphs, and thus might not cover target pairs of argumentative units well. We introduce a new generative approach to finding inference chains that connect these pairs by making use of the Commonsense Transformer (COMET). We evaluate our approach on three datasets for both the two-label (attack/support) and three-label (attack/support/neutral) tasks. Our approach significantly outperforms the state-of-the-art, by 2-5% in F1 score, on two out of the three datasets with minor improvements on the remaining one. © 2023 Association for Computational Linguistics.",Final,
Li S.; Jiang W.; Si P.; Yang C.; Qiu Y.; Zhang J.; Zhou J.; Yang Y.,"Li, Siheng (57686691600); Jiang, Wangjie (57798510500); Si, Pengda (57205745102); Yang, Cheng (57001472900); Qiu, Yao (57275213500); Zhang, Jinchao (57216614926); Zhou, Jie (57211746430); Yang, Yujiu (35729585000)",57686691600; 57798510500; 57205745102; 57001472900; 57275213500; 57216614926; 57211746430; 35729585000,Enhancing Dialogue Generation with Conversational Concept Flows,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159857556&partnerID=40&md5=ec37f2cb428d60c4e74c4fd9382bac85,"Human conversations contain natural and reasonable topic shifts, reflected as the concept flows across utterances. Previous researches prove that explicitly modeling concept flows with a large commonsense knowledge graph effectively improves response quality. However, we argue that there exists a gap between the knowledge graph and the conversation. The knowledge graph has limited commonsense knowledge and ignores the characteristics of natural conversations. Thus, many concepts and relations in conversations are not included. To bridge this gap, we propose to enhance dialogue generation with conversational concept flows. Specifically, we extract abundant concepts and relations from natural conversations and build a new conversation-aware knowledge graph. In addition, we design a novel relation-aware graph encoder to capture the concept flows guided by the knowledge graph. Experimental results on the large-scale Reddit conversation dataset indicate that our method performs better than strong baselines, and further analysis verifies the effectiveness of each component. © 2023 Association for Computational Linguistics.",Final,
Cohen R.; Geva M.; Berant J.; Globerson A.,"Cohen, Roi (58095297800); Geva, Mor (57198508721); Berant, Jonathan (52163188700); Globerson, Amir (18934352000)",58095297800; 57198508721; 52163188700; 18934352000,Crawling The Internal Knowledge-Base of Language Models,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151094098&partnerID=40&md5=0841d1d3a7c9fb6508948d96a2859b1c,"Language models are trained on large volumes of text, and as a result their parameters might contain a significant body of factual knowledge. Any downstream task performed by these models implicitly builds on these facts, and thus it is highly desirable to have means for representing this body of knowledge in an interpretable way. However, there is currently no mechanism for such a representation. Here, we propose to address this goal by extracting a knowledge-graph of facts from a given language model. We describe a procedure for “crawling” the internal knowledge-base of a language model. Specifically, given a seed entity, we expand a knowledge-graph around it. The crawling procedure is decomposed into sub-tasks, realized through specially designed prompts that control for both precision (i.e., that no wrong facts are generated) and recall (i.e., the number of facts generated). We evaluate our approach on graphs crawled starting from dozens of seed entities, and show it yields high precision graphs (82-92%), while emitting a reasonable number of facts per entity. © 2023 Association for Computational Linguistics.",Final,
Mirtaheri M.; Rostami M.; Galstyan A.,"Mirtaheri, Mehrnoosh (57197876200); Rostami, Mohammad (55408018500); Galstyan, Aram (7003679856)",57197876200; 55408018500; 7003679856,History Repeats: Overcoming Catastrophic Forgetting For Event-Centric Temporal Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174129964&partnerID=40&md5=c4e7370f4fc523f053b1737d1752242c,"Temporal knowledge graph (TKG) completion models typically rely on having access to the entire graph during training. However, in real-world scenarios, TKG data is often received incrementally as events unfold, leading to a dynamic non-stationary data distribution over time. While one could incorporate fine-tuning to existing methods to allow them to adapt to evolving TKG data, this can lead to forgetting previously learned patterns. Alternatively, retraining the model with the entire updated TKG can mitigate forgetting but is computationally burdensome. To address these challenges, we propose a general continual training framework that is applicable to any TKG completion method, and leverages two key ideas: (i) a temporal regularization that encourages repurposing of less important model parameters for learning new knowledge, and (ii) a clustering-based experience replay that reinforces the past knowledge by selectively preserving only a small portion of the past data. Our experimental results on widely used event-centric TKG datasets demonstrate the effectiveness of our proposed continual training framework in adapting to new events while reducing catastrophic forgetting. Further, we perform ablation studies to show the effectiveness of each component of our proposed framework. Finally, we investigate the relation between the memory dedicated to experience replay and the benefit gained from our clustering-based sampling strategy. © 2023 Association for Computational Linguistics.",Final,
Perez-Beltrachini L.; Jain P.; Monti E.; Lapata M.,"Perez-Beltrachini, Laura (43061399900); Jain, Parag (57214221258); Monti, Emilio (57217163724); Lapata, Mirella (55910108500)",43061399900; 57214221258; 57217163724; 55910108500,Semantic Parsing for Conversational Question Answering over Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159861014&partnerID=40&md5=f9ea647d798225fa730d6a389d5c7c49,"In this paper, we are interested in developing semantic parsers which understand natural language questions embedded in a conversation with a user and ground them to formal queries over definitions in a general purpose knowledge graph (KG) with very large vocabularies (covering thousands of concept names and relations, and millions of entities). To this end, we develop a dataset where user questions are annotated with SPARQL parses and system answers correspond to execution results thereof. We present two different semantic parsing approaches and highlight the challenges of the task: dealing with large vocabularies, modelling conversation context, predicting queries with multiple entities, and generalising to new questions at test time. We hope our dataset will serve as useful testbed for the development of conversational semantic parsers. © 2023 Association for Computational Linguistics.",Final,
Nguyen C.D.M.; French T.; Liu W.; Stewart M.,"Nguyen, Chau Duc Minh (58282242700); French, Tim (13611425300); Liu, Wei (36077178500); Stewart, Michael (57196713433)",58282242700; 13611425300; 36077178500; 57196713433,CylE: Cylinder Embeddings for Multi-hop Reasoning over Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159859189&partnerID=40&md5=2e382a720664e4b5b1242043319730b2,"Recent geometric-based approaches have been shown to efficiently model complex logical queries (including the intersection operation) over Knowledge Graphs based on the natural representation of Venn diagram. Existing geometric-based models (using points, boxes embeddings), however, cannot handle the logical negation operation. Further, those using cones embeddings are limited to representing queries by two-dimensional shapes, which reduced their effectiveness in capturing entities query relations for correct answers. To overcome this challenge, we propose unbounded cylinder embeddings (namely CylE), which is a novel geometric-based model based on three-dimensional shapes. Our approach can handle a complete set of basic first-order logic operations (conjunctions, disjunctions and negations). CylE considers queries as Cartesian products of unbounded sector-cylinders and consider a set of nearest boxes corresponds to the set of answer entities. Precisely, the conjunctions can be represented via the intersections of unbounded sector-cylinders. Transforming queries to Disjunctive Normal Form can handle queries with disjunctions. The negations can be represented by considering the closure of complement for an arbitrary unbounded sector-cylinder. Empirical results show that the performance of multi-hop reasoning task using CylE significantly increases over state-of-the-art geometric-based query embedding models for queries without negation. For queries with negation operations, though the performance is on a par with the best performing geometric-based model, CylE significantly outperforms a recent distribution-based model. © 2023 Association for Computational Linguistics.",Final,
Wang A.; Duan P.; Li Y.; Hu W.; Xiong S.,"Wang, Aoxing (58566007300); Duan, Pengfei (39461199200); Li, Yongbing (58566007400); Hu, Wenyan (58565661700); Xiong, Shengwu (57203905556)",58566007300; 39461199200; 58566007400; 58565661700; 57203905556,LMGFuse: Language Models and Graph reasoning Fuse deeply for question answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170036315&doi=10.18293%2fSEKE2023-023&partnerID=40&md5=1c3db8f6e91205c1057c7ac669e9851c,"The combination of pre-trained language models (LM) and knowledge graphs (KG) can enhance the reasoning ability for Question Answering. However, previous methods typically fuse the two modalities in a shallow or knowledge-draining manner, not taking full advantage of the knowledge representation of both. How to effectively fuse the different knowledge representations is still a problem of current research. In our work, a novel model is proposed that fuses LM modal knowledge representations and graph neural network (GNN) modal knowledge representations deeply over multiple layers of modality interaction operations. Specifically, the model includes an information interaction unit, through which KG and LM knowledge can be transferred between modalities to realize knowledge fusion directly, reducing information loss. In addition, we add the context node of implicit knowledge from LM encoding in the construction of the reasoning subgraph in advance for enhancing the reasoning of the GNN. We evaluate our model on two domains in the biomedical benchmark (MedQA-USMLE) and commonsense benchmarks (OpenBookQA and CommonsenseQA). Experimental results show that our model achieves a particular improvement over existing LM and LM+KG models for reasoning over both situational constraints and structured knowledge. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Final,All Open Access; Bronze Open Access
He J.; Simon Chi Lok U.; Gutiérrez-Basulto V.; Pan J.Z.,"He, Jie (58405192100); Simon Chi Lok, U. (58407315100); Gutiérrez-Basulto, Víctor (36607853700); Pan, Jeff Z. (8856621200)",58405192100; 58407315100; 36607853700; 8856621200,BUCA: A Binary Classification Approach to Unsupervised Commonsense Question Answering,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172243565&partnerID=40&md5=d043c884578e03a732f53ebd11aa3abf,"Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), but this usually requires a large number of training examples. In this paper, we propose to transform the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. To this end, for training the model, we convert the knowledge graph triples into reasonable and unreasonable texts. Extensive experimental results show the effectiveness of our approach on various multiple choice question answering benchmarks. Furthermore, compared with existing UCR approaches using KGs, ours is less data hungry. Our code is available at https://github.com/probe2/BUCA. © 2023 Association for Computational Linguistics.",Final,
Lu Y.; Bao J.; Ma Z.; Han X.; Wu Y.; Cui S.; He X.,"Lu, Yu (57851320400); Bao, Junwei (57224540005); Ma, Zichen (57224977789); Han, Xiaoguang (55451013500); Wu, Youzheng (57211752827); Cui, Shuguang (57210290902); He, Xiaodong (37085932700)",57851320400; 57224540005; 57224977789; 55451013500; 57211752827; 57210290902; 37085932700,AUGUST: an Automatic Generation Understudy for Synthesizing Conversational Recommendation Datasets,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172432428&partnerID=40&md5=0cbb0900efe4690f942b4fbfb0592114,"High-quality data is essential for conversational recommendation systems and serves as the cornerstone of the network architecture development and training strategy design. Existing works contribute heavy human efforts to manually labeling or designing and extending recommender dialogue templates. However, they suffer from: (i) the limited number of human annotators results in that datasets can hardly capture rich and large-scale cases in the real world, (ii) the limited experience and knowledge of annotators accounts for the uninformative corpus and inappropriate recommendations. In this paper, we propose a novel automatic dataset synthesis approach that can generate both large-scale and high-quality recommendation dialogues through a data2text generation process, where unstructured recommendation conversations are generated from structured graphs based on user-item information from the real world. In doing so, we comprehensively exploit: (i) rich personalized user profiles from traditional recommendation datasets, (ii) rich external knowledge from knowledge graphs, and (iii) the conversation ability contained in human-to-human conversational recommendation datasets. Extensive experiments validate the benefit brought by the automatically syn-thesised data under the low-resource scenarios, and demonstrates the promising potential to facilitate developing a more effective conversational recommendation system. © 2023 Association for Computational Linguistics.",Final,
Gao S.; Borges B.; Oh S.; Bayazit D.; Kanno S.; Wakaki H.; Mitsufuji Y.; Bosselut A.,"Gao, Silin (57710377800); Borges, Beatriz (57224542338); Oh, Soyoung (58303520900); Bayazit, Deniz (58655352300); Kanno, Saya (57905252300); Wakaki, Hiromi (57903831200); Mitsufuji, Yuki (55967134100); Bosselut, Antoine (57193225759)",57710377800; 57224542338; 58303520900; 58655352300; 57905252300; 57903831200; 55967134100; 57193225759,PEACOK: Persona Commonsense Knowledge for Consistent and Engaging Narratives,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174388824&partnerID=40&md5=afb4245b08ca9ebbbcf28a65b038d906,"Sustaining coherent and engaging narratives requires dialogue or storytelling agents to understand how the personas of speakers or listeners ground the narrative. Specifically, these agents must infer personas of their listeners to produce statements that cater to their interests. They must also learn to maintain consistent speaker personas for themselves throughout the narrative, so that their counterparts feel involved in a realistic conversation or story. However, personas are diverse and complex: they entail large quantities of rich interconnected world knowledge that is challenging to robustly represent in general narrative systems (e.g., a singer is good at singing, and may have attended conservatoire). In this work, we construct a new large-scale persona commonsense knowledge graph, PEACOK, containing ∼100K human-validated persona facts. Our knowledge graph schematizes five dimensions of persona knowledge identified in previous studies of human interactive behaviours, and distils facts in this schema from both existing commonsense knowledge graphs and large-scale pretrained language models. Our analysis indicates that PEACOK contains rich and precise world persona inferences that help downstream systems generate more consistent and engaging narratives. © 2023 Association for Computational Linguistics.",Final,
Min C.; Na H.; Song Y.; Ahn J.; Im D.-H.,"Min, Chanwook (58112697500); Na, Hyungsun (58451541000); Song, Yeji (57417544000); Ahn, Jinhyun (56621886700); Im, Dong-Hyuk (55194116800)",58112697500; 58451541000; 57417544000; 56621886700; 55194116800,Effective Use of Knowledge Graphs in a Language Representation Model,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163974986&doi=10.1007%2f978-981-99-1252-0_98&partnerID=40&md5=740b0269e1c38c61d2f4ceeb73e5346f,"Methods such as knowledge-enabled language representation model (K-BERT) that help train models using external information, such as knowledge graphs, have recently been proposed in the field of natural language processing. However, adding knowledge that does not match the topic when external information is used may hinder training. Hence, a method is required that adds only knowledge matching the topic of the input data by partitioning the external information by topic. Topic-based knowledge graph BERT (TK-BERT), which uses the existing latent Dirichlet allocation (LDA) model to partition the knowledge, does not consider the contextual information. To compensate for this drawback and effectively use external information, this study uses the BERTopic technique to partition the knowledge graph. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Fung Y.; Wang H.; Wang T.; Kebarighotbi A.; Bansal M.; Ji H.; Natarajan P.,"Fung, Yi (57221303250); Wang, Han (58608180500); Wang, Tong (57221095004); Kebarighotbi, Ali (35792089900); Bansal, Mohit (16466939600); Ji, Heng (35240121900); Natarajan, Prem (8601591400)",57221303250; 58608180500; 57221095004; 35792089900; 16466939600; 35240121900; 8601591400,DeepMaven: Deep Question Answering on Long-Distance Movie/TV Show Videos with Multimedia Knowledge Extraction and Synthesis,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159851183&partnerID=40&md5=f3044e26daaa64b1edb4ab709c00a3cf,"Long video content understanding poses a challenging set of research questions as it involves long-distance, cross-media reasoning and knowledge awareness. In this paper, we present a new benchmark for this problem domain, targeting the task of deep movie/TV question answering (QA) beyond previous work's focus on simple plot summary and short video moment settings. We define several baselines based on direct retrieval of relevant context for long-distance movie QA. Observing that real-world QAs may require higher-order multi-hop inferences, we further propose a novel framework, called the DEEPMAVEN, which extracts events, entities, and relations from the rich multimedia content in long videos to preconstruct movie knowledge graphs (movieKGs), and at the time of QA inference, complements general semantics with structured knowledge for more effective information retrieval and knowledge reasoning. We also introduce our recently collected DeepMovieQA dataset, including 1,000 long-form QA pairs from 41 hours of videos, to serve as a new and useful resource for future work. Empirical results show the DeepMaven performs competitively for both the new DeepMovieQA and the pre-existing MovieQA dataset. © 2023 Association for Computational Linguistics.",Final,
Cripwell L.; Belz A.; Gardent C.; Gatt A.; Borg C.; Borg M.; Judge J.; Lorandi M.; Nikiforovskaya A.; Soto-Martinez W.; Thomson C.,"Cripwell, Liam (57190666850); Belz, Anya (58876536800); Gardent, Claire (14015644100); Gatt, Albert (22937542800); Borg, Claudia (57198796886); Borg, Marthese (58886891200); Judge, John (57953649500); Lorandi, Michela (57222867073); Nikiforovskaya, Anna (57221152979); Soto-Martinez, William (58886954100); Thomson, Craig (57217389216)",57190666850; 58876536800; 14015644100; 22937542800; 57198796886; 58886891200; 57953649500; 57222867073; 57221152979; 58886954100; 57217389216,The 2023 WebNLG Shared Task on Low Resource Languages Overview and Evaluation Results (WebNLG 2023),-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170846749&partnerID=40&md5=a35a54b4c7893393c6ee15f93b43879f,"The WebNLG task consists of mapping a knowledge graph to a text verbalising the content of that graph. The 2017 WebNLG edition required participating systems to generate English text from a set of DBpedia triples, while the 2020 WebNLG+ challenge additionally included generation into Russian and semantic parsing of English and Russian texts. In contrast, WebNLG 2023 focuses on four under-resourced languages which are severely under-represented in research on text generation, namely Breton, Irish, Maltese and Welsh. In addition, WebNLG 2023 once again includes Russian. In this paper, we present the organisation of the shared task (data, timeline, evaluation), briefly describe the participating systems and summarise results for participating systems. © 2023 Association for Computational Linguistics.",Final,
Wang R.; Li B.; Lu Y.; Sun D.; Li J.; Yan Y.; Liu S.; Tong H.; Abdelzaher T.F.,"Wang, Ruijie (57219371499); Li, Baoyu (58507119200); Lu, Yichen (58506896400); Sun, Dachun (57217170629); Li, Jinning (57203539613); Yan, Yuchen (57222727289); Liu, Shengzhong (57203223910); Tong, Hanghang (7201360533); Abdelzaher, Tarek F. (7004058432)",57219371499; 58507119200; 58506896400; 57217170629; 57203539613; 57222727289; 57203223910; 7201360533; 7004058432,Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174045730&partnerID=40&md5=0c7e263a048423dedfcbd14853c28938,"This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both false negative issue (i.e., potential true facts being excluded) and false positive issue (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call label posterior) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies missing facts to provide high-quality grounds of reasoning. They are unified in a simple yet effective self-training procedure. Empirically, extensive experiments on three benchmark KG and one Twitter dataset with various degrees of false negative/positive cases demonstrate the effectiveness of nPUGraph. © 2023 Association for Computational Linguistics.",Final,
Di Bonaventura C.; Muti A.; Stranisci M.A.,"Di Bonaventura, Chiara (57848860300); Muti, Arianna (57220748586); Stranisci, Marco Antonio (57198815487)",57848860300; 57220748586; 57198815487,O-Dang at HODI and HaSpeeDe3: A Knowledge-Enhanced Approach to Homotransphobia and Hate Speech Detection in Italian,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173573144&partnerID=40&md5=198199f704c5e253d766d66a65bcf862,"This paper describes our methods implemented during the EVALITA 2023 campaign for homotransphobia (HODI task) and hate speech detection (HaSpeeDe3 task) in Italian. We present three knowledge-enhanced approaches, namely via triple verbalisation, via prompting and via a majority vote, and we compare them to the AlBERTo baseline. These systems leverage the knowledge graph O-Dang, which contains information about named entities in Italian dangerous speech. Our knowledge-enhanced systems outperformed all the competition's baselines. Our best submissions achieved the macro-F1 score of 0.912 for HaSpeeDe3 and 0.795 for HODI, reaching the 1st and 3rd place, respectively. These results were achieved by using our baseline for HODI, and a majority voting approach for HaSpeeDe3. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Schwertmann L.; Ravi M.P.K.; de Melo G.,"Schwertmann, Lena (57207834770); Ravi, Manoj Prabhakar Kannan (57222109070); de Melo, Gerard (23088528100)",57207834770; 57222109070; 23088528100,Model-Agnostic Bias Measurement in Link Prediction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159850556&partnerID=40&md5=2d89a5635d899b46d4a9a9f9baafac09,"Link prediction models based on factual knowledge graphs are commonly used in applications such as search and question answering. However, work investigating social bias in these models has been limited. Previous work focused on knowledge graph embeddings, so more recent classes of models achieving superior results by fine-tuning Transformers have not yet been investigated. We therefore present a model-agnostic approach for bias measurement leveraging fairness metrics to compare bias in knowledge graph embedding-based predictions (KG only) with models that use pre-trained, Transformer-based language models (KG+LM). We further create a dataset to measure gender bias in occupation predictions and assess whether the KG+LM models are more or less biased than KG only models. We find that gender bias tends to be higher for the KG+LM models and analyze potential connections to the accuracy of the models and the data bias inherent in our dataset. Finally, we discuss limitations and ethical considerations of our work. The repository containing the source code and the data set is publicly available at https://github.com/lena-schwert/comparing-bias-in-KG-models. © 2023 Association for Computational Linguistics.",Final,
Jiang C.; Zhu T.; Zhou H.; Liu C.; Deng T.; Hu C.; Li J.,"Jiang, Chunyang (57829835300); Zhu, Tianchen (57477485100); Zhou, Haoyi (57196123986); Liu, Chang (57221259012); Deng, Ting (24463471900); Hu, Chunming (36091049100); Li, Jianxin (55720560100)",57829835300; 57477485100; 57196123986; 57221259012; 24463471900; 36091049100; 55720560100,Path Spuriousness-aware Reinforcement Learning for Multi-Hop Knowledge Graph Reasoning,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159855166&partnerID=40&md5=6d4e0a1801de214b652af974adceb4c4,"Multi-hop reasoning; a prevalent approach for query answering, aims at inferring new facts along reasonable paths over a knowledge graph. Reinforcement learning (RL) methods can be adopted by formulating the problem into a Markov decision process. However, common suffering within RL-based reasoning models is that the agent can be biased to spurious paths which coincidentally lead to the correct answer with poor explanation. In this work, we take a deep dive into this phenomenon and define a metric named Path Spuriousness (PS), to quantitatively estimate to what extent a path is spurious. Guided by the definition of PS, we design a model with a new reward that considers both answer accuracy and path reasonableness. We test our method on five datasets and experiments reveal that our method considerably enhances the agent's capacity to prevent spurious paths while keeping comparable to state-of-the-art performance. © 2023 Association for Computational Linguistics.",Final,
Wang Y.; Wang W.; Chen Q.; Huang K.; Nguyen A.; De S.,"Wang, Yuqi (57304296500); Wang, Wei (56948482100); Chen, Qi (57307371300); Huang, Kaizhu (13403476100); Nguyen, Anh (57650295900); De, Suparna (24722884400)",57304296500; 56948482100; 57307371300; 13403476100; 57650295900; 24722884400,Prompt-based Zero-shot Text Classification with Conceptual Knowledge,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173429815&partnerID=40&md5=9ee0d9a1deff1ba135017a17249dbb82,"In recent years, pre-trained language models have garnered significant attention due to their effectiveness, which stems from the rich knowledge acquired during pre-training. To mitigate the inconsistency issues between pre-training tasks and downstream tasks and to facilitate the resolution of language-related issues, prompt-based approaches have been introduced, which are particularly useful in low-resource scenarios. However, existing approaches mostly rely on verbalizers to translate the predicted vocabulary to task-specific labels. The major limitations of this approach are the ignorance of potentially relevant domain-specific words and being biased by the pre-training data. To address these limitations, we propose a framework that incorporates conceptual knowledge for text classification in the extreme zero-shot setting. The framework includes prompt-based keyword extraction, weight assignment to each prompt keyword, and final representation estimation in the knowledge graph embedding space. We evaluated the method on four widely-used datasets for sentiment analysis and topic detection, demonstrating that it consistently outperforms recently-developed prompt-based approaches in the same experimental settings. © 2023 Association for Computational Linguistics.",Final,
Li R.; Chen X.; Li C.; Shen Y.; Zhao J.; Wang Y.; Han W.; Sun H.; Deng W.; Zhang Q.; Xie X.,"Li, Rui (57200722715); Chen, Xu (57189698899); Li, Chaozhuo (57196073466); Shen, Yanming (22835995600); Zhao, Jianan (57815547500); Wang, Yujing (56347999900); Han, Weihao (57209227296); Sun, Hao (57216325974); Deng, Weiwei (57203399957); Zhang, Qi (54931372200); Xie, Xing (57221820833)",57200722715; 57189698899; 57196073466; 22835995600; 57815547500; 56347999900; 57209227296; 57216325974; 57203399957; 54931372200; 57221820833,To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174388798&partnerID=40&md5=26fcf57464eb6243425818d3d9af1f31,"Embedding models have shown great power in knowledge graph completion (KGC) task. By learning structural constraints for each training triple, these methods implicitly memorize intrinsic relation rules to infer missing links. However, this paper points out that the multi-hop relation rules are hard to be reliably memorized due to the inherent deficiencies of such implicit memorization strategy, making embedding models underperform in predicting links between distant entity pairs. To alleviate this problem, we present Vertical Learning Paradigm (VLP), which extends embedding models by allowing to explicitly copy target information from related factual triples for more accurate prediction. Rather than solely relying on the implicit memory, VLP directly provides additional cues to improve the generalization ability of embedding models, especially making the distant link prediction significantly easier. Moreover, we also propose a novel relative distance based negative sampling technique (ReD) for more effective optimization. Experiments demonstrate the validity and generality of our proposals on two standard benchmarks. Our code is available at https://github.com/rui9812/VLP. © 2023 Association for Computational Linguistics.",Final,
Ng H.W.; Koh A.; Foong A.; Ong J.,"Ng, Han Wei (57844280000); Koh, Aiden (57844023800); Foong, Anthea (57844797200); Ong, Jeremy (7103112675)",57844280000; 57844023800; 57844797200; 7103112675,Real-Time Hybrid Language Model for Virtual Patient Conversations,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164941428&doi=10.1007%2f978-3-031-36272-9_71&partnerID=40&md5=03f92b525169632d16fc9a139af46cdd,"Advancements in deep learning have enabled the development of online learning tools for medical training, which is important for remote learning. However, face-to-face interaction is essential for practicing human-centric skills such as clinical skills. Presently, in medical training, such interactions can be mimicked using deep learning methodologies. However, the understanding of such models is often limited whereby lightweight models are unable to generalize beyond scope while large language models tend to produce unexpected responses. To overcome this, we propose a hybrid lightweight and large language model for creating virtual patients, which can be used for real-time autonomous training of trainee doctors in clinical settings using online platforms. This ensures high-quality and standardized learning for all individuals regardless of location and background. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Roy K.; Garg T.; Palit V.,"Roy, Kaushik (57221320197); Garg, Tarun (55406928700); Palit, Vedant (58303348300)",57221320197; 55406928700; 58303348300,Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168704444&doi=10.1109%2fCAI54212.2023.00108&partnerID=40&md5=c0ce1f2cb00152b17f9feca07f79c0e6,"A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowledge graphs. This has significant application-level user trust implications as stochastic patterns without a strong sense of meaning cannot be trusted in high-stakes applications.  © 2023 IEEE.",Final,All Open Access; Green Open Access
Kale K.; Bhattacharyya P.; Gune M.; Shetty A.; Lawyer R.,"Kale, Kaveri (57766457200); Bhattacharyya, Pushpak (7101803108); Gune, Milind (6507129306); Shetty, Aditya (57221834802); Lawyer, Rustom (57765804700)",57766457200; 7101803108; 6507129306; 57221834802; 57765804700,KGVL-BART: Knowledge Graph Augmented Visual Language BART for Radiology Report Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159860119&partnerID=40&md5=0e22ea05b76f6c8b06521037374425fb,"Timely generation of radiology reports and diagnoses is a challenge worldwide due to the enormous number of cases and shortage of radiology specialists. In this paper, we propose a Knowledge Graph Augmented Vision Language BART (KGVL-BART) model that takes as input two chest X-ray images- one frontal and the other lateral- along with tags which are diagnostic keywords, and outputs a report with the patient-specific findings. Our system development effort is divided into 3 stages: i) construction of the Chest X-ray KG (referred to as chestX-KG), ii) image feature extraction, and iii) training a KGVL-BART model using the visual, text, and KG data. The dataset we use is the well-known Indiana University Chest X-ray reports with the train, validation, and test split of 3025 instances, 300 instances, and 500 instances respectively. We construct a Chest X-Ray knowledge graph from these reports by extracting entity1-relation-entity2 triples; the triples get extracted by a rule-based tool of our own. Constructed KG is verified by two experienced radiologists (with experience of 30 years and 8 years, respectively). We demonstrate that our model- KGVL-BART- outperforms State-of-the-Art transformer-based models on standard NLG scoring metrics. We also include a qualitative evaluation of our system by experienced radiologist (with experience of 30 years) on the test data, which showed that 73% of the reports generated were fully correct, only 5.5% are completely wrong and 21.5% have important missing details though overall correct. To the best of our knowledge, ours is the first system to make use of multi-modality and domain knowledge to generate X-ray reports automatically. © 2023 Association for Computational Linguistics.",Final,
To N.D.; Reformat M.Z.; Yager R.R.,"To, Nhuan D. (57195642538); Reformat, Marek Z. (6603618138); Yager, Ronald R. (35618760400)",57195642538; 6603618138; 35618760400,Human-Centric Question-Answering System with Linguistic Terms,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153373680&doi=10.1007%2f978-3-031-25759-9_12&partnerID=40&md5=06265b51058ca48073516133f852b253,"Current Question-Answering Systems can automatically answer questions posed by humans in a natural language. However, most of them can only answer questions that do not contain imprecise concepts and lead to short answers. This paper introduces a Human-Centric Question-Answering system capable of answering questions containing user-defined, personalized linguistic terms. The system works with information represented in the form of knowledge graphs. We describe the system and present its main components, emphasizing a few extensions that make the system distinctive. We illustrate the execution of the system with a few examples. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Ge X.; Wang Y.-C.; Wang B.; Jay Kuo C.-C.,"Ge, Xiou (57202498636); Wang, Yun-Cheng (57218521783); Wang, Bin (57209905481); Jay Kuo, C.-C. (57580595700)",57202498636; 57218521783; 57209905481; 57580595700,Compounding Geometric Operations for Knowledge Graph Completion,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173113764&partnerID=40&md5=2e9cda1fe2d00ae30a49318c849f0a4c,"Geometric transformations including translation, rotation, and scaling are commonly used operations in image processing. Besides, some of them are successfully used in developing effective knowledge graph embedding (KGE). Inspired by the synergy, we propose a new KGE model by leveraging all three operations in this work. Since translation, rotation, and scaling operations are cascaded to form a composite one, the new model is named CompoundE. By casting CompoundE in the framework of group theory, we show that quite a few distanced-based KGE models are special cases of CompoundE. CompoundE extends the simple distance-based scoring functions to relation-dependent compound operations on head and/or tail entities. To demonstrate the effectiveness of CompoundE, we perform three prevalent KG prediction tasks including link prediction, path query answering, and entity typing, on a range of datasets. CompoundE outperforms extant models consistently, demonstrating its effectiveness and flexibility. © 2023 Association for Computational Linguistics.",Final,
Zou J.; Xu X.; Hou J.; Yan Q.; Zheng H.-T.,"Zou, Jiaxin (57945864700); Xu, Xianghong (57678048800); Hou, Jiawei (58560730400); Yan, Qiang (57217028802); Zheng, Hai-Tao (57203433967)",57945864700; 57678048800; 58560730400; 57217028802; 57203433967,Self-supervised Bidirectional Prompt Tuning for Entity-enhanced Pre-trained Language Model,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169602416&doi=10.1109%2fIJCNN54540.2023.10192045&partnerID=40&md5=5693123f4b19acc41a50f9ea7dc2c96e,"With the promotion of the pre-training paradigm, researchers are increasingly focusing on injecting external knowledge, such as entities and triplets from knowledge graphs, into pre-trained language models (PTMs) to improve their understanding and logical reasoning abilities. This results in significant improvements in natural language understanding and generation tasks and some level of interpretability. In this paper, we propose a novel two-stage entity knowledge enhancement pipeline for Chinese pre-trained models based on 'bidirectional' prompt tuning. The pipeline consists of a 'forward' stage, in which we construct fine-grained entity type prompt templates to boost PTMs injected with entity knowledge, and a 'backward' stage, where the trained templates are used to generate type-constrained context-dependent negative samples for contrastive learning. Experiments on six classification tasks in the Chinese Language Understanding Evaluation (CLUE) benchmark demonstrate that our approach significantly improves upon the baseline results in most datasets, particularly those that have a strong reliance on diverse and extensive knowledge. © 2023 IEEE.",Final,
Li J.; Shomer H.; Ding J.; Wang Y.; Ma Y.; Shah N.; Tang J.; Yin D.,"Li, Juanhui (57192109219); Shomer, Harry (57713283500); Ding, Jiayuan (57312265800); Wang, Yiqi (57217171165); Ma, Yao (57201255717); Shah, Neil (56719006400); Tang, Jiliang (56245477300); Yin, Dawei (35759826200)",57192109219; 57713283500; 57312265800; 57217171165; 57201255717; 56719006400; 56245477300; 35759826200,Are Message Passing Neural Networks Really Helpful for Knowledge Graph Completion?,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174418789&partnerID=40&md5=3ad9159a0e7c298c62334e560db7bb43,"Knowledge graphs (KGs) facilitate a wide variety of applications. Despite great efforts in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Message Passing (Graph) Neural Networks (MPNNs), to learn powerful embeddings. The success of these methods is naturally attributed to the use of MPNNs over simpler multi-layer perceptron (MLP) models, given their additional message passing (MP) component. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to MPNNs, suggesting that MP may not be as crucial as previously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance. This suggests a conflation of scoring function design, loss function design, and MP in prior work, with promising insights regarding the scalability of state-of-the-art KGC methods today, as well as careful attention to more suitable MP designs for KGC tasks tomorrow. Our codes are publicly available at: https://github.com/Juanhui28/Are_MPNNs_helpful. © 2023 Association for Computational Linguistics.",Final,
Dayal R.; Nangia P.; Vijh S.; Kumar S.; Agarwal S.; Saxena S.,"Dayal, Raghav (58310557200); Nangia, Parv (58309981600); Vijh, Surbhi (57201362000); Kumar, Sumit (57215077928); Agarwal, Saurabh (57190606444); Saxena, Shivank (56872327400)",58310557200; 58309981600; 57201362000; 57215077928; 57190606444; 56872327400,Development of Chatbot Retrieving Fact-Based Information Using Knowledge Graph,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161616687&doi=10.1007%2f978-981-19-9876-8_13&partnerID=40&md5=85234d3cf9caac909ff2d54e6e37ad75,"Chatbot assists users by providing useful responses and not just a conversational system functionalities. The advanced Chatbots such as Siri and Alexa are the results of evolution of different response generation and NLU techniques that have arrived since 1960s. Usually, chatbots are designed to address domain-specific queries; for instance, a medical chatbot requires the user to provide his/her symptoms; in the corporate world, the chatbots designed are mainly for addressing the FAQs asked by their clients/customers. However, state-of-the-art technologies are emerging, and knowledge graph is one of them. The idea of using knowledge graphs is that the data stored in them is linked. The proposed-chatbot addresses the problem of answering factoid questions by retrieving information from knowledge graphs. Initially, the neural machine translation approach was used; however, due to its limitations, keyword extraction approach was adopted for the proposed chatbot. In order to compare the proposed chatbot system with DBpedia metrics, the F-measure quality parameter were used for determining the overall performance of chatbots. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Xue X.; Zhang C.; Xu T.; Niu Z.,"Xue, Xiaojun (57385747900); Zhang, Chunxia (55703936700); Xu, Tianxiang (57210647712); Niu, Zhendong (23393033800)",57385747900; 55703936700; 57210647712; 23393033800,Constrained Tuple Extraction with Interaction-Aware Network,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174409432&partnerID=40&md5=ea7961ed2bc3c72f55ac357d9ec7596e,"Tuples extraction is a fundamental task for information extraction and knowledge graph construction. The extracted tuples are usually represented as knowledge triples consisting of subject, relation, and object. In practice, however, the validity of knowledge triples is associated with and changes with the spatial, temporal, or other kinds of constraints. Motivated by this observation, this paper proposes a constrained tuple extraction (CTE) task to guarantee the validity of knowledge tuples. Formally, the CTE task is to extract constrained tuples from unstructured text, which adds constraints to conventional triples. To this end, we propose an interaction-aware network. Combinatorial interactions among context-specific external features and distinct-granularity internal features are exploited to effectively mine the potential constraints. Moreover, we have built a new dataset containing totally 1,748,826 constrained tuples for training and 3656 ones for evaluation. Experiments on our dataset and the public CaRB dataset demonstrate the superiority of the proposed model. The constructed dataset and the codes are publicly available. © 2023 Association for Computational Linguistics.",Final,
Li Y.; Xue B.; Zhang R.; Zou L.,"Li, Yanzeng (57814628700); Xue, Bingcong (57223986987); Zhang, Ruoyu (57261601200); Zou, Lei (8359099800)",57814628700; 57223986987; 57261601200; 8359099800,AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174408461&partnerID=40&md5=46a387968a8b4da481ec650c95dd0978,"Attribute extraction aims to identify attribute names and the corresponding values from descriptive texts, which is the foundation for extensive downstream applications such as knowledge graph construction, search engines, and e-Commerce. In previous studies, attribute extraction is generally treated as a classification problem for predicting attribute types or a sequence tagging problem for labeling attribute values, where two paradigms, i.e., closed-world and open-world assumption, are involved. However, both of these paradigms have limitations in terms of real-world applications. And prior studies attempting to integrate these paradigms through ensemble, pipeline, and co-training models, still face challenges like cascading errors, high computational overhead, and difficulty in training. To address these existing problems, this paper presents Attribute Tree, a unified formulation for real-world attribute extraction application, where closed-world, open-world, and semi-open attribute extraction tasks are modeled uniformly. Then a text-to-tree generation model, AtTGen, is proposed to learn annotations from different scenarios efficiently and consistently. Experiments demonstrate that our proposed paradigm well covers various scenarios for real-world applications, and the model achieves state-of-the-art, outperforming existing methods by a large margin on three datasets. Our code, pre-trained model, and datasets are available at https://github.com/lsvih/AtTGen. © 2023 Association for Computational Linguistics.",Final,
Tang R.; Zhao Y.; Zong C.; Zhou Y.,"Tang, Rongchuan (57265372500); Zhao, Yang (57202271643); Zong, Chengqing (7005615574); Zhou, Yu (57169094000)",57265372500; 57202271643; 7005615574; 57169094000,Multilingual Knowledge Graph Completion with Language-Sensitive Multi-Graph Attention,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174407812&partnerID=40&md5=59ca451eff34ad612ee2e8f0a366a579,"Multilingual Knowledge Graph Completion (KGC) aims to predict missing links with multilingual knowledge graphs. However, existing approaches suffer from two main drawbacks: (a) alignment dependency: the multilingual KGC is always realized with joint entity or relation alignment, which introduces additional alignment models and increases the complexity of the whole framework; (b) training inefficiency: the trained model will only be used for the completion of one target KG, although the data from all KGs are used simultaneously. To address these drawbacks, we propose a novel multilingual KGC framework with language-sensitive multi-graph attention such that the missing links on all given KGs can be inferred by a universal knowledge completion model. Specifically, we first build a relational graph neural network by sharing the embeddings of aligned nodes to transfer language-independent knowledge. Meanwhile, a language-sensitive multi-graph attention (LSMGA) is proposed to deal with the information inconsistency among different KGs. Experimental results show that our model achieves significant improvements on the DBP-5L and E-PKG datasets. © 2023 Association for Computational Linguistics.",Final,
Li W.; Wei W.; Qu X.; Mao X.; Yuan Y.; Xie W.; Chen D.,"Li, Wendi (58305037600); Wei, Wei (56126506200); Qu, Xiaoye (57204328498); Mao, Xianling (56949703000); Yuan, Ye (58598052100); Xie, Wenfeng (58530607900); Chen, Dangyang (57859709700)",58305037600; 56126506200; 57204328498; 56949703000; 58598052100; 58530607900; 57859709700,TREA: Tree-structure Reasoning Schema for Conversational Recommendation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172435438&partnerID=40&md5=b18132310b79ccc7eb62463cb27ddca0,"Conversational recommender systems (CRS) aim to timely trace the dynamic interests of users through dialogues and generate relevant responses for item recommendations. Recently, various external knowledge bases (especially knowledge graphs) are incorporated into CRS to enhance the understanding of conversation contexts. However, recent reasoning-based models heavily rely on simplified structures such as linear structures or fixed-hierarchical structures for causality reasoning; hence they cannot fully figure out sophisticated relationships among utterances with external knowledge. To address this, we propose a novel Tree-structure Reasoning schEmA named TREA. TREA constructs a multi-hierarchical scalable tree as the reasoning structure to clarify the causal relationships between mentioned entities, and fully utilizes historical conversations to generate more reasonable and suitable responses for recommended results. Extensive experiments on two public CRS datasets have demonstrated the effectiveness of our approach. Our code is available at https://github.com/WindyLee0822/TREA. © 2023 Association for Computational Linguistics.",Final,
De Bellis A.; Biancofiore G.M.; Anelli V.W.; Narducci F.; Di Noia T.; Ragone A.; Di Sciascio E.,"De Bellis, Alessandro (57945863300); Biancofiore, Giovanni Maria (56684845900); Anelli, Vito Walter (57078657900); Narducci, Fedelucio (35107856400); Di Noia, Tommaso (6508366184); Ragone, Azzurra (8970868400); Di Sciascio, Eugenio (6603827610)",57945863300; 56684845900; 57078657900; 35107856400; 6508366184; 8970868400; 6603827610,Semantic Interpretation of BERT embeddings with Knowledge Graphs,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173494150&partnerID=40&md5=d56e643e19b5d88dad9391e03ad488d0,"Pretrained language models have transformed the way we process natural languages, enhancing the performance of related systems. BERT has played a pivotal role in revolutionizing the field of Natural Language Processing (NLP). However, the deep learning framework behind BERT lacks interpretability. Recent research has focused on explaining the knowledge BERT acquires from the textual sources used for pre-training its linguistic model. In this study, we analyze the latent vector space produced by BERT's context-aware word embeddings. Our aim is to determine whether certain areas of the BERT vector space have an explicit meaning related to a Knowledge Graph (KG). Using the Link Prediction (LP) task, we demonstrate the presence of explicit and meaningful regions of the BERT vector space. Moreover, we establish links between BERT's vector space and specific ontology concepts in the KG by learning classification patterns. To the best of our knowledge, this is the first attempt to interpret BERT's learned linguistic knowledge through a KG by relying on its pre-trained context-aware word embeddings. © 2023 CEUR-WS. All rights reserved.",Final,
Yuan S.; Yang D.; Liu J.; Tian S.; Liang J.; Xiao Y.; Xie R.,"Yuan, Siyu (57291357000); Yang, Deqing (56138582400); Liu, Jinxi (57928742000); Tian, Shuyu (57733676200); Liang, Jiaqing (57188696905); Xiao, Yanghua (24377046200); Xie, Rui (57220790933)",57291357000; 56138582400; 57928742000; 57733676200; 57188696905; 24377046200; 57220790933,Causality-aware Concept Extraction based on Knowledge-guided Prompting,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174410417&partnerID=40&md5=b47c70140409ba2c675e5879ceddf719,"Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens. As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt can effectively alleviate concept bias and improve the performance of PLM-based CE models. The code has been released on https://github.com/siyuyuan/KPCE. © 2023 Association for Computational Linguistics.",Final,
Elnozahy W.A.; El Khayat G.A.,"Elnozahy, Walaa A. (57215082559); El Khayat, Ghada A. (36805676400)",57215082559; 36805676400,Multi-Lang Question Answering Framework for Decision Support in Educational Institutes,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160827524&doi=10.5220%2f0012059700003470&partnerID=40&md5=b15fb71cbd88ec9ef4d52a56ce8ab3e9,"Language Diversity has always been an important factor in different educational institutes; Also, a challenge for those interested in Data Analysis, Question answering, and Natural Language Processing (NLP). Researchers who are interested in linguistics are involved in enhancing language processing techniques, and how to apply them. They usually work through Question answering systems or Chatbots. Question Answering Systems and chatbots are now highly recognized, especially after the huge commercial announcement for services such as ChatGPT and Google’s new AI tool. Considering that these tools are very useful as open-domain tools. However, if we think from an institutional perspective, it will require further validation due to the domain type and the data type. it’s also easier for the Decision maker to comprehend and use. During the past few years, many attempts have been made to include Question Answering Systems in the Education sector. However, most of these attempts were single language Software mostly using English. Also, targeted students as a decision-maker to support the education process between teachers and students instead of the educational actors on a strategic level. The scarcity of the tools available in this domain, make it a challenging topic that needs more research attention. In this research, we are Proposing a Multi-lang Question Answering Framework that aims to support the Educational Sector from a strategic point of view. It aims to provide a Generic framework that will help Universities Identify the Students who will be best fit for a specific university program. The framework aims to cope with and adjust to the data type and enhance its conditions from historical data. Regardless of the resource language and origin. It is based on an ontological model for the education domain and uses NLP to process the data and get relevant answers for the users. Future work for this research will focus on enhancing the retrieval for the system, especially using the Arabic language, and support more languages in the tool. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda.",Final,All Open Access; Hybrid Gold Open Access
Kardos P.; Farkas R.,"Kardos, Péter (36052850200); Farkas, Richárd (21233343600)",36052850200; 21233343600,Are These Descriptions Referring to the Same Entity or Just to Similar Ones?,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173557372&doi=10.1007%2f978-3-031-34107-6_31&partnerID=40&md5=3d8097454035e0165438d92085d17ee2,"The Knowledge Graph matching task is to identify nodes in the two graphs that refer to the same concept. In this paper, we focus on the analysis of textual descriptions of the concepts. We employ neural language models as they can score well on text content similarity On the other hand, we show that the text similarity of entity descriptions does not equal to referring to the exact same entity. Our text-based multi-step system was among the top participants at the Knowledge Graph matching track of the Ontology Alignment Evaluation Initiative. © 2023, IFIP International Federation for Information Processing.",Final,
Gujarathi P.; Reddy M.; Tayade N.; Chakraborty S.,"Gujarathi, Pranav (57382584200); Reddy, Manohar (56405635400); Tayade, Neha (57208105434); Chakraborty, Sunandan (55354995000)",57382584200; 56405635400; 57208105434; 55354995000,A Study of Extracting Causal Relationships from Text,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138287961&doi=10.1007%2f978-3-031-16075-2_59&partnerID=40&md5=df6854bca642cfd69e8e8e23800891d4,"Discovering causal knowledge is an important aspect of much scientific research and such findings are often recorded in scholarly articles. Automatically identifying such knowledge from article text can be a useful tool and can act as an impetus for further research on those topics. Numerous applications, including building a causal knowledge graph, making pipelines for root cause analysis, discovering opportunities for drug discovery, and overall, a scalable building block towards turning large pieces of text into organized information can be built following such an approach. However, it requires robust methods to identify and aggregate causal knowledge from a large set of articles. The main challenge in designing new methods is the absence of a large labeled dataset. As a result, existing methods trained on existing datasets with limited size and variations in linguistic pattern, are unable to generalize well on unseen text. In this paper, we explore multiple unsupervised approaches, including a reinforcement learning-based model that learns to identify causal sentences from a small set of labeled sentences. We describe and discuss in detail our experiments for each approach to further encourage exploration of methods that can be re-utilized for different tasks as well, as opposed to simply exploring a supervised learning process which although superior in performance lacks the versatility to be re-purposed for slightly different tasks. We evaluate our methods on a custom-created dataset and show unique techniques to extract cause-effect relationships from the English language. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Decter-Frain A.; Barash V.,"Decter-Frain, Ari (57190231716); Barash, Vlad (35067781200)",57190231716; 35067781200,Using Knowledge Graphs to Detect Partisanship in Online Political Discourse,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148722173&doi=10.1007%2f978-3-031-21127-0_5&partnerID=40&md5=247279fc7df02d0d6fe993d6824aa3bd,"Existing methods for detecting partisanship and polarization on social media focus on either linguistic or network aspects of online communication, and tend to study a single platform. We explore the possibility of using knowledge graph embeddings to detect and analyze partisanship in online discourse. Knowledge graphs can potentially combine linguistic and network information across multiple platforms to enable more accurate discovery of a political dimension in online space. We train embeddings on heterogeneous graphs with different combinations of information text, network, single- and multi-platform information. Building on previous work, we develop a semi-supervised approach for uncovering a political dimension in the embedding space from a handful of labelled observations, and show that this method enables more accurate differentiation between liberal and conservative Twitter accounts. These results indicate that knowledge graphs can potentially be useful tools for analyzing online discourse. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Yilahun H.; Hamdulla A.,"Yilahun, Hankiz (57189440233); Hamdulla, Askar (24829192500)",57189440233; 24829192500,Entity extraction based on the combination of information entropy and TF-IDF,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147719357&doi=10.1504%2fijris.2023.128371&partnerID=40&md5=f97d8bd256c360427612e1e6813164c7,"Traditional knowledge graph entity extraction methods require expert knowledge and a large number of artificial features. Furthermore, deficiencies exist in the accuracy and efficiency of key word extraction based on methods such as TF-IDF. Thus, this study proposes a Chinese entity extraction method based on the combination of information entropy and TF-IDF. First, the text is preprocessed, which involves operations such as sentence segmentation, word segmentation, removal of stop words, and POS tagging, to detect key words based on POS. Secondly, the word frequency is analysed to determine feature word weight, and the TF-IDF algorithm is used to compare the importance of keyword. Finally, information entropy is used to improve the TF-IDF algorithm to provide entity knowledge for the construction of the knowledge graph. The entity extraction method and optimisation scheme proposed in this study can help users extract domain entities and provide better entity resources for the construction of knowledge graphs. Copyright © 2023 Inderscience Enterprises Ltd.",Final,
Sun B.; Li Y.; Zhang J.; Xu H.; Ma X.; Xia P.,"Sun, Bowen (57324267500); Li, Yamin (57200556139); Zhang, Jun (58105129400); Xu, Honghong (58105042900); Ma, Xiaoqiang (36930770600); Xia, Ping (57206153681)",57324267500; 57200556139; 58105129400; 58105042900; 36930770600; 57206153681,Topic Controlled Steganography via Graph-to-Text Generation,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148219278&doi=10.32604%2fcmes.2023.025082&partnerID=40&md5=944fe4fd7f7fb977a1190e8e4da15d67,"Generation-based linguistic steganography is a popular research area of information hiding. The text generative steganographic method based on conditional probability coding is the direction that researchers have recently paid attention to. However, in the course of our experiment, we found that the secret information hiding in the text tends to destroy the statistical distribution characteristics of the original text, which indicates that this method has the problem of the obvious reduction of text quality when the embedding rate increases, and that the topic of generated texts is uncontrollable, so there is still room for improvement in concealment. In this paper, we propose a topic-controlled steganography method which is guided by graph-to-text generation. The proposed model can automatically generate steganographic texts carrying secret messages from knowledge graphs, and the topic of the generated texts is controllable. We also provide a graph path coding method with corresponding detailed algorithms for graph-to-text generation. Different from traditional linguistic steganography methods, we encode the secret information during graph path coding rather than using conditional probability. We test our method in different aspects and compare it with other text generative steganographic methods. The experimental results show that the model proposed in this paper can effectively improve the quality of the generated text and significantly improve the concealment of steganographic text. © 2023 Tech Science Press. All rights reserved.",Final,All Open Access; Gold Open Access
Kornai A.,"Kornai, András (6506991157)",6506991157,Trainability and real-world knowledge,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143808229&doi=10.1007%2f978-981-19-5607-2_8&partnerID=40&md5=7596f8d0e853b316851913bfafe9c110,"Until this point, we concentrated on the lexicon, conceived of as the repository of shared linguistic information. In 8.1 we take on the problem of integrating real-world knowledge, nowadays typically stored in knowledge graphs as billions of RDF triples, and linguistic knowledge, stored in a much smaller dictionary, typically compressible to a few megabytes. We present proper names as point vectors (rather than the polytopes we use for common nouns and most other lexical entries), and introduce the notion of content continuations, algorithms that extend the lexical entries to more detailed hypergraphs that can refer to technical nodes, such as Date, FloatingPointNumber, or Obligation (see 9.1) that are missing from the core lexicon. © 2023, The Author(s).",Final,All Open Access; Hybrid Gold Open Access
To N.D.; Reformat M.Z.; Yager R.R.,"To, Nhuan D. (57195642538); Reformat, Marek Z. (6603618138); Yager, Ronald R. (35618760400)",57195642538; 6603618138; 35618760400,Question-Answering System over Knowledge Graphs Using Analogical-Problem-Solving Approach,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142712075&doi=10.1007%2f978-3-031-08580-2_1&partnerID=40&md5=ac8ebb14c03053565a298f30882469a2,"We introduce an analogical-problem-solving based question-answering system, LingTeQA. It generates templates from known pairs question-SPARQL query and uses generated templates to answer newly asked questions. These questions can be of regular/usual form and can contain imprecise concepts represented by linguistic terms. The system works over open-domain Knowledge Graphs on the Web. In addition, LingTeQA can generate linguistic summaries to answer questions whose answers contain large amounts of numerical values. This system is accessible at https://www.lingteqa.site. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Xu Z.; Dang Y.,"Xu, Zhaoguang (57191840489); Dang, Yanzhong (8223823300)",57191840489; 8223823300,Data-driven causal knowledge graph construction for root cause analysis in quality problem solving,-1,,-1,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131171635&doi=10.1080%2f00207543.2022.2078748&partnerID=40&md5=92be48e0a35b44df9af696dd5885611d,"Root cause analysis (RCA) plays an essential role in quality problem solving (QPS). Due to the difficulty of obtaining causal knowledge of quality problems, companies often rely on expert experience and conventional RCA tools when conducting RCA. Rich QPS data have remained mostly untapped but provide the potential for causal knowledge mining, while the semistructured nature of these data poses enormous challenges to this task. Thus, we propose a data-driven framework to mine large-scale causalities between quality problems and production factors from QPS data and exploit a causal knowledge graph for quality problems (QPCKG) to express these causalities. We first classify QPS data to identify the data containing causality. The causal linguistic patterns are then employed to extract cause slots and effect slots from these data. Subsequently, we apply the BiLSTM-CRF to extract the core content of problems. A vertex fusion method is last proposed to integrate discrete causalities into QPCKG. The approach is validated in a real-world application at a leading automotive company. Three potential applications of the QPCKG are demonstrated for quality diagnosis and prediction. The QPCKG reveals a grand picture of the core interaction mechanism of product quality and production factors and provides decision-making support for RCA. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",Final,
Wang W.; Zhang C.; Li H.; Xiao Z.,"Wang, Wenjing (57555458000); Zhang, Chunxiao (55703945000); Li, Heng (57226498765); Xiao, Ziwei (57221819281)",57555458000; 55703945000; 57226498765; 57221819281,Construction of bilingual knowledge graph based on meteorological simulation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127242722&doi=10.1111%2ftgis.12917&partnerID=40&md5=824cf60ea17b49777208bb954383e121,"Geographical simulation is the core function of virtual geographic environments (VGEs). Providing knowledge support has become a key issue in current research. The literature involves massive knowledge, especially for meteorological simulation, an important component of the geographic environment. However, this knowledge is noisy, unstructured, and difficult to share and reuse. Based on weather research and forecasting models, this study constructs a cross-language knowledge graph to manage difficult-to-handle knowledge and to make complex knowledge structured and more complete. First, we propose a cross-language knowledge graph construction framework. Second, the bidirectional long short-term memory-conditional random fields and translation-based multilingual knowledge graph embedding model are used to extract knowledge and align cross-lingual entities. Finally, the bilingual knowledge graph is visually stored with a graph database. The framework and method can provide efficient queries and analyses for the meteorological field, while helping to provide a knowledge base for knowledge-driven VGEs. © 2022 John Wiley & Sons Ltd.",Final,
Dong Q.; Liu Y.; Cheng S.; Wang S.; Cheng Z.; Niu S.; Yin D.,"Dong, Qian (57223087484); Liu, Yiding (57194505428); Cheng, Suqi (26025634000); Wang, Shuaiqiang (22636318500); Cheng, Zhicong (57224731577); Niu, Shuzi (55364665100); Yin, Dawei (35759826200)",57223087484; 57194505428; 26025634000; 22636318500; 57224731577; 55364665100; 35759826200,Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135058838&doi=10.1145%2f3477495.3531997&partnerID=40&md5=9de896176b943edfab78d5de3dfbc983,"Passage re-ranking is to obtain a permutation over the candidate passage set from retrieval stage. Re-rankers have been boomed by Pre-trained Language Models (PLMs) due to their overwhelming advantages in natural language understanding. However, existing PLM based re-rankers may easily suffer from vocabulary mismatch and lack of domain specific knowledge. To alleviate these problems, explicit knowledge contained in knowledge graph is carefully introduced in our work. Specifically, we employ the existing knowledge graph which is incomplete and noisy, and first apply it in passage re-ranking task. To leverage a reliable knowledge, we propose a novel knowledge graph distillation method and obtain a knowledge meta graph as the bridge between query and passage. To align both kinds of embedding in the latent space, we employ PLM as text encoder and graph neural network over knowledge meta graph as knowledge encoder. Besides, a novel knowledge injector is designed for the dynamic interaction between text and knowledge encoder. Experimental results demonstrate the effectiveness of our method especially in queries requiring in-depth domain knowledge. © 2022 Owner/Author.",Final,All Open Access; Bronze Open Access; Green Open Access
Yang J.; Ying X.; Shi Y.; Tong X.; Wang R.; Chen T.; Xing B.,"Yang, Jinfa (57214872614); Ying, Xianghua (7004495215); Shi, Yongjie (57193810663); Tong, Xin (57205367654); Wang, Ruibin (57470322900); Chen, Taiyan (57658287600); Xing, Bowei (58121794500)",57214872614; 7004495215; 57193810663; 57205367654; 57470322900; 57658287600; 58121794500,Learning Hierarchy-Aware Quaternion Knowledge Graph Embeddings with Representing Relations as 3D Rotations,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165527207&partnerID=40&md5=39737386dfa6e9b52fbe95e8b2d61ad1,"Knowledge graph embedding aims to represent entities and relations as low-dimensional vectors, which is an effective way for predicting missing links. It is crucial for knowledge graph embedding models to model and infer various relation patterns, such as symmetry/antisymmetry. However, many existing approaches fail to model semantic hierarchies, which are common in the real world. We propose a new model called HRQE, which represents entities as pure quaternions. The relational embedding consists of two parts: (a) Using unit quaternions to represent the rotation part in 3D space, where the head entities are rotated by the corresponding relations through Hamilton product. (b) Using scale parameters to constrain the modulus of entities to make them have hierarchical distributions. To the best of our knowledge, HRQE is the first model that can encode symmetry/antisymmetry, inversion, composition, multiple relation patterns and learn semantic hierarchies simultaneously. Experimental results demonstrate the effectiveness of HRQE against some of the SOTA methods on four well-established knowledge graph completion benchmarks. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Colas A.; Alvandipour M.; Wang D.Z.,"Colas, Anthony (57215596114); Alvandipour, Mehrdad (57225248448); Wang, Daisy Zhe (24559372400)",57215596114; 57225248448; 24559372400,GAP: A Graph-aware Language Model Framework for Knowledge Graph-to-Text Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159852632&partnerID=40&md5=1e242ce310728839c0bc801fd62ef29a,"Recent improvements in KG-to-text generation are due to additional auxiliary pre-training tasks designed to give the fine-tune task a boost in performance. These tasks require extensive computational resources while only suggesting marginal improvements. Here, we demonstrate that by fusing graph-aware elements into existing pre-trained language models, we are able to outperform state-of-the-art models and close the gap imposed by additional pre-training tasks. We do so by proposing a mask structure to capture neighborhood information and a novel type encoder that adds a bias to the graph-attention weights depending on the connection type. Experiments on two KG-to-text benchmark datasets show our models are competitive while involving fewer parameters and no additional pre-training tasks. By formulating the problem as a framework, we can interchange the various proposed components and begin interpreting KG-to-text generative models based on the topological and type information found in a graph. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Anelli V.W.; Biancofiore G.M.; De Bellis A.; Di Noia T.; Di Sciascio E.,"Anelli, Vito Walter (57078657900); Biancofiore, Giovanni Maria (56684845900); De Bellis, Alessandro (57945863300); Di Noia, Tommaso (6508366184); Di Sciascio, Eugenio (6603827610)",57078657900; 56684845900; 57945863300; 6508366184; 6603827610,Interpretability of BERT Latent Space through Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140838623&doi=10.1145%2f3511808.3557617&partnerID=40&md5=b9b5a69740607a1a8441174189e36492,"The advent of pretrained language have renovated the ways of handling natural languages, improving the quality of systems that rely on them. BERT played a crucial role in revolutionizing the Natural Language Processing (NLP) area. However, the deep learning framework it implements lacks interpretability. Thus, recent research efforts aimed to explain what BERT learns from the text sources exploited to pre-train its linguistic model. In this paper, we analyze the latent vector space resulting from the BERT context-aware word embeddings. We focus on assessing whether regions of the BERT vector space hold an explicit meaning attributable to a Knowledge Graph (KG). First, we prove the existence of explicitly meaningful areas through the Link Prediction (LP) task. Then, we demonstrate these regions being linked to explicit ontology concepts of a KG by learning classification patterns. To the best of our knowledge, this is the first attempt at interpreting the BERT learned linguistic knowledge through a KG relying on its pretrained context-aware word embeddings. © 2022 ACM.",Final,All Open Access; Bronze Open Access
Wang H.; Wang Y.,"Wang, Huajie (57980304600); Wang, Yinglin (8297974200)",57980304600; 8297974200,EREC: Enhanced Language Representations with Event Chains,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144324586&doi=10.3390%2finfo13120582&partnerID=40&md5=548ee604da529227686e4e5760682afb,"The natural language model BERT uses a large-scale unsupervised corpus to accumulate rich linguistic knowledge during its pretraining stage, and then, the information is fine-tuned for specific downstream tasks, which greatly improves the understanding capability of various natural language tasks. For some specific tasks, the capability of the model can be enhanced by introducing external knowledge. In fact, these methods, such as ERNIE, have been proposed for integrating knowledge graphs into BERT models, which significantly enhanced its capabilities in related tasks such as entity recognition. However, for two types of tasks, commonsense causal reasoning and predicting the ending of stories, few previous studies have combined model modification and process optimization to integrate external knowledge. Therefore, referring to ERNIE, in this paper, we propose enhanced language representation with event chains (EREC), which focuses on keywords in the text corpus and their implied relations. Event chains are integrated into EREC as external knowledge. Furthermore, various graph networks are used to generate embeddings and to associate keywords in the corpus. Finally, via multi-task training, external knowledge is integrated into the model generated in the pretraining stage so as to enhance the effect of the model in downstream tasks. The experimental process of the EREC model is carried out with a three-stage design, and the experimental results show that EREC has a deeper understanding of the causal relationship and event relationship contained in the text by integrating the event chains, and it achieved significant improvements on two specific tasks. © 2022 by the authors.",Final,All Open Access; Gold Open Access
Harrando I.; Reboud A.; Schleider T.; Ehrhart T.; Troncy R.,"Harrando, Ismail (57219181682); Reboud, Alison (57219177410); Schleider, Thomas (57221924078); Ehrhart, Thibault (57209225814); Troncy, Raphael (23986650400)",57219181682; 57219177410; 57221924078; 57209225814; 23986650400,ProZe: Explainable and Prompt-Guided Zero-Shot Text Classification,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134266254&doi=10.1109%2fMIC.2022.3187080&partnerID=40&md5=caff491190f189bdc18254f20e0c4324,"As technology accelerates the generation and communication of textual data, the need to automatically understand this content becomes a necessity. In order to classify text, being it for tagging, indexing, or curating documents, one often relies on large, opaque models that are trained on preannotated datasets, making the process unexplainable, difficult to scale, and ill-adapted for niche domains with scarce data. To tackle these challenges, we propose ProZe, a text classification approach that leverages knowledge from two sources: prompting pretrained language models, as well as querying ConceptNet, a common-sense knowledge base which can be used to add a layer of explainability to the results. We evaluate our approach empirically and we show how this combination not only performs on par with state-of-the-art zero shot classification on several domains, but also offers explainable predictions that can be visualized.  © 1997-2012 IEEE.",Final,
Zhao J.; Cui M.; Gao X.; Yan S.; Ni Q.,"Zhao, Jingsheng (49662741800); Cui, Mingyu (57479703600); Gao, Xiang (57226033531); Yan, Shuai (58234796900); Ni, Qihui (58235237600)",49662741800; 57479703600; 57226033531; 58234796900; 58235237600,Chinese Named Entity Recognition Based on BERT and Lexicon Enhancement,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158001934&doi=10.1145%2f3584376.3584482&partnerID=40&md5=5baae41a228e6d2556524a63f09c5c23,"Named entity recognition is an important part of information extraction and knowledge graph construction, and is the basic work of natural language processing. Chinese named entity recognition mainly adopts word-based and character-based methods, word-based methods rely on word segmentation and common word segmentation methods have word segmentation errors, which easily cause error propagation, character-based methods avoid this error but do not make full use of lexicon information. The performance of Chinese named entity recognition can be effectively improved by introducing lexicon information into character-based named entity recognition. In this paper, we propose a BERT-IDCNN-CRF model combined with the SoftLexicon method. First, the BERT pre-training language model is used to train the character embedding vector, and the lexicon information is obtained by the SoftLexicon method. Then, the lexicon information is combined with the character vector representation obtained by training. Next, the fused vector representation is input to the IDCNN model for further training. Finally, the recognition results of Chinese named entities are obtained by the CRF model. The experimental results show that the F1 value can reach 95.95%, 70.63% and 95.28% on Resume, Weibo and MSRA datasets, and the training speed is faster than BERT-BiLSTM-CRF. © 2022 ACM.",Final,
Chen C.; Wang Y.; Li B.; Lam K.-Y.,"Chen, Chen (58383960100); Wang, Yufei (58747837700); Li, Bing (57226853550); Lam, Kwok-Yan (7403657062)",58383960100; 58747837700; 57226853550; 7403657062,Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165733852&partnerID=40&md5=ab8bab2dcfee4c50b2eba548f3163494,"Knowledge Graph Completion (KGC) has been recently extended to multiple knowledge graph (KG) structures, initiating new research directions, e.g. static KGC, temporal KGC and few-shot KGC (Ji et al., 2022). Previous works often design KGC models closely coupled with specific graph structures, which inevitably results in two drawbacks: 1) structure-specific KGC models are mutually incompatible; 2) existing KGC methods are not adaptable to emerging KGs. In this paper, we propose KG-S2S, a Seq2Seq generative framework that could tackle different verbalizable graph structures by unifying the representation of KG facts into “flat” text, regardless of their original form. To remedy the KG structure information loss from the “flat” text, we further improve the input representations of entities and relations, and the inference algorithm in KG-S2S. Experiments on five benchmarks show that KG-S2S outperforms many competitive baselines, setting new state-of-the-art performance. Finally, we analyze KG-S2S’s ability on the different relations and the Non-entity Generations © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
He Z.; Han Y.; Ouyang Z.; Gao W.; Chen H.; Xu G.; Wu J.,"He, Zhenfeng (57551124400); Han, Yuqiang (57194034767); Ouyang, Zhenqiu (57486966500); Gao, Wei (57089477000); Chen, Hongxu (57213704736); Xu, Guandong (8987733300); Wu, Jian (56197228100)",57551124400; 57194034767; 57486966500; 57089477000; 57213704736; 8987733300; 56197228100,DIALMED: A Dataset for Dialogue-based Medication Recommendation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162720168&partnerID=40&md5=ffcba81f1a27094a48b6f1e8c51d89ae,"Medication recommendation is a crucial task for intelligent healthcare systems. Previous studies mainly recommend medications with electronic health records (EHRs). However, some details of interactions between doctors and patients may be ignored or omitted in EHRs, which are essential for automatic medication recommendation. Therefore, we make the first attempt to recommend medications with the conversations between doctors and patients. In this work, we construct DIALMED, the first high-quality dataset for medical dialogue-based medication recommendation task. It contains 11, 996 medical dialogues related to 16 common diseases from 3 departments and 70 corresponding common medications. Furthermore, we propose a Dialogue structure and Disease knowledge aware Network (DDN), where a QA Dialogue Graph mechanism is designed to model the dialogue structure and the knowledge graph is used to introduce external disease knowledge. The extensive experimental results demonstrate that the proposed method is a promising solution to recommend medications with medical dialogues. The dataset and code are available at https://github.com/f-window/DialMed. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Ju J.; Yang D.; Liu J.,"Ju, Jinhao (57946023500); Yang, Deqing (56138582400); Liu, Jingping (57208656857)",57946023500; 56138582400; 57208656857,Commonsense Knowledge Base Completion with Relational Graph Attention Network and Pre-trained Language Model,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140829084&doi=10.1145%2f3511808.3557564&partnerID=40&md5=ca524077fd4ed4ef3d86466b44ec78e5,"Many commonsense knowledge graphs (CKGs) still suffer from incompleteness although they have been applied in many natural language processing tasks successfully. Due to the scale and sparsity of CKGs, existing knowledge base completion models are not still competent for CKGs. In this paper, we propose a commonsense knowledge base completion (CKBC) model which learns the structural representations and contextual representations of CKG nodes and relations, respectively by a relational graph attention network and a pre-trained language model. Based on these two types of representations, the scoring decoder in our model achieves a more accurate prediction for a given triple. Our empirical studies on the representative CKG ConceptNet demonstrate our model's superiority over the state-of-the-art CKBC models. © 2022 ACM.",Final,
Tokuhisa R.; Kawano K.; Nakamura A.; Koide S.,"Tokuhisa, Ryoko (12144452500); Kawano, Keisuke (57208439594); Nakamura, Akihiro (57322494700); Koide, Satoshi (57190489621)",12144452500; 57208439594; 57322494700; 57190489621,Enhancing Contextual Word Representations Using Embedding of Neighboring Entities in Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165749483&partnerID=40&md5=b8690bac20b6972ed8a48a55051454fd,"Pre-trained language models (PLMs) such as BERT and RoBERTa have dramatically improved the performance of various natural language processing tasks. Although these models are trained on large amounts of raw text, they have no explicit grounding in real-world entities. Knowledge graphs (KGs) are manually annotated with factual knowledge and store the relations between nodes corresponding to entities as labeled edges. This paper proposes a mechanism called KG-attention, which integrates the structure of a KG into recent PLM architectures. Unlike the existing PLM+KG integration methods, KG-attention generalizes the embeddings of neighboring entities using the relation embeddings; accordingly, it can handle relations between unconnected entities in the KG. Experimental results demonstrated that our method achieved significant improvements in a relation classification task, an entity typing task, and several language comprehension tasks. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Dong Y.; Wang L.; Xiang J.; Guo X.; Xie Y.,"Dong, Yao (57236860100); Wang, Lei (57070597700); Xiang, Ji (36678599900); Guo, Xiaobo (57208886736); Xie, Yuqiang (57212572981)",57236860100; 57070597700; 36678599900; 57208886736; 57212572981,RotateCT: Knowledge Graph Embedding by Rotation and Coordinate Transformation in Complex Space,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165732801&partnerID=40&md5=cdb8e95dd090c89e3da7c57f85662d12,"Knowledge graph embedding, which aims to learn representations of entities and relations in knowledge graphs, finds applications in various downstream tasks. The key to success of knowledge graph embedding models are the ability to model relation patterns including symmetry/antisymmetry, inversion, commutative composition and non-commutative composition. Although existing methods fail in modeling the non-commutative composition patterns, several approaches support this pattern by modeling beyond Euclidean space and complex space. Nevertheless, expanding to complicated spaces such as quaternion can easily lead to a substantial increase in the amount of parameters, which greatly reduces the computational efficiency. In this paper, we propose a new knowledge graph embedding method called RotateCT, which first transforms the coordinates of each entity, and then represents each relation as a rotation from head entity to tail entity in complex space. By design, RotateCT can infer the non-commutative composition patterns and improve the computational efficiency. Experiments on multiple datasets empirically show that RotateCT outperforms most state-of-the-art methods on link prediction and path query answering. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Ma H.; Li Z.; Guo H.,"Ma, Haoyang (57615436800); Li, Zeyu (57433072800); Guo, Hongyu (57821805800)",57615436800; 57433072800; 57821805800,Using Noise and External Knowledge to Enhance Chinese Pre-trained Model,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156175143&doi=10.1109%2fICTAI56018.2022.00076&partnerID=40&md5=38cb82e9a46de78c8c4a1a65aa195706,"Pre-trained language models (PLMs) have the risk of overfitting pre-trained tasks and data in fine-tuning, while Chinese PLMs often ignore external knowledge such as word and sentence to learn representations. Therefore, we propose a Chinese PLM enhancement method using noise and external knowledge (NEK). NEK first adds different uniform noises to the PLM according to the standard deviation of different parameter matrices, so as to obtain the perturbed PLM. In the fine-tuning phase, NEK builds a heterogeneous linguistic graph based on external knowledge. This module adopts a graph-based approach to generalize information of different granularities in Chinese linguistics, and enhances Chinese PLM on this basis. Experimental results show that NEK brings performance improvements to a variety of different Chinese PLMs on six natural language processing tasks on eight benchmark datasets. © 2022 IEEE.",Final,
Guan X.; Cao B.; Gao Q.; Yin Z.; Liu B.; Cao J.,"Guan, Xin (57672811500); Cao, Biwei (57672531300); Gao, Qingqing (57226098447); Yin, Zheng (58310044200); Liu, Bo (55574235161); Cao, Jiuxin (14618987100)",57672811500; 57672531300; 57226098447; 58310044200; 55574235161; 14618987100,CORN: Co-Reasoning Network for Commonsense Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161488065&partnerID=40&md5=cc6b950487cf9cf0a091a3e8fc6323fa,"Commonsense question answering (QA) requires machines to utilize the QA content and external commonsense knowledge graph (KG) for reasoning when answering questions. Existing work uses two independent modules to model the QA contextual text representation and relationships between QA entities in KG, which prevents information sharing between modules for co-reasoning. In this paper, we propose a novel model, Co-Reasoning Network (CORN), which adopts a bidirectional multi-level connection structure based on Co-Attention Transformer. The structure builds bridges to connect each layer of the text encoder and graph encoder, which can introduce the QA entity relationship from KG to the text encoder and bring contextual text information to the graph encoder, so that these features can be deeply interactively fused to form comprehensive text and graph node representations. Meanwhile, we propose a QA-aware node based KG subgraph construction method. The QA-aware nodes aggregate the question entity nodes and the answer entity nodes, and further guide the expansion and construction process of the subgraph to enhance the connectivity and reduce the introduction of noise. We evaluate our model on QA benchmarks in the CommonsenseQA and OpenBookQA datasets, and CORN achieves state-of-the-art performance. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Nagpal A.; Dasgupta R.; Ganesan B.,"Nagpal, Abhinav (57208717957); Dasgupta, Riddhiman (57190278878); Ganesan, Balaji (57195555227)",57208717957; 57190278878; 57195555227,Fine Grained Classification of Personal Data Entities with Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122651180&doi=10.1145%2f3493700.3493707&partnerID=40&md5=4bf9cd84ebd1efb33c5d356c353b9d1f,"Fine grained entity classification is the task of assigning context-specific, fine grained labels to entities extracted in an NLP Pipeline. Before the advent of language models, several artificial neural network models were proposed for this task. We revisit these models and compare them with BERT-based models for the specific task of classifying Personal Data Entities (PDE). We observe that using side information from rule-based annotators improves neural model performance on this task and can complement language models.  © 2022 ACM.",Final,
Guo Q.; Cao S.; Yi Z.,"Guo, Quan (56431775900); Cao, Shuai (57788530600); Yi, Zhang (57218404893)",56431775900; 57788530600; 57218404893,A medical question answering system using large language models and knowledge graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133671254&doi=10.1002%2fint.22955&partnerID=40&md5=7ea43e5404af0c332906aa84dfff8a93,"Question answering systems have become prominent in all areas, while in the medical domain it has been challenging because of the abundant domain knowledge. Retrieval based approach has become promising as large pretrained language models come forth. This study focuses on building a retrieval-based medical question answering system, tackling the challenge with large language models and knowledge extensions via graphs. We first retrieve an extensive but coarse set of answers via Elasticsearch efficiently. Then, we utilize semantic matching with pretrained language models to achieve a fine-grained ranking enhanced with named entity recognition and knowledge graphs to exploit the relation of the entities in question and answer. A new architecture based on siamese structures for answer selection is proposed. To evaluate the approach, we train and test the model on two Chinese data sets, NLPCC2017 and cMedQA. We also conduct experiments on two English data sets, TREC-QA and WikiQA. Our model achieves consistent improvement as compared to strong baselines on all data sets. Qualification studies with cMedQA and our in-house data set show that our system gains highly competitive performance. The proposed medical question answering system outperforms baseline models and systems in quantification and qualification evaluations. © 2022 Wiley Periodicals LLC.",Final,
Le Vine N.; Boxer E.; Dinani M.; Tortora P.; Das S.,"Le Vine, Nataliya (57095066600); Boxer, Eric (57193341208); Dinani, Mustafa (58094811900); Tortora, Paolo (58094894600); Das, Subhradeep (57781508900)",57095066600; 57193341208; 58094811900; 58094894600; 57781508900,Identifying Early Warning Signals from News Using Network Community Detection,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147607881&partnerID=40&md5=98c0d714119360239bcd8a0cb6aa4ebe,"The paper addresses the challenge of accelerating identification of changes in risk drivers in the insurance industry. Specifically, the work presents a method to identify significant news events (”signals”) from batches of news data to inform Life & Health insurance decisions. Signals are defined as events that are relevant to a tracked risk driver, widely discussed in multiple news outlets, contain novel information and affect stakeholders. The method converts unstructured data (news articles) into a sequence of keywords by employing a linguistic knowledge graph-based model. Then, for each time window, the method forms a graph with extracted keywords as nodes and draws weighted edges based on keyword co-occurrences in articles. Lastly, events are derived in an unsupervised way as graph communities and scored for the requirements of a signal: relevance, novelty and virality. The methodology is illustrated for a Life & Health topic using news articles from Dow Jones DNA proprietary data set, and assessed against baselines on a publicly available news data set. The method is implemented as an analytics engine in Early Warning System deployed at Swiss Re for the last 1.5 years to extract relevant events from live news data. We present the system's architectural design in production and discuss its use and impact. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Elizarov A.M.; Kirillovich A.V.; Lipachev E.K.; Nevzorova O.A.,"Elizarov, A.M. (57192360965); Kirillovich, A.V. (55994716700); Lipachev, E.K. (6505830683); Nevzorova, O.A. (6506234633)",57192360965; 55994716700; 6505830683; 6506234633,OntoMathPRO: An Ontology of Mathematical Knowledge,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142261919&doi=10.1134%2fS1064562422700016&partnerID=40&md5=ce72ade030498a674f9eb45007f0fa3d,"Abstract: The article describes OntoMathPRO, the first Linked Open Data ontology of professional mathematical knowledge. The ontology is designed to represent mathematical concepts. The concepts of the ontology are organized into two hierarchies: a hierarchy of mathematical objects and a hierarchy of reified relationships. OntoMathPRO respects meta-ontological distinctions provided by a foundational ontology and annotates the concepts as kinds and roles. Relationships between mathematical objects are represented in a reified form, i.e., as instances of relationship concepts linked to their arguments that are instances of role concepts. The ontology defines multilingual lexicons that describe how the concepts are expressed in natural language text. The lexicons are represented as Linguistic Linked Open Data datasets. The OntoMathPRO ontology is under development and will be enriched by new areas of mathematics. © 2022, Pleiades Publishing, Ltd.",Final,
Yu H.; Li Z.; Bi C.; Chen H.,"Yu, Helong (55510987100); Li, Ziqing (57470786900); Bi, Chunguang (56472400400); Chen, Huiling (36865973700)",55510987100; 57470786900; 56472400400; 36865973700,An effective deep learning method with multi-feature and attention mechanism for recognition of Chinese rice variety information,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125471784&doi=10.1007%2fs11042-022-12458-2&partnerID=40&md5=13174d3bde48b0643830fdd7b90b5591,"In the process of Chinese rice variety information named entity recognition, traditional methods cannot extract potential semantic information from data and cannot capture long-distance dependence. So, this paper proposes a Chinese rice variety information named entity recognition method based on a bidirectional long short-term memory network and conditional random field (BiLSTM-CRF), which combines radical features, word segmentation boundary features, and multi-head attention mechanism. First, the radical features and word segmentation boundary features are encoded and integrated into a pre-trained character vector as the model embedding to solve the disadvantage of the lack of semantic information. Then, the multi-head attention mechanism is introduced to assist the bidirectional long short-term memory network (BiLSTM) in acquiring long-distance context-dependence. Finally, a conditional random field (CRF) is used to realize character-level sequence annotation and then realize the named entity recognition task of Chinese rice variety information. The experimental results show that this model’s precision, recall, and F1-score are 95.78%, 97.07%, and 96.42%, respectively. The three evaluation indices are better than those of the other models. The model proposed in this paper can effectively identify Chinese rice variety information entities and provides method support for the subsequent construction of a Chinese rice variety information knowledge graph. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Final,
Linjordet T.; Balog K.; Setty V.,"Linjordet, Trond (46761148300); Balog, Krisztian (15043772700); Setty, Vinay (55163655300)",46761148300; 15043772700; 55163655300,Towards Formally Grounded Evaluation Measures for Semantic Parsing-based Knowledge Graph Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138344666&doi=10.1145%2f3539813.3545146&partnerID=40&md5=4dc8323ddc6fa6cd5335cfb9f7dce016,"Knowledge graph question answering (KGQA) is important to make structured information accessible without formal query language expertise on the part of the users. The semantic parsing (SP) flavor of this task maps a natural language question to a formal query that is machine executable, such as SPARQL. The SP-KGQA task is currently evaluated by adopting measures from other tasks, such as information retrieval and machine translation. However, this adoption typically occurs without fully considering the desired behavior of SP-KGQA systems. To address this, we articulate task-specific desiderata, then develop novel SP-KGQA measures based on a probabilistic framework. We use the desiderata to formulate a set of axioms for SP-KGQA measures and conduct an axiomatic analysis that reveals insufficiencies of established measures previously used to report SP-KGQA performance. We also perform experimental evaluations, using synthetic and state-of-the-art neural machine translation approaches. The results highlight the importance of grounded alternative SP-KGQA measures.  © 2022 ACM.",Final,
Curry E.; Salwala D.; Dhingra P.; Pontes F.A.; Yadav P.,"Curry, Edward (12790805000); Salwala, Dhaval (57215659410); Dhingra, Praneet (57353896300); Pontes, Felipe Arruda (57225798449); Yadav, Piyush (57216831316)",12790805000; 57215659410; 57353896300; 57225798449; 57216831316,Multimodal Event Processing: A Neural-Symbolic Paradigm for the Internet of Multimedia Things,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123310192&doi=10.1109%2fJIOT.2022.3143171&partnerID=40&md5=0bf409ab711cb0f9129fd6f218ec4702,"With the Internet of Multimedia Things (IoMT) becoming a reality, new approaches are needed to process real-time multimodal event streams. Existing approaches to event processing have limited consideration for the challenges of multimodal events, including the need for complex content extraction, and increased computational and memory costs. This article explores event processing as a basis for processing real-time IoMT data. This article introduces the multimodal event processing (MEP) paradigm, which provides a formal basis for native approaches to neural multimodal content analysis (i.e., computer vision, linguistics, and audio) with symbolic event processing rules to support real-time queries over multimodal data streams using the multimodal event processing language to express single, primitive multimodal, and complex multimodal event patterns. The content of multimodal streams is represented using multimodal event knowledge graphs to capture the semantic, spatial, and temporal content of the multimodal streams. The approach is implemented and evaluated within a MEP engine using single and multimodal queries achieving near real-time performance with a throughput of 30 frames processed per second (fps) and subsecond latency of 0.075-0.30 s for video streams of 30 fps input rate. Support for high input stream rates (45 fps) is achieved through content-aware load-shedding techniques with a 127X latency improvement resulting in only a minor decrease in accuracy.  © 2014 IEEE.",Final,All Open Access; Hybrid Gold Open Access
Di Buono M.P.; Gonçalo Oliveira H.; Barbu Mititelu V.; Spahiu B.; Nolano G.,"Di Buono, Maria Pia (55968435900); Gonçalo Oliveira, Hugo (25031534700); Barbu Mititelu, Verginica (14042533100); Spahiu, Blerina (56454388200); Nolano, Gennaro (57219739014)",55968435900; 25031534700; 14042533100; 56454388200; 57219739014,Paving the way for enriched metadata of linguistic linked data,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140839697&doi=10.3233%2fSW-222994&partnerID=40&md5=bd6800d8819cbc3abba005ec392ffb25,"The need for reusable, interoperable, and interlinked linguistic resources in Natural Language Processing downstream tasks has been proved by the increasing efforts to develop standards and metadata suitable to represent several layers of information. Nevertheless, despite these efforts, the achievement of full compatibility for metadata in linguistic resource production is still far from being reached. Access to resources observing these standards is hindered either by (i) lack of or incomplete information, (ii) inconsistent ways of coding their metadata, and (iii) lack of maintenance. In this paper, we offer a quantitative and qualitative analysis of descriptive metadata and resources availability of two main metadata repositories: LOD Cloud and Annohub. Furthermore, we introduce a metadata enrichment, which aims at improving resource information, and a metadata alignment to META-SHARE ontology, suitable for easing the accessibility and interoperability of such resources.  © 2022 - The authors. Published by IOS Press.",Final,All Open Access; Bronze Open Access
Esmeir S.; Câmara A.; Meij E.,"Esmeir, Saher (8201407300); Câmara, Arthur (57210429436); Meij, Edgar (23398197500)",8201407300; 57210429436; 23398197500,Entity Retrieval from Multilingual Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154557749&partnerID=40&md5=2c474e6cf528f77a8d506ea817353035,"Knowledge Graphs (KGs) are structured databases that capture real-world entities and their relationships. The task of entity retrieval from a KG aims at retrieving a ranked list of entities relevant to a given user query. While English-only entity retrieval has attracted considerable attention, user queries, as well as the information contained in the KG, may be represented in multiple-and possibly distinct-languages. Furthermore, KG content may vary between languages due to different information sources and points of view. Recent advances in language representation have enabled natural ways of bridging gaps between languages. In this paper, we, therefore, propose to utilise language models (LMs) and diverse entity representations to enable truly multilingual entity retrieval. We propose two approaches: (i) an array of monolingual retrievers and (ii) a single multilingual retriever trained using queries and documents in multiple languages. We show that while our approach is on par with the significantly more complex state-of-the-art method for the English task, it can be successfully applied to virtually any language with an LM. Furthermore, it allows languages to benefit from one another, yielding significantly better performance, both for low- and high-resource languages. © 2022 Association for Computational Linguistics.",Final,
Atkinson J.; Escudero A.,"Atkinson, John (57225812365); Escudero, Alex (57763445200)",57225812365; 57763445200,Evolutionary natural-language coreference resolution for sentiment analysis,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137279708&doi=10.1016%2fj.jjimei.2022.100115&partnerID=40&md5=6031211320ff98f2a04ce02480642a01,"Communicating messages on social media usually conveys much implicit linguistic knowledge, which makes it difficult to process texts for further analysis. One of the major problems, the linguistic coreference resolution task involves detecting coreference chains of entities and pronouns that coreference them. It has mostly been addressed for formal and full-sized text in which a relatively clear discourse structure can be discovered, using Natural-Language Processing techniques. However, texts in social media are short, informal and lack a lot of underlying linguistic information to make decisions so traditional methods can not be applied. Furthermore, this may significantly impact the performance of several tasks on social media applications such as opinion mining, network analysis, sentiment analysis, text categorization. In order to deal with these issues, this research address the task of linguistic co-referencing using an evolutionary computation approach. It combines discourse coreference analysis techniques, domain-based heuristics (i.e., syntactic, semantic and world knowledge), graph representation methods, and evolutionary computation algorithms to resolving implicit co-referencing within informal opinion texts. Experiments were conducted to assess the ability of the model to find implicit referents on informal messages, showing the promise of our approach when compared to related methods. © 2022 The Author(s)",Final,All Open Access; Gold Open Access
Liu X.; Yin D.; Zheng J.; Zhang X.; Zhang P.; Yang H.; Dong Y.; Tang J.,"Liu, Xiao (57195957831); Yin, Da (57222525338); Zheng, Jingnan (57871630900); Zhang, Xingjian (57847574600); Zhang, Peng (57204109983); Yang, Hongxia (57054215300); Dong, Yuxiao (49963255100); Tang, Jie (57719061000)",57195957831; 57222525338; 57871630900; 57847574600; 57204109983; 57054215300; 49963255100; 57719061000,OAG-BERT: Towards a Unified Backbone Language Model for Academic Knowledge Services,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142056&doi=10.1145%2f3534678.3539210&partnerID=40&md5=935bfb006d446c606e3c73eb345abc36,"Academic Knowledge Services have substantially facilitated the development of human science and technology, providing a plenitude of useful research tools. However, many applications highly depend on ad-hoc models and expensive human labeling to understand professional contents, hindering deployments in real world. To create a unified backbone language model for various knowledge-intensive academic knowledge mining challenges, based on the world's largest public academic graph Open Academic Graph (OAG), we pre-train an academic language model, namely OAG-BERT, to integrate massive heterogeneous entity knowledge beyond scientific corpora. We develop novel pre-training strategies along with zero-shot inference techniques. OAG-BERT's superior performance on 9 knowledge-intensive academic tasks (including 2 demo applications) demonstrates its qualification to serve as a foundation for academic knowledge services. Its zero-shot capability also offers great potential to mitigate the need of costly annotations. OAG-BERT has been deployed to multiple real-world applications, such as reviewer recommendations for NSFC (National Nature Science Foundation of China) and paper tagging in the AMiner system. All codes and pre-trained models are available via the CogDL.  © 2022 ACM.",Final,All Open Access; Bronze Open Access; Green Open Access
Yu D.; Zhu C.; Yang Y.; Zeng M.,"Yu, Donghan (57219492469); Zhu, Chenguang (57210636804); Yang, Yiming (35231480000); Zeng, Michael (57211638200)",57219492469; 57210636804; 35231480000; 57211638200,JAKET: Joint Pre-training of Knowledge Graph and Language Understanding,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124398714&partnerID=40&md5=d123091dd875411aebad1af5587111cf,"Knowledge graphs (KGs) contain rich information about world knowledge, entities, and relations. Thus, they can be great supplements to existing pre-trained language models. However, it remains a challenge to efficiently integrate information from KG into language modeling. And the understanding of a knowledge graph requires related context. We propose a novel joint pre-training framework, JAKET, to model both the knowledge graph and language. The knowledge module and language module provide essential information to mutually assist each other: the knowledge module produces embeddings for entities in text while the language module generates context-aware initial embeddings for entities and relations in the graph. Our design enables the pre-trained model to easily adapt to unseen knowledge graphs in new domains. Experiment results on several knowledge-aware NLP tasks show that our proposed framework achieves superior performance by effectively leveraging knowledge in language understanding. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Zheng C.; Kordjamshidi P.,"Zheng, Chen (57219690556); Kordjamshidi, Parisa (24476235400)",57219690556; 24476235400,Dynamic Relevance Graph Network for Knowledge-Aware Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165790874&partnerID=40&md5=aabce48c04c7065a5947dfde64791ee4,"This work investigates the challenge of learning and reasoning for Commonsense Question Answering given an external source of knowledge in the form of a knowledge graph (KG). We propose a novel graph neural network architecture, called Dynamic Relevance Graph Network (DRGN). DRGN operates on a given KG subgraph based on the question and answers entities and uses the relevance scores between the nodes to establish new edges dynamically for learning node representations in the graph network. This explicit usage of relevance as graph edges has the following advantages, a) the model can exploit the existing relationships, re-scale the node weights, and influence the way the neighborhood nodes’ representations are aggregated in the KG subgraph, b) It potentially recovers the missing edges in KG that are needed for reasoning. Moreover, as a byproduct, our model improves handling the negative questions due to considering the relevance between the question node and the graph entities. Our proposed approach shows competitive performance on two QA benchmarks, CommonsenseQA and OpenbookQA, compared to the state-of-the-art published results. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
,,,"COLING 2022 - Proceedings of TextGraphs-16: Graph-based Methods for Natural Language Processing, NLP 2022 - 29th International Conference on Computational Linguistics",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179608599&partnerID=40&md5=b001e5519ca64ec39e59580f764da087,The proceedings contain 15 papers. The topics discussed include: multilevel hypernode graphs for effective and efficient entity linking; cross-modal contextualized hidden state projection method for expanding of taxonomic graphs; sharing parameter by conjugation for knowledge graph embeddings in complex space; a clique-based graphical approach to detect interpretable adjectival senses in Hungarian; the effectiveness of masked language modeling and adapters for factual knowledge injection; text-aware graph embeddings for donation behavior prediction; word sense disambiguation of French lexicographical examples using lexical networks; temporal graph analysis of misinformation spreaders in social media; IJS at TextGraphs-16 natural language premise selection task: will contextual information improve natural language premise selection?; and keyword-based natural language premise selection for an automatic mathematical statement proving.,Final,
Xu Z.; Ye P.; Chen H.; Zhao M.; Chen H.; Zhang W.,"Xu, Zezhong (57338558400); Ye, Peng (57900604000); Chen, Hui (57221150709); Zhao, Meng (58361580600); Chen, Huajun (35268022500); Zhang, Wen (56902283700)",57338558400; 57900604000; 57221150709; 58361580600; 35268022500; 56902283700,Ruleformer: Context-aware Rule Mining over Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162207437&partnerID=40&md5=56fefa28f28b007b8c19f4db8e525815,"Rule mining is an effective approach for reasoning over knowledge graph (KG). Existing works mainly concentrate on mining rules. However, there might be several rules that could be applied for reasoning for one relation, and how to select appropriate rules for completion of different triples has not been discussed. In this paper, we propose to take the context information into consideration, which helps select suitable rules for the inference tasks. Based on this idea, we propose a transformer-based rule mining approach, Ruleformer1. It consists of two blocks: 1) an encoder extracting the context information from subgraph of head entities with modified attention mechanism, and 2) a decoder which aggregates the subgraph information from the encoder output and generates the probability of relations for each step of reasoning. The basic idea behind Ruleformer is regarding rule mining process as a sequence to sequence task. To make the subgraph a sequence input to the encoder and retain the graph structure, we devise a relational attention mechanism in Transformer. The experiment results show the necessity of considering these information in rule mining task and the effectiveness of our model. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Wang P.; Li S.; Pang K.; He L.; Li D.; Tang J.; Wang T.,"Wang, Pancheng (57203516691); Li, Shasha (36634432600); Pang, Kunyuan (56457638600); He, Liangliang (57194775107); Li, Dong (57224479170); Tang, Jintao (8701005000); Wang, Ting (55925347300)",57203516691; 36634432600; 56457638600; 57194775107; 57224479170; 8701005000; 55925347300,Multi-Document Scientific Summarization from a Knowledge Graph-Centric View,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162815040&partnerID=40&md5=750b5b121148eaf0ffc6a66d3a26b60d,"Multi-Document Scientific Summarization (MDSS) aims to produce coherent and concise summaries for clusters of topic-relevant scientific papers. This task requires precise understanding of paper content and accurate modeling of cross-paper relationships. Knowledge graphs convey compact and interpretable structured information for documents, which makes them ideal for content modeling and relationship modeling. In this paper, we present KGSum1, an MDSS model centred on knowledge graphs during both the encoding and decoding process. Specifically, in the encoding process, two graph-based modules are proposed to incorporate knowledge graph information into paper encoding, while in the decoding process, we propose a two-stage decoder by first generating knowledge graph information of summary in the form of descriptive sentences, followed by generating the final summary. Empirical results show that the proposed architecture brings substantial improvements over baselines on the Multi-Xscience dataset. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Zhang J.; Qin B.; Zhang Y.; Zhou J.; Wang H.,"Zhang, Jian (57216968887); Qin, Bo (58590156900); Zhang, Yufei (57211170611); Zhou, Junhua (57193167689); Wang, Hongwei (54785526500)",57216968887; 58590156900; 57211170611; 57193167689; 54785526500,A knowledge extraction framework for domain-specific application with simplified pre-trained language model and attention-based feature extractor,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131311095&doi=10.1007%2fs11761-022-00337-5&partnerID=40&md5=74df5496a00c3f9cd74ae65e922594ca,"With the advancement of industrial informatics, intelligent algorithms are increasingly applied in various industrial products and applications. In this paper, we proposed a knowledge extraction framework for domain-specific text. This framework can extract entities from text the subsequent tasks such as knowledge graph construction. The proposed framework contains three modules, namely domain feature pre-trained model, LSTM-based named entity recognition and the attention-based nested named entity recognition. The domain feature pre-trained model can effectively learn the features of domain corpus such as professional terms that are not included in the general domain corpus. Flat named entity recognition can use the vector from pre-trained model to obtain the entity from domain-specific text. The nested named entity recognition based on the attention mechanism and the weight sliding balance strategy can effectively identify entity types with higher nesting rates. The framework achieves good results in the field of nuclear power plant maintenance reports, and the methods for domain pre-trained model and LSTM-based flat named entity recognition have been successfully applied to practical tasks. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Final,
Luo Z.; Xu W.; Liu W.; Bian J.; Yin J.; Liu T.-Y.,"Luo, Zhiping (57205189734); Xu, Wentao (57218551927); Liu, Weiqing (54407167900); Bian, Jiang (57203105806); Yin, Jian (35316639800); Liu, Tie-Yan (57221068510)",57205189734; 57218551927; 54407167900; 57203105806; 35316639800; 57221068510,KGE-CL: Contrastive Learning of Tensor Decomposition Based Knowledge Graph Embeddings,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164206821&partnerID=40&md5=4a1c0847504eb28f19afcfb82539ee2a,"Learning the embeddings of knowledge graphs (KG) is vital in artificial intelligence, and can benefit various downstream applications, such as recommendation and question answering. In recent years, many research efforts have been proposed for knowledge graph embedding (KGE). However, most previous KGE methods ignore the semantic similarity between the related entities and entity-relation couples in different triples since they separately optimize each triple with the scoring function. To address this problem, we propose a simple yet efficient contrastive learning framework for tensor decomposition based (TDB) KGE, which can shorten the semantic distance of the related entities and entity-relation couples in different triples and thus improve the performance of KGE. We evaluate our proposed method on three standard KGE datasets: WN18RR, FB15k-237 and YAGO3-10. Our method can yield some new state-of-the-art results, achieving 51.2% MRR, 46.8% Hits@1 on the WN18RR dataset, 37.8% MRR, 28.6% Hits@1 on FB15k-237 dataset, and 59.1% MRR, 51.8% Hits@1 on the YAGO3-10 dataset. Source codes and data of this paper can be found at https://github.com/Wentao-Xu/KGE-CL. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Aracena C.; Villena F.; Rojas M.; Dunstan J.,"Aracena, Claudio (56938726600); Villena, Fabián (57214225679); Rojas, Matias (57877440900); Dunstan, Jocelyn (23968027900)",56938726600; 57214225679; 57877440900; 23968027900,A Knowledge-Graph-Based Intrinsic Test for Benchmarking Medical Concept Embeddings and Pretrained Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154552744&partnerID=40&md5=5f66db3444e6b8b4c584c38014fe7173,"Using language models created from large data sources has improved the performance of several deep learning-based architectures, obtaining state-of-the-art results in several NLP extrinsic tasks. However, little research is related to creating intrinsic tests that allow us to compare the quality of different language models when obtaining contextualized embeddings. This gap increases even more when working on specific domains in languages other than English. This paper proposes a novel graph-based intrinsic test that allows us to measure the quality of different language models in clinical and biomedical domains in Spanish. Our results show that our intrinsic test performs better for clinical and biomedical language models than a general one. Also, it correlates with better outcomes for a NER task using a probing model over contextualized embeddings. We hope our work will help the clinical NLP research community to evaluate and compare new language models in other languages and find the most suitable models for solving downstream tasks.  © 2022 Association for Computational Linguistics.",Final,
Zhang H.; Liu X.; Pan H.; Ke H.; Ou J.; Fang T.; Song Y.,"Zhang, Hongming (57202439109); Liu, Xin (57206739249); Pan, Haojie (57209225200); Ke, Haowen (57223746349); Ou, Jiefu (57219740889); Fang, Tianqing (57222014949); Song, Yangqiu (14039604300)",57202439109; 57206739249; 57209225200; 57223746349; 57219740889; 57222014949; 14039604300,ASER: Towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131378130&doi=10.1016%2fj.artint.2022.103740&partnerID=40&md5=4b35652f9e710bbe859c792e9300a183,"Commonsense knowledge acquisition and reasoning have long been a core artificial intelligence problem. However, in the past, there has been a lack of scalable methods to collect commonsense knowledge. In this paper, we propose to develop principles for collecting commonsense knowledge based on selectional preference, which is a common phenomenon in human languages that has been shown to be related to semantics. We generalize the definition of selectional preference from one-hop linguistic syntactic relations to higher-order relations over linguistic graphs. Unlike previous commonsense knowledge definitions (e.g., ConceptNet), the selectional preference (SP) knowledge only relies on statistical distributions over linguistic graphs, which can be efficiently and accurately acquired from the unlabeled corpora with modern tools, rather than human-defined relations. As a result, acquiring SP knowledge is a much more scalable way of acquiring commonsense knowledge. Following this principle, we develop a large-scale eventuality (a linguistic term covering activity, state, and event)-based knowledge graph ASER, where each eventuality is represented as a dependency graph, and the relation between them is a discourse relation defined in shallow discourse parsing. The higher-order selectional preference over collected linguistic graphs reflects various kinds of commonsense knowledge. For example, dogs are more likely to bark than cats as the eventuality “dog barks” appears 14,998 times in ASER while “cat barks” only appears 6 times. “Be hungry” is more likely to be the reason rather than result of “eat food” as the edge 〈“be hungry,” Cause, “eat food”〉 appears in ASER while 〈“eat food,” Cause, “be hungry”〉 does not. Moreover, motivated by the observation that humans understand events by abstracting the observed events to a higher level and can thus transfer their knowledge to new events, we propose a conceptualization module on top of the collected knowledge to significantly boost the coverage of ASER. In total, ASER contains 648 million edges between 438 million eventualities. After conceptualization with Probase, a selectional preference based concept-instance relational knowledge base, our concept graph contains 15 million conceptualized eventualities and 224 million edges between them. Detailed analysis is provided to demonstrate its quality. All the collected data, APIs, and tools that can help convert collected SP knowledge into the format of ConceptNet are available at https://github.com/HKUST-KnowComp/ASER. © 2022 Elsevier B.V.",Final,All Open Access; Green Open Access
Maharana A.; Bansal M.,"Maharana, Adyasha (57194338660); Bansal, Mohit (16466939600)",57194338660; 16466939600,GRADA: Graph Generative Data Augmentation for Commonsense Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165748329&partnerID=40&md5=36bba4818cb0c6bc0127e6f484b755d9,"Recent advances in commonsense reasoning have been fueled by the availability of large-scale human annotated datasets. Manual annotation of such datasets, many of which are based on existing knowledge bases, is expensive and not scalable. Moreover, it is challenging to build augmentation data for commonsense reasoning because the synthetic questions need to adhere to real-world scenarios. Hence, we present GRADA, a graph-generative data augmentation framework to synthesize factual data samples from knowledge graphs for commonsense reasoning datasets. First, we train a graph-to-text model for conditional generation of questions from graph entities and relations. Then, we train a generator with GAN loss to generate distractors for synthetic questions. Our approach improves performance for SocialIQA, CODAH, HellaSwag and CommonsenseQA, and works well for generative tasks like ProtoQA. We show improvement in robustness to semantic adversaries after training with GRADA and provide human evaluation of the quality of synthetic datasets in terms of factuality and answerability. Our work provides evidence and encourages future research into graph-based generative data augmentation. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Perevalov A.; Both A.; Diefenbach D.; Ngonga Ngomo A.-C.,"Perevalov, Aleksandr (57207821935); Both, Andreas (23966392700); Diefenbach, Dennis (57189301891); Ngonga Ngomo, Axel-Cyrille (23397850200)",57207821935; 23966392700; 57189301891; 23397850200,Can Machine Translation be a Reasonable Alternative for Multilingual Question Answering Systems over Knowledge Graphs?,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129802817&doi=10.1145%2f3485447.3511940&partnerID=40&md5=26959d4f4349c2f3b0645c66e61d9dce,"Providing access to information is the main and most important purpose of the Web. However, despite available easy-to-use tools (e.g., search engines, chatbots, question answering) the accessibility is typically limited by the capability of using the English language. This excludes a huge amount of people. In this work, we discuss Knowledge Graph Question Answering (KGQA) systems that aim at providing natural language access to data stored in Knowledge Graphs (KG). While several KGQA systems have been proposed, only very few have dealt with a language other than English. In this work, we follow our research agenda of enabling speakers of any language to access the knowledge stored in KGs. Because of the lack of native support for many languages, we use machine translation (MT) tools to evaluate KGQA systems regarding questions in languages that are unsupported by a KGQA system. In total, our evaluation is based on 8 different languages (including some that never were evaluated before). For the intensive evaluation, we extend the QALD-9 dataset for KGQA with Wikidata queries and high-quality translations. The extension was done in a crowdsourcing manner by native speakers of the different languages. By using multiple KGQA systems for the evaluation, we were enabled to investigate and answer the main research question: ""Can MT be an alternative for multilingual KGQA systems?"". The evaluation results demonstrated that the monolingual KGQA systems can be effectively ported to the new languages with MT tools. © 2022 ACM.",Final,
Koloski B.; Montariol S.; Purver M.; Pollak S.,"Koloski, Boshko (57222028629); Montariol, Syrielle (57212342147); Purver, Matthew (12446164000); Pollak, Senja (55543643800)",57222028629; 57212342147; 12446164000; 55543643800,Knowledge informed sustainability detection from short financial texts,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153328409&partnerID=40&md5=21e69db1673a6a1f66f42b6d1f394259,"Nowadays in the finance world, there is a global trend for responsible investing, linked with a growing need for developing automated methods for analysing Environmental, Social and Governance (ESG) related elements in financial texts. In this work we propose a solution to the FinSim4-ESG task, consisting in classifying sentences from financial reports as sustainable or unsustainable. We propose a novel knowledge-based latent heterogeneous representation that relies on knowledge from taxonomies, knowledge graphs and multiple contemporary document representations. We hypothesize that an approach based on a combination of knowledge and document representations can introduce significant improvement over conventional document representation approaches. We perform ensembling, both at the classifier level and at the representation level (late-fusion and early-fusion). The proposed approaches achieve competitive accuracy of 89% and are 5.85% behind the best score in the shared task.  ©2022 Association for Computational Linguistics.",Final,
Alobaid A.; Corcho O.,"Alobaid, Ahmad (57172680000); Corcho, Oscar (14010357000)",57172680000; 14010357000,Balancing coverage and specificity for semantic labelling of subject columns,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123592120&doi=10.1016%2fj.knosys.2021.108092&partnerID=40&md5=31b4c8b4bd1bc756a60dc00ead6af7e1,"Many data are published on the Web using tabular data formats (e.g., spreadsheets). One of the main challenges for their effective (re)use is their generalized lack of semantics (e.g., column names are not usually standardized, and their meaning and content are not always clear). There is a common understanding that the reuse of tabular data may be improved by annotating them with the types used in knowledge graphs. In this paper, we present a novel approach to automatically type entity columns in tabular data with ontology classes. In contrast with existing proposals in the state-of-the-art, our approach does not require external linguistic resources, lookup services, model training, building a model of the knowledge graph beforehand, or having a human in the loop. © 2022 The Author(s)",Final,
Wold S.,"Wold, Sondre (57933865400)",57933865400,The Effectiveness of Masked Language Modeling and Adapters for Factual Knowledge Injection,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179139672&partnerID=40&md5=16437be636b160d0181a15d1bb4d6602,"This paper studies the problem of injecting factual knowledge into large pre-trained language models. We train adapter modules on parts of the ConceptNet knowledge graph using the masked language modeling objective and evaluate the success of the method by a series of probing experiments on the LAMA probe. Mean P@K curves for different configurations indicate that the technique is effective, increasing the performance on subsets of the LAMA probe for large values of k by adding as little as 2.1% additional parameters to the original models. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Xu M.; Wang D.; Feng S.; Yang Z.; Zhang Y.,"Xu, Minghao (58506079400); Wang, Daling (8543200700); Feng, Shi (36173786700); Yang, Zhenfei (57285361600); Zhang, Yifei (36618421200)",58506079400; 8543200700; 36173786700; 57285361600; 36618421200,KC-ISA: An Implicit Sentiment Analysis Model Combining Knowledge Enhancement and Context Features,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160670947&partnerID=40&md5=2e80ebcdbdc00d7f1bb934aacd777e63,"Sentiment analysis has always been an important research direction in natural language processing. The research can be divided into explicit sentiment analysis and implicit sentiment analysis according to whether there are sentiment words in language expression. There have been many research results in explicit sentiment analysis. However, implicit sentiment analysis is rarely studied. Compared with explicit sentiment expression, implicit sentiment expression usually omits a lot of knowledge and common sense, and context also has an important impact on implicit sentiment expression. In this paper, we use a knowledge graph to supplement implicit sentiment expression and propose a novel Implicit Sentiment Analysis model combining Knowledge enhancement and Context features (dubbed KC-ISA). The KC-ISA model can effectively integrate external knowledge and contextual features by the coattention mechanism. Finally, we conduct experiments on the SMP2019 implicit sentiment analysis dataset. Moreover, to verify the generality of the model, we also conduct experiments on two common sentiment analysis datasets. The results on three datasets show that our proposed KC-ISA model can achieve better results on text sentiment analysis. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Zhang A.X.; Liang X.; Wu B.; Zheng X.; Zhang S.; Guo Y.; Wang J.; Liu X.,"Zhang, Alex X. (58505975400); Liang, Xun (57219190169); Wu, Bo (57236307000); Zheng, Xiangping (57236021100); Zhang, Sensen (58209292700); Guo, Yuhui (57236863600); Wang, Jun (58464522600); Liu, Xinyao (58506190900)",58505975400; 57219190169; 57236307000; 57236021100; 58209292700; 57236863600; 58464522600; 58506190900,Eureka: Neural Insight Learning for Knowledge Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165742017&partnerID=40&md5=750f1473ec6e16b42aa25f20d5393612,"The human recognition system has presented the remarkable ability to effortlessly learn novel knowledge from only a few trigger events based on prior knowledge, which is called insight learning. Mimicking such behavior on Knowledge Graph Reasoning (KGR) is an interesting and challenging research problem with many practical applications. Simultaneously, existing works, such as knowledge embedding and few-shot learning models, have been limited to conducting KGR in either “seen-to-seen” or “unseen-to-unseen” scenarios. To this end, we propose a neural insight learning framework named Eureka to bridge the “seen” to “unseen” gap. Eureka is empowered to learn the seen relations with sufficient training triples while providing the flexibility of learning unseen relations given only one trigger without sacrificing its performance on seen relations. Eureka meets our expectation of the model to acquire seen and unseen relations at no extra cost, and eliminate the need to retrain when encountering emerging unseen relations. Experimental results on two real-world datasets demonstrate that the proposed framework also outperforms various state-of-the-art baselines on datasets of both seen and unseen relations. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Drucker J.; Polack P.; Santachiara P.,"Drucker, Johanna (36941662000); Polack, Peter (57784692100); Santachiara, Pietro (57191029743)",36941662000; 57784692100; 57191029743,Heterochronologies: a platform for correlation and research in temporal graphics,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162797266&partnerID=40&md5=d4381a654235d43da61741c41044a45d,"The difficulty of integrating the data, metadata, and classification schemes produced across a wide geographic, historical, and cultural variety of institutional sites and practices was a major impetus for the creation of Linked Data (LD). The promise was to make diverse sets of data interoperable through subscription to an array of standardizations while leaving the original data intact. These operational requirements enable interoperability at the expense of specificity, and require considerable resources for implementation. While LD supports connection and access across disparate data sets, it is not focused on the intellectual issues that have to do with enabling the correlation and comparison of diverse ontologies, or preserving and exploring their epistemic and cultural specificity — issues essential to humanistic study. In addition, LD is exclusively concerned with linguistic data, and can hence not be applied to information that is expressed in graphical form. Contrastingly, the Heterochronologies project regards temporality as a concept expressed epistemically through various culturally-specific, authoritative ontologies, which are instantiated by graphical representations such as chronologies and timelines. The project concentrates on extracting computationally tractable structured data from historical images so that the underlying ontologies may be compared without subsuming them into a hegemonic data model. In this sense, the Heterochronologies project is an exercise in comparative ontology. In this paper we describe the factors that motivated the project; its various epistemological underpinnings, as well as the methodological approach that guided its development; the phases of our work; and the contributions that emerged from the project. Though currently still in development, its culmination is a digital platform — the Time Capsule — that supports comparative pedagogy, and in so doing demonstrates both validity and relevance of a few fundamental notions: a) structured data can be systematically extracted from graphical structures with a logical approach; b) comparisons of temporal schemes can be supported by a digital platform that considers them as instantiations of ontologies that need not be reconciled to a single standard; c) the historical and cultural specificity of these ontologies can be exposed and analyzed using digital means. © 2022, Alliance of Digital Humanities Organisations. All rights reserved.",Final,
Papadopoulou M.; Roche C.; Tamiolaki E.-M.,"Papadopoulou, Maria (57209033822); Roche, Christophe (7103052641); Tamiolaki, Eleni-Melina (57862064000)",57209033822; 7103052641; 57862064000,The LACRIMALit Ontology of Crisis: An Event-Centric Model for Digital History,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136625174&doi=10.3390%2finfo13080398&partnerID=40&md5=08fe55db7ca8c5082e02f6f26f3ec432,"The article presents the building of an event-centric model for the computational representation of crisis events using an ontology encoded in the Web Ontology Language (OWL). The work presented here is done in collaboration with the Leaders and Crisis Management in Ancient Literature. A Comparative Approach (LACRIMALit) project, (2022–2025) hosted at the Institute for Mediterranean Studies/Foundation for Research and Technology (IMS-FORTH). A key outcome of the project is the LACRIMALit ontology that aims principally at the semantic annotation of ancient Greek historiographical texts in open access via Perseus Digital Library. The ontology will facilitate reasoning on and across these documents and enable their semantic querying. The tagset of annotations, concepts, relations, and terms of the ontology will be both human and machine readable, extensible and reusable. The annotated corpus of texts to be produced will be available for sophisticated queries based on the concepts and relations, defined by the ontologies. This will considerably improve the string-based querying of the texts in their present digital format. This article presents the principles of conceptualization of the domain in the three dimensions: domain knowledge (mainly classes illustrated with some individuals), linguistic dimension (terms, proper names, definite descriptions), and references. © 2022 by the authors.",Final,All Open Access; Gold Open Access
Seonwoo Y.; Yoon S.; Dernoncourt F.; Bui T.; Oh A.,"Seonwoo, Yeon (57204820914); Yoon, Seunghyun (57201772909); Dernoncourt, Franck (55827671700); Bui, Trung (57189374262); Oh, Alice (35190968400)",57204820914; 57201772909; 55827671700; 57189374262; 35190968400,Virtual Knowledge Graph Construction for Zero-Shot Domain-Specific Document Retrieval,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165752735&partnerID=40&md5=e98c79475a1391ba6c8b6d5ea823b8e4,"Domain-specific documents cover terminologies and specialized knowledge. This has been the main challenge of domain-specific document retrieval systems. Previous approaches propose domain-adaptation and transfer learning methods to alleviate this problem. However, these approaches still follow the same document representation method in previous approaches; a document is embedded into a single vector. In this study, we propose VKGDR. VKGDR represents a given corpus into a graph of entities and their relations (known as a virtual knowledge graph) and computes the relevance between queries and documents based on the graph representation. We conduct three experiments 1) domain-specific document retrieval, 2) comparison of our virtual knowledge graph construction method with previous approaches, and 3) ablation study on each component of our virtual knowledge graph. From the results, we see that unsupervised VKGDR outperforms baselines in a zero-shot setting and even outperforms fully-supervised bi-encoder. We also verify that our virtual knowledge graph construction method results in better retrieval performance than previous approaches. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Zhang T.; Dong J.; Wang J.; Wang C.; Wang A.; Liu Y.; Huang J.; Li Y.; He X.,"Zhang, Taolin (57221142663); Dong, Junwei (58727657500); Wang, Jianing (57222532099); Wang, Chengyu (55926354300); Wang, Ang (57221127398); Liu, Yinghui (57937336600); Huang, Jun (57199287007); Li, Yong (58448812700); He, Xiaofeng (55641972700)",57221142663; 58727657500; 57222532099; 55926354300; 57221127398; 57937336600; 57199287007; 58448812700; 55641972700,Revisiting and Advancing Chinese Natural Language Understanding with Accelerated Heterogeneous Knowledge Pre-training,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152946763&partnerID=40&md5=4206a7e44922725065ccf65637157c87,"Recently, knowledge-enhanced pre-trained language models (KEPLMs) improve context-aware representations via learning from structured relations in knowledge graphs, and/or linguistic knowledge from syntactic or dependency analysis. Unlike English, there is a lack of high-performing open-source Chinese KEPLMs in the natural language processing (NLP) community to support various language understanding applications. In this paper, we revisit and advance the development of Chinese natural language understanding with a series of novel Chinese KEPLMs released in various parameter sizes, namely CKBERT (Chinese knowledge-enhanced BERT). Specifically, both relational and linguistic knowledge is effectively injected into CKBERT based on two novel pre-training tasks, i.e., linguistic-aware masked language modeling and contrastive multi-hop relation modeling. Based on the above two pre-training paradigms and our in-house implemented TorchAccelerator, we have pre-trained base (110M), large (345M) and huge (1.3B) versions of CKBERT efficiently on GPU clusters. Experiments demonstrate that CKBERT outperforms strong baselines for Chinese over various benchmark NLP tasks and in terms of different model sizes. © 2022 Association for Computational Linguistics.",Final,
Huang H.; Shang Y.-M.; Sun X.; Wei W.; Mao X.,"Huang, Heyan (7405614195); Shang, Yu-Ming (57197783149); Sun, Xin (57460439100); Wei, Wei (56126506200); Mao, Xianling (56949703000)",7405614195; 57197783149; 57460439100; 56126506200; 56949703000,"Three birds, one stone: A novel translation based framework for joint entity and relation extraction",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121150141&doi=10.1016%2fj.knosys.2021.107677&partnerID=40&md5=10c238f444a44ce24b10e21ad4b0b034,"Joint entity and relation extraction is an important task in natural language processing and knowledge graph construction. Existing studies mainly focus on three issues: redundant predictions, overlapping triples and relation connections. However, as far as we know, none of them is able to solve the three problems simultaneously in a unified architecture. To address this issue, in this paper, we propose a novel translation based unified framework. Specifically, the proposed framework contains two components: an entity tagger and a relation extractor. The former is used to recognize all candidate head entities and tail entities respectively. The latter predicts relations for every entity pair dynamically through ranking with translation mechanism. To show the superiority of the proposed framework, we instantiate it through the simplest binary entity tagger and TransE algorithm. Extensive experiments over two widely used datasets demonstrate that, even with the simplest components, the proposed framework can still achieve competitive performance with most previous baselines. Moreover, the framework is flexible. It enjoys further performance boost when employing more powerful entity tagger and knowledge graph embedding algorithm. © 2021 Elsevier B.V.",Final,
Gerritse E.J.; Hasibi F.; De Vries A.P.,"Gerritse, Emma J. (57201855655); Hasibi, Faegheh (55350091400); De Vries, Arjen P. (56221254000)",57201855655; 55350091400; 56221254000,Entity-aware Transformers for Entity Search,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133007031&doi=10.1145%2f3477495.3531971&partnerID=40&md5=50fd0b695910abf5ce4c0280ac047d89,"Pre-trained language models such as BERT have been a key ingredient to achieve state-of-the-art results on a variety of tasks in natural language processing and, more recently, also in information retrieval. Recent research even claims that BERT is able to capture factual knowledge about entity relations and properties, the information that is commonly obtained from knowledge graphs. This paper investigates the following question: Do BERT-based entity retrieval models benefit from additional entity information stored in knowledge graphs? To address this research question, we map entity embeddings into the same input space as a pre-trained BERT model and inject these entity embeddings into the BERT model. This entity-enriched language model is then employed on the entity retrieval task. We show that the entity-enriched BERT model improves effectiveness on entity-oriented queries over a regular BERT model, establishing a new state-of-the-art result for the entity retrieval task, with substantial improvements for complex natural language queries and queries requesting a list of entities with a certain property. Additionally, we show that the entity information provided by our entity-enriched model particularly helps queries related to less popular entities. Last, we observe empirically that the entity-enriched BERT models enable fine-tuning on limited training data, which otherwise would not be feasible due to the known instabilities of BERT in few-sample fine-tuning, thereby contributing to data-efficient training of BERT for entity search. © 2022 Owner/Author.",Final,All Open Access; Bronze Open Access; Green Open Access
Alpizar-Chacon I.; Sosnovsky S.,"Alpizar-Chacon, Isaac (57192594375); Sosnovsky, Sergey (8935519700)",57192594375; 8935519700,What's in an Index: Extracting Domain-specific Knowledge Graphs from Textbooks,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129893646&doi=10.1145%2f3485447.3512140&partnerID=40&md5=649df281b9997ff172b352f616735d0a,"A typical index at the end of a textbook contains a manually-provided vocabulary of terms related to the content of the textbook. In this paper, we extend our previous work on extraction of knowledge models from digital textbooks. We are taking a more critical look at the content of a textbook index and present a mechanism for classifying index terms according to their domain specificity: a core domain concept, an in-domain concept, a concept from a related domain, and a concept from a foreign domain. We link the extracted models to DBpedia and leverage the aggregated linguistic and structural information from textbooks and DBpedia to construct and prune the domain-specific knowledge graphs. The evaluation experiments demonstrate (1) the ability of the approach to identify (with high accuracy) different levels of domain specificity for automatically extracted concepts, (2) its cross-domain robustness, and (3) the added value of the domain specificity information. These results clearly indicate the improved quality of the refined knowledge graphs and widen their potential applicability. © 2022 ACM.",Final,
Barik A.M.; Hsu W.; Lee M.L.,"Barik, Anab Maulana (57340529900); Hsu, Wynne (7402002763); Lee, Mong Li (7409117252)",57340529900; 7402002763; 7409117252,Incorporating External Knowledge for Evidence-based Fact Verification,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137430660&doi=10.1145%2f3487553.3524622&partnerID=40&md5=4e2ad96852a70af2f38d0e4958fe7263,"Existing fact verification methods employ pre-trained language models such as BERT for the contextual representation of evidence sentences. However, such representations do not take into account commonsense knowledge and these methods often conclude that there is not enough information to predict whether a claim is supported or refuted by the evidence sentences. In this work, we propose a framework called CGAT that incorporates external knowledge from ConceptNet to enrich the contextual representations of evidence sentences. We employ graph attention models to propagate the information among the evidence sentences before predicting the veracity of the claim. Experiment results on the benchmark FEVER dataset and UKP Snopes Corpus indicate that the proposed approach leads to higher accuracy and FEVER score compared to state-of-the-art claim verification methods.  © 2022 Owner/Author.",Final,All Open Access; Bronze Open Access
Yao Y.; Zhang Z.; Xu Y.; Li C.,"Yao, Yuanzhou (58102499400); Zhang, Zhao (57202848584); Xu, Yongjun (7406453263); Li, Chao (56401283200)",58102499400; 57202848584; 7406453263; 56401283200,Data Augmentation for Few-Shot Knowledge Graph Completion from Hierarchical Perspective,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161303630&partnerID=40&md5=6ea7a033810959d5c3a11b38aa41e91c,"Few-shot knowledge graph completion (FKGC) has become a new research focus in the field of knowledge graphs in recent years, which aims to predict the missing links for relations that only have a few associative triples. Existing models attempt to solve the problem via learning entity and relation representations. However, the limited training data severely hinders the performance of existing models. To this end, we propose to solve the FKGC problem with the data augmentation technique. Specifically, we perform data augmentation from two perspectives, i.e., inter-task view and intra-task view. The former generates new tasks for FKGC, while the latter enriches the support or query set for an individual task. It is worth noting that the proposed framework can be applied to a number of existing FKGC models. Experimental evaluation on two public datasets indicates our model is capable of achieving substantial improvements over baselines. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Xie X.; Zhang N.; Li Z.; Deng S.; Chen H.; Xiong F.; Chen M.; Chen H.,"Xie, Xin (57222379771); Zhang, Ningyu (55923601900); Li, Zhoubo (57420992100); Deng, Shumin (57201556430); Chen, Hui (57221150709); Xiong, Feiyu (57217171492); Chen, Mosha (57221142851); Chen, Huajun (35268022500)",57222379771; 55923601900; 57420992100; 57201556430; 57221150709; 57217171492; 57221142851; 35268022500,From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137489177&doi=10.1145%2f3487553.3524238&partnerID=40&md5=980ffc73d59a2104eea78b7073fb6271,"Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1.  © 2022 ACM.",Final,All Open Access; Bronze Open Access; Green Open Access
Li M.; Ji S.,"Li, Mingchen (57219493264); Ji, Shihao (57207105926)",57219493264; 57207105926,Semantic Structure based Query Graph Prediction for Question Answering over Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159639044&partnerID=40&md5=c14663af775c43de718e82cc92da03df,"Building query graphs from natural language questions is an important step in complex question answering over knowledge graph (Complex KGQA). In general, a question can be correctly answered if its query graph is built correctly and the right answer is then retrieved by issuing the query graph against the KG. Therefore, this paper focuses on query graph generation from natural language questions. Existing approaches for query graph generation ignore the semantic structure of a question, resulting in a large number of noisy query graph candidates that undermine prediction accuracies. In this paper, we define six semantic structures from common questions in KGQA and develop a novel Structure-BERT to predict the semantic structure of a question. By doing so, we can first filter out noisy candidate query graphs, and then rank the remaining candidates with a BERT-based ranking model. Extensive experiments on two popular benchmarks MetaQA and WebQuestionsSP (WSP) demonstrate the effectiveness of our method as compared to state-of-the-arts. The source code can be found at https://github.com/ToneLi/SSKGQA. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Andrus B.R.; Nasiri Y.; Cui S.; Cullen B.; Fulda N.,"Andrus, Berkeley R (57219335671); Nasiri, Yeganeh (58093770400); Cui, Shilong (58093770500); Cullen, Benjamin (58093886500); Fulda, Nancy (6507317548)",57219335671; 58093770400; 58093770500; 58093886500; 6507317548,Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136147942&partnerID=40&md5=575517eed8e211cd1de8a06485132a68,"Large transformer-based language models have achieved incredible success at various tasks which require narrative comprehension, including story completion, answering questions about stories, and generating stories ex nihilo. However, due to the limitations of finite context windows, these language models struggle to produce or understand stories longer than several thousand tokens. In order to mitigate the document length limitations that come with finite context windows, we introduce a novel architecture that augments story processing with an external dynamic knowledge graph. In contrast to static commonsense knowledge graphs which hold information about the real world, these dynamic knowledge graphs reflect facts extracted from the story being processed. Our architecture uses these knowledge graphs to create informationrich prompts which better facilitate story comprehension than prompts composed only of story text. We apply our architecture to the tasks of question answering and story completion. To complement this line of research, we introduce two long-form question answering tasks, LF-SQuAD and LFQUOREF, in which the document length exceeds the size of the language model's context window, and introduce a story completion evaluation method that bypasses the stochastic nature of language model generation. We demonstrate broad improvement over typical prompt formulation methods for both question answering and story completion using GPT-2, GPT-3 and XLNet.  Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Li J.; Katsis Y.; Baldwin T.; Kim H.-C.; Bartko A.; McAuley J.; Hsu C.-N.,"Li, Jiacheng (57214938288); Katsis, Yannis (12645568400); Baldwin, Tyler (57217364680); Kim, Ho-Cheol (57203629703); Bartko, Andrew (57220950932); McAuley, Julian (14822353500); Hsu, Chun-Nan (22933960800)",57214938288; 12645568400; 57217364680; 57203629703; 57220950932; 14822353500; 22933960800,SPOT: Knowledge-Enhanced Language Representations for Information Extraction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140840401&doi=10.1145%2f3511808.3557459&partnerID=40&md5=1d328118829c45d8759057510a4c281c,"Knowledge-enhanced pre-trained models for language representation have been shown to be more effective in knowledge base construction tasks (i.e.,∼relation extraction) than language models such as BERT. These knowledge-enhanced language models incorporate knowledge into pre-training to generate representations of entities or relationships. However, existing methods typically represent each entity with a separate embedding. As a result, these methods struggle to represent out-of-vocabulary entities and a large amount of parameters, on top of their underlying token models (i.e., the transformer), must be used and the number of entities that can be handled is limited in practice due to memory constraints. Moreover, existing models still struggle to represent entities and relationships simultaneously. To address these problems, we propose a new pre-trained model that learns representations of both entities and relationships from token spans and span pairs in the text respectively. By encoding spans efficiently with span modules, our model can represent both entities and their relationships but requires fewer parameters than existing models. We pre-trained our model with the knowledge graph extracted from Wikipedia and test it on a broad range of supervised and unsupervised information extraction tasks. Results show that our model learns better representations for both entities and relationships than baselines, while in supervised settings, fine-tuning our model outperforms RoBERTa consistently and achieves competitive results on information extraction tasks. © 2022 Owner/Author.",Final,All Open Access; Bronze Open Access
Feng X.; Qu Z.; Cheng Y.; Watanabe T.; Yugami N.,"Feng, Xincan (58633520500); Qu, Zhi (57903497100); Cheng, Yuchang (58753683400); Watanabe, Taro (55618598600); Yugami, Nobuhiro (56262771000)",58633520500; 57903497100; 58753683400; 55618598600; 56262771000,Sharing Parameter by Conjugation for Knowledge Graph Embeddings in Complex Space,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179138386&partnerID=40&md5=98b0954d875b67a066e26a43b0ba19df,"A Knowledge Graph (KG) is the directed graphical representation of entities and relations in the real world. KG can be applied in diverse Natural Language Processing (NLP) tasks where knowledge is required. The need to scale up and complete KG automatically yields Knowledge Graph Embedding (KGE), a shallow machine learning model that is suffering from memory and training time consumption issues. To mitigate the computational load, we propose a parameter-sharing method, i.e., using conjugate parameters for complex numbers employed in KGE models. Our method improves memory efficiency by 2x in relation embedding while achieving comparable performance to the state-of-the-art non-conjugate models, with faster, or at least comparable, training time. We demonstrated the generalizability of our method on two best-performing KGE models 5*E (Nayyeri et al., 2021) and ComplEx (Trouillon et al., 2016) on five benchmark datasets. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Rezaei N.; Reformat M.Z.,"Rezaei, Navid (57194447980); Reformat, Marek Z. (6603618138)",57194447980; 6603618138,Utilizing Language Models to Expand Vision-Based Commonsense Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137397624&doi=10.3390%2fsym14081715&partnerID=40&md5=360366d3c0d5000bdac821f8bac6fb3f,"The introduction and ever-growing size of the transformer deep-learning architecture have had a tremendous impact not only in the field of natural language processing but also in other fields. The transformer-based language models have contributed to a renewed interest in commonsense knowledge due to the abilities of deep learning models. Recent literature has focused on analyzing commonsense embedded within the pre-trained parameters of these models and embedding missing commonsense using knowledge graphs and fine-tuning. We base our current work on the empirically proven language understanding of very large transformer-based language models to expand a limited commonsense knowledge graph, initially generated only on visual data. The few-shot-prompted pre-trained language models can learn the context of an initial knowledge graph with less bias than language models fine-tuned on a large initial corpus. It is also shown that these models can offer new concepts that are added to the vision-based knowledge graph. This two-step approach of vision mining and language model prompts results in the auto-generation of a commonsense knowledge graph well equipped with physical commonsense, which is human commonsense gained by interacting with the physical world. To prompt the language models, we adapted the chain-of-thought method of prompting. To the best of our knowledge, it is a novel contribution to the domain of the generation of commonsense knowledge, which can result in a five-fold cost reduction compared to the state-of-the-art. Another contribution is assigning fuzzy linguistic terms to the generated triples. The process is end to end in the context of knowledge graphs. It means the triples are verbalized to natural language, and after being processed, the results are converted back to triples and added to the commonsense knowledge graph. © 2022 by the authors.",Final,All Open Access; Gold Open Access
Cai L.; Mao X.; Ma M.; Yuan H.; Zhu J.; Lan M.,"Cai, Li (57909359800); Mao, Xin (57214939376); Ma, Meirong (57313724900); Yuan, Hao (57711666700); Zhu, Jianchao (57313864200); Lan, Man (7102783244)",57909359800; 57214939376; 57313724900; 57711666700; 57313864200; 7102783244,A Simple Temporal Information Matching Mechanism for Entity Alignment Between Temporal Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165762406&partnerID=40&md5=08f204a3d06434147a61d31c48a2f0e6,"Entity alignment (EA) aims to find entities in different knowledge graphs (KGs) that refer to the same object in the real world. Recent studies incorporate temporal information to augment the representations of KGs. The existing methods for EA between temporal KGs (TKGs) utilize a time-aware attention mechanism to incorporate relational and temporal information into entity embeddings. The approaches outperform the previous methods by using temporal information. However, we believe that it is not necessary to learn the embeddings of temporal information in KGs since most TKGs have uniform temporal representations. Therefore, we propose a simple graph neural network (GNN) model combined with a temporal information matching mechanism, which achieves better performance with less time and fewer parameters. Furthermore, since alignment seeds are difficult to label in real-world applications, we also propose a method to generate unsupervised alignment seeds via the temporal information of TKG. Extensive experiments on public datasets indicate that our supervised method significantly outperforms the previous methods and the unsupervised one has competitive performance. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Geng S.; Fu Z.; Tan J.; Ge Y.; De Melo G.; Zhang Y.,"Geng, Shijie (57209221629); Fu, Zuohui (57209224010); Tan, Juntao (57243986300); Ge, Yingqiang (57209226063); De Melo, Gerard (23088528100); Zhang, Yongfeng (36816821200)",57209221629; 57209224010; 57243986300; 57209226063; 23088528100; 36816821200,Path Language Modeling over Knowledge Graphsfor Explainable Recommendation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125780198&doi=10.1145%2f3485447.3511937&partnerID=40&md5=c15aa857d571c1c0e2cd98af5c34a8c9,"To facilitate human decisions with credible suggestions, personalized recommender systems should have the ability to generate corresponding explanations while making recommendations. Knowledge graphs (KG), which contain comprehensive information about users and products, are widely used to enable this. By reasoning over a KG in a node-by-node manner, existing explainable models provide a KG-grounded path for each user-recommended item. Such paths serve as an explanation and reflect the historical behavior pattern of the user. However, not all items can be reached following the connections within the constructed KG under finite hops. Hence, previous approaches are constrained by a recall bias in terms of existing connectivity of KG structures. To overcome this, we propose a novel Path Language Modeling Recommendation (PLM-Rec) framework, learning a language model over KG paths consisting of entities and edges. Through path sequence decoding, PLM-Rec unifies recommendation and explanation in a single step and fulfills them simultaneously. As a result, PLM-Rec not only captures the user behaviors but also eliminates the restriction to pre-existing KG connections, thereby alleviating the aforementioned recall bias. Moreover, the proposed technique makes it possible to conduct explainable recommendation even when the KG is sparse or possesses a large number of relations. Experiments and extensive ablation studies on three Amazon e-commerce datasets demonstrate the effectiveness and explainability of the PLM-Rec framework. © 2022 ACM.",Final,
Yang Z.; Wang B.; Zhou J.; Tan Y.; Zhao D.; Huang K.; He R.; Hou Y.,"Yang, Zhitong (58040557500); Wang, Bo (56949454300); Zhou, Jinfeng (57558200300); Tan, Yue (58506099900); Zhao, Dongming (7403490494); Huang, Kun (57614133600); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",58040557500; 56949454300; 57558200300; 58506099900; 7403490494; 57614133600; 19835197000; 7402198932,TopKG: Target-oriented Dialog via Global Planning on Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165542587&partnerID=40&md5=c49e21b77f812eebfadd6bf96d15fa1f,"Target-oriented dialog aims to reach a global target through multi-turn conversation. The key to the task is the global planning towards the target, which flexibly guides the dialog concerning the context. However, existing target-oriented dialog works take a local and greedy strategy for response generation, where global planning is absent. In this work, we propose global planning for target-oriented dialog on a commonsense knowledge graph (KG). We design a global reinforcement learning with the planned paths to flexibly adjust the local response generation model towards the global target. We also propose a KG-based method to collect target-oriented samples automatically from the chit-chat corpus for model training. Experiments show that our method can reach the target with a higher success rate, fewer turns, and more coherent responses. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Kirillovich A.V.; Nevzorova O.A.; Lipachev E.K.,"Kirillovich, A.V. (55994716700); Nevzorova, O.A. (6506234633); Lipachev, E.K. (6505830683)",55994716700; 6506234633; 6505830683,OntoMathPRO2.0 Ontology: Updates of Formal Model,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159931449&doi=10.1134%2fS1995080222150136&partnerID=40&md5=5a26eae354ba7b786c8296ad782332c6,"Abstract: This paper is devoted to the problems of ontology-based mathematical knowledge management and representation. The main attention is paid to the development of a formal model for the representation of mathematical statements in the Open Linked Data cloud. The proposed model is intended for applications that extract mathematical facts from natural language mathematical texts and represent these facts as Linked Open Data. The model is used in development of a new version of the OntoMathPRO ontology of professional mathematics is described. OntoMathPRO underlies a semantic publishing platform, that takes as an input a collection of mathematical papers in LaTeX format and builds their ontology-based Linked Open Data representation. The semantic publishing platform, in turn, is a central component of OntoMath digital ecosystem, an ecosystem of ontologies, text analytics tools, and applications for mathematical knowledge management, including semantic search for mathematical formulas and a recommender system for mathematical papers. According to the new model, the ontology is organized into three layers: a foundational ontology layer, a domain ontology layer and a linguistic layer. The domain ontology layer contains language-independent math concepts. The linguistic layer provides linguistic grounding for these concepts, and the foundation ontology layer provides them with meta-ontological annotations. The concepts are organized in two main hierarchies: the hierarchy of objects and the hierarchy of reified relationships. © 2022, Pleiades Publishing, Ltd.",Final,All Open Access; Green Open Access
Wu Z.; Zhang M.; Zhu M.; Li Y.; Zhu T.; Yang H.; Peng S.; Qin Y.,"Wu, Zhanglin (57387088200); Zhang, Min (57282022500); Zhu, Ming (58021037900); Li, Yinglu (57386898100); Zhu, Ting (57879149400); Yang, Hao (57208745952); Peng, Song (57226320078); Qin, Ying (57208747392)",57387088200; 57282022500; 58021037900; 57386898100; 57879149400; 57208745952; 57226320078; 57208747392,KG-BERTScore: Incorporating Knowledge Graph into BERTScore for Reference-Free Machine Translation Evaluation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148546185&doi=10.1145%2f3579051.3579065&partnerID=40&md5=1a569483f435253f4e55514d599682a3,"BERTScore is an effective and robust automatic metric for reference-based machine translation evaluation. In this paper, we incorporate multilingual knowledge graph into BERTScore and propose a metric named KG-BERTScore, which linearly combines the results of BERTScore and bilingual named entity matching for reference-free machine translation evaluation. From the experimental results on WMT19 QE as a metric without references shared tasks, our metric KG-BERTScore gets higher overall correlation with human judgements than the current state-of-The-Art metrics for reference-free machine translation evaluation.1 Moreover, the pre-Trained multilingual model used by KG-BERTScore and the parameter for linear combination are also studied in this paper. © 2022 Owner/Author.",Final,All Open Access; Green Open Access
Lu W.; Zhang Z.; Yuan P.; Jin H.; Hua Q.,"Lu, Wei (57220644305); Zhang, Zhaobo (57228034800); Yuan, Pingpeng (12762118900); Jin, Hai (56434989100); Hua, Qiangsheng (15060090400)",57220644305; 57228034800; 12762118900; 56434989100; 15060090400,Learning Chinese Word Embeddings By Discovering Inherent Semantic Relevance in Sub-characters,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140850689&doi=10.1145%2f3511808.3557376&partnerID=40&md5=76f73f6b95a90a09caccda24bdb6a4ca,"Learning Chinese word embeddings is important in many tasks of Chinese language information processing, such as entity linking, entity extraction, and knowledge graph. A Chinese word consists of Chinese characters, which can be decomposed into sub-characters (radical, component, stroke, etc). Similar to roots in English words, sub-characters also indicate the origins and basic semantics of Chinese characters. So, many researches follow the approaches designed for learning embeddings of English words to improve Chinese word embeddings. However, some Chinese characters sharing the same sub-characters have different meanings. Furthermore, with more cultural interaction and the popularization of the Internet and web, many neologisms, such as transliterated loanwords and network terms, are emerging, which are only close to the pronunciation of their characters, but far from their semantics. Here, a tripartite weighted graph is proposed to model the semantic relationship among words, characters, and sub-characters, in which the semantic relationship is evaluated according to the Chinese linguistic information. So, the semantic relevance hidden in lower components (sub-characters, characters) can be used to further distinguish the semantics of corresponding higher components (characters, words). Then, the tripartite weighted graph is fed into our Chinese word embedding modelinsideCC to reveal the semantic relationship among different language components, and learn the embeddings of words. Extensive experimental results on multiple corpora and datasets verify that our proposed methods outperform the state-of-the-art counterparts by a significant margin. © 2022 ACM.",Final,
Gui X.; Zhao F.; Jin L.; Jin H.,"Gui, Xiangyu (57205489267); Zhao, Feng (57191956476); Jin, Langjunqing (57216907391); Jin, Hai (56434989100)",57205489267; 57191956476; 57216907391; 56434989100,OpticE: A Coherence Theory-Based Model for Link Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165760587&partnerID=40&md5=a99a3613b2ebd480c54f0622cfa69fff,"Knowledge representation learning is a key step required for link prediction tasks with knowledge graphs (KGs). During the learning process, the semantics of each entity are embedded by a vector or a point in a feature space. The distance between these points is a measure of semantic similarity. However, in a KG, while two entities may have similar semantics in some relations, they have different semantics in others. It is ambiguous to assign a fixed distance to depict the variant semantic similarity of entities. To alleviate the semantic ambiguity in KGs, we design a new embedding approach named OpticE, which is derived from the well-known physical phenomenon of optical interference. It is a lightweight and relation-adaptive model based on coherence theory, in which each entity’s semantics vary automatically regarding different relations. In addition, a unique negative sampling method is proposed to combine the multimapping properties and self-adversarial learning during the training process. The experimental results obtained on practical KG benchmarks show that the OpticE model, with elegant structures, can compete with existing link prediction methods. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Liu Y.; Sun Z.; Li G.; Hu W.,"Liu, Yang (58396468700); Sun, Zequn (57191745946); Li, Guangyao (57220029478); Hu, Wei (57191221527)",58396468700; 57191745946; 57220029478; 57191221527,I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140835971&doi=10.1145%2f3511808.3557355&partnerID=40&md5=65eb8d26e4888d0743507cc5e4f32584,"Knowledge graph (KG) embedding seeks to learn vector representations for entities and relations. Conventional models reason over graph structures, but they suffer from the issues of graph incompleteness and long-tail entities. Recent studies have used pre-trained language models to learn embeddings based on the textual information of entities and relations, but they cannot take advantage of graph structures. In the paper, we show empirically that these two kinds of features are complementary for KG embedding. To this end, we propose CoLE, a Co-distillation Learning method for KG Embedding that exploits the complementarity of graph structures and text information. Its graph embedding model employs Transformer to reconstruct the representation of an entity from its neighborhood subgraph. Its text embedding model uses a pre-trained language model to generate entity representations from the soft prompts of their names, descriptions and relational neighbors. To let the two models promote each other, we propose co-distillation learning that allows them to distill selective knowledge from each other's prediction logits. In our co-distillation learning, each model serves as both a teacher and a student. Experiments on benchmark datasets demonstrate that the two models outperform their related baselines, and the ensemble method CoLE with co-distillation learning advances the state-of-the-art of KG embedding. © 2022 ACM.",Final,
Zhang T.; Wang C.; Hu N.; Qiu M.; Tang C.; He X.; Huang J.,"Zhang, Taolin (57221142663); Wang, Chengyu (55926354300); Hu, Nan (57226278026); Qiu, Minghui (55537463100); Tang, Chengguang (57219766342); He, Xiaofeng (55641972700); Huang, Jun (57199287007)",57221142663; 55926354300; 57226278026; 55537463100; 57219766342; 55641972700; 57199287007,DKPLM: Decomposable Knowledge-Enhanced Pre-trained Language Model for Natural Language Understanding,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140392417&partnerID=40&md5=2300234ed5f5dd982a4de2dd82c0784a,"Knowledge-Enhanced Pre-trained Language Models (KEPLMs) are pre-trained models with relation triples injecting from knowledge graphs to improve language understanding abilities.Experiments show that our model outperforms other KEPLMs significantly over zero-shot knowledge probing tasks and multiple knowledge-aware language understanding tasks. To guarantee effective knowledge injection, previous studies integrate models with knowledge encoders for representing knowledge retrieved from knowledge graphs. The operations for knowledge retrieval and encoding bring significant computational burdens, restricting the usage of such models in real-world applications that require high inference speed. In this paper, we propose a novel KEPLM named DKPLM that decomposes knowledge injection process of the pre-trained language models in pre-training, fine-tuning and inference stages, which facilitates the applications of KEPLMs in realworld scenarios. Specifically, we first detect knowledge-aware long-tail entities as the target for knowledge injection, enhancing the KEPLMs' semantic understanding abilities and avoiding injecting redundant information. The embeddings of long-tail entities are replaced by ""pseudo token representations"" formed by relevant knowledge triples. We further design the relational knowledge decoding task for pre-training to force the models to truly understand the injected knowledge by relation triple reconstruction. Experiments show that our model outperforms other KEPLMs significantly over zeroshot knowledge probing tasks and multiple knowledge-aware language understanding tasks. We further show that DKPLM has a higher inference speed than other competing models due to the decomposing mechanism. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Niu G.; Li B.; Zhang Y.; Pu S.,"Niu, Guanglin (57191197891); Li, Bo (56092633500); Zhang, Yongfei (34874069700); Pu, Shiliang (56462199300)",57191197891; 56092633500; 34874069700; 56462199300,Perform Like an Engine: A Closed-Loop Neural-Symbolic Learning Framework for Knowledge Graph Inference,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165768747&partnerID=40&md5=40468d7e31ff8e7bd1799a12837c65d6,"Knowledge graph (KG) inference aims to address the natural incompleteness of KGs, including rule learning-based and KG embedding (KGE) models. However, the rule learning-based models suffer from low efficiency and generalization while KGE models lack interpretability. To address these challenges, we propose a novel and effective closed-loop neural-symbolic learning framework EngineKG via incorporating our developed KGE and rule learning modules. KGE module exploits symbolic rules and paths to enhance the semantic association between entities and relations for improving KG embeddings and interpretability. A novel rule pruning mechanism is proposed in the rule learning module by leveraging paths as initial candidate rules and employing KG embeddings together with concepts for extracting more high-quality rules. Experimental results on four real-world datasets show that our model outperforms the relevant baselines on link prediction tasks, demonstrating the superiority of our KG inference model in a neural-symbolic learning fashion. The source code and datasets of this paper are available at https://github.com/ngl567/EngineKG. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Amin S.; Minervini P.; Chang D.; Stenetorp P.; Neumann G.,"Amin, Saadullah (57210371505); Minervini, Pasquale (36617521100); Chang, David (57198890682); Stenetorp, Pontus (36663192600); Neumann, Günter (7202631822)",57210371505; 36617521100; 57198890682; 36663192600; 7202631822,MEDDISTANT19: Towards an Accurate Benchmark for Broad-Coverage Biomedical Relation Extraction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159634736&partnerID=40&md5=357c34ad94229d9bf20a0e30078d0259,"Relation extraction in the biomedical domain is challenging due to the lack of labeled data and high annotation costs, needing domain experts. Distant supervision is commonly used to tackle the scarcity of annotated data by automatically pairing knowledge graph relationships with raw texts. Such a pipeline is prone to noise and has added challenges to scale for covering a large number of biomedical concepts. We investigated existing broad-coverage distantly supervised biomedical relation extraction benchmarks and found a significant overlap between training and test relationships ranging from 26% to 86%. Furthermore, we noticed several inconsistencies in the data construction process of these benchmarks, and where there is no train-test leakage, the focus is on interactions between narrower entity types. This work presents a more accurate benchmark MEDDISTANT19 for broad-coverage distantly supervised biomedical relation extraction that addresses these shortcomings and is obtained by aligning the MEDLINE abstracts with the widely used SNOMED Clinical Terms knowledge base. Lacking thorough evaluation with domain-specific language models, we also conduct experiments validating general domain relation extraction findings to biomedical relation extraction. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Kovriguina L.; Teucher R.; Wardenga R.,"Kovriguina, Liubov (56119059000); Teucher, Roman (57803401500); Wardenga, Robert (57216694090)",56119059000; 57803401500; 57216694090,TextGraphs-16 Natural Language Premise Selection Task: Zero-Shot Premise Selection with Prompting Generative Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177427852&partnerID=40&md5=fdc388fec1959622611898b9af3c5189,"Automated theorem proving can benefit a lot from methods employed in natural language processing, knowledge graphs and information retrieval: this non-trivial task combines formal languages understanding, reasoning; similarity search. We tackle this task by enhancing semantic similarity ranking with prompt engineering, which has become a new paradigm in natural language understanding. None of our approaches requires additional training. Despite encouraging results reported by prompt engineering approaches for a range of NLP tasks, for the premise selection task vanilla re-ranking by prompting GPT-3 doesn’t outperform semantic similarity ranking with SBERT, but merging of the both rankings shows better results. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Bogdanchikov A.; Ayazbayev D.; Varlamis I.,"Bogdanchikov, Andrey (57216432873); Ayazbayev, Dauren (58027694900); Varlamis, Iraklis (6603228762)",57216432873; 58027694900; 6603228762,Classification of Scientific Documents in the Kazakh Language Using Deep Neural Networks and a Fusion of Images and Text,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144598844&doi=10.3390%2fbdcc6040123&partnerID=40&md5=518737ebfaf53f5931c84aed71f57907,"The rapid development of natural language processing and deep learning techniques has boosted the performance of related algorithms in several linguistic and text mining tasks. Consequently, applications such as opinion mining, fake news detection or document classification that assign documents to predefined categories have significantly benefited from pre-trained language models, word or sentence embeddings, linguistic corpora, knowledge graphs and other resources that are in abundance for the more popular languages (e.g., English, Chinese, etc.). Less represented languages, such as the Kazakh language, balkan languages, etc., still lack the necessary linguistic resources and thus the performance of the respective methods is still low. In this work, we develop a model that classifies scientific papers written in the Kazakh language using both text and image information and demonstrate that this fusion of information can be beneficial for cases of languages that have limited resources for machine learning models’ training. With this fusion, we improve the classification accuracy by 4.4499% compared to the models that use only text or only image information. The successful use of the proposed method in scientific documents’ classification paves the way for more complex classification models and more application in other domains such as news classification, sentiment analysis, etc., in the Kazakh language. © 2022 by the authors.",Final,All Open Access; Gold Open Access
Qiao Z.; Ye W.; Zhang T.; Mo T.; Li W.; Zhang S.,"Qiao, Zile (57885433300); Ye, Wei (57202350940); Zhang, Tong (57204720801); Mo, Tong (36632540700); Li, Weiping (35229637800); Zhang, Shikun (7409376421)",57885433300; 57202350940; 57204720801; 36632540700; 35229637800; 7409376421,Exploiting Hybrid Semantics of Relation Paths for Multi-hop Question Answering Over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165771491&partnerID=40&md5=2149115ff8c433ea946abf9fbf3e2cb0,"Answering natural language questions on knowledge graphs (KGQA) remains a great challenge in terms of understanding complex questions via multi-hop reasoning. Previous efforts usually exploit large-scale entity-related text corpora or knowledge graph (KG) embeddings as auxiliary information to facilitate answer selection. However, the rich semantics implied in off-the-shelf relation paths between entities is far from well explored. This paper proposes improving multi-hop KGQA by exploiting relation paths’ hybrid semantics. Specifically, we integrate explicit textual information and implicit KG structural features of relation paths based on a novel rotate-and-scale entity link prediction framework. Extensive experiments on three existing KGQA datasets demonstrate the superiority of our method, especially in multi-hop scenarios. Further investigation confirms our method’s systematical coordination between questions and relation paths to identify answer entities. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Pais V.-F.,"Pais, Vasile-Florian (16686767100)",16686767100,Speech Recognition Technology and Applications,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140700694&doi=10.52305%2fBKWM8996&partnerID=40&md5=d451d2068a0c42d582e33e0612ed98e7,"Speech represents the most natural means of communication between humans. By using Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) systems, machines also become able to interact with humans using speech. This is of particular importance for building interactive robots or speech-enabled chatbots. This book starts by exploring state-of-the-art ASR and TTS approaches, making use of artificial neural networks, relevant also to low-resource scenarios. Then, it explores the application of speech technology to specific domains, such as the medical domain, human-robot interaction, and even interlinking of speech and text resources using linguistic linked open data (LLOD) principles. The book also provides punctuation restoration techniques, enabling the production of high-quality text transcripts. Included algorithms have low latency and can be parallelized, thus enabling their use in interactive systems. Chapter authors are professors and scientific researchers with experience in building and using natural language processing algorithms and speech applications. © 2022 by Nova Science Publishers, Inc. All rights reserved.",Final,
Martinez-Rodriguez J.L.; Lopez-Arevalo I.; Rios-Alvarado A.B.,"Martinez-Rodriguez, Jose L. (55642245600); Lopez-Arevalo, Ivan (56000858100); Rios-Alvarado, Ana B. (35186366800)",55642245600; 56000858100; 35186366800,Mining information from sentences through Semantic Web data and Information Extraction tasks,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092208200&doi=10.1177%2f0165551520934387&partnerID=40&md5=cfaa96766b7274a5a4289c03a7e2da53,"The Semantic Web provides guidelines for the representation of information about real-world objects (entities) and their relations (properties). This is helpful for the dissemination and consumption of information by people and applications. However, the information is mainly contained within natural language sentences, which do not have a structure or linguistic descriptions ready to be directly processed by computers. Thus, the challenge is to identify and extract the elements of information that can be represented. Hence, this article presents a strategy to extract information from sentences and its representation with Semantic Web standards. Our strategy involves Information Extraction tasks and a hybrid semantic similarity measure to get entities and relations that are later associated with individuals and properties from a Knowledge Base to create RDF triples (Subject–Predicate–Object structures). The experiments demonstrate the feasibility of our method and that it outperforms the accuracy provided by a pattern-based method from the literature. © The Author(s) 2020.",Final,
Lv X.; Xie Z.; Xu D.; Jin X.; Ma K.; Tao L.; Qiu Q.; Pan Y.,"Lv, Xia (50661785000); Xie, Zhong (36164790400); Xu, Dexin (57556111900); Jin, Xiangguo (57556112000); Ma, Kai (56406842100); Tao, Liufeng (57210018064); Qiu, Qinjun (57203591589); Pan, Yongsheng (57556293400)",50661785000; 36164790400; 57556111900; 57556112000; 56406842100; 57210018064; 57203591589; 57556293400,Chinese Named Entity Recognition in the Geoscience Domain Based on BERT,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127309366&doi=10.1029%2f2021EA002166&partnerID=40&md5=60b5b599bc5110001b7732426345e27a,"Geological reports are frequently used by geologists involved in geological surveys and scientific research to record the results and outcomes of geological surveys. With such a rich data source, a substantial amount of knowledge has yet to be mined and analyzed. This paper focuses on automatically information extraction from geological reports, namely, geological named entity recognition. Geological named entity recognition has an important role in data mining, knowledge discovery and Knowledge graph construction. Existing general named entity recognition models/tools are limited in the domain of geoscience due to the various language irregularities associated with geological text, such as informal sentence structures, several domain-geoscience words, large character lengths and multiple combinations of independent words. We present Bidirectional encoder representations from transformers (BERT)-(Bidirectional gated recurrent unit network) BiGRU- (Conditional random field) CRF, which is a deep learning-based geological named entity recognition model that is designed specifically with these linguistic irregularities in mind. Based on the pretrained language model, an integrated deep learning model incorporating BERT, BiGRU and CRF is constructed to obtain character vectors rich in semantic information through the BERT pretrained language model to alleviate for the lack of specificity of static word vectors (e.g., word2vec) and to improve the extraction capability of complex geological entities. We demonstrate our proposed model by applying it to four test datasets, including a geoscience NER data set from regional geological reports, and by comparing its performance with those of five baseline models. © 2022 The Authors. Earth and Space Science published by Wiley Periodicals LLC on behalf of American Geophysical Union.",Final,All Open Access; Gold Open Access
Xu J.; Zhang B.; Li J.; Zhang Y.,"Xu, Jianhua (57779648800); Zhang, Binbin (55721032800); Li, Jianyu (57223100053); Zhang, Yongjia (57778973100)",57779648800; 55721032800; 57223100053; 57778973100,Chinese Word Segmentation with Many Rare Terms in Low-Resource Scenarios,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133342261&doi=10.1145%2f3528114.3528124&partnerID=40&md5=7f857bd7d0c781a1974d1c9083c06026,"In constructing the domain-specific knowledge graphs, we can use the texts accumulated in the domain as data sources for analysis. However, in many domains, there are many rare terms in the text that make the generic corpus inapplicable, but no domain-specific corpus is available. Using the existing Chinese word segmentation (CWS) corpus and methods, this type of texts cannot be effectively segmented. For such special texts without applicable corpus, this paper proposes a domain dictionary-based Chinese word segmentation method based on the BiLSTM-CNN-CRF method. We firstly manually label a part of the samples, then combine randomly selected words from the dictionary into the manually labeled sentences to generate pseudo-labeled data, and merge the two to get a composite training set. Then we preprocess the texts, replace the rare terms with non-segmentable strings to further improve the accuracy of word segmentation. The experimental results show that our approach has higher accuracy, recall and F1 score in the task of segmenting texts with many rare terms in low-resource scenarios. Our approach can be applied to the task of Chinese word segmentation in specific domains containing rare terms.  © 2022 ACM.",Final,
Shen J.; Wang C.; Gong L.; Song D.,"Shen, Jianhao (57220573591); Wang, Chenguang (56367840700); Gong, Linyuan (57214129756); Song, Dawn (57225849829)",57220573591; 56367840700; 57214129756; 57225849829,Joint Language Semantic and Structure Embedding for Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158857870&partnerID=40&md5=79fce07397785544ff50dcbd7607a469,"The task of completing knowledge triplets has broad downstream applications. Both structural and semantic information plays an important role in knowledge graph completion. Unlike previous approaches that rely on either the structures or semantics of the knowledge graphs, we propose to jointly embed the semantics in the natural language description of the knowledge triplets with their structure information. Our method embeds knowledge graphs for the completion task via fine-tuning pre-trained language models with respect to a probabilistic structured loss, where the forward pass of the language models captures semantics and the loss reconstructs structures. Our extensive experiments on a variety of knowledge graph benchmarks have demonstrated the state-of-the-art performance of our method. We also show that our method can significantly improve the performance in a low-resource regime, thanks to the better use of semantics. The code and datasets are available at https://github.com/pkusjh/LASS. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Saeedizade M.J.; Torabian N.; Minae-Bidgol B.,"Saeedizade, Mohammad Javad (57226168029); Torabian, Najmeh (23480765100); Minae-Bidgol, Behrouz (58221121500)",57226168029; 23480765100; 58221121500,KGRefiner: Knowledge Graph Refinement for Improving Accuracy of Translational Link Prediction Methods,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156121153&partnerID=40&md5=e2183cdc456a6ec691f8e9f0120fb1ab,"Link Prediction is the task of predicting missing relations between knowledge graph(KG) entities. Recent work in link prediction mainly attempted to adapt a model to increase link prediction accuracy by using more layers in neural network architecture, which heavily rely on computational resources. This paper proposes the refinement of knowledge graphs to perform link prediction operations more accurately using relatively fast translational models. Translational link prediction models have significantly less complexity (faster) than deep learning approaches but are less accurate; this motivated us to improve their accuracy. Our method uses the ontologies of knowledge graphs to add information as auxiliary nodes to the graph. Then, these auxiliary nodes are connected to ordinary nodes of the KG that contain auxiliary information in their hierarchy. Our experiments show that our method can significantly increase the performance of translational link prediction methods in Hit@10, Mean Rank, and Mean Reciprocal Rank, with the same complexity as translational models. © 2022 Association for Computational Linguistics.",Final,
Peng M.; Liu B.; Xie Q.; Xu W.; Wang H.; Peng M.,"Peng, Miao (57938314000); Liu, Ben (57937723800); Xie, Qianqian (57190030285); Xu, Wenjie (57385295700); Wang, Hua (7501735520); Peng, Min (7202484705)",57938314000; 57937723800; 57190030285; 57385295700; 7501735520; 7202484705,SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149868381&partnerID=40&md5=9782ba6ceb73621e381fbdee0a6955db,"Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of SMiLE is available at https://github.com/GKNL/SMiLE. © 2022 Association for Computational Linguistics.",Final,
Fang Y.; Zhang Y.,"Fang, Yanbo (58137555400); Zhang, Yongfeng (36816821200)",58137555400; 36816821200,Data-Efficient Concept Extraction from Pre-trained Language Models for Commonsense Explanation Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149835618&partnerID=40&md5=7893f118859ad2a5e8397368699b6195,"Predicting the key explanation concept is essential for generating commonsense explanations. This paper introduces a method to predict the concept from pre-trained language models for commonsense explanation generation. Our experiment found that adopting a language model as the concept extractor and fine-tuning it with 20% training data can improve the quality and accuracy of the generated explanations over multiple evaluation metrics. Compared with conventional methods that search concepts over knowledge graphs, our method does not require the preparation and training models to search through knowledge graphs. To better understand the results from pre-trained language models, we also designed a metric to evaluate the retrieved concepts. Through analysis and experiments, we show the correlation between this metric and the performance of the generators, and we also show the importance of attaching concepts for generating high-quality sentences. © 2022 Association for Computational Linguistics.",Final,
Deng H.; Zhang Y.; Zhang Y.; Ying W.; Yu C.; Wei Wang J.G.; Bai X.; Yang N.; Ma J.; Chen X.; Zhou T.,"Deng, Haolin (57980330600); Zhang, Yanan (57266789300); Zhang, Yangfan (57980330700); Ying, Wangyang (57979591200); Yu, Changlong (57211937170); Wei Wang, Jun Gao (58130766900); Bai, Xiaoling (57980330800); Yang, Nan (57814026500); Ma, Jin (57847648900); Chen, Xiang (58379989800); Zhou, Tianhua (57980137000)",57980330600; 57266789300; 57980330700; 57979591200; 57211937170; 58130766900; 57980330800; 57814026500; 57847648900; 58379989800; 57980137000,Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149444788&partnerID=40&md5=f5ada8097688c3c58ce8f770fa4d3cf9,"Event extraction (EE) is crucial to downstream tasks such as new aggregation and event knowledge graph construction. Most existing EE datasets manually define fixed event types and design specific schema for each of them, failing to cover diverse events emerging from the online text. Moreover, news titles, an important source of event mentions, have not gained enough attention in current EE research. In this paper, We present Title2Event, a large-scale sentence-level dataset benchmarking Open Event Extraction without restricting event types. Title2Event contains more than 42, 000 news titles in 34 topics collected from Chinese web pages. To the best of our knowledge, it is currently the largest manually-annotated Chinese dataset for open event extraction. We further conduct experiments on Title2Event with different models and show that the characteristics of titles make it challenging for event extraction, addressing the significance of advanced study on this problem. The dataset and baseline codes are available at https://open-event-hub.github.io/title2event. © 2022 Association for Computational Linguistics.",Final,
Song R.; He S.; Zheng S.; Gao S.; Liu K.; Yu Z.; Zhao J.,"Song, Ran (57212212531); He, Shizhu (56021680600); Zheng, Suncong (55838664300); Gao, Shengxiang (12762206800); Liu, Kang (55729555700); Yu, Zhengtao (8883303600); Zhao, Jun (57190004147)",57212212531; 56021680600; 55838664300; 12762206800; 55729555700; 8883303600; 57190004147,Decoupling Mixture-of-Graphs: Unseen Relational Learning for Knowledge Graph Completion by Fusing Ontology and Textual Experts,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148270566&partnerID=40&md5=be2e746783ef66ab12ff926d74931b39,"Knowledge Graph Embedding (KGE) has been proposed and successfully utilized for knowledge Graph Completion (KGC). But classic KGE paradigm often fail in unseen relation representations. Previous studies mainly utilize the textual descriptions of relations and its neighbor relations to represent unseen relations. In fact, the semantics of a relation can be expressed by three kinds of graphs: factual graph, ontology graph, textual description graph, and they can complement each other. A more common scenario in the real world is that seen and unseen relations appear at the same time. In this setting, the training set (only seen relations) and testing set (both seen and unseen relations) own different distributions. And the train-test inconsistency problem will make KGE methods easily overfit on seen relations and under-performance on unseen relations. In this paper, we propose decoupling mixture-of-graph experts (DMoG) for unseen relations learning, which could represent the unseen relations in the factual graph by fusing ontology and textual graphs, and decouple fusing space and reasoning space to alleviate overfitting for seen relations. The experiments on two unseen-only public datasets and a mixture dataset verify the effectiveness of the proposed method, which improves the state-of-the-art methods by 6.84% in Hits@10 on average. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
,,,Findings of the Association for Computational Linguistics: EMNLP 2022,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149819406&partnerID=40&md5=190c31e0d2ce203cab3365118adc2eb2,The proceedings contain 547 papers. The topics discussed include: LogicSolver: towards interpretable math word problem solving with logical prompt-enhanced learning; commonsense knowledge salience evaluation with a benchmark dataset in e-commerce; automatic rule induction for efficient semi-supervised learning; improving semantic matching through dependency-enhanced pre-trained model with adaptive fusion; acceptability judgements via examining the topology of attention maps; clip-tuning: towards derivative-free prompt learning with a mixture of rewards; soft-labeled contrastive pre-training for function-level code representation; conditioned masked language and image modeling for image-text dense retrieval; does simultaneous speech translation need simultaneous models?; utilizing language-image pretraining for efficient and robust bilingual word alignment; grape: knowledge graph enhanced passage reader for open-domain question answering; and dialogue meaning representation for task-oriented dialogue systems.,Final,
Socrates V.,"Socrates, Vimig (57194574332)",57194574332,Extraction of Diagnostic Reasoning Relations for Clinical Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149134159&partnerID=40&md5=1f4ebb3e8d5f9e6071a1f95885b743ac,"Clinical knowledge graphs lack meaningful diagnostic relations (e.g. comorbidities, sign/symptoms), limiting their ability to represent real-world diagnostic processes. Previous methods in biomedical relation extraction have focused on concept relations, such as gene-disease and disease-drug, and largely ignored clinical processes. In this thesis, we leverage a clinical reasoning ontology and propose methods to extract such relations from a physician-facing point-of-care reference wiki and consumer health resource texts. Given the lack of data labeled with diagnostic relations, we also propose new methods of evaluating the correctness of extracted triples in the zero-shot setting. We describe a process for the intrinsic evaluation of new facts by triple confidence filtering and clinician manual review, as well as extrinsic evaluation in the form of a differential diagnosis prediction task. © 2022 Association for Computational Linguistics.",Final,
Tong V.; Nguyen D.Q.; Huynh T.T.; Nguyen T.T.; Nguyen Q.V.H.; Niepert M.,"Tong, Vinh (57223911262); Nguyen, Dat Quoc (35932254600); Huynh, Trung Thanh (57954810500); Nguyen, Tam Thanh (57755801900); Nguyen, Quoc Viet Hung (57190497691); Niepert, Mathias (23009564300)",57223911262; 35932254600; 57954810500; 57755801900; 57190497691; 23009564300,Joint Multilingual Knowledge Graph Completion and Alignment,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149841976&partnerID=40&md5=ae5c788e78bc6aba61d1b60778261490,"Knowledge graph (KG) alignment and completion are usually treated as two independent tasks. While recent work has leveraged entity and relation alignments from multiple KGs, such as alignments between multilingual KGs with common entities and relations, a deeper understanding of the ways in which multilingual KG completion (MKGC) can aid the creation of multilingual KG alignments (MKGA) is still limited. Motivated by the observation that structural inconsistencies - the main challenge for MKGA models - can be mitigated through KG completion methods, we propose a novel model for jointly completing and aligning knowledge graphs. The proposed model combines two components that jointly accomplish KG completion and alignment. These two components employ relation-aware graph neural networks that we propose to encode multi-hop neighborhood structures into entity and relation representations. Moreover, we also propose (i) a structural inconsistency reduction mechanism to incorporate information from the completion into the alignment component, and (ii) an alignment seed enlargement and triple transferring mechanism to enlarge alignment seeds and transfer triples during KGs alignment. Extensive experiments on a public multilingual benchmark show that our proposed model outperforms existing competitive baselines, obtaining new state-of-the-art results on both MKGC and MKGA tasks. © 2022 Association for Computational Linguistics.",Final,
Zhang L.; Li R.,"Zhang, Lihui (57538068100); Li, Ruifan (13608752200)",57538068100; 13608752200,KE-GCL: Knowledge Enhanced Graph Contrastive Learning for Commonsense Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149842789&partnerID=40&md5=432cdc1fd6c369b9f182bad936339370,"Commonsense question answering (CQA) aims to choose the correct answers for commonsense questions. Most existing works focus on extracting and reasoning over external knowledge graphs (KG). However, the noise in KG prevents these models from learning effective representations. In this paper, we propose a Knowledge Enhanced Graph Contrastive Learning model (KE-GCL) by incorporating the contextual descriptions of entities and adopting a graph contrastive learning scheme. Specifically, for QA pairs we represent the knowledge from KG and contextual descriptions. Then, the representations of contextual descriptions as context nodes are inserted into KG, forming the knowledge-enhanced graphs. Moreover, we design a contrastive learning method on graphs. For knowledge-enhanced graphs, we build their augmented views with an adaptive sampling strategy. After that, we reason over graphs to update their representations by scattering edges and aggregating nodes. To further improve GCL, hard graph negatives are chosen based on incorrect answers. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our proposed KE-GCL, which outperforms previous methods consistently. © 2022 Association for Computational Linguistics.",Final,
Su Y.; Wang Z.; Fang T.; Zhang H.; Song Y.; Zhang T.,"Su, Ying (57951712000); Wang, Zihao (57202647584); Fang, Tianqing (57222014949); Zhang, Hongming (57202439109); Song, Yangqiu (14039604300); Zhang, Tong (7404373332)",57951712000; 57202647584; 57222014949; 57202439109; 14039604300; 7404373332,MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149845136&partnerID=40&md5=7a4e747251be3e9934491eca7141fa79,"Commonsense reasoning tasks such as commonsense knowledge graph completion and commonsense question answering require powerful representation learning. In this paper, we propose to learn commonsense knowledge representation by MICO, a Multi-alternative contrastIve learning framework on COmmonsense knowledge graphs (MICO). MICO generates the commonsense knowledge representation by contextual interaction between entity nodes and relations with multi-alternative contrastive learning. In MICO, the head and tail entities in an (h, r, t) knowledge triple are converted to two relation-aware sequence pairs (a premise and an alternative) in the form of natural language. Semantic representations generated by MICO can benefit the following two tasks by simply comparing the distance score between the representations: 1) zero-shot commonsense question answering task; 2) inductive commonsense knowledge graph completion task. Extensive experiments show the effectiveness of our method. © 2022 Association for Computational Linguistics.",Final,
Aglionby G.; Teufel S.,"Aglionby, Guy (57324841000); Teufel, Simone (55930364000)",57324841000; 55930364000,Faithful Knowledge Graph Explanations in Commonsense Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149439346&partnerID=40&md5=318133655d5b11e8a941545786cb6fb8,"Knowledge graphs are commonly used as sources of information in commonsense question answering, and can also be used to express explanations for the model's answer choice. A common way of incorporating facts from the graph is to encode them separately from the question, and then combine the two representations to select an answer. In this paper, we argue that highly faithful graph-based explanations cannot be extracted from existing models of this type. Such explanations will not include reasoning done by the transformer encoding the question, so will be incomplete. We confirm this theory with a novel proxy measure for faithfulness and propose two architecture changes to address the problem. Our findings suggest a path forward for developing architectures for faithful graph-based explanations. © 2022 Association for Computational Linguistics.",Final,
Zhang M.; Dai R.; Dong M.; He T.,"Zhang, Miao (57226277643); Dai, Rufeng (58130770400); Dong, Ming (57197774629); He, Tingting (7202512806)",57226277643; 58130770400; 57197774629; 7202512806,DRLK: Dynamic Hierarchical Reasoning with Language Model and Knowledge Graph for Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149436116&partnerID=40&md5=6653019f0657490988794bf4203fb00e,"In recent years, Graph Neural Network (GNN) approaches with enhanced knowledge graphs (KG) perform well in question answering (QA) tasks. One critical challenge is how to effectively utilize interactions between the QA context and KG. However, existing work only adopts the identical QA context representation to interact with multiple layers of KG, which results in a restricted interaction. In this paper, we propose DRLK (Dynamic Hierarchical Reasoning with Language Model and Knowledge Graphs), a novel model that utilizes dynamic hierarchical interactions between the QA context and KG for reasoning. DRLK extracts dynamic hierarchical features in the QA context, and performs inter-layer and intra-layer interactions on each iteration, allowing the KG representation to be grounded with the hierarchical features of the QA context. We conduct extensive experiments on four benchmark datasets in medical QA and commonsense reasoning. The experimental results demonstrate that DRLK achieves state-of-the-art performances on two benchmark datasets and performs competitively on the others. © 2022 Association for Computational Linguistics.",Final,
Zhao Y.; Huang J.; Hu W.; Chen Q.; Qiu X.; Huo C.; Ren W.,"Zhao, Yao (57218795541); Huang, Jiacheng (57203389111); Hu, Wei (57191221527); Chen, Qijin (57222065731); Qiu, Xiaoxia (57438671700); Huo, Chengfu (26436423200); Ren, Weijun (57200656788)",57218795541; 57203389111; 57191221527; 57222065731; 57438671700; 26436423200; 57200656788,Implicit Relation Linking for Question Answering over Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149139681&partnerID=40&md5=6e571ee0ff84cda0c606ba367c532674,"Relation linking (RL) is a vital module in knowledge-based question answering (KBQA) systems. It aims to link the relations expressed in natural language (NL) to the corresponding ones in knowledge graph (KG). Existing methods mainly rely on the textual similarities between NL and KG to build relation links. Due to the ambiguity of NL and the incompleteness of KG, many relations in NL are implicitly expressed, and may not link to a single relation in KG, which challenges the current methods. In this paper, we propose an implicit RL method called ImRL, which links relation phrases in NL to relation paths in KG. To find proper relation paths, we propose a novel path ranking model that aligns not only textual information in the word embedding space but also structural information in the KG embedding space between relation phrases in NL and relation paths in KG. Besides, we leverage a gated mechanism with attention to inject prior knowledge from external paraphrase dictionaries to address the relation phrases with vague meaning. Our experiments on two benchmark and a newly-created datasets show that ImRL significantly outperforms several state-of-the-art methods, especially for implicit RL. © 2022 Association for Computational Linguistics.",Final,
Naseem U.; Bandi A.; Raza S.; Rashid J.; Chakravarthi B.R.,"Naseem, Usman (57212385431); Bandi, Ajay (55386327700); Raza, Shaina (57489139800); Rashid, Junaid (57203222981); Chakravarthi, Bharathi Raja (57201188126)",57212385431; 55386327700; 57489139800; 57203222981; 57201188126,Incorporating Medical Knowledge to Transformer-based Language Models for Medical Dialogue Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149140051&partnerID=40&md5=2cd1f2b15727c8756d45dfb3ebac34e5,"Medical dialogue systems have the potential to assist doctors in expanding access to medical care, improving the quality of patient experiences, and lowering medical expenses. The computational methods are still in their early stages and are not ready for widespread application despite their great potential. Existing transformer-based language models have shown promising results but lack domain-specific knowledge. However, to diagnose like doctors, an automatic medical diagnosis necessitates more stringent requirements for the rationality of the dialogue in the context of relevant knowledge. In this study, we propose a new method that addresses the challenges of medical dialogue generation by incorporating medical knowledge into transformer-based language models. We present a method that leverages an external medical knowledge graph and injects triples as domain knowledge into the utterances. Automatic and human evaluation on a publicly available dataset demonstrates that incorporating medical knowledge outperforms several state-of-the-art baseline methods. © 2022 Association for Computational Linguistics.",Final,
Chen Y.; Liang C.,"Chen, Yangbin (58430870800); Liang, Chunfeng (58031700100)",58430870800; 58031700100,Wish I Can Feel What You Feel: A Neural Approach for Empathetic Response Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149899298&partnerID=40&md5=a7dd5775b31c40aa545d3c491d400e0c,"Expressing empathy is important in everyday conversations, and exploring how empathy arises is crucial in automatic response generation. Most previous approaches consider only a single factor that affects empathy. However, in practice, empathy generation and expression is a very complex and dynamic psychological process. A listener needs to find out events which cause a speaker's emotions (emotion cause extraction), project the events into some experience (knowledge extension), and express empathy in the most appropriate way (communication mechanism). To this end, we propose a novel approach, which integrates the three components - emotion cause, knowledge graph, and communication mechanism for empathetic response generation. Experimental results on the benchmark dataset demonstrate the effectiveness of our method and show that incorporating the key components generates more informative and empathetic responses. © 2022 Association for Computational Linguistics.",Final,
Hao C.; Xie M.; Zhang P.,"Hao, Chuzhan (58130714800); Xie, Minghui (58130714900); Zhang, Peng (55547109921)",58130714800; 58130714900; 55547109921,ACENet: Attention Guided Commonsense Reasoning on Hybrid Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149438152&partnerID=40&md5=1466acf219a4d1af60c4a32adbce5043,"Augmenting pre-trained language models (PLMs) with knowledge graphs (KGs) has demonstrated superior performance on commonsense reasoning. Given a commonsense based QA context (question and multiple choices), existing approaches usually estimate the plausibility of candidate choices separately based on their respective retrieved KGs, without considering the interference among different choices. In this paper, we propose an Attention guided Commonsense rEasoning Network (ACENet) to endow the neural network with the capability of integrating hybrid knowledge. Specifically, our model applies the multilayer interaction of answer choices to continually strengthen correct choice information and guide the message passing of GNN. In addition, we also design a mix attention mechanism of nodes and edges to iteratively select supporting evidence on hybrid knowledge graph. Experimental results demonstrate the effectiveness of our proposed model through considerable performance gains across CommonsenseQA and OpenbookQA datasets. © 2022 Association for Computational Linguistics.",Final,
Hu Y.; Xu W.; Liu Q.; Wang L.; Wu S.,"Hu, Yaxuan (58170971900); Xu, Weizhi (57222313234); Liu, Qiang (56818103100); Wang, Liping (57222901741); Wu, Shu (36245362600)",58170971900; 57222313234; 56818103100; 57222901741; 36245362600,Can Pretrained Language Models Reason on Sparse Commonsense Knowledge Graph?,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151665091&doi=10.1109%2fICCC56324.2022.10065877&partnerID=40&md5=50895203e4fd209ef0c8ba8dc4452e44,"Commonsense knowledge is the knowledge shared by most humans, which is always stored in commonsense knowledge graph (CKG) as triplets. In this paper, we focus on the task of CKG competition, whose target is to predict the tail (head) target given the head (tail) entity and the relation. Most existing works employ the graph-based models, which aggregate information from neighboring entities on CKG. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, the semantic relations between head and tail entities are neglected. Secondly, due to the sparsity of CKG, they rely on the graph densification that it will bring unexpected noises. To solve these problems, we propose a unified framework for COmmonSense knowledge graph completion based on BERT, namely COS-BERT. Firstly, we transfer each triplet into a natural sentence. Then, we fine-tune the pretrained language model using the transformed sentences. Finally, we rank the candidates based on the output representation of sentences. Furthermore, we add a pre-filter to obtain a subset of candidates on the inference stage to save unnecessary computation costs. Comprehensive experiments have demonstrated the superiority of COS-BERT over the state-of-the-arts.  © 2022 IEEE.",Final,
Wu G.; Lu Z.; Miao Z.; Zhuo X.; Zhang Z.,"Wu, Gongqing (8363712000); Lu, Zhenya (58086492400); Miao, Zhuochun (58111309200); Zhuo, Xingrui (57462717500); Zhang, Zan (56050102400)",8363712000; 58086492400; 58111309200; 57462717500; 56050102400,Label Enhanced Event Detection with Collective Knowledge and Heterogeneous Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148540241&doi=10.1109%2fICKG55886.2022.00046&partnerID=40&md5=97288052bb4154be4ec756168eb9a18c,"Event Detection (ED) aims to recognize instances of specified types of event triggers in text. Existing graph neural network-based models have achieved promising progress to alleviate this problem by capturing different orders of syntactic information, but they are limited by two issues. First, the long-range syntactic information between words is not fully exploited. Second, they ignore the semantic information provided by dependency labels which provide linguistic knowledge that is useful to ED. As a result, we proposed a label-enhanced dense graph convolutional network that employs dense connectivity and Graph Transformer Networks (GTN) to learn a flexible selection of edge types and composite relations between the words. Each layer can make use of the collective knowledge of dense blocks in order to model syntactic dependencies over long distances through dense connectivity. The proposed model achieves state-of-the-art performance for ED on common datasets after extensive experiments are conducted to show its advantages.  © 2022 IEEE.",Final,
Zhang D.; Huang L.; Ma T.; Xue H.,"Zhang, Dongjie (57226111313); Huang, Longtao (37121905700); Ma, Ting (58138220500); Xue, Hui (57209881434)",57226111313; 37121905700; 58138220500; 57209881434,Multimodal Knowledge Learning for Named Entity Disambiguation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149819536&partnerID=40&md5=ca8bdbe065dd960a89b1d0c6e1a55a75,"With the popularity of online social media, massive-scale multimodal information has brought new challenges to traditional Named Entity Disambiguation (NED) tasks. Recently, Multimodal Named Entity Disambiguation (MNED) has been proposed to link ambiguous mentions with the textual and visual contexts to a predefined knowledge graph. Existing attempts usually perform MNED by annotating multimodal mentions and adding multimodal features to traditional NED models. However, these studies may suffer from 1) failing to model multimodal information at the knowledge level, and 2) lacking multimodal annotation data against the large-scale unlabeled corpus. In this paper, we explore a pioneer study on leveraging multimodal knowledge learning to address the MNED task. Specifically, we first harvest multimodal knowledge in the Meta-Learning way, which is much easier than collecting ambiguous mention corpus. Then we design a knowledge-guided transfer learning strategy to extract unified representation from different modalities. Finally, we propose an Interactive Multimodal Learning Network (IMN) to fully utilize the multimodal information on both the mention and knowledge sides. Extensive experiments conducted on two public MNED datasets demonstrate that the proposed method achieves improvements over the state-of-the-art multimodal methods. © 2022 Association for Computational Linguistics.",Final,
Singh S.; Aji A.F.; Singh G.; Christodoulopoulos C.,"Singh, Siffi (58090881300); Aji, Alham Fikri (58583850200); Singh, Gaurav (57244193900); Christodoulopoulos, Christos (24490919800)",58090881300; 58583850200; 57244193900; 24490919800,REDTab: A Relation Extraction Dataset for Knowledge Extraction from Web Tables,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146122209&partnerID=40&md5=791db4a7ce44c9cacd974ce453c43f02,"Relational web-tables are significant sources of structural information that are widely used for relation extraction and population of facts into knowledge graphs. To transform the web-table data into knowledge, we need to identify the relations that exist between column pairs. Currently, there are only a handful of publicly available datasets with relations annotated against natural web-tables. Most datasets are constructed using synthetic tables that lack valuable metadata information, or are limited in size to be considered as a challenging evaluation set. In this paper, we present REDTab, the largest natural-table relation extraction dataset. We have annotated ~9K tables and ~22K column pairs using crowd sourced annotators from MTurk, which has 50x larger number of column pairs than the existing human-annotated benchmark. Our test set is specially designed to be challenging as observed in our experiment results using TaBERT. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Zhang X.; Bosselut A.; Yasunaga M.; Ren H.; Liang P.; Manning C.D.; Leskovec J.,"Zhang, Xikun (57221160022); Bosselut, Antoine (57193225759); Yasunaga, Michihiro (57203242413); Ren, Hongyu (57207374365); Liang, Percy (56646712700); Manning, Christopher D. (35280197500); Leskovec, Jure (12241436100)",57221160022; 57193225759; 57203242413; 57207374365; 56646712700; 35280197500; 12241436100,GREASELM: GRAPH REASONING ENHANCED LANGUAGE MODELS FOR QUESTION ANSWERING,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150365378&partnerID=40&md5=5edaf0f6ac6005f51624e151ccdcecb0,"Answering complex questions about textual narratives requires reasoning over both stated context and the world knowledge that underlies it. However, pretrained language models (LM), the foundation of most modern QA systems, do not robustly represent latent relationships between concepts, which is necessary for reasoning. While knowledge graphs (KG) are often used to augment LMs with structured representations of world knowledge, it remains an open question how to effectively fuse and reason over the KG representations and the language context, which provides situational constraints and nuances. In this work, we propose GREASELM, a new model that fuses encoded representations from pretrained LMs and graph neural networks over multiple layers of modality interaction operations. Information from both modalities propagates to the other, allowing language context representations to be grounded by structured world knowledge, and allowing linguistic nuances (e.g., negation, hedging) in the context to inform the graph representations of knowledge. Our results on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMLE) domains demonstrate that GREASELM can more reliably answer questions that require reasoning over both situational constraints and structured knowledge, even outperforming models 8× larger. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.",Final,
Kwapong B.; Sen A.; Fletcher K.K.,"Kwapong, Benjamin (57209601251); Sen, Amartya (56732361700); Fletcher, Kenneth K. (50861085700)",57209601251; 56732361700; 50861085700,ELECTRA-KG: A Transformer-Knowledge Graph Recommender System,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146665127&doi=10.1007%2f978-3-031-23515-3_5&partnerID=40&md5=15f4638f34608689767ef63bf1bd87dd,"Knowledge graphs (KGs) are becoming popular in recommender systems in recent times because of the wealth of side information they provide. Many researchers rely on KGs to help resolve the issues of cold start, diversity, and explainability in recommendations. However, the existing approaches usually ignore entity descriptions, which are essential in providing content information for entities in KGs. In this work, we propose a contextual language model for KG completion known as ELECTRA-KG (Efficiently Learning an Encoder that Classifies Token Replacements Accurately). We formulate the recommendation task as a KG link prediction task where we have an incomplete knowledge graph and we use state-of-the-art approaches to complete it. We do this by identifying missing facts among entities from our test data. To evaluate and validate our method, we perform a couple of experiments. First, we run experiments to demonstrate how well our model compares to state-of-the-art KG embedding models. Second, we run further experiments with our model on the tag recommendation task and compare our results to existing baselines. Our results show that our model outperforms the existing baselines on the tag recommendation task. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Li Y.; Yu K.; Huang X.; Zhang Y.,"Li, Yuling (57203532541); Yu, Kui (36869285500); Huang, Xiaoling (57202150886); Zhang, Yuhong (36601706500)",57203532541; 36869285500; 57202150886; 36601706500,Learning Inter-Entity Interaction for Few-Shot Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149436521&partnerID=40&md5=886e425176b8ee54313fea405c5a41c7,"Few-shot knowledge graph completion (FKGC) aims to infer unknown fact triples of a relation using its few-shot reference entity pairs. Recent FKGC studies focus on learning semantic representations of entity pairs by separately encoding the neighborhoods of head and tail entities. Such practice, however, ignores the inter-entity interaction, resulting in low-discrimination representations for entity pairs, especially when these entity pairs are associated with 1-to-N, N-to-1, and N-to-N relations. To address this issue, this paper proposes a novel FKGC model, named Cross-Interaction Attention Network (CIAN) to investigate the inter-entity interaction between head and tail entities. Specifically, we first explore the interactions within entities by computing the attention between the task relation and each entity neighbor, and then model the interactions between head and tail entities by letting an entity to attend to the neighborhood of its paired entity. In this way, CIAN can figure out the relevant semantics between head and tail entities, thereby generating more discriminative representations for entity pairs. Extensive experiments on two public datasets show that CIAN outperforms several state-of-the-art methods. The source code is available at https://github.com/cjlyl/FKGC-CIAN. © 2022 Association for Computational Linguistics.",Final,
Xiao H.; Liu X.; Song Y.; Wong G.Y.; See S.,"Xiao, Huiru (57209221787); Liu, Xin (57206739249); Song, Yangqiu (14039604300); Wong, Ginny Y. (57938989500); See, Simon (7004029208)",57209221787; 57206739249; 14039604300; 57938989500; 7004029208,Complex Hyperbolic Knowledge Graph Embeddings with Fast Fourier Transform,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149437153&partnerID=40&md5=2526afff0f636f2103b07aa97c8c904a,"The choice of geometric space for knowledge graph (KG) embeddings can have significant effects on the performance of KG completion tasks. The hyperbolic geometry has been shown to capture the hierarchical patterns due to its tree-like metrics, which addressed the limitations of the Euclidean embedding models. Recent explorations of the complex hyperbolic geometry further improved the hyperbolic embeddings for capturing a variety of hierarchical structures. However, the performance of the hyperbolic KG embedding models for non-transitive relations is still unpromising, while the complex hyperbolic embeddings do not deal with multi-relations. This paper aims to utilize the representation capacity of the complex hyperbolic geometry in multi-relational KG embeddings. To apply the geometric transformations which account for different relations and the attention mechanism in the complex hyperbolic space, we propose to use the fast Fourier transform (FFT) as the conversion between the real and complex hyperbolic space. Constructing the attention-based transformations in the complex space is very challenging, while the proposed Fourier transform-based complex hyperbolic approaches provide a simple and effective solution. Experimental results show that our methods outperform the baselines, including the Euclidean and the real hyperbolic embedding models. © 2022 Association for Computational Linguistics.",Final,
Silecchia S.; Vezzani F.; Di Nunzio G.M.,"Silecchia, Sara (58055857300); Vezzani, Federica (57197778794); Di Nunzio, Giorgio Maria (57210368958)",58055857300; 57197778794; 57210368958,Knowledge Representation and Language Simplification of Human Rights,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146046004&partnerID=40&md5=f042c3f89bab2e043e58fceac97161ae,"In this paper, we propose the description of a very recent interdisciplinary project aiming at analysing both the conceptual and linguistic dimensions of human rights terminology. This analysis will result in the form of a new knowledge-based multilingual terminological resource which is designed in order to meet the FAIR principles for Open Science and will serve, in the future, as a prototype for the development of a new software for the simplified rewriting of international legal texts relating to human rights, in order to facilitate their comprehension for non-expert people. Given the early stage of the project, we will focus on the description of its rationale, the planned workflow, and the theoretical approach which will be adopted to achieve the main goal of this ambitious research project. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Tuan Y.-L.; Beygi S.; Fazel-Zarandi M.; Gao Q.; Cervone A.; Wang W.Y.,"Tuan, Yi-Lin (57204047867); Beygi, Sajjad (57456658800); Fazel-Zarandi, Maryam (57220399478); Gao, Qiaozi (57155640200); Cervone, Alessandra (57140266500); Wang, William Yang (57233559700)",57204047867; 57456658800; 57220399478; 57155640200; 57140266500; 57233559700,Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue Systems,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149112828&partnerID=40&md5=ec6a3b09159d66d8df9e0ca6d4f0ba2b,"Users interacting with voice assistants today need to phrase their requests in a very specific manner to elicit an appropriate response. This limits the user experience, and is partly due to the lack of reasoning capabilities of dialogue platforms and the hand-crafted rules that require extensive labor. One possible way to improve user experience and relieve the manual efforts of designers is to build an end-to-end dialogue system that can do reasoning itself while perceiving user's utterances. In this work, we propose a novel method to incorporate the knowledge reasoning capability into dialogue systems in a more scalable and generalizable manner. Our proposed method allows a single transformer model to directly walk on a large-scale knowledge graph to generate responses. To the best of our knowledge, this is the first work to have transformer models generate responses by reasoning over differentiable knowledge graphs. We investigate the reasoning abilities of the proposed method on both task-oriented and domain-specific chitchat dialogues. Empirical results show that this method can effectively and efficiently incorporate a knowledge graph into a dialogue system with fully-interpretable reasoning paths. © 2022 Association for Computational Linguistics.",Final,
Wang Z.; Du H.; Yao Q.; Li X.,"Wang, Zhen (57219048884); Du, Haotong (57866047700); Yao, Quanming (57002177700); Li, Xuelong (57218666474)",57219048884; 57866047700; 57002177700; 57218666474,Search to Pass Messages for Temporal Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149866184&partnerID=40&md5=622f7149d4a33f6297a0766edbe3740f,"Completing missing facts is a fundamental task for temporal knowledge graphs (TKGs). Recently, graph neural network (GNN) based methods, which can simultaneously explore topological and temporal information, have become the state-of-the-art (SOTA) to complete TKGs. However, these studies are based on hand-designed architectures and fail to explore the diverse topological and temporal properties of TKG. To address this issue, we propose to use neural architecture search (NAS) to design data-specific message passing architecture for TKG completion. In particular, we develop a generalized framework to explore topological and temporal information in TKGs. Based on this framework, we design an expressive search space to fully capture various properties of different TKGs. Meanwhile, we adopt a search algorithm, which trains a supernet structure by sampling single path for efficient search with less cost. We further conduct extensive experiments on three benchmark datasets. The results show that the searched architectures by our method achieve the SOTA performances. Besides, the searched models can also implicitly reveal diverse properties in different TKGs. Our code is released in https://github.com/striderdu/SPA. © 2022 Association for Computational Linguistics.",Final,
Li M.; Chen J.; Mensah S.; Aletras N.; Yang X.; Ye Y.,"Li, Mingchen (57219493264); Chen, Junfan (57214236442); Mensah, Samuel (57191418149); Aletras, Nikolaos (55418795600); Yang, Xiulong (57219508020); Ye, Yang (57219508930)",57219493264; 57214236442; 57191418149; 55418795600; 57219508020; 57219508930,A Hierarchical N-Gram Framework for Zero-Shot Link Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149851526&partnerID=40&md5=68936c5f1642b21997a38f59a30ffc91,"Knowledge graphs typically contain a large number of entities but often cover only a fraction of all relations between them (i.e., incompleteness). Zero-shot link prediction (ZSLP) is a popular way to tackle the problem by automatically identifying unobserved relations between entities. Most recent approaches use textual features of relations (e.g., surface names or textual descriptions) as auxiliary information to improve the encoded representation. These methods lack robustness as they are bound to support only tokens from a fixed vocabulary and are unable to model out-of-vocabulary (OOV) words. Subword units such as character n-grams have the capability of generating more expressive representations for OOV words. Hence, in this paper, we propose a Hierarchical N-gram framework for Zero-Shot Link Prediction (HNZSLP) that leverages character n-gram information for ZSLP. Our approach works by first constructing a hierarchical n-gram graph from the surface name of relations. Subsequently, a new Transformer-based network models the hierarchical n-gram graph to learn a relation embedding for ZSLP. Experimental results show that our proposed HNZSLP method achieves state-of-the-art performance on two standard ZSLP datasets. © 2022 Association for Computational Linguistics.",Final,
Sen P.; de Carvalho B.W.S.R.; Abdelaziz I.; Kapanipathi P.; Roukos S.; Gray A.,"Sen, Prithviraj (57201526762); de Carvalho, Breno W.S.R. (57274957600); Abdelaziz, Ibrahim (56997333500); Kapanipathi, Pavan (36623952200); Roukos, Salim (6602206925); Gray, Alexander (57213004841)",57201526762; 57274957600; 56997333500; 36623952200; 6602206925; 57213004841,Logical Neural Networks for Knowledge Base Completion with Embeddings & Rules,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441496&partnerID=40&md5=8a588a6b15b7bd28cd8b52ebd178b256,"Knowledge base completion (KBC) has benefitted greatly by learning explainable rules in an human-interpretable dialect such as first-order logic. Rule-based KBC has so far, mainly focussed on learning one of two types of rules: conjunction-of-disjunctions and disjunction-of-conjunctions. We qualitatively show, via examples, that one of these has an advantage over the other when it comes to achieving high quality KBC. To the best of our knowledge, we are the first to propose learning both kinds of rules within a common framework. To this end, we propose to utilize logical neural networks (LNN) (Riegel et al., 2020), a powerful neuro-symbolic AI framework that can express both kinds of rules and learn these end-to-end using gradient-based optimization. Our in-depth experiments show that our LNN-based approach to learning rules for KBC leads to roughly 10% relative improvements, if not more, over SotA rule-based KBC methods. Moreover, by showing how to combine our proposed methods with knowledge graph embeddings we further achieve additional 7.5% relative improvement. © 2022 Association for Computational Linguistics.",Final,
Lin Z.; Zhang Z.; Wang M.; Shi Y.; Wu X.; Zheng Y.,"Lin, Zhenxi (57222054366); Zhang, Ziheng (57220158275); Wang, Meng (56430062700); Shi, Yinghui (57885662300); Wu, Xian (57209291701); Zheng, Yefeng (8062522600)",57222054366; 57220158275; 56430062700; 57885662300; 57209291701; 8062522600,Multi-modal Contrastive Representation Learning for Entity Alignment,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146546314&partnerID=40&md5=91945ca89f14f214f0ccb0a8cece335e,"Multi-modal entity alignment aims to identify equivalent entities between two different multi-modal knowledge graphs, which consist of structural triples and images associated with entities. Most previous works focus on how to utilize and encode information from different modalities, while it is not trivial to leverage multi-modal knowledge in entity alignment because of the modality heterogeneity. In this paper, we propose MCLEA, a Multi-modal Contrastive Learning based Entity Alignment model, to obtain effective joint representations for multi-modal entity alignment. Different from previous works, MCLEA considers task-oriented modality and models the inter-modal relationships for each entity representation. In particular, MCLEA firstly learns multiple individual representations from multiple modalities, and then performs contrastive learning to jointly model intra-modal and inter-modal interactions. Extensive experimental results show that MCLEA outperforms state-of-the-art baselines on public datasets under both supervised and unsupervised settings. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Zhang X.; Yang Q.; Xu D.,"Zhang, Xuanyu (57216622285); Yang, Qing (57224474365); Xu, Dongliang (57224477954)",57216622285; 57224474365; 57224477954,TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149882140&partnerID=40&md5=4c19832bbae65dc5fded9a6719676172,"Knowledge graph embedding (KGE) aims to learn continuous vector representations of relations and entities in knowledge graph (KG). Recently, transition-based KGE methods have become popular and achieved promising performance. However, scoring patterns like TransE are not suitable for complex scenarios where the same entity pair has different relations. Although some models attempt to employ entity-relation interaction or projection to improve entity representation for one-to-many/many-to-one/many-to-many complex relations, they still continue the traditional scoring pattern, where only a single relation vector in the relation part is used to translate the head entity to the tail entity or their variants. And recent research shows that entity representation only needs to consider entities and their interactions to achieve better performance. Thus, in this paper, we propose a novel transition-based method, TranS, for KGE. The single relation vector of the relation part in the traditional scoring pattern is replaced by the synthetic relation representation with entity-relation interactions to solve these issues. And the entity part still retains its independence through entity-entity interactions. Experiments on a large KG dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results. © 2022 Association for Computational Linguistics.",Final,
Widjaja H.; Gashteovski K.; Rim W.B.; Liu P.; Malon C.; Ruffinelli D.; Lawrence C.; Neubig G.,"Widjaja, Haris (57865836400); Gashteovski, Kiril (57210585423); Rim, Wiem Ben (57843047500); Liu, Pengfei (57001789500); Malon, Christopher (6506315347); Ruffinelli, Daniel (57195074131); Lawrence, Carolin (57204284641); Neubig, Graham (36141167700)",57865836400; 57210585423; 57843047500; 57001789500; 6506315347; 57195074131; 57204284641; 36141167700,KGxBoard: Explainable and Interactive Leaderboard for Evaluation of Knowledge Graph Completion Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149632718&partnerID=40&md5=b6348ba88af647191c0c00d1b81c4249,"Knowledge Graphs (KGs) store information in the form of (head, predicate, tail)-triples. To augment KGs with new knowledge, researchers proposed models for KG Completion (KGC) tasks such as link prediction; i.e., answering (h; p; ?) or (?; p; t) queries. Such models are usually evaluated with averaged metrics on a held-out test set. While useful for tracking progress, averaged single-score metrics cannot reveal what exactly a model has learned-or failed to learn. To address this issue, we propose KGxBoard: an interactive framework for performing fine-grained evaluation on meaningful subsets of the data, each of which tests individual and interpretable capabilities of a KGC model. In our experiments, we highlight the findings that we discovered with the use of KGxBoard, which would have been impossible to detect with standard averaged single-score metrics. © 2022 Association for Computational Linguistics.",Final,
Chakrabarti S.; Singh H.; Lohiya S.; Jain P.; Mausam,"Chakrabarti, Soumen (58570163200); Singh, Harkanwar (57223899797); Lohiya, Shubham (58130550200); Jain, Prachi (7402520556); Mausam (55963402300)",58570163200; 57223899797; 58130550200; 7402520556; 55963402300,Joint Completion and Alignment of Multilingual Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149435242&partnerID=40&md5=34dfe40b80eb1e5ef08aa34a1508afa6,"Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph (KG). Multilingual KGs associate entities and relations with surface forms written in different languages. An entity or relation may be associated with distinct IDs in different KGs, necessitating entity alignment (EA) and relation alignment (RA). Many effective algorithms have been proposed for completion and alignment as separate tasks. Here we show that these tasks are synergistic and best solved together. Our multitask approach starts with a state-of-the-art KG embedding scheme, but adds a novel relation representation based on sets of embeddings of (subject, object) entity pairs. This representation leads to a new relation alignment loss term based on a maximal bipartite matching between two sets of embedding vectors. This loss is combined with traditional KGC loss and optionally, losses based on text embeddings of entity (and relation) names. In experiments over KGs in seven languages, we find that our system achieves large improvements in KGC compared to a strong completion model that combines known facts in all languages. It also outperforms strong EA and RA baselines, underscoring the value of joint alignment and completion. © 2022 Association for Computational Linguistics.",Final,
Mavromatis C.; Karypis G.,"Mavromatis, Costas (57220154088); Karypis, George (15069396800)",57220154088; 15069396800,ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149884958&partnerID=40&md5=314c49ddf95429e298857a0a518a4d34,"Knowledge Graph Question Answering (KGQA) involves retrieving entities as answers from a Knowledge Graph (KG) using natural language queries. The challenge is to learn to reason over question-relevant KG facts that traverse KG entities and lead to the question answers. To facilitate reasoning; the question is decoded into instructions, which are dense question representations used to guide the KG traversals. However, if the derived instructions do not exactly match the underlying KG information, they may lead to reasoning under irrelevant context. Our method, termed REAREV, introduces a new way to KGQA reasoning with respect to both instruction decoding and execution. To improve instruction decoding, we perform reasoning in an adaptive manner, where KG-aware information is used to iteratively update the initial instructions. To improve instruction execution, we emulate breadth-first search (BFS) with graph neural networks (GNNs). The BFS strategy treats the instructions as a set and allows our method to decide on their execution order on the fly. Experimental results on three KGQA benchmarks demonstrate the REAREV's effectiveness compared with previous state-of-the-art, especially when the KG is incomplete or when we tackle complex questions. Our code is publicly available at https://github.com/cmavro/ReaRev_KGQA. © 2022 Association for Computational Linguistics.",Final,
Chen Y.; Zhang Y.; Huang Y.,"Chen, Yubo (57935192700); Zhang, Yunqi (58067011400); Huang, Yongfeng (14627673100)",57935192700; 58067011400; 14627673100,Learning Reasoning Patterns for Relational Triple Extraction with Mutual Generation of Text and Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146501713&partnerID=40&md5=1cb931150fb88ae61d1bb7f85e2135d4,"Relational triple extraction is a critical task for constructing knowledge graphs. Existing methods focused on learning text patterns from explicit relational mentions. However, they usually suffered from ignoring relational reasoning patterns, thus failed to extract the implicitly implied triples. Fortunately, the graph structure of a sentence's relational triples can help find multi-hop reasoning paths. Moreover, the type inference logic through the paths can be captured with the sentence's supplementary relational expressions that represent the real-world conceptual meanings of the paths' composite relations. In this paper, we propose a unified framework to learn the relational reasoning patterns for this task. To identify multi-hop reasoning paths, we construct a relational graph from the sentence (text-to-graph generation) and apply multi-layer graph convolutions to it. To capture the relation type inference logic of the paths, we propose to understand the unlabeled conceptual expressions by reconstructing the sentence from the relational graph (graph-to-text generation) in a self-supervised manner. Experimental results on several benchmark datasets demonstrate the effectiveness of our method. © 2022 Association for Computational Linguistics.",Final,
Ye H.; Zhang N.; Chen H.; Chen H.,"Ye, Hongbin (57221148832); Zhang, Ningyu (55923601900); Chen, Hui (57221150709); Chen, Huajun (35268022500)",57221148832; 55923601900; 57221150709; 35268022500,Generative Knowledge Graph Construction: A Review,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149440678&partnerID=40&md5=1e8e105c6bb7a37f953d56e5c80e07b9,"Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future. © 2022 Association for Computational Linguistics.",Final,
Li Z.; Hou Z.; Guan S.; Jin X.; Peng W.; Bai L.; Lyu Y.; Li W.; Guo J.; Cheng X.,"Li, Zixuan (57201739412); Hou, Zhongni (57437579600); Guan, Saiping (57196080482); Jin, Xiaolong (16417309500); Peng, Weihua (57220993199); Bai, Long (57219876463); Lyu, Yajuan (57192308367); Li, Wei (57221638294); Guo, Jiafeng (24174196100); Cheng, Xueqi (55855927900)",57201739412; 57437579600; 57196080482; 16417309500; 57220993199; 57219876463; 57192308367; 57221638294; 24174196100; 55855927900,HiSMatch: Historical Structure Matching based Temporal Knowledge Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149890957&partnerID=40&md5=e370e56b7a0f995f554233f8180afe2f,"A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective timestamps, which adopts quadruples in the form of (subject, relation, object, timestamp) to describe dynamic facts. TKG reasoning has facilitated many real-world applications via answering such queries as (query entity, query relation, ?, future timestamp) about future. This is actually a matching task between a query and candidate entities based on their historical structures, which reflect behavioral trends of the entities at different timestamps. In addition, recent KGs provide background knowledge of all the entities, which is also helpful for the matching. Thus, in this paper, we propose the Historical Structure Matching (HiSMatch) model. It applies two structure encoders to capture the semantic information contained in the historical structures of the query and candidate entities. Besides, it adopts another encoder to integrate the background knowledge into the model. TKG reasoning experiments on six benchmark datasets demonstrate the significant improvement of the proposed HiSMatch model, with up to 5.6% performance improvement in MRR, compared to the state-of-the-art baselines. © 2022 Association for Computational Linguistics.",Final,
Zhu R.; Luo X.; Ma M.; Wang P.,"Zhu, Renbo (57219925742); Luo, Xukun (57848566300); Ma, Meng (23005645600); Wang, Ping (55605729700)",57219925742; 57848566300; 23005645600; 55605729700,Adaptive Graph Convolutional Network for Knowledge Graph Entity Alignment,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149856424&partnerID=40&md5=078fa7ba6bbfa5edc40609a6382f70c0,"Entity alignment (EA) aims to identify equivalent entities from different Knowledge Graphs (KGs), which is a fundamental task for integrating KGs. Throughout its development, Graph Convolutional Network (GCN) has become one of the mainstream methods for EA. The key idea that GCN works in EA is that entities with similar neighbor structures are highly likely to be aligned. However, the noisy neighbors of entities transfer invalid information, drown out equivalent information, lead to inaccurate entity embeddings, and finally reduce the performance of EA. In this paper, we propose a lightweight framework with no training parameters for both supervised and unsupervised EA. Based on the Sinkhorn algorithm, we design a reliability measure for pseudo equivalent entities and propose Adaptive Graph Convolutional Network to deal with neighbor noises in GCN. During the training, the network dynamically updates the adaptive weights of relation triples to weaken the propagation of noises. Extensive experiments on benchmark datasets demonstrate that our framework outperforms the state-of-the-art methods in both supervised and unsupervised settings. © 2022 Association for Computational Linguistics.",Final,
Ju M.; Yu W.; Zhao T.; Zhang C.; Ye Y.,"Ju, Mingxuan (57207571149); Yu, Wenhao (57209227271); Zhao, Tong (57207568082); Zhang, Chuxu (55879440900); Ye, Yanfang (57323577100)",57207571149; 57209227271; 57207568082; 55879440900; 57323577100,GRAPE: Knowledge Graph Enhanced Passage Reader for Open-domain Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149648352&partnerID=40&md5=57842b9c0e44d10d4a136cd7ccc9bde5,"A common thread of open-domain question answering (QA) models employs a retriever-reader pipeline that first retrieves a handful of relevant passages from Wikipedia and then peruses the passages to produce an answer. However, even state-of-the-art readers fail to capture the complex relationships between entities appearing in questions and retrieved passages, leading to answers that contradict the facts. In light of this, we propose a novel knowledge Graph enhanced passage reader, namely GRAPE, to improve the reader performance for open-domain QA. Specifically, for each pair of question and retrieved passage, we first construct a localized bipartite graph, attributed to entity embeddings extracted from the intermediate layer of the reader model. Then, a graph neural network learns relational knowledge while fusing graph and contextual representations into the hidden states of the reader model. Experiments on three open-domain QA benchmarks show GRAPE can improve the state-of-the-art performance by up to 2.2 exact match score with a negligible overhead increase, with the same retriever and retrieved passages. Our code is publicly available at https://github.com/jumxglhf/GRAPE. © 2022 Association for Computational Linguistics.",Final,
Zeng S.; Yuan Z.; Yu S.,"Zeng, Sihang (57221784472); Yuan, Zheng (57218628572); Yu, Sheng (56324605100)",57221784472; 57218628572; 56324605100,Automatic Biomedical Term Clustering by Learning Fine-grained Term Representations,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149121494&partnerID=40&md5=3c91e461ae2731e0394d5609c7801d73,"Term clustering is important in biomedical knowledge graph construction. Using similarities between terms embedding is helpful for term clustering. State-of-the-art term embeddings leverage pretrained language models to encode terms, and use synonyms and relation knowledge from knowledge graphs to guide contrastive learning. These embeddings provide close embeddings for terms belonging to the same concept. However, from our probing experiments, these embeddings are not sensitive to minor textual differences which leads to failure for biomedical term clustering. To alleviate this problem, we adjust the sampling strategy in pretraining term embeddings by providing dynamic hard positive and negative samples during contrastive learning to learn fine-grained representations which result in better biomedical term clustering. We name our proposed method as CODER++, and it has been applied in clustering biomedical concepts in the newly released Biomedical Knowledge Graph named BIOS. © 2022 Association for Computational Linguistics.",Final,
Yang D.; Qing P.; Li Y.; Lu H.; Lin X.,"Yang, Dong (58374204200); Qing, Peijun (57959198500); Li, Yang (58446726300); Lu, Haonan (56963042500); Lin, Xiaodong (56760471400)",58374204200; 57959198500; 58446726300; 56963042500; 56760471400,GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149443666&partnerID=40&md5=ae609063f2b7e741c85723025f51b8e8,"Embedding knowledge graphs (KGs) for multi-hop logical reasoning is a challenging problem due to massive and complicated structures in many KGs. Recently, many promising works projected entities and queries into a geometric space to efficiently find answers. However, it remains challenging to model the negation and union operator. The negation operator has no strict boundaries, which generates overlapped embeddings and leads to obtaining ambiguous answers. An additional limitation is that the union operator is non-closure, which undermines the model to handle a series of union operators. To address these problems, we propose a novel probabilistic embedding model, namely Gamma Embeddings (GammaE), for encoding entities and queries to answer different types of FOL queries on KGs. We utilize the linear property and strong boundary support of the Gamma distribution to capture more features of entities and queries, which dramatically reduces model uncertainty. Furthermore, GammaE implements the Gamma mixture method to design the closed union operator. The performance of GammaE is validated on three large logical query datasets. Experimental results show that GammaE significantly outperforms state-of-the-art models on public benchmarks. © 2022 Association for Computational Linguistics.",Final,
An Y.; Greenberg J.; Hu X.; Kalinowski A.; Fang X.; Zhao X.; McClellan S.; Uribe-Romo F.J.; Langlois K.; Furst J.; Gomez-Gualdron D.A.; Fajardo-Rojas F.; Ardila K.; Saikin S.K.; Harper C.A.; Daniel R.,"An, Yuan (35316861700); Greenberg, Jane (7402354070); Hu, Xiaohua (57730482300); Kalinowski, Alex (57221141771); Fang, Xiao (57986073400); Zhao, Xintong (57222100813); McClellan, Scott (57282341100); Uribe-Romo, Fernando J. (14038466600); Langlois, Kyle (57814129900); Furst, Jacob (57815105800); Gomez-Gualdron, Diego A. (22978765500); Fajardo-Rojas, Fernando (57218253996); Ardila, Katherine (57814527300); Saikin, Semion K. (6602826159); Harper, Corey A. (57202287209); Daniel, Ron (57191692568)",35316861700; 7402354070; 57730482300; 57221141771; 57986073400; 57222100813; 57282341100; 14038466600; 57814129900; 57815105800; 22978765500; 57218253996; 57814527300; 6602826159; 57202287209; 57191692568,Exploring Pre-Trained Language Models to Build Knowledge Graph for Metal-Organic Frameworks (MOFs),-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147906256&doi=10.1109%2fBigData55660.2022.10020568&partnerID=40&md5=3c6a360dbf88757944621f12cb480597,"Building a knowledge graph is a time-consuming and costly process which often applies complex natural language processing (NLP) methods for extracting knowledge graph triples from text corpora. Pre-trained large Language Models (PLM) have emerged as a crucial type of approach that provides readily available knowledge for a range of AI applications. However, it is unclear whether it is feasible to construct domain-specific knowledge graphs from PLMs. Motivated by the capacity of knowledge graphs to accelerate data-driven materials discovery, we explored a set of state-of-the-art pre-trained general-purpose and domain-specific language models to extract knowledge triples for metal-organic frameworks (MOFs). We created a knowledge graph benchmark with 7 relations for 1248 published MOF synonyms. Our experimental results showed that domain-specific PLMs consistently outperformed the general-purpose PLMs for predicting MOF related triples. The overall benchmarking results, however, show that using the present PLMs to create domain-specific knowledge graphs is still far from being practical, motivating the need to develop more capable and knowledgeable pre-trained language models for particular applications in materials science. © 2022 IEEE.",Final,
Chia Y.K.; Bing L.; Aljunied S.M.; Si L.; Poria S.,"Chia, Yew Ken (57216870236); Bing, Lidong (24314897600); Aljunied, Sharifah Mahani (57194444492); Si, Luo (7006717974); Poria, Soujanya (55316592700)",57216870236; 24314897600; 57194444492; 7006717974; 55316592700,A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149443826&partnerID=40&md5=9e853e0a4003fee6e39495786f162624,"Relation extraction has the potential for large-scale knowledge graph construction, but current methods do not consider the qualifier attributes for each relation triplet, such as time, quantity or location. The qualifiers form hyper-relational facts which better capture the rich and complex knowledge graph structure. For example, the relation triplet (Leonard Parker, Educated At, Harvard University) can be factually enriched by including the qualifier (End Time, 1967). Hence, we propose the task of hyper-relational extraction to extract more specific and complete facts from text. To support the task, we construct HyperRED, a large-scale and general-purpose dataset. Existing models cannot perform hyper-relational extraction as it requires a model to consider the interaction between three entities. Hence, we propose CubeRE, a cube-filling model inspired by table-filling approaches and explicitly considers the interaction between relation triplets and qualifiers. To improve model scalability and reduce negative class imbalance, we further propose a cube-pruning method. Our experiments show that CubeRE outperforms strong baselines and reveal possible directions for future research. Our code and data are available at github.com/declare-lab/HyperRED. © 2022 Association for Computational Linguistics.",Final,
Hui B.; Xia T.; Ku W.-S.,"Hui, Bo (57219876568); Xia, Tian (57224878710); Ku, Wei-Shinn (35303076200)",57219876568; 57224878710; 35303076200,A Localized Geometric Method to Match Knowledge in Low-dimensional Hyperbolic Space,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441801&partnerID=40&md5=777224f84b0120bcb540b55011718337,"Matching equivalent entities across Knowledge graphs is a pivotal step for knowledge fusion. Previous approaches usually study the problem in Euclidean space. However, recent works have shown that hyperbolic space has a higher capacity than Euclidean space and hyperbolic embedding can represent the hierarchical structure in a knowledge graph. In this paper, we propose a localized geometric method to find equivalent entities in hyperbolic space. Specifically, we use a hyperbolic neural network to encode the lingual information of entities and the structure of both knowledge graphs into a low-dimensional hyperbolic space. To address the asymmetry of structure on different KGs and the localized nature of relations, we learn an instance-specific geometric mapping function based on rotation to match entity pairs. A contrastive loss function is used to train the model. The experiment verifies the power of low-dimensional hyperbolic space for entity matching and shows that our method outperforms the state of the art by a large margin. © 2022 Association for Computational Linguistics.",Final,
Yang J.; Ying X.; Shi Y.; Tong X.; Wang R.; Chen T.; Xing B.,"Yang, Jinfa (57214872614); Ying, Xianghua (7004495215); Shi, Yongjie (57193810663); Tong, Xin (57205367654); Wang, Ruibin (57470322900); Chen, Taiyan (57658287600); Xing, Bowei (58121794500)",57214872614; 7004495215; 57193810663; 57205367654; 57470322900; 57658287600; 58121794500,Knowledge Graph Embedding by Adaptive Limit Scoring Loss Using Dynamic Weighting Strategy,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146296724&partnerID=40&md5=550491eba079ba275a2243c612f06cfc,"Knowledge graph embedding aims to represent entities and relations as low-dimensional vectors, which is an effective way for predicting missing links in knowledge graphs. Designing a strong and effective loss framework is essential for knowledge graph embedding models to distinguish between correct and incorrect triplets. The classic margin-based ranking loss limits the scores of positive and negative triplets to have a suitable margin. The recently proposed Limit-based Scoring Loss independently limits the range of positive and negative triplet scores. However, these loss frameworks use equal or fixed penalty terms to reduce the scores of positive and negative sample pairs, which is inflexible in optimization. Our intuition is that if a triplet score deviates far from the optimum, it should be emphasized. To this end, we propose Adaptive Limit Scoring Loss, which simply re-weights each triplet to highlight the less-optimized triplet scores. We apply this loss framework to several knowledge graph embedding models such as TransE, TransH and ComplEx. The experimental results on link prediction and triplet classification show that our proposed method has achieved performance on par with the state of the art. © 2022 Association for Computational Linguistics.",Final,
Wang Z.,"Wang, Zhu (57203515076)",57203515076,AMD Results for OAEI 2022,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146423755&partnerID=40&md5=5d40e36481c36d7e9d14b4536f18bebe,"AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching.  © 2022 Copyright for this paper by its authors.",Final,
Bhana N.; Van Zyl T.L.,"Bhana, Nimesh (57797735900); Van Zyl, Terence L. (26532116600)",57797735900; 26532116600,Knowledge Graph Fusion for Language Model Fine-Tuning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151672939&doi=10.1109%2fISCMI56532.2022.10068451&partnerID=40&md5=42176ef63c67d3df5ff2c0db0aaadd0f,"Language Models such as BERT (Bidirectional Encoder Representations from Transformers) have grown in popularity due to their ability to be pre-trained and perform robustly on a wide range of Natural Language Processing tasks. Often seen as an evolution over traditional word embedding techniques, they can produce semantic representations of text, useful for tasks such as semantic similarity. However, state-of-the-art models often have high computational requirements and lack global context or domain knowledge which is required for complete language understanding. To address these limitations, we investigate the benefits of knowledge incorporation into the fine-tuning stages of BERT. An existing K-BERT model, which enriches sentences with triplets from a Knowledge Graph, is adapted for the English language and extended to inject contextually relevant information into sentences. As a side-effect, changes made to K-BERT for accommodating the English language also extend to other word-based languages. Experiments conducted indicate that injected knowledge introduces noise. We see statistically significant improvements for knowledge-driven tasks when this noise is minimised. We show evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant.  © 2022 IEEE.",Final,All Open Access; Green Open Access
Zhao J.; Bai T.; Wei Y.; Wu B.,"Zhao, Jiaqi (57219391133); Bai, Ting (57194901003); Wei, Yuting (57755481200); Wu, Bin (56449782000)",57219391133; 57194901003; 57755481200; 56449782000,PoetryBERT: Pre-training with Sememe Knowledge for Classical Chinese Poetry,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148688121&doi=10.1007%2f978-981-19-8991-9_26&partnerID=40&md5=b1b02d0b060448452208f585b363c744,"Classical Chinese poetry has a history of thousands of years and is a precious cultural heritage of humankind. Compared with the modern Chinese corpus, it is irrecoverable and specially organized, making it difficult to be learned by existing pre-trained language models. Besides, with the thousands of years of development, many words in classical Chinese poetry have changed their meanings or been out of use today, which further limiting the capability of existing pre-trained models to learn the semantics of classical Chinese poetry. To address these challenges, we construct a large-scale sememe knowledge graph of classical Chinese Poetry (SKG-Poetry), which connects the vocabularies in classical Chinese poetry and modern Chinese. By extracting the sememe knowledge from classical Chinese poetry, our model PoetryBERT not only enlarges the irrecoverable pre-training corpus but also enriches the semantics of the vocabularies in classical Chinese poetry, which enables PoetryBERT to be successfully used in downstream tasks. Specifically, we evaluate our model in two tasks in the field of Chinese classical poetry, which are poetry theme classification and poetry-modern Chinese translation. Extensive experiments are conducted on the two tasks to show the effectiveness of sememe knowledge based pre-training model. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Long X.; Zhuang L.; Aodi L.; Wang S.; Li H.,"Long, Xiao (57330719500); Zhuang, Liansheng (16178485300); Aodi, Li (58130530200); Wang, Shafei (56386347700); Li, Houqiang (35956273100)",57330719500; 16178485300; 58130530200; 56386347700; 35956273100,Neural-based Mixture Probabilistic Query Embedding for Answering FOL queries on Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149436040&partnerID=40&md5=58a9d1ae254a59368ce18cb1d94caded,"Query embedding (QE)-which aims to embed entities and first-order logical (FOL) queries in a vector space, has shown great power in answering FOL queries on knowledge graphs (KGs). Existing QE methods divide a complex query into a sequence of mini-queries according to its computation graph and perform logical operations on the answer sets of mini-queries to get answers. However, most of them assume that answer sets satisfy an individual distribution (e.g., Uniform, Beta, or Gaussian), which is often violated in real applications and limit their performance. In this paper, we propose a Neural-based Mixture Probabilistic Query Embedding Model (NMP-QEM) that encodes the answer set of each mini-query as a mixed Gaussian distribution with multiple means and covariance parameters, which can approximate any random distribution arbitrarily well in real KGs. Additionally, to overcome the difficulty in defining the closed solution of negation operation, we introduce neural-based logical operators of projection, intersection and negation for a mixed Gaussian distribution to answer all the FOL queries. Extensive experiments demonstrate that NMP-QEM significantly outperforms existing state-of-the-art methods on benchmark datasets. In NELL995, NMP-QEM achieves a 31% relative improvement over the state-of-the-art. © 2022 Association for Computational Linguistics.",Final,
Wei F.; Nguyen U.T.,"Wei, Feng (57211201021); Nguyen, Uyen Trang (55664212400)",57211201021; 55664212400,An Attention-Based Neural Network Using Human Semantic Knowledge and Its Application to Clickbait Detection,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147130131&doi=10.1109%2fOJCS.2022.3213791&partnerID=40&md5=185dd1987a49618930efc50cfa5f8bab,"Clickbait is a commonly used social engineering technique to carry out phishing attacks, illegitimate marketing, and dissemination of disinformation. As a result, clickbait detection has become a popular research topic in recent years due to the prevalence of clickbait on the web and social media. In this article, we propose a novel attention-based neural network for the task of clickbait detection. To the best of our knowledge, our work is the first that incorporates human semantic knowledge into an artificial neural network, and uses linguistic knowledge graphs to guide attention mechanisms for the clickbait detection task. Extensive experimental results show that the proposed model outperforms existing state-of-the-art clickbait classifiers, even when training data is limited. The proposed model also performs better or comparably to powerful pretrained models, namely, BERT, RoBERTa, and XLNet, while being much more lightweight. Furthermore, we conducted experiments to demonstrate that the use of human semantic knowledge can significantly enhance the performance of pretrained models in the semisupervised domain such as BERT, RoBERTa, and XLNet.  © 2020 IEEE.",Final,All Open Access; Gold Open Access
Dikeoulias I.; Amin S.; Neumann G.,"Dikeoulias, Ioannis (57209223328); Amin, Saadullah (57210371505); Neumann, Günter (7202631822)",57209223328; 57210371505; 7202631822,Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic Representations,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149114224&partnerID=40&md5=bc495855acdb067d50abbefb8489761e,"Temporal knowledge graph completion (TKGC) has become a popular approach for reasoning over the event and temporal knowledge graphs, targeting the completion of knowledge with accurate but missing information. In this context, tensor decomposition has successfully modeled interactions between entities and relations. Their effectiveness in static knowledge graph completion motivates us to introduce Time-LowFER, a family of parameter-efficient and time-aware extensions of the low-rank tensor factorization model LowFER. Noting several limitations in current approaches to represent time, we propose a cycle-aware time-encoding scheme for time features, which is model-agnostic and offers a more generalized representation of time. We implement our methods in a unified temporal knowledge graph embedding framework, focusing on time-sensitive data processing. The experiments show that our proposed methods perform on par or better than the state-of-the-art semantic matching models on two benchmarks. © 2022 Association for Computational Linguistics.",Final,
Yao P.; Renwick T.; Barbosa D.,"Yao, Peiran (57203393167); Renwick, Tobias (57701935500); Barbosa, Denilson (14027953400)",57203393167; 57701935500; 14027953400,WordTies: Measuring Word Associations in Language Models via Constrained Sampling,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149889157&partnerID=40&md5=573ad708302f9764b70a4b76f573bc1d,"Word associations are widely used in psychology to provide insights on how humans perceive and understand concepts. Comparing word associations in language models (LMs) to those generated by human subjects can serve as a proxy to uncover embedded lexical and commonsense knowledge in language models. While much helpful work has been done applying direct metrics, such as cosine similarity, to help understand latent spaces, these metrics are symmetric, while human word associativity is asymmetric. We propose WordTies, an algorithm based on constrained sampling from LMs, which allows an asymmetric measurement of associated words, given a cue word as the input. Comparing to existing methods, word associations found by this method share more overlap with associations provided by humans, and observe the asymmetric property of human associations. To examine possible reasons behind associations, we analyze the knowledge and reasoning behind the word pairings as they are linked to lexical and commonsense knowledge graphs. When the knowledge about the nature of the word pairings is combined with a probability that the LM has learned that information, we have a new way to examine what information is captured in LMs. © 2022 Association for Computational Linguistics.",Final,
Yu W.; Zhu C.; Qin L.; Zhang Z.; Zhao T.; Jiang M.,"Yu, Wenhao (57209227271); Zhu, Chenguang (57210636804); Qin, Lianhui (57220825027); Zhang, Zhihan (57216615600); Zhao, Tong (57207568082); Jiang, Meng (36179647500)",57209227271; 57210636804; 57220825027; 57216615600; 57207568082; 36179647500,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149115674&partnerID=40&md5=10f962a00836c1abaf0207f0223ee00f,"Generative commonsense reasoning (GCR) in natural language is to reason about the commonsense while generating coherent text. Recent years have seen a surge of interest in improving the generation quality of commonsense reasoning tasks. Nevertheless, these approaches have seldom investigated diversity in the GCR tasks, which aims to generate alternative explanations for a real-world situation or predict all possible outcomes. Diversifying GCR is challenging as it expects to generate multiple outputs that are not only semantically different but also grounded in commonsense knowledge. In this paper, we propose MoKGE, a novel method that diversifies the generative reasoning by a mixture of expert (MoE) strategy on commonsense knowledge graphs (KG). A set of knowledge experts seek diverse reasoning on KG to encourage various generation outputs. Empirical experiments demonstrated that MoKGE can significantly improve the diversity while achieving on par performance on accuracy on two GCR benchmarks, based on both automatic and human evaluations. © 2022 Association for Computational Linguistics.",Final,
Ravishankar S.; Thai J.; Abdelaziz I.; Mihindukulasooriya N.; Naseem T.; Kapanipathi P.; Rossiello G.; Fokoue A.,"Ravishankar, Srinivas (57220034443); Thai, June (57350238200); Abdelaziz, Ibrahim (56997333500); Mihindukulasooriya, Nandana (56406504100); Naseem, Tahira (22958080800); Kapanipathi, Pavan (36623952200); Rossiello, Gaetano (57190124913); Fokoue, Achille (15135570400)",57220034443; 57350238200; 56997333500; 56406504100; 22958080800; 36623952200; 57190124913; 15135570400,A Two-Stage Approach towards Generalization in Knowledge Base Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149820797&partnerID=40&md5=e5c747338c58c9910cc22685da44f44e,"Most existing approaches for Knowledge Base Question Answering focus on a specific underlying knowledge base either because of inherent assumptions in the approach, or because evaluating it on a different knowledge base requires non-trivial changes. However, many popular knowledge bases share similarities in their underlying schemas that can be leveraged to facilitate generalization across knowledge bases. To achieve this generalization, we introduce a Knowledge Base Question Answering framework based on a two-stage architecture that explicitly separates semantic parsing from the knowledge base interaction, facilitating transfer learning across datasets and knowledge graphs. We show that pretraining on datasets with a different underlying knowledge base can nevertheless provide significant performance gains and reduce sample complexity. Our approach, applicable to both weakly-supervised and strongly-supervised settings, achieves comparable or state-of-the-art performance for LC-QuAD (DBpedia), WebQSP (Freebase), SimpleQuestions (Wikidata) and MetaQA (Wikimovies-KG). © 2022 Association for Computational Linguistics.",Final,
Hua W.; Zhang Y.,"Hua, Wenyue (57311348800); Zhang, Yongfeng (36816821200)",57311348800; 36816821200,System 1 + System 2 = Better World: Neural-Symbolic Chain of Logic Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149687806&partnerID=40&md5=70e542bd5d8b253145c9f42c9e2be2ff,"Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science - which proposes that human cognition process involves two stages: an intuitive, unconscious and fast process relying on perception called System 1, and a logical, conscious and slow process performing complex reasoning called System 2 - we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks. © 2022 Association for Computational Linguistics.",Final,
Zhang Y.; Li P.; Liang H.; Jatowt A.; Yang Z.,"Zhang, Yao (57208656743); Li, Peiyao (57238184100); Liang, Hongru (57203502035); Jatowt, Adam (14826985000); Yang, Zhenglu (7405435962)",57208656743; 57238184100; 57203502035; 14826985000; 7405435962,Fact-Tree Reasoning for N-ary Question Answering over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149124836&partnerID=40&md5=f07f0b1dfc872f6bd54488b2158bf09b,"Current Question Answering over Knowledge Graphs (KGQA) task mainly focuses on performing answer reasoning upon KGs with binary facts. However, it neglects the n-ary facts, which contain more than two entities. In this work, we highlight a more challenging but under-explored task: n-ary KGQA, i.e., answering n-ary facts questions upon n-ary KGs. Nevertheless, the multi-hop reasoning framework popular in binary KGQA task is not directly applicable on n-ary KGQA. We propose two feasible improvements: 1) upgrade the basic reasoning unit from entity or relation to fact, and 2) upgrade the reasoning structure from chain to tree. Therefore, we propose a novel fact-tree reasoning framework, FacTree, which integrates the above two upgrades. FacTree transforms the question into a fact tree and performs iterative fact reasoning on the fact tree to infer the correct answer. Experimental results on the n-ary KGQA dataset we constructed and two binary KGQA benchmarks demonstrate the effectiveness of FacTree compared with state-of-the-art methods. © 2022 Association for Computational Linguistics.",Final,
Lovelace J.; Rosé C.P.,"Lovelace, Justin (57219816779); Rosé, Carolyn Penstein (8097137900)",57219816779; 8097137900,A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149438458&partnerID=40&md5=0051e10c3022185b13c9382a3da241b2,"Recent work has demonstrated that entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs. In this work, we conduct a comprehensive exploration of how to best extract and incorporate those embeddings into knowledge graph completion models. We explore the suitability of the extracted embeddings for direct use in entity ranking and introduce both unsupervised and supervised processing methods that can lead to improved downstream performance. We then introduce supervised embedding extraction methods that can extract more informative representations. We then synthesize our findings and develop a knowledge graph completion model that significantly outperforms recent neural models. © 2022 Association for Computational Linguistics.",Final,
Xia Y.; Zhang M.; Liu Q.; Wu S.; Zhang X.-Y.,"Xia, Yuwei (58109644600); Zhang, Mengqi (57215545099); Liu, Qiang (56818103100); Wu, Shu (36245362600); Zhang, Xiao-Yu (54895721300)",58109644600; 57215545099; 56818103100; 36245362600; 54895721300,MetaTKG: Learning Evolutionary Meta-Knowledge for Temporal Knowledge Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149437887&partnerID=40&md5=8c7692ac7852592e8ebd77d4dc7e894a,"Reasoning over Temporal Knowledge Graphs (TKGs) aims to predict future facts based on given history. One of the key challenges for prediction is to learn the evolution of facts. Most existing works focus on exploring evolutionary information in history to obtain effective temporal embeddings for entities and relations, but they ignore the variation in evolution patterns of facts, which makes them struggle to adapt to future data with different evolution patterns. Moreover, new entities continue to emerge along with the evolution of facts over time. Since existing models highly rely on historical information to learn embeddings for entities, they perform poorly on such entities with little historical information. To tackle these issues, we propose a novel Temporal Meta-learning framework for TKG reasoning; MetaTKG for brevity. Specifically, our method regards TKG prediction as many temporal meta-tasks, and utilizes the designed Temporal Meta-learner to learn evolutionary meta-knowledge from these meta-tasks. The proposed method aims to guide the backbones to learn to adapt quickly to future data and deal with entities with little historical information by the learned meta-knowledge. Specially, in temporal meta-learner, we design a Gating Integration module to adaptively establish temporal correlations between meta-tasks. Extensive experiments on four widely-used datasets and three backbones demonstrate that our method can greatly improve the performance. © 2022 Association for Computational Linguistics.",Final,
,,,BioNLP 2022 @ ACL 2022 - Proceedings of the 21st Workshop on Biomedical Language Processing,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149126618&partnerID=40&md5=53f2ab78928d9a756108d24d81d53ba4,The proceedings contain 44 papers. The topics discussed include: explainable assessment of healthcare articles with QA; a sequence-to-sequence approach for document-level relation extraction; position-based prompting for health outcome generation; how you say it matters: measuring the impact of verbal disfluency tags on automated dementia detection; zero-shot aspect-based scientific document summarization using self-supervised pre-training; data augmentation for biomedical factoid question answering; slot filling for biomedical information extraction; automatic biomedical term clustering by learning fine-grained term representations; incorporating medical knowledge to transformer-based language models for medical dialogue generation; memory-aligned knowledge graph for clinically accurate radiology image report generation; simple semantic-based data augmentation for named entity recognition in biomedical texts; auxiliary learning for named entity recognition with multiple auxiliary biomedical training data; and improving supervised drug-protein relation extraction with distantly supervised models.,Final,
Tan C.-H.; Gu J.-C.; Tao C.; Ling Z.-H.; Xu C.; Hu H.; Geng X.; Jiang D.,"Tan, Chao-Hong (57211745357); Gu, Jia-Chen (57204394727); Tao, Chongyang (57204468075); Ling, Zhen-Hua (24473163500); Xu, Can (57205550388); Hu, Huang (57215722413); Geng, Xiubo (57216694637); Jiang, Daxin (57226177359)",57211745357; 57204394727; 57204468075; 24473163500; 57205550388; 57215722413; 57216694637; 57226177359,TEGTOK: Augmenting Text Generation via Task-specific and Open-world Knowledge,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149117694&partnerID=40&md5=f3975f5fa14ad680896430958a690e7a,"Generating natural and informative texts has been a long-standing problem in NLP. Much effort has been dedicated into incorporating pre-trained language models (PLMs) with various open-world knowledge, such as knowledge graphs or wiki pages. However, their ability to access and manipulate the task-specific knowledge is still limited on downstream tasks, as this type of knowledge is usually not well covered in PLMs and is hard to acquire. To address the problem, we propose augmenting TExt Generation via Task-specific and Open-world Knowledge (TEGTOK) in a unified framework. Our model selects knowledge entries from two types of knowledge sources through dense retrieval and then injects them into the input encoding and output decoding stages respectively on the basis of PLMs. With the help of these two types of knowledge, our model can learn what and how to generate. Experiments on two text generation tasks of dialogue generation and question generation, and on two datasets show that our method achieves better performance than various baseline models. © 2022 Association for Computational Linguistics.",Final,
Du X.; Jia Y.; Zan H.,"Du, Xiaojing (57465047400); Jia, Yuxiang (53984459500); Zan, Hongying (23391538300)",57465047400; 53984459500; 23391538300,MRC-based Medical NER with Multi-task Learning and Multi-strategies,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146371035&partnerID=40&md5=addc9063431fccb8956eb2c6602e835d,"Medical named entity recognition (NER), a fundamental task of medical information extraction, is crucial for medical knowledge graph construction, medical question answering, and automatic medical record analysis, etc. Compared with named entities (NEs) in general domain, medical named entities are usually more complex and prone to be nested. To cope with both flat NEs and nested NEs, we propose a MRC-based approach with multi-task learning and multi-strategies. NER can be treated as a sequence labeling (SL) task or a span boundary detection (SBD) task. We integrate MRC-CRF model for SL and MRC-Biaffine model for SBD into the multi-task learning architecture, and select the more efficient MRC-CRF as the final decoder. To further improve the model, we employ multi-strategies, including adaptive pre-training, adversarial training, and model stacking with cross validation. Experiments on both nested NER corpus CMeEE and flat NER corpus CCKS2019 show the effectiveness of the MRC-based model with multi-task learning and multi-strategies. © 2022 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License.",Final,
Hou Y.; Fu G.; Sachan M.,"Hou, Yifan (57224532589); Fu, Guoji (57211276409); Sachan, Mrinmaya (36094978300)",57224532589; 57211276409; 36094978300,What Has Been Enhanced in my Knowledge-Enhanced Language Model?,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149832655&partnerID=40&md5=97929a65a69eaa712387481814a148e5,"A number of knowledge integration (KI) methods have recently been proposed to incorporate external knowledge into pretrained language models (LMs). Even though knowledge-enhanced LMs outperform base LMs on knowledge-intensive tasks, the inner-workings of these KI methods are not well-understood. For instance, it is unclear which knowledge is effectively integrated into knowledge-enhanced LMs and which is not; and if such integration leads to catastrophic forgetting of already learned knowledge. We show that existing model interpretation methods such as linear probes and prompts have some key limitations in answering these questions. We revisit KI from an information-theoretic view and propose a new theoretically sound probe called Graph Convolution Simulator (GCS) for KI interpretation. GCS uses graph attention on the corresponding knowledge graph for interpretation. In our experiments we verify that GCS can provide reasonable interpretation results for two well-known knowledge-enhanced LMs: ERNIE and K-Adapter. We also find that only a marginal amount of knowledge is successfully integrated in these models, and simply increasing the size of the KI corpus may not lead to better knowledge-enhanced LMs. © 2022 Association for Computational Linguistics.",Final,
Li Y.; Liu J.; Li C.; Yang M.,"Li, Yunshui (58137112000); Liu, Junhao (57218625434); Li, Chengming (57192580201); Yang, Min (56349712700)",58137112000; 57218625434; 57192580201; 56349712700,Self-Distillation with Meta Learning for Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149901117&partnerID=40&md5=b7ecfebfeb1294cdb71dd3865f4490a3,"In this paper, we propose a self-distillation framework with meta learning (MetaSD) for knowledge graph completion with dynamic pruning, which aims to learn compressed graph embeddings and tackle the long-tail samples. Specifically, we first propose a dynamic pruning technique to obtain a small pruned model from a large source model, where the pruning mask of the pruned model could be updated adaptively per epoch after the model weights are updated. The pruned model is supposed to be more sensitive to difficult-to-memorize samples (e.g., long-tail samples) than the source model. Then, we propose a one-step meta self-distillation method for distilling comprehensive knowledge from the source model to the pruned model, where the two models co-evolve in a dynamic manner during training. In particular, we exploit the performance of the pruned model, which is trained alongside the source model in one iteration, to improve the source model's knowledge transfer ability for the next iteration via meta learning. Extensive experiments show that MetaSD achieves competitive performance compared to strong baselines, while being 10x smaller than baselines. © 2022 Association for Computational Linguistics.",Final,
Das S.; Saha S.; Srihari R.K.,"Das, Souvik (57226612469); Saha, Sougata (57226603644); Srihari, Rohini K. (6701894771)",57226612469; 57226603644; 6701894771,Diving Deep into Modes of Fact Hallucinations in Dialogue Systems,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149865476&partnerID=40&md5=fb5977bfa578dc47f81e7c9f9021f688,"Knowledge Graph(KG) grounded conversations often use large pre-trained models and usually suffer from fact hallucination. Frequently entities with no references in knowledge sources and conversation history are introduced into responses, thus hindering the flow of the conversation-existing work attempt to overcome this issue by tweaking the training procedure or using a multi-step refining method. However, minimal effort is put into constructing an entity-level hallucination detection system, which would provide fine-grained signals that control fallacious content while generating responses. As a first step to address this issue, we dive deep to identify various modes of hallucination in KG-grounded chatbots through human feedback analysis. Secondly, we propose a series of perturbation strategies to create a synthetic dataset named FADE (FActual Dialogue Hallucination DEtection Dataset). Finally, we conduct comprehensive data analyses and create multiple baseline models for hallucination detection to compare against human-verified data and already established benchmarks. © 2022 Association for Computational Linguistics.",Final,
,,,"Proceedings - 2022 IEEE International Conference on e-Business Engineering, ICEBE 2022",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148601126&partnerID=40&md5=cd9c67c955723d12ec7853a5441fc608,The proceedings contain 50 papers. The topics discussed include: aesthetic research of dynamic ink contour stylized material based on movable camera in 3D game and their real-time rendering method taking the OKAMI HD game for example; an exploratory study on Nepalese teenager's visual recognition and preferences in serious games; engaging females with a model for affective storytelling; enhancing transaction monitoring controls to detect money laundering using machine learning; knowledge graph completion based on hyperbolic graph contrastive attention network; an end-to-end speech recognition system based on shared encoder; combining linguistic and behavioral clues to detect spam in online reviews; edge-cloud hybrid tiny data reduction model for anomaly detection; and stacking-based multi-features fusion ensemble learning for product quality prediction.,Final,
Lee M.; Park J.-H.; Kim J.; Kim K.-M.; Lee S.,"Lee, Mingyu (57226816346); Park, Jun-Hyung (57204908433); Kim, Junho (58033038500); Kim, Kang-Min (57195197726); Lee, SangKeun (56152308000)",57226816346; 57204908433; 58033038500; 57195197726; 56152308000,Efficient Pre-training of Masked Language Model via Concept-based Curriculum Masking,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149433616&partnerID=40&md5=710252a94f4bb378ae3681972ea69d16,"Masked language modeling (MLM) has been widely used for pre-training effective bidirectional representations, but incurs substantial training costs. In this paper, we propose a novel concept-based curriculum masking (CCM) method to efficiently pre-train a language model. CCM has two key differences from existing curriculum learning approaches to effectively reflect the nature of MLM. First, we introduce a carefully-designed linguistic difficulty criterion that evaluates the MLM difficulty of each token. Second, we construct a curriculum that gradually masks words related to the previously masked words by retrieving a knowledge graph. Experimental results show that CCM significantly improves pre-training efficiency. Specifically, the model trained with CCM shows comparative performance with the original BERT on the General Language Understanding Evaluation benchmark at half of the training cost. Code is available at https://github.com/KoreaMGLEE/Concept-based-curriculum-masking. © 2022 Association for Computational Linguistics.",Final,
Peng X.; Xie K.; Alabdulkarim A.; Kayam H.; Dani S.; Riedl M.O.,"Peng, Xiangyu (57219758425); Xie, Kaige (57215721212); Alabdulkarim, Amal (57193562354); Kayam, Harshith (57385013900); Dani, Samihan (57384316300); Riedl, Mark O. (7004421643)",57219758425; 57215721212; 57193562354; 57385013900; 57384316300; 7004421643,Guiding Neural Story Generation with Reader Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149902968&partnerID=40&md5=07e250718db841200ad516e7bb55c8ec,"Automated storytelling has long captured the attention of researchers for the ubiquity of narratives in everyday life. However, it is challenging to maintain coherence and stay on-topic toward a specific ending when generating narratives with neural language models. In this paper, we introduce Story generation with Reader Models (StoRM), a framework in which a reader model is used to reason about the story should progress. A reader model infers what a human reader believes about the concepts, entities, and relations about the fictional story world. We show how an explicit reader model represented as a knowledge graph affords story coherence and provides controllability in the form of achieving a given story world state goal. Experiments show that our model produces significantly more coherent and on-topic stories, outperforming baselines in dimensions including plot plausibility and staying on topic. © 2022 Association for Computational Linguistics.",Final,
Li Q.; Joty S.; Wang D.; Feng S.; Zhang Y.,"Li, Qian (57199178910); Joty, Shafiq (24779447500); Wang, Daling (8543200700); Feng, Shi (36173786700); Zhang, Yifei (36618421200)",57199178910; 24779447500; 8543200700; 36173786700; 36618421200,Alleviating Sparsity of Open Knowledge Graphs with Ternary Contrastive Learning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149840553&partnerID=40&md5=d1bb7087d25d7b331582669b36cfb373,"Sparsity of formal knowledge and roughness of non-ontological construction make sparsity problem particularly prominent in Open Knowledge Graphs (OpenKGs). Due to sparse links, learning effective representation for few-shot entities becomes difficult. We hypothesize that by introducing negative samples, a contrastive learning (CL) formulation could be beneficial in such scenarios. However, existing CL methods model KG triplets as binary objects of entities ignoring the relation-guided ternary propagation patterns and they are too generic, i.e., they ignore zero-shot, few-shot and synonymity problems that appear in OpenKGs. To address this, we propose TernaryCL, a CL framework based on ternary propagation patterns among head, relation and tail. TernaryCL designs Contrastive Entity and Contrastive Relation to mine ternary discriminative features with both negative entities and relations, introduces Contrastive Self to help zero- and few-shot entities learn discriminative features, Contrastive Synonym to model synonymous entities, and Contrastive Fusion to aggregate graph features from multiple paths. Extensive experiments on benchmarks demonstrate the superiority of TernaryCL over state-of-the-art models. © 2022 Association for Computational Linguistics.",Final,
Pan Y.; Liu J.; Zhang L.; Zhao T.; Lin Q.; Hu X.; Wang Q.,"Pan, Yudai (57213269002); Liu, Jun (55904548100); Zhang, Lingling (57191711163); Zhao, Tianzhe (57220897349); Lin, Qika (57204147391); Hu, Xin (57214932902); Wang, Qianying (57209304229)",57213269002; 55904548100; 57191711163; 57220897349; 57204147391; 57214932902; 57209304229,Inductive Relation Prediction with Logical Reasoning Using Contrastive Representations,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149444683&partnerID=40&md5=50f2cf413a5f9a6e707c73411ed87ba1,"Relation prediction in knowledge graphs (KGs) aims at predicting missing relations in incomplete triples, whereas the dominant embedding paradigm has a restriction on handling unseen entities during testing. In the real-world scenario, the inductive setting is more common because entities in the training process are finite. Previous methods capture an inductive ability by implicit logic in KGs. However, it would be challenging to preciously acquire entity-independent relational semantics of compositional logic rules and to deal with the deficient supervision of logic caused by the scarcity of relational semantics. To this end, we propose a novel graph convolutional network (GCN)-based model LogCo with logical reasoning by contrastive representations. LogCo firstly extracts enclosing subgraphs and relational paths between two entities to supply the entity-independence. Then a contrastive strategy for relational path instances and the subgraph is proposed for the issue of deficient supervision. The contrastive representations are learned for a joint training regime. Finally, prediction results and logic rules for reasoning are attained. Comprehensive experiments on twelve inductive datasets show that LogCo achieves outstanding performance comparing with SOTA inductive baselines. © 2022 Association for Computational Linguistics.",Final,
Dai Q.; Heinzerling B.; Inui K.,"Dai, Qin (57202889179); Heinzerling, Benjamin (56904240800); Inui, Kentaro (35487508600)",57202889179; 56904240800; 35487508600,Cross-stitching Text and Knowledge Graph Encoders for Distantly Supervised Relation Extraction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149443472&partnerID=40&md5=85b4c413ec7fa4d483f0b044d183696e,"Bi-encoder architectures for distantly-supervised relation extraction are designed to make use of the complementary information found in text and knowledge graphs (KG). However, current architectures suffer from two drawbacks. They either do not allow any sharing between the text encoder and the KG encoder at all, or, in case of models with KG-to-text attention, only share information in one direction. Here, we introduce cross-stitch bi-encoders, which allow full interaction between the text encoder and the KG encoder via a cross-stitch mechanism. The cross-stitch mechanism allows sharing and updating representations between the two encoders at any layer, with the amount of sharing being dynamically controlled via cross-attention-based gates. Experimental results on two relation extraction benchmarks from two different domains show that enabling full interaction between the two encoders yields strong improvements. © 2022 Association for Computational Linguistics.",Final,
Luo S.; Yu S.,"Luo, Shengxuan (57223907731); Yu, Sheng (56324605100)",57223907731; 56324605100,An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149148622&partnerID=40&md5=f95b80eef8a6f52e3f8db48c7d1a820b,"Knowledge graph integration typically suffers from the widely existing dangling entities that cannot find alignment cross knowledge graphs (KGs). The dangling entity set is unavailable in most real-world scenarios, and manually mining the entity pairs that consist of entities with the same meaning is labor-consuming. In this paper, we propose a novel accurate Unsupervised method for joint Entity alignment (EA) and Dangling entity detection (DED), called UED. The UED mines the literal semantic information to generate pseudo entity pairs and globally guided alignment information for EA and then utilizes the EA results to assist the DED. We construct a medical cross-lingual knowledge graph dataset, MedED, providing data for both the EA and DED tasks. Extensive experiments demonstrate that in the EA task, UED achieves EA results comparable to those of state-of-the-art supervised EA baselines and outperforms the current state-of-the-art EA methods by combining supervised EA data. For the DED task, UED obtains high-quality results without supervision. © 2022 Association for Computational Linguistics.",Final,
,,,"ACL 2022 - 60th Annual Meeting of the Association for Computational Linguistics, Proceedings of System Demonstrations",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149105819&partnerID=40&md5=2ec6a2d23cab9fb0025329820258232e,"The proceedings contain 27 papers. The topics discussed include: UKP-SQUARE: an online platform for question answering research; ViLMedic: a framework for research at the intersection of vision and language in medical AI; TextPruner: a model pruning toolkit for pre-trained language models; AnnIE: an annotation platform for constructing complete open information extraction benchmark; AdapterHub playground: simple and flexible few-shot learning with adapters; QiuNiu: a Chinese lyrics generation system with passage-level input; automatic gloss dictionary for sign language learners; PromptSource: an integrated development environment and repository for natural language prompts; COVID-19 claim radar: a structured claim extraction and tracking system; TS-Anno: an annotation tool to build, annotate and evaluate text simplification corpora; and CogKGE: a knowledge graph embedding toolkit and benchmark for representing multi-source and heterogeneous knowledge.",Final,
Mei X.; Yang L.; Jiang Z.; Cai X.,"Mei, Xin (57219710183); Yang, Libin (57198986816); Jiang, Zuowei (57884550700); Cai, Xiaoyan (55368428400)",57219710183; 57198986816; 57884550700; 55368428400,An Adaptive Logical Rule Embedding Model for Inductive Reasoning over Temporal Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149437748&partnerID=40&md5=fe6841ac3d03b22817fa5e342aef9ebc,"Temporal knowledge graphs (TKGs) extrapolation reasoning predicts future events based on historical information, which has great research significance and broad application value. Existing methods can be divided into embedding-based methods and logical rule-based methods. Embedding-based methods rely on learned entity and relation embeddings to make predictions and thus lack interpretability. Logical rule-based methods bring scalability problems due to being limited by the learned logical rules. We combine the two methods to capture deep causal logic by learning rule embeddings, and propose an interpretable model for temporal knowledge graph reasoning called adaptive logical rule embedding model for inductive reasoning (ALRE-IR). ALRE-IR can adaptively extract and assess reasons contained in historical events, and make predictions based on causal logic. Furthermore, we propose a one-class augmented matching loss for optimization. When evaluated on ICEWS14, ICEWS0515 and ICEWS18 datasets, the performance of ALRE-IR outperforms other state-of-the-art baselines. The results also demonstrate that ALRE-IR still shows outstanding performance when transferred to related dataset with common relation vocabulary, indicating our proposed model has good zero-shot reasoning ability. © 2022 Association for Computational Linguistics.",Final,
Ma Y.; Wang Z.; Li M.; Cao Y.; Chen M.; Li X.; Sun W.; Deng K.; Wang K.; Sun A.; Shao J.,"Ma, Yubo (57485133600); Wang, Zehao (57485970600); Li, Mukai (57486383000); Cao, Yixin (57015851100); Chen, Meiqi (57271422200); Li, Xinze (58121980700); Sun, Wenqi (58121980800); Deng, Kunquan (57669517100); Wang, Kun (56979525500); Sun, Aixin (7202552214); Shao, Jing (57200616653)",57485133600; 57485970600; 57486383000; 57015851100; 57271422200; 58121980700; 58121980800; 57669517100; 56979525500; 7202552214; 57200616653,MMEKG: Multi-modal Event Knowledge Graph towards Universal Representation across Modalities,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146205542&partnerID=40&md5=3cce9c58696349cff44627f026251429,"Events are fundamental building blocks of real-world happenings. In this paper, we present a large-scale, multi-modal event knowledge graph named MMEKG. MMEKG unifies different modalities of knowledge via events, which complement and disambiguate each other. Specifically, MMEKG incorporates (i) over 990 thousand concept events with 644 relation types to cover most types of happenings, and (ii) over 863 million instance events connected through 934 million relations, which provide rich contextual information in texts and/or images. To collect billion-scale instance events and relations among them, we additionally develop an efficient yet effective pipeline for textual/visual knowledge extraction system. We also develop an induction strategy to create million-scale concept events and a schema organizing all events and relations in MMEKG. To this end, we also provide a pipeline1 enabling our system to seamlessly parse texts/images to event graphs and to retrieve multi-modal knowledge at both concept- and instance-levels. © 2022 Association for Computational Linguistics.",Final,
Zhang X.; Li W.; Bai Q.; Liu W.; Wang H.,"Zhang, Xinchun (58073781300); Li, Weihua (57190971520); Bai, Quan (56962723200); Liu, William (56962720400); Wang, Huan (56716572400)",58073781300; 57190971520; 56962723200; 56962720400; 56716572400,A Novel Story Plots Extraction Based Rapid Reading Comprehension System to Assist the Education for Low-income Families,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146637328&doi=10.1109%2fITNAC55475.2022.9998397&partnerID=40&md5=3b8cd1c8d6948a70184e2290e5d1b113,"Poverty has posed many threats to the children's education. Children in low-income families tend to have uneducated and/or very busy parents, and their reading after school is less being instructed and supported by their parents even they want to support but without the capacity and/or sufficient time to read and understand the huge volume of stories and novels. In this paper, we aim to tackle the above challenges and develop a rapid reading comprehension system to assist those parents rapidly understanding the story content by proposing a novel system that is capable of generating and visualising story plots from the massive literature narratives. Meanwhile, the visualised story plots are represented as a sequenced knowledge graph, helping those uneducated or busy parents grasp the story's linguistic meanings and flow. Furthermore, a well-known fiction book, i.e., 'Alice in Wonderland' is utilised as case studies to validate the proposed system. The primary experimental results reveal that story plot extraction can effectively provide explicit information for presenting storylines chapter by chapter at the early stage of this research initiative.  © 2022 IEEE.",Final,
Shen J.; Wang C.; Yuan Y.; Han J.; Ji H.; Sen K.; Zhang M.; Song D.,"Shen, Jianhao (57220573591); Wang, Chenguang (56367840700); Yuan, Ye (57221532255); Han, Jiawei (24325399900); Ji, Heng (35240121900); Sen, Koushik (8226489200); Zhang, Ming (57853084000); Song, Dawn (57225849829)",57220573591; 56367840700; 57221532255; 24325399900; 35240121900; 8226489200; 57853084000; 57225849829,PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149889015&partnerID=40&md5=3be0a5d37be91338142216600ef3ea44,"This paper presents a parameter-lite transfer learning approach of pretrained language models (LM) for knowledge graph (KG) completion. Instead of finetuning, which modifies all LM parameters, we only tune a few new parameters while keeping the original LM parameters fixed. We establish this via reformulating KG completion as a “fill-in-the-blank” task, and introducing a parameter-lite encoder on top of the original LMs. We show that, by tuning far fewer parameters than finetuning, LMs transfer non-trivially to most tasks and reach competitiveness with prior state-of-the-art approaches. For instance, we outperform the fully finetuning approaches on a KG completion benchmark by tuning only 1% of the parameters. © 2022 Association for Computational Linguistics.",Final,
Brate R.; Dang M.-H.; Hoppe F.; He Y.; Meroño-Peñuela A.; Sadashivaiah V.,"Brate, Ryan (57221254725); Dang, Minh-Hoang (58112930100); Hoppe, Fabian (57219900264); He, Yuan (57372933500); Meroño-Peñuela, Albert (55891390100); Sadashivaiah, Vijay (56943483400)",57221254725; 58112930100; 57219900264; 57372933500; 55891390100; 56943483400,Improving Language Model Predictions via Prompts Enriched with Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148589788&partnerID=40&md5=4a6410c310241641a62b093993d54843,"Despite advances in deep learning and knowledge graphs (KGs), using language models for natural language understanding and question answering remains a challenging task. Pre-trained language models (PLMs) have shown to be able to leverage contextual information, to complete cloze prompts, next sentence completion and question answering tasks in various domains. Unlike structured data querying in e.g. KGs, mapping an input question to data that may or may not be stored by the language model is not a simple task. Recent studies have highlighted the improvements that can be made to the quality of information retrieved from PLMs by performing amendments to otherwise naive prompts. In this paper, we explore the effects of enriching prompts with additional contextual information leveraged from the Wikidata KG on language model performance. Specifically, we compare the performance of naive vs. KG-engineered cloze prompts for genre completion in the movie domain. Selecting a broad range of commonly available Wikidata properties, we show that enrichment of cloze-style prompts with Wikidata information can result in a significantly higher recall in the selected BERT and RoBERTa large PLMs. However, it is also apparent that the optimum level of data enrichment differs between models. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Zhou J.; Wang B.; Huang M.; Zhao D.; Huang K.; He R.; Hou Y.,"Zhou, Jinfeng (57558200300); Wang, Bo (56949454300); Huang, Minlie (7404260571); Zhao, Dongming (7403490494); Huang, Kun (57614133600); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",57558200300; 56949454300; 7404260571; 7403490494; 57614133600; 19835197000; 7402198932,Aligning Recommendation and Conversation via Dual Imitation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149439246&partnerID=40&md5=847e9472023649c192b2d101d90fd0c9,"Human conversations of recommendation naturally involve the shift of interests which can align the recommendation actions and conversation process to make accurate recommendations with rich explanations. However, existing conversational recommendation systems (CRS) ignore the advantage of user interest shift in connecting recommendation and conversation, which leads to an ineffective loose coupling structure of CRS. To address this issue, by modeling the recommendation actions as recommendation paths in a knowledge graph (KG), we propose DICR (Dual Imitation for Conversational Recommendation), which designs a dual imitation to explicitly align the recommendation paths and user interest shift paths in a recommendation module and a conversation module, respectively. By exchanging alignment signals, DICR achieves bidirectional promotion between recommendation and conversation modules and generates high-quality responses with accurate recommendations and coherent explanations. Experiments demonstrate that DICR outperforms the state-of-the-art models on recommendation and conversation performance with automatic, human, and novel explainability metrics. © 2022 Association for Computational Linguistics.",Final,
Zhang X.F.; Beauchamp N.; Wang L.,"Zhang, Xinliang Frederick (57701275100); Beauchamp, Nick (57191164537); Wang, Lu (56304420000)",57701275100; 57191164537; 56304420000,Generative Entity-to-Entity Stance Detection with Knowledge Graph Augmentation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149439761&partnerID=40&md5=d576d658a1ca299a341a5bb19f41f52d,"Stance detection is typically framed as predicting the sentiment in a given text towards a target entity. However, this setup overlooks the importance of the source entity, i.e., who is expressing the opinion. In this paper, we emphasize the need for studying interactions among entities when inferring stances. We first introduce a new task, entity-to-entity (E2E) stance detection, which primes models to identify entities in their canonical names and discern stances jointly. To support this study, we curate a new dataset with 10, 619 annotations labeled at the sentence-level from news articles of different ideological leanings. We present a novel generative framework to allow the generation of canonical names for entities as well as stances among them. We further enhance the model with a graph encoder to summarize entity activities and external knowledge surrounding the entities. Experiments show that our model outperforms strong comparisons by large margins. Further analyses demonstrate the usefulness of E2E stance detection for understanding media quotation and stance landscape, as well as inferring entity ideology. © 2022 Association for Computational Linguistics.",Final,
,,,"2nd Workshop on Sentiment Analysis and Linguistic Linked Data, SALLD 2022 - held in conjunction with the International Conference on Language Resources and Evaluation, LREC 2022 - Proceedings",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146231277&partnerID=40&md5=298a4db0b883e2eb804dade604b298ca,"The proceedings contain 6 papers. The topics discussed include: from data to meaning in representation of emotions; O-Dang! the ontology of dangerous speech messages; movie rating prediction using sentiment features; evaluating a new Danish sentiment resource: the Danish sentiment lexicon, DSL; correlating facts and social media trends on environmental quantities leveraging commonsense reasoning and human sentiments; and sentiment analysis of Serbian old novels.",Final,
Soliman H.; Adel H.; Gad-Elrab M.; Milchevski D.; Strötgen J.,"Soliman, Hassan (57917352000); Adel, Heike (55839314700); Gad-Elrab, Mohamed (57191728959); Milchevski, Dragan (56286119700); Strötgen, Jannik (35932986600)",57917352000; 55839314700; 57191728959; 56286119700; 35932986600,A Study on Entity Linking Across Domains: Which Data is Best for Fine-Tuning?,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149107958&partnerID=40&md5=8391e3faec0945aae3600f8ab84808ef,"Entity linking disambiguates mentions by mapping them to entities in a knowledge graph (KG). One important question in today’s research is how to extend neural entity linking systems to new domains. In this paper, we aim at a system that enables linking mentions to entities from a general-domain KG and a domain-specific KG at the same time. In particular, we represent the entities of different KGs in a joint vector space and address the questions of which data is best suited for creating and fine-tuning that space, and whether fine-tuning harms performance on the general domain. We find that a combination of data from both the general and the special domain is most helpful. The first is especially necessary for avoiding performance loss on the general domain. While additional supervision on entities that appear in both KGs performs best in an intrinsic evaluation of the vector space, it has less impact on the downstream task of entity linking. © 2022 Association for Computational Linguistics.",Final,
Li Y.; Fan W.; Liu C.; Lin C.; Qian J.,"Li, Yizhi (57682279900); Fan, Wei (57221024776); Liu, Chao (57682280000); Lin, Chenghua (35322970500); Qian, Jiang (55730662300)",57682279900; 57221024776; 57682280000; 35322970500; 55730662300,TranSHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149438313&partnerID=40&md5=fcf79ac8cf662f5269f183eb9f4ea1eb,"Knowledge graph embedding methods are important for the knowledge graph completion (or link prediction) task. One existing efficient method, PairRE, leverages two separate vectors to model complex relations (i.e., 1-to-N, N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly restricts entities on the hyper-ellipsoid surfaces which limits the optimization of entity distribution, leading to suboptimal performance of knowledge graph completion. To address this issue, we propose a novel score function TranSHER, which leverages relation-specific translations between head and tail entities to relax the constraint of hyper-ellipsoid restrictions. By introducing an intuitive and simple relation-specific translation, TranSHER can provide more direct guidance on optimization and capture more semantic characteristics of entities with complex relations. Experimental results show that TranSHER achieves significant performance improvements on link prediction and generalizes well to datasets in different domains and scales. Our codes are public available at https://github.com/yizhilll/TranSHER. © 2022 Association for Computational Linguistics.",Final,
Shang C.; Qin B.; Peng P.; Wang H.,"Shang, Chunnan (57222505612); Qin, Bo (58590156900); Peng, Peng (57208757737); Wang, Hongwei (54785526500)",57222505612; 58590156900; 57208757737; 54785526500,Simultaneous Extraction of Entities and Relations Based on Pre-Trained Language Model and Pre-defined Language Templates,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148611230&doi=10.1109%2fICEBE55470.2022.00046&partnerID=40&md5=7500433e221d4b2e965064ec8f7e57e7,"With the advent of the era of big data, the need to obtain core information from text data is getting stronger and stronger. And the knowledge graph can visually represent the core information of the text. Entity relation extraction is a challenge and key part of knowledge graph construction. In this paper, we propose a model that can effectively perform entity relation extraction. The model adopts a joint training approach based on parameter sharing to solve the error propagation problem in pipelined extraction. At the same time, the model uses a pre-Trained language model as the basis to solve the problem of lack of semantic knowledge in traditional models. Further, it uses a linguistic template-based approach to bridge the discrepancies in training and fine-Tuning of pre-Trained language models. To validate the proposed approach, we conduct comparative experiments on the SemEval2010 dataset and conll04 dataset. The validation results demonstrate that our model can improve the accuracy, recall, and F1 score of joint entity relationship extraction compared to the baseline models.  © 2022 IEEE.",Final,
Wang C.; Li J.; Chen Y.; Liu K.; Zhao J.,"Wang, Chenhao (57214862680); Li, Jiachun (58130611700); Chen, Yubo (57935192700); Liu, Kang (55729555700); Zhao, Jun (57190004147)",57214862680; 58130611700; 57935192700; 55729555700; 57190004147,CN-AutoMIC: Distilling Chinese Commonsense Knowledge from Pretrained Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149442496&partnerID=40&md5=64842f8e676c773c8796f0be985b0743,"Commonsense knowledge graphs (CKGs) are increasingly applied in various natural language processing tasks. However, most existing CKGs are limited to English, which hinders related research in non-English languages. Meanwhile, directly generating commonsense knowledge from pretrained language models has recently received attention, yet it has not been explored in non-English languages. In this paper, we propose a large-scale Chinese CKG generated from multilingual PLMs, named as CN-AutoMIC, aiming to fill the research gap of non-English CKGs. To improve the efficiency, we propose generate-by-category strategy to reduce invalid generation. To ensure the filtering quality, we develop cascaded filters to discard low-quality results. To further increase the diversity and density, we introduce a bootstrapping iteration process to reuse generated results. Finally, we conduct detailed analyses on CN-AutoMIC from different aspects. Empirical results show the proposed CKG has high quality and diversity, surpassing the direct translation version of similar English CKGs. We also find some interesting deficiency patterns and differences between relations, which reveal pending problems in commonsense knowledge generation. We share the resources and related models for further study. © 2022 Association for Computational Linguistics.",Final,
Sun H.; Geng S.; Zhong J.; Hu H.; He K.,"Sun, Haohai (57267496800); Geng, Shangyi (58130503000); Zhong, Jialun (57226185301); Hu, Han (55923489500); He, Kun (57204773777)",57267496800; 58130503000; 57226185301; 55923489500; 57204773777,Graph Hawkes Transformer for Extrapolated Reasoning on Temporal Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149441041&partnerID=40&md5=5dd2b764325d47367ca6dac3c46dd518,"Temporal Knowledge Graph (TKG) reasoning has attracted increasing attention due to its enormous potential value, and the critical issue is how to model the complex temporal structure information effectively. Recent studies use the method of encoding graph snapshots into hidden vector space and then performing heuristic deductions, which perform well on the task of entity prediction. However, these approaches cannot predict when an event will occur, and have the following limitations: 1) there are many facts not related to the query that can confuse the model; 2) there exists information forgetting caused by long-term evolutionary processes. To this end, we propose a Graph Hawkes Transformer (GHT) for both TKG entity prediction and time prediction tasks in the future time. In GHT, there are two variants of Transformer, which capture the instantaneous structural information and temporal evolution information, respectively, and a new relational continuous-time encoding function to facilitate feature evolution with the Hawkes process. Extensive experiments on four public datasets demonstrate its superior performance, especially on long-term evolutionary tasks. © 2022 Association for Computational Linguistics.",Final,
Koleva A.; Ringsquandl M.; Buckley M.; Hasan R.; Tresp V.,"Koleva, Aneta (57219229377); Ringsquandl, Martin (55841755800); Buckley, Mark (57216966754); Hasan, Rakebul (57917096600); Tresp, Volker (6603805670)",57219229377; 55841755800; 57216966754; 57917096600; 6603805670,Named Entity Recognition in Industrial Tables using Tabular Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152899872&partnerID=40&md5=11d3dde2ce25eb60b6a5195960a7f118,"Specialized transformer-based models for encoding tabular data have gained interest in academia. Although tabular data is omnipresent in industry, applications of table transformers are still missing. In this paper, we study how these models can be applied to an industrial Named Entity Recognition (NER) problem where the entities are mentioned in tabular-structured spreadsheets. The highly technical nature of spreadsheets as well as the lack of labeled data present major challenges for fine-tuning transformer-based models. Therefore, we develop a dedicated table data augmentation strategy based on available domain-specific knowledge graphs. We show that this boosts performance in our low-resource scenario considerably. Further, we investigate the benefits of tabular structure as inductive bias compared to tables as linearized sequences. Our experiments confirm that a table transformer outperforms other baselines and that its tabular inductive bias is vital for convergence of transformer-based models. © 2022 Association for Computational Linguistics.",Final,
Bikaun T.; Stewart M.; Liu W.,"Bikaun, Tyler (57555509100); Stewart, Michael (57196713433); Liu, Wei (36077178500)",57555509100; 57196713433; 36077178500,QuickGraph: A Rapid Annotation Tool for Knowledge Graph Extraction from Technical Text,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149100652&partnerID=40&md5=6046ff89a0f84c8f4f5fcb207cac6c62,"Acquiring high-quality annotated corpora for complex multi-task information extraction (MT-IE) is an arduous and costly process for human-annotators. Adoption of unsupervised techniques for automated annotation have thus become popular. However, these techniques rely heavily on dictionaries, gazetteers, and knowledge bases. While such resources are abundant for general domains, they are scarce for specialised technical domains. To tackle this challenge, we present QuickGraph1, the first collaborative MT-IE annotation tool built with indirect weak supervision and clustering to maximise annotator productivity. QuickGraph’s main contribution is a set of novel features that enable knowledge graph extraction through rapid and consistent complex multi-task entity and relation annotation. In this paper, we discuss these key features and qualitatively compare QuickGraph to existing annotation tools. A demonstration of our system is available at: https://youtu.be/ ZlzH-AAoGXs. © 2022 Association for Computational Linguistics.",Final,
Zhang Z.; Chen S.; Wu M.; Zhu K.Q.,"Zhang, Zhiling (57218450371); Chen, Siyuan (57712421800); Wu, Mengyue (57190753127); Zhu, Kenny Q. (8857364700)",57218450371; 57712421800; 57190753127; 8857364700,Symptom Identification for Interpretable Detection of Multiple Mental Disorders on Social Media,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149433959&partnerID=40&md5=c7992d84d163fa7588fa34051aabf68b,"Mental disease detection (MDD) from social media has suffered from poor generalizability and interpretability, due to lack of symptom modeling. This paper introduces PsySym, the first annotated symptom identification corpus of multiple psychiatric disorders, to facilitate further research progress. PsySym is annotated according to a knowledge graph of the 38 symptom classes related to 7 mental diseases complied from established clinical manuals and scales, and a novel annotation framework for diversity and quality. Experiments show that symptom-assisted MDD enabled by PsySym can outperform strong pure-text baselines. We also exhibit the convincing MDD explanations provided by symptom predictions with case studies, and point to their further potential applications. © 2022 Association for Computational Linguistics.",Final,
Hou Y.; Jiao W.; Liu M.; Allen C.; Tu Z.; Sachan M.,"Hou, Yifan (57224532589); Jiao, Wenxiang (57610296600); Liu, Meizhen (57204286385); Allen, Carl (58435398200); Tu, Zhaopeng (52164571000); Sachan, Mrinmaya (36094978300)",57224532589; 57610296600; 57204286385; 58435398200; 52164571000; 36094978300,Adapters for Enhanced Modeling of Multilingual Knowledge and Text,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149830097&partnerID=40&md5=bf1136a31b487ea937e04c56d7fe2ad7,"Large language models appear to learn facts from the large text corpora they are trained on. Such facts are encoded implicitly within their many parameters, making it difficult to verify or manipulate what knowledge has been learned. Language models have recently been extended to multilingual language models (MLLMs), enabling knowledge to be learned across hundreds of languages. Meanwhile, knowledge graphs contain facts in an explicit triple format, which require careful and costly curation and are only available in a few high-resource languages, restricting their research and application. To address these issues, we propose to enhance MLLMs with knowledge from multilingual knowledge graphs (MLKGs) so as to tackle language and knowledge graph tasks across many languages, including low-resource ones. Specifically, we introduce a lightweight adapter set to enhance MLLMs with cross-lingual entity alignment and facts from MLKGs for many languages. Experiments on common benchmarks show that such enhancement benefits both MLLMs and MLKGs, achieving: (1) comparable or improved performance for knowledge graph completion and entity alignment relative to baselines, especially for low-resource languages (for which knowledge graphs are unavailable); and (2) improved MLLM performance on language understanding tasks that require multilingual factual knowledge; all while maintaining performance on other general language tasks. © 2022 Association for Computational Linguistics.",Final,
Remy F.; Demuynck K.; Demeester T.,"Remy, François (57931756200); Demuynck, Kris (6602829411); Demeester, Thomas (35415697600)",57931756200; 6602829411; 35415697600,BioLORD: Learning Ontological Representations from Definitions for Biomedical Concepts and their Textual Descriptions,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149817343&partnerID=40&md5=439fa9d9f0dcb791d634ce790123f2a1,"This work introduces BioLORD, a new pretraining strategy for producing meaningful representations for clinical sentences and biomedical concepts. State-of-the-art methodologies operate by maximizing the similarity in representation of names referring to the same concept, and preventing collapse through contrastive learning. However, because biomedical names are not always self-explanatory, it sometimes results in non-semantic representations. BioLORD overcomes this issue by grounding concept representations using definitions, as well as short descriptions derived from a multi-relational knowledge graph consisting of biomedical ontologies. Thanks to this grounding, our model produces more semantic concept representations that match more closely the hierarchical structure of ontologies. BioLORD establishes a new state of the art for text similarity on both clinical sentences (MedSTS) and biomedical concepts (MayoSRS). © 2022 Association for Computational Linguistics.",Final,
Hu Z.; Gutiérrez-Basulto V.; Xiang Z.; Li R.; Pan J.Z.,"Hu, Zhiwei (57204826103); Gutiérrez-Basulto, Víctor (36607853700); Xiang, Zhiliang (57701809900); Li, Ru (57192310904); Pan, Jeff Z. (8856621200)",57204826103; 36607853700; 57701809900; 57192310904; 8856621200,Transformer-based Entity Typing in Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149438605&partnerID=40&md5=722db63c4c3238845fc85a0db7e206e7,"We investigate the knowledge graph entity typing task which aims at inferring plausible entity types. In this paper, we propose a novel Transformer-based Entity Typing (TET) approach, effectively encoding the content of neighbors of an entity. More precisely, TET is composed of three different mechanisms: a local transformer allowing to infer missing types of an entity by independently encoding the information provided by each of its neighbors; a global transformer aggregating the information of all neighbors of an entity into a single long sequence to reason about more complex entity types; and a context transformer integrating neighbors content based on their contribution to the type inference through information exchange between neighbor pairs. Furthermore, TET uses information about class membership of types to semantically strengthen the representation of an entity. Experiments on two real-world datasets demonstrate the superior performance of TET compared to the state-of-the-art. © 2022 Association for Computational Linguistics.",Final,
Ding W.; Chen H.; Li H.; Qu Y.,"Ding, Wentao (57149612700); Chen, Hao (57933748700); Li, Huayu (57933787800); Qu, Yuzhong (8400208900)",57149612700; 57933748700; 57933787800; 8400208900,Semantic Framework based Query Generation for Temporal Question Answering over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149440637&partnerID=40&md5=0a161a24d0a24534c46c5ff7701c5bfd,"Answering factual questions with temporal intent over knowledge graphs (temporal KGQA) attracts rising attention in recent years. In the generation of temporal queries, existing KGQA methods ignore the fact that some intrinsic connections between events can make them temporally related, which may limit their capability. We systematically analyze the possible interpretation of temporal constraints and conclude the interpretation structures as the Semantic Framework of Temporal Constraints, SF-TCons. Based on the semantic framework, we propose a temporal question answering method, SF-TQA, which generates query graphs by exploring the relevant facts of mentioned entities, where the exploring process is restricted by SF-TCons. Our evaluations show that SF-TQA significantly outperforms existing methods on two benchmarks over different knowledge graphs. © 2022 Association for Computational Linguistics.",Final,
Jin Z.; Cao P.; Chen Y.; Liu K.; Zhao J.,"Jin, Zhuoran (57331118600); Cao, Pengfei (57205099786); Chen, Yubo (57935192700); Liu, Kang (55729555700); Zhao, Jun (57190004147)",57331118600; 57205099786; 57935192700; 55729555700; 57190004147,"A Good Neighbor, A Found Treasure: Mining Treasured Neighbors for Knowledge Graph Entity Typing",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149436025&partnerID=40&md5=e3841d97d078e5764e6eb7393a1e55e2,"The task of knowledge graph entity typing (KGET) aims to infer the missing types for entities in knowledge graphs. Some pioneering work has proved that neighbor information is essential for the task. However, existing methods only leverage the one-hop neighbor information of the central entity, ignoring the multi-hop neighbor information that can provide valuable clues for inference. Besides, we also observe that there are co-occurrence relations between types, which is very helpful in alleviating the false-negative problem. In this paper, we propose a novel method called Mining Treasured Neighbors (MiNer) to make use of these two characteristics. Firstly, we devise a Neighbor Information Aggregation module to aggregate the neighbor information. Then, we propose an Entity Type Inference module to mitigate the adverse impact of the irrelevant neighbor information. Finally, a Type Co-occurrence Regularization module is designed to prevent the model from overfitting the false-negative examples caused by missing types. Experimental results on two widely used datasets indicate that our approach significantly outperforms previous state-of-the-art methods. © 2022 Association for Computational Linguistics.",Final,
Zheng C.; Wang Y.; Jia X.,"Zheng, Can (57855591900); Wang, Yanshan (55246542700); Jia, Xiaowei (56589359200)",57855591900; 55246542700; 56589359200,Graph-Augmented Cyclic Learning Framework for Similarity Estimation of Medical Clinical Notes,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139001908&doi=10.1109%2fICHI54592.2022.00026&partnerID=40&md5=adba35287193ff27c4d87845190319d2,"Semantic textual similarity (STS) in the clinical domain helps improve diagnostic efficiency and produce concise texts for downstream data mining tasks. However, given the high degree of domain knowledge involved in clinic text, it remains challenging for general language models to infer implicit medical relationships behind clinical sentences and output similarities correctly. In this paper, we present a graph-augmented cyclic learning framework for similarity estimation in the clinical domain. The framework can be conveniently implemented on a state-of-art backbone language model, and improve its performance by leveraging domain knowledge through co-training with an auxiliary graph convolution network (GCN) based network. We report the success of introducing domain knowledge in GCN and the co-training framework by improving the Bio-clinical BERT baseline by 16.3% and 27.9%, respectively.  © 2022 IEEE.",Final,All Open Access; Green Open Access
Ye X.; Yavuz S.; Hashimoto K.; Zhou Y.; Xiong C.,"Ye, Xi (57217225613); Yavuz, Semih (57207854542); Hashimoto, Kazuma (56576913200); Zhou, Yingbo (57204047196); Xiong, Caiming (37017840800)",57217225613; 57207854542; 56576913200; 57204047196; 37017840800,RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145276718&partnerID=40&md5=4cb751a52270934785c67f54ae272dd3,"Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-of-the-art results on GRAILQA and WEBQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GRAILQA leaderboard. In addition, RnG-KBQA outperforms all prior approaches on the popular WEBQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization. © 2022 Association for Computational Linguistics.",Final,
Zosa E.; Boros E.; Koloski B.; Pivovarova L.,"Zosa, Elaine (57211409420); Boros, Emanuela (36605783500); Koloski, Boshko (57222028629); Pivovarova, Lidia (36697047700)",57211409420; 36605783500; 57222028629; 36697047700,"EMBEDDIA at SemEval-2022 Task 8: Investigating Sentence, Image, and Knowledge Graph Representations for Multilingual News Article Similarity",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137563843&partnerID=40&md5=99637a60423f8764c34e5ade600aa683,"In this paper, we present the participation of the EMBEDDIA team in the SemEval-2022 Task 8 (Multilingual News Article Similarity). We cover several techniques and propose different methods for finding the multilingual news article similarity by exploring the dataset in its entirety. We take advantage of the textual content of the articles, the provided metadata (e.g., titles, keywords, topics), the translated articles, the images (those that were available), and knowledge graph-based representations for entities and relations present in the articles. We, then, compute the semantic similarity between the different features and predict through regression the similarity scores. Our findings show that, while our proposed methods obtained promising results, exploiting the semantic textual similarity with sentence representations is unbeatable. Finally, in the official SemEval-2022 Task 8, we ranked fifth in the overall team ranking cross-lingual results, and second in the English-only results. © 2022 Association for Computational Linguistics.",Final,
De Giorgis S.; Gangemi A.; Damiano R.,"De Giorgis, Stefano (57194034894); Gangemi, Aldo (55605133800); Damiano, Rossana (7103083846)",57194034894; 55605133800; 7103083846,Basic Human Values and Moral Foundations Theory in ValueNet Ontology,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140482396&doi=10.1007%2f978-3-031-17105-5_1&partnerID=40&md5=cf688174203d8ce76f9ab72ee7829f8d,"Values, as intended in ethics, determine the shape and validity of moral and social norms, grounding our everyday individual and community behavior on commonsense knowledge. The attempt to untangle human moral and social value-oriented structure of relations requires investigating both the dimension of subjective human perception of the world, and socio-cultural dynamics and multi-agent social interactions. Formalising latent moral content in human interaction is an appealing perspective that would enable a deeper understanding of both social dynamics and individual cognitive and behavioral dimension. To formalize this broad knowledge area, in the context of ValueNet, a modular ontology representing and operationalising moral and social values, we present two modules aiming at representing two main informal theories in literature: (i) the Basic Human Values theory by Shalom Schwartz and (ii) the Moral Foundations Theory by Graham and Haidt. ValueNet is based on reusable Ontology Design Patterns, is aligned to the DOLCE foundational ontology, and is a component of the Framester factual-linguistic knowledge graph. © 2022, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Yu C.; Zhang H.; Song Y.; Ng W.,"Yu, Changlong (57211937170); Zhang, Hongming (57202439109); Song, Yangqiu (14039604300); Ng, Wilfred (7401613441)",57211937170; 57202439109; 14039604300; 7401613441,CoCoLM: Complex Commonsense Enhanced Language Model with Discourse Relations,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145927071&partnerID=40&md5=7ab61d05913b23a61a18cd67377d3d26,"Large-scale pre-trained language models have demonstrated strong knowledge representation ability. However, recent studies suggest that even though these giant models contain rich simple commonsense knowledge (e.g., bird can fly and fish can swim.), they often struggle with complex commonsense knowledge that involves multiple eventualities (verb-centric phrases, e.g., identifying the relationship between “Jim yells at Bob” and “Bob is upset”). To address this issue, in this paper, we propose to help pre-trained language models better incorporate complex commonsense knowledge. Unlike direct finetuning approaches, we do not focus on a specific task and instead propose a general language model named CoCoLM. Through the careful training over a large-scale eventuality knowledge graph ASER, we successfully teach pre-trained language models (i.e., BERT and RoBERTa) rich discourse-level commonsense knowledge among eventualities. Experiments on multiple commonsense tasks that require the correct understanding of eventualities demonstrate the effectiveness of CoCoLM. © 2022 Association for Computational Linguistics.",Final,
Moiseev F.; Dong Z.; Alfonseca E.; Jaggi M.,"Moiseev, Fedor (57216614609); Dong, Zhe (57219621355); Alfonseca, Enrique (8966688000); Jaggi, Martin (35190508300)",57216614609; 57219621355; 8966688000; 35190508300,SKILL: Structured Knowledge Infusion for Large Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138332978&partnerID=40&md5=ec022641069053410f5fe5656b238e55,"Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3× improvement of exact match score on MetaQA task compared to T5 baseline. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs. © 2022 Association for Computational Linguistics.",Final,
Liang X.; Wu S.; Li M.; Li Z.,"Liang, Xinnian (57221153056); Wu, Shuangzhi (56368117400); Li, Mu (35110581300); Li, Zhoujun (56024684400)",57221153056; 56368117400; 35110581300; 56024684400,Modeling Multi-Granularity Hierarchical Features for Relation Extraction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138364619&partnerID=40&md5=b3f0fc00cc400a271ae01b7dd74304aa,"Relation extraction is a key task in Natural Language Processing (NLP), which aims to extract relations between entity pairs from given texts. Recently, relation extraction (RE) has achieved remarkable progress with the development of deep neural networks. Most existing research focuses on constructing explicit structured features using external knowledge such as knowledge graph and dependency tree. In this paper, we propose a novel method to extract multi-granularity features based solely on the original input sentences. We show that effective structured features can be attained even without external knowledge. Three kinds of features based on the input sentences are fully exploited, which are in entity mention level, segment level, and sentence level. All the three are jointly and hierarchically modeled. We evaluate our method on three public benchmarks: SemEval 2010 Task 8, Tacred, and Tacred Revisited. To verify the effectiveness, we apply our method to different encoders such as LSTM and BERT. Experimental results show that our method significantly outperforms existing state-of-the-art models that even use external knowledge. Extensive analyses demonstrate that the performance of our model is contributed by the capture of multi-granularity features and the model of their hierarchical structure. Code and data are available at https://github.com/xnliang98/sms. © 2022 Association for Computational Linguistics.",Final,
,,,"Proceedings of the 16th Linguistic Annotation Workshop, LAW 2022 - held in conjunction with the Language Resources and Evaluation Conference, LREC 2022 Workshop",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145992601&partnerID=40&md5=74977f6c39692497ac0cfa565716014b,The proceedings contain 20 papers. The topics discussed include: automatic approach for building dataset of citation functions for COVID-19; the development of a comprehensive Spanish dictionary for phonetic and lexical tagging in socio-phonetic research (ESPADA); converting the Sinica treebank of mandarin Chinese to universal dependencies; desiderata for the annotation of information structure in complex sentences; the sensitivity of annotator bias to task definitions in argument mining; NLP in human rights research: extracting knowledge graphs about police and army units and their commanders; advantages of a complex multilayer annotation scheme: the case of the Prague dependency treebank; annotation of messages from social media for influencer detection; Midas loop: a prioritized human-in-the-loop annotation for large scale; and building a biomedical full-text part-of-speech corpus semi-automatically.,Final,
Maharana A.; Bansal M.,"Maharana, Adyasha (57194338660); Bansal, Mohit (16466939600)",57194338660; 16466939600,GRADA: Graph Generative Data Augmentation for Commonsense Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137743286&partnerID=40&md5=c3da7da024bb402f8be1ca885e021a5c,"Recent advances in commonsense reasoning have been fueled by the availability of large-scale human annotated datasets. Manual annotation of such datasets, many of which are based on existing knowledge bases, is expensive and not scalable. Moreover, it is challenging to build augmentation data for commonsense reasoning because the synthetic questions need to adhere to real-world scenarios. Hence, we present GRADA, a graph-generative data augmentation framework to synthesize factual data samples from knowledge graphs for commonsense reasoning datasets. First, we train a graph-to-text model for conditional generation of questions from graph entities and relations. Then, we train a generator with GAN loss to generate distractors for synthetic questions. Our approach improves performance for SocialIQA, CODAH, HellaSwag and CommonsenseQA, and works well for generative tasks like ProtoQA. We show improvement in robustness to semantic adversaries after training with GRADA and provide human evaluation of the quality of synthetic datasets in terms of factuality and answerability. Our work provides evidence and encourages future research into graph-based generative data augmentation. © 2022 Association for Computational Linguistics.",Final,
Deng Z.; Zhu Y.; Qi Q.; Witbrock M.; Riddle P.,"Deng, Zhenyun (56449898500); Zhu, Yonghua (56674877400); Qi, Qianqian (57883379300); Witbrock, Michael (6602830183); Riddle, Patricia (8948904700)",56449898500; 56674877400; 57883379300; 6602830183; 8948904700,Explicit Graph Reasoning Fusing Knowledge and Contextual Information for Multi-hop Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137668195&partnerID=40&md5=48dd0863e68e57cf0467157f48129533,"Current graph-neural-network-based (GNN-based) approaches to multi-hop questions integrate clues from scattered paragraphs in an entity graph, achieving implicit reasoning by synchronous update of graph node representations using information from neighbours; this is poorly suited for explaining how clues are passed through the graph in hops. In this paper, we describe a structured Knowledge and contextual Information Fusion GNN (KIFGraph) whose explicit multi-hop graph reasoning mimics human step by step reasoning. Specifically, we first integrate clues at multiple levels of granularity (question, paragraph, sentence, entity) as nodes in the graph, connected by edges derived using structured semantic knowledge, then use a contextual encoder to obtain the initial node representations, followed by step-by-step two-stage graph reasoning that asynchronously updates node representations. Each node can be related to its neighbour nodes through fused structured knowledge and contextual information, reliably integrating their answer clues. Moreover, a masked attention mechanism (MAM) filters out noisy or redundant nodes and edges, to avoid ineffective clue propagation in graph reasoning. Experimental results show performance competitive with published models on the HotpotQA dataset. © 2022 Association for Computational Linguistics.",Final,
Ramli I.; Krisnadhi A.A.; Prasojo R.E.,"Ramli, Inigo (57964275600); Krisnadhi, Adila Alfa (23467371600); Prasojo, Radityo Eko (56406407700)",57964275600; 23467371600; 56406407700,"IndoKEPLER, IndoWiki, and IndoLAMA: A Knowledge-enhanced Language Model, Dataset, and Benchmark for the Indonesian Language",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141842381&doi=10.1109%2fIWBIS56557.2022.9924844&partnerID=40&md5=82b99fe57f26c7a770c8c463093bf607,"Pretrained language models posses an ability to learn the structural representation of a natural language by processing unstructured textual data. However, the current language model design lacks the ability to learn factual knowledge from knowledge graphs. Several attempts have been made to address this issue, such as the development of KEPLER. KEPLER combines the BERT language model and TransE knowledge embedding method to achieve a language model that can incorporate knowledge graphs as training data. Unfortunately, such knowledge enhanced language model is not yet available for the Indonesian language. In this experiment, we propose IndoKEPLER: a language model trained usingWikipedia Bahasa Indonesia andWikidata. We also create a new knowledge probing benchmark named IndoLAMA to test the ability of a language model to recall factual knowledge. The benchmark is based on LAMA, which is designed to test the suitability of our language model to be used as a knowledge base. IndoLAMA tests a language model by giving cloze style question and compare the prediction of the model to the factually correct answer. This experiment shows that IndoKEPLER increases the ability of a normal DistilBERT model to recall factual knowledge by 0.8%. Moreover, the most significant increase happens when dealing with many-to-one relationships, where IndoKEPLER outperforms it's original text encoder model by 3%.  © 2022 IEEE.",Final,
Shang C.; Wang G.; Qi P.; Huang J.,"Shang, Chao (57202291768); Wang, Guangtao (57216613192); Qi, Peng (57190487937); Huang, Jing (57211716889)",57202291768; 57216613192; 57190487937; 57211716889,Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140438205&partnerID=40&md5=3f04bdf11c545a746c0828bec606e3f8,"Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG. © 2022 Association for Computational Linguistics.",Final,
Jin Z.; Men T.; Yuan H.; He Z.; Sui D.; Wang C.; Xue Z.; Chen Y.; Zhao J.,"Jin, Zhuoran (57331118600); Men, Tianyi (58122130000); Yuan, Hongbang (58121681600); He, Zhitao (58121980600); Sui, Dianbo (57216695834); Wang, Chenhao (57214862680); Xue, Zhipeng (57222420705); Chen, Yubo (57935192700); Zhao, Jun (57190004147)",57331118600; 58122130000; 58121681600; 58121980600; 57216695834; 57214862680; 57222420705; 57935192700; 57190004147,A Knowledge Graph Embedding Toolkit and Benchmark for Representing Multi-source and Heterogeneous Knowledge,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140374897&partnerID=40&md5=f5bb6b5688aab68d9dee222835700c16,"In this paper, we propose, a knowledge graph embedding (KGE) toolkit, which aims to represent the multi-source and heterogeneous knowledge. For multi-source knowledge, unlike existing methods that mainly focus on entity-centric world knowledge, CogKGE also supports the representations of event-centric world knowledge, commonsense knowledge and linguistic knowledge. For heterogeneous knowledge, besides structured triple facts, CogKGE leverages additional unstructured information, such as text descriptions, node types and temporal information, to enhance the meaning of embeddings. Moreover, CogKGE aims to provide a unified programming framework for KGE tasks and a series of knowledge representations for downstream tasks. As a research framework, CogKGE consists of five parts, including core, data, model, knowledge and adapter module. As a knowledge discovery toolkit, CogKGE provides pre-trained embedders to discover new facts, cluster entities and check facts. Furthermore, we construct two new benchmark datasets for further research on multi-source heterogeneous KGE tasks: EventKG240K and CogNet360K. We also release an online system1 to discover knowledge visually. Source code, datasets and pre-trained embeddings are publicly available at GitHub2, with a short instruction video3 © 2022 Association for Computational Linguistics.",Final,
Luo Z.; Ghosh S.; Guillory D.; Kato K.; Darrell T.; Xu H.,"Luo, Zhekun (57219483609); Ghosh, Shalini (55369873100); Guillory, Devin (57202588855); Kato, Keizo (57116882200); Darrell, Trevor (7003377605); Xu, Huijuan (57157552100)",57219483609; 55369873100; 57202588855; 57116882200; 7003377605; 57157552100,Disentangled Action Recognition with Knowledge Bases,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138427602&partnerID=40&md5=29a46edd15f33034654ace2b5958d6b7,"Action in video usually involves the interaction of human with objects. Action labels are typically composed of various combinations of verbs and nouns, but we may not have training data for all possible combinations. In this paper, we aim to improve the generalization ability of the compositional action recognition model to novel verbs or novel nouns that are unseen during training time, by leveraging the power of knowledge graphs. Previous work utilizes verb-noun compositional action nodes in the knowledge graph, making it inefficient to scale since the number of compositional action nodes grows quadratically with respect to the number of verbs and nouns. To address this issue, we propose our approach: Disentangled Action Recognition with Knowledge-bases (DARK), which leverages the inherent compositionality of actions. DARK trains a factorized model by first extracting disentangled feature representations for verbs and nouns, and then predicting classification weights using relations in external knowledge graphs. The type constraint between verb and noun is extracted from external knowledge bases and finally applied when composing actions. DARK has better scalability in the number of objects and verbs, and achieves state-of-the-art performance on the Charades dataset. We further propose a new benchmark split based on the Epic-kitchen dataset which is an order of magnitude bigger in the numbers of classes and samples, and benchmark various models on this benchmark. © 2022 Association for Computational Linguistics.",Final,
Vasilogamvrakis N.; Koliopoulou M.; Sfakakis M.; Giannoulopoulou G.,"Vasilogamvrakis, Nikos (57581705600); Koliopoulou, Maria (56134709400); Sfakakis, Michalis (6506370379); Giannoulopoulou, Giannoula (56584454700)",57581705600; 56134709400; 6506370379; 56584454700,Testing the Word-Based Model in the Ontological Analysis of Modern Greek Derivational Morphology,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137991670&doi=10.1007%2f978-3-031-15743-1_52&partnerID=40&md5=a41c235f1cb327b3d2d801034baef968,"In the present article we explore the Item and Process (IP) approach - frequently known as Word-Based (WB) - as a theoretical model to ontologically represent the interconnection between derivatives of Modern Greek (MG). The model puts emphasis on the word as an indivisible base unit, the template rules to which words are subsumed to form new ones and the kind of relationships they establish. After a brief MG morphological analysis and the representation of various WB formation rules we proceed to test those on the MMoOn model in order to check its ontological expressiveness. In doing so we adopt an as possible top-down approach so that templates dynamically link to their respective lexical instances. Although the model generally satisfies the IP paradigm specifications it seems deficient in dealing with MG language-specific derivational rules or directional peculiarities and not very persuasive in terms of input-output categorial change representation as well as in dealing with derivatives at lexical-to-hyper-lexical level. To tackle these issues, we propose possible solutions and present their advantages in each case. © 2022, Springer Nature Switzerland AG.",Final,
Kim Y.J.; Kwak B.-W.; Kim Y.; Amplayo R.K.; Hwang S.-W.; Yeo J.,"Kim, Yu Jin (58741727900); Kwak, Beong-Woo (57440717600); Kim, Youngwook (57440816700); Amplayo, Reinald Kim (57194033228); Hwang, Seung-Won (9734566500); Yeo, Jinyoung (55522655700)",58741727900; 57440717600; 57440816700; 57194033228; 9734566500; 55522655700,Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138321335&partnerID=40&md5=56fb7baef656fa0faa8a6fe6271c9bd3,"Commonsense reasoning systems should be able to generalize to diverse reasoning cases. However, most state-of-the-art approaches depend on expensive data annotations and over-fit to a specific benchmark without learning how to perform general semantic reasoning. To overcome these drawbacks, zero-shot QA systems have shown promise as a robust learning scheme by transforming a commonsense knowledge graph (KG) into synthetic QA-form samples for model training. Considering the increasing type of different commonsense KGs, this paper aims to extend the zero-shot transfer learning scenario into multiple-source settings, where different KGs can be utilized synergetically. Towards this goal, we propose to mitigate the loss of knowledge from the interference among the different knowledge sources, by developing a modular variant of the knowledge aggregation as a new zero-shot commonsense reasoning framework. Results on five commonsense reasoning benchmarks demonstrate the efficacy of our framework, improving the performance with multiple KGs. © 2022 Association for Computational Linguistics.",Final,
Aglionby G.; Teufel S.,"Aglionby, Guy (57324841000); Teufel, Simone (55930364000)",57324841000; 55930364000,Identifying relevant common sense information in knowledge graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137693898&partnerID=40&md5=a8d4ff6a7c3a4de346b46a3e4c3b69b7,"Knowledge graphs are often used to store common sense information that is useful for various tasks. However, the extraction of contextually-relevant knowledge is an unsolved problem, and current approaches are relatively simple. Here we introduce a triple selection method based on a ranking model and find that it improves question answering accuracy over existing methods. We additionally investigate methods to ensure that extracted triples form a connected graph. Graph connectivity is important for model interpretability, as paths are frequently used as explanations for the reasoning that connects question and answer. © 2022 Association for Computational Linguistics.",Final,
Bai Y.; Lv X.; Li J.; Hou L.; Qu Y.; Dai Z.; Xiong F.,"Bai, Yushi (57275220300); Lv, Xin (57211203656); Li, Juanzi (8304332600); Hou, Lei (56622056400); Qu, Yincen (57426107100); Dai, Zelin (57223747910); Xiong, Feiyu (57217171492)",57275220300; 57211203656; 8304332600; 56622056400; 57426107100; 57223747910; 57217171492,SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144945241&partnerID=40&md5=686622fc08d3d4e533bc74b1ac659440,"Multi-hop knowledge graph (KG) reasoning has been widely studied in recent years to provide interpretable predictions on missing links with evidential paths. Most previous works use reinforcement learning (RL) based methods that learn to navigate the path towards the target entity. However, these methods suffer from slow and poor convergence, and they may fail to infer a certain path when there is a missing edge along the path. Here we present SQUIRE, the first Sequence-to-sequence based multi-hop reasoning framework, which utilizes an encoder-decoder Transformer structure to translate the query to a path. Our framework brings about two benefits: (1) It can learn and predict in an end-to-end fashion, which gives better and faster convergence; (2) Our transformer model does not rely on existing edges to generate the path, and has the flexibility to complete missing edges along the path, especially in sparse KGs. Experiments on standard and sparse KGs show that our approach yields significant improvement over prior methods, while converging 4x-7x faster. © 2022 Association for Computational Linguistics.",Final,
Hu Z.; Xu Y.; Yu W.; Wang S.; Yang Z.; Zhu C.; Chang K.-W.; Sun Y.,"Hu, Ziniu (57195286594); Xu, Yichong (57195953104); Yu, Wenhao (57209227271); Wang, Shuohang (57191852679); Yang, Ziyi (58737023400); Zhu, Chenguang (57210636804); Chang, Kai-Wei (24502911300); Sun, Yizhou (25823970300)",57195286594; 57195953104; 57209227271; 57191852679; 58737023400; 57210636804; 24502911300; 25823970300,Empowering Language Models with Knowledge Graph Reasoning for Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140200159&partnerID=40&md5=cc21b0286089e8fcaf534126a3c44662,"Answering open-domain questions requires world knowledge about in-context entities. As pre-trained Language Models (LMs) lack the power to store all required knowledge, external knowledge sources, such as knowledge graphs, are often used to augment LMs. In this work, we propose knOwledge REasOning empowered Language Model (OREOLM), which consists of a novel Knowledge Interaction Layer that can be flexibly plugged into existing Transformer-based LMs to interact with a differentiable Knowledge Graph Reasoning module collaboratively. In this way, LM guides KG to walk towards the desired answer, while the retrieved knowledge improves LM. By adopting OREOLM to RoBERTa and T5, we show significant performance gain, achieving state-of-art results in the Closed-Book setting. The performance enhancement is mainly from the KG reasoning's capacity to infer missing relational facts. In addition, OREOLM provides reasoning paths as rationales to interpret the model's decision. © 2022 Association for Computational Linguistics.",Final,
Jung Y.-H.; Park J.-H.; Choi J.-Y.; Lee M.; Kim J.; Kim K.-M.; Lee S.,"Jung, Yong-Ho (58122245700); Park, Jun-Hyung (57204908433); Choi, Joon-Young (58121794300); Lee, Mingyu (57226816346); Kim, Junho (58033038500); Kim, Kang-Min (57195197726); Lee, SangKeun (56152308000)",58122245700; 57204908433; 58121794300; 57226816346; 58033038500; 57195197726; 56152308000,Learning from Missing Relations: Contrastive Learning with Commonsense Knowledge Graphs for Commonsense Inference,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140203309&partnerID=40&md5=fcffb8da91f81363e6d9ab00c3489271,"Commonsense inference poses a unique challenge to reason and generate the physical, social, and causal conditions of a given event. Existing approaches to commonsense inference utilize commonsense transformers, which are large-scale language models that learn commonsense knowledge graphs. However, they suffer from a lack of coverage and expressive diversity of the graphs, resulting in a degradation of the representation quality. In this paper, we focus on addressing missing relations in commonsense knowledge graphs, and propose a novel contrastive learning framework called SOLAR. Our framework contrasts sets of semantically similar and dissimilar events, learning richer inferential knowledge compared to existing approaches. Empirical results demonstrate the efficacy of SOLAR in commonsense inference of diverse commonsense knowledge graphs. Specifically, SOLAR outperforms the state-of-the-art commonsense transformer on commonsense inference with ConceptNet by 1.84% on average among 8 automatic evaluation metrics. In-depth analysis of SOLAR sheds light on the effects of the missing relations utilized in learning commonsense knowledge graphs. © 2022 Association for Computational Linguistics.",Final,
Gao S.; Hwang J.D.; Kanno S.; Wakaki H.; Mitsufuji Y.; Bosselut A.,"Gao, Silin (57710377800); Hwang, Jena D. (35109145400); Kanno, Saya (57905252300); Wakaki, Hiromi (57903831200); Mitsufuji, Yuki (55967134100); Bosselut, Antoine (57193225759)",57710377800; 35109145400; 57905252300; 57903831200; 55967134100; 57193225759,ComFact: A Benchmark for Linking Contextual Commonsense Knowledge,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144325054&partnerID=40&md5=016deb8e2f39ebe0c506b38a7cd28b3c,"Understanding rich narratives, such as dialogues and stories, often requires natural language processing systems to access relevant knowledge from commonsense knowledge graphs. However, these systems typically retrieve facts from KGs using simple heuristics that disregard the complex challenges of identifying situationally-relevant commonsense knowledge (e.g., contextualization, implicitness, ambiguity). In this work, we propose the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs. Our novel benchmark, ComFact, contains ∼293k in-context relevance annotations for commonsense triplets across four stylistically diverse dialogue and storytelling datasets. Experimental results confirm that heuristic fact linking approaches are imprecise knowledge extractors. Learned fact linking models demonstrate across-the-board performance improvements (∼34.6% F1) over these heuristics. Furthermore, improved knowledge retrieval yielded average downstream improvements of 9.8% for a dialogue response generation task. However, fact linking models still significantly underperform humans, suggesting our benchmark is a promising testbed for research in commonsense augmentation of NLP systems. © 2022 Association for Computational Linguistics.",Final,
Sreekantan J.; Hutchison C.; Amatya P.,"Sreekantan, Jaijith (57564798800); Hutchison, Chad (57987934800); Amatya, Pratuat (57987934900)",57564798800; 57987934800; 57987934900,Expert System for Question Answering on Anomalous Events and Mitigation Strategies Using Bidirectional Transformers and Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143069310&doi=10.2118%2f211855-MS&partnerID=40&md5=95026fb04238744a2ac457d932bb8cc9,"Daily drilling reports provide vital information for well planning as they capture anomalous events and mitigation measures during drilling operations. Previous works predominantly focus on search frameworks for information retrieval from these reports. However, the context between searches is lost, preventing users from narrowing down to the exact answer. Here, we present a transformer-based closed domain conversational agent for longer dialogues to guide users to contextual information for anomalous drilling events through natural language. Automated text extraction, cleaning and validation tasks are initially performed to resolve data quality issues prior to language modeling on a validated data set. Subsequently, a knowledge-based graph is created by node embedding using entity extractions and by learning the semantic-level relationships between entity nodes such as well names and events. Further, conversational agents are trained on the knowledge graphs for natural dialogue generation using neural machine translation models. Here, users' questions are translated into a query in a structured language that is evaluated directly over the knowledge graph in order to generate the desired answers. The workflow was tested on an asset with multiple wells experiencing several anomalous events during drilling such as stuck pipe, circulation losses and kicks. The end-to-end workflow was tested on its ability to retrieve anomalous events and present mitigation measures in the aforementioned data set based on the descriptions input by survey participants. Performance on the anomaly extraction, attribute mapping and mitigation performance were evaluated through F1 scores. A significantly high F1 score was recorded for anomaly extraction. This is predominantly driven by high precision due to explicit modeling of the reports as a knowledge graph. In addition to testing the workflow end to end, we tested the knowledge graph representation in isolation. For this, ranking metrics and triple classification with negative samples were used for the evaluation. The adjusted mean rank index was close to one, indicating high performance. Structured querying on the knowledge graphs also showed high accuracy for classifying anomalous events in the drilling report. The work described in this paper automates the end-to-end workflow for building an expert system for answering questions about anomalous events and mitigation strategies using daily drilling reports. Our novel approach using a knowledge graph with a transformer-based conversational agent enables users to perform detailed interactive investigation of anomalous events observed in daily drilling reports and create mitigation strategies. The workflow also allows for incorporating prior domain knowledge from drilling experts. Copyright © 2022, Society of Petroleum Engineers.",Final,
Zhu Y.; Guan Z.; Wei S.; Wu B.,"Zhu, Yangfu (57716193300); Guan, Zhanming (57202891452); Wei, Siqi (57837001200); Wu, Bin (56449782000)",57716193300; 57202891452; 57837001200; 56449782000,PerKG: A Personality Knowledge Graph for Personality Analysis,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142731042&doi=10.1109%2fSMC53654.2022.9945152&partnerID=40&md5=85430689bde172236a6a373f9ee50ba4,"With the blossoming of online social networks (OSN), personality analysis based on OSN texts has gained much research attention in recent years. The previous methods mainly focus on human-designed features extracted through psychological dictionaries or semantic features extracted through language models. However, the shallow statistics features can not fully convey the personality information and the language models can not capture enough psychological background knowledge. Besides, the lack of large labeled datasets has been a serious obstacle impending further research. To tackle these problems, we propose a personality analysis model, namely PerKG, which combines personality knowledge graph and heterogeneous graph representation learning to exploit external knowledge from psycholinguistics and learn the group-level information to predict users' personalities accurately. Specifically, we construct a personality knowledge graph based on existing psycholinguistics knowledge. And then, for each user, we align the user information with the knowledge graph to obtain the personality heterogeneous graph. Finally, the personality vector of each entity node is learned for prediction by designing a walk strategy on the personality heterogeneous graph. Detailed experimentation shows that our proposed PerKG architecture can effectively improve the performance and alleviate the label sparsity problem of personality analysis.  © 2022 IEEE.",Final,
Dutt R.; Bhattacharjee K.; Gangadharaiah R.; Roth D.; Rose C.P.,"Dutt, Ritam (57205030520); Bhattacharjee, Kasturi (57219686973); Gangadharaiah, Rashmi (13608130200); Roth, Dan (7401669040); Rose, Carolyn Penstein (8097137900)",57205030520; 57219686973; 13608130200; 7401669040; 8097137900,PERKGQA: Question Answering over Personalized Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137363826&partnerID=40&md5=4197a8e1af762146bdd0e75073951480,"Previous studies on question answering over knowledge graphs have typically operated over a single knowledge graph (KG). This KG is assumed to be known a priori and is leveraged similarly for all users' queries during inference. However, such an assumption is not applicable to real-world settings, such as healthcare, where one needs to handle queries of new users over unseen KGs during inference. Furthermore, privacy concerns and high computational costs render it infeasible to query the single KG that has information about all users while answering a specific user's query. The above concerns motivate our question answering setting over personalized knowledge graphs (PERKGQA) where each user has restricted access to their KG. We observe that current state-of-the-art KGQA methods that require learning prior node representations fare poorly. We propose two complementary approaches, PATHCBR and PATHRGCN for PERKGQA. The former is a simple non-parametric technique that employs case-based reasoning; while the latter is a parametric approach using graph neural networks. Our proposed methods circumvent learning prior representations, can generalize to unseen KGs, and outperform strong baselines on an academic and an internal dataset by 6.5% and 10.5%. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Mitra S.; Ramnani R.; Sengupta S.,"Mitra, Sayantan (57219948707); Ramnani, Roshni (55252820800); Sengupta, Shubhashis (15127774600)",57219948707; 55252820800; 15127774600,Constraint-based Multi-hop Question Answering with Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137740989&partnerID=40&md5=02a4c3c72fa775f4d2a7b45c775954cb,"The objective of a Question-Answering system over Knowledge Graph (KGQA) is to respond to natural language queries presented over the KG. A complex question answering system typically addresses one of the two categories of complexity: questions with constraints and questions involving multiple hops of relations. Most of the previous works have addressed these complexities separately. Multi-hop KGQA necessitates reasoning across numerous edges of the KG in order to arrive at the correct answer. Because KGs are frequently sparse, multi-hop KGQA presents extra complications. Recent works have developed KG embedding approaches to reduce KG sparsity by performing missing link prediction. In this paper, we tried to address multi-hop constrained-based queries using KG embeddings to generate more flexible query graphs. Empirical results indicate that the proposed methodology produces state-of-the-art outcomes on three KGQA datasets. © 2022 Association for Computational Linguistics.",Final,
Li Y.; Peng B.; Shen Y.; Mao Y.; Liden L.; Yu Z.; Gao J.,"Li, Yu (57219751720); Peng, Baolin (56182809200); Shen, Yelong (56729408300); Mao, Yi (57210641199); Liden, Lars (57209191263); Yu, Zhou (57205750897); Gao, Jianfeng (55702627000)",57219751720; 56182809200; 56729408300; 57210641199; 57209191263; 57205750897; 55702627000,Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138391384&partnerID=40&md5=567e10877c64b22381fdb3d1815432d7,"Knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources. Existing systems perform poorly on unseen topics due to limited topics covered in the training data. In addition, it is challenging to generalize to the domains that require different types of knowledge sources. To address the above challenges, we present PLUG, a language model that homogenizes different knowledge sources to a unified knowledge representation for knowledge-grounded dialogue generation tasks. We first retrieve relevant information from heterogeneous knowledge sources (e.g., wiki, dictionary, or knowledge graph); Then the retrieved knowledge is transformed into text and concatenated with dialogue history to feed into the language model for generating responses. PLUG is pre-trained on a large-scale knowledge-grounded dialogue corpus. The empirical evaluation on two benchmarks shows that PLUG generalizes well across different knowledge-grounded dialogue tasks. It achieves comparable performance with state-of-the-art methods in the fully-supervised setting and significantly outperforms other approaches in zero-shot and few-shot settings. © 2022 Association for Computational Linguistics.",Final,
Yu W.; Zhu C.; Qin L.; Zhang Z.; Zhao T.; Jiang M.,"Yu, Wenhao (57209227271); Zhu, Chenguang (57210636804); Qin, Lianhui (57220825027); Zhang, Zhihan (57216615600); Zhao, Tong (57207568082); Jiang, Meng (36179647500)",57209227271; 57210636804; 57220825027; 57216615600; 57207568082; 36179647500,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137720554&partnerID=40&md5=f4974263e8c41c2706c6f6b7325aa342,"Generative commonsense reasoning (GCR) in natural language is to reason about the commonsense while generating coherent text. Recent years have seen a surge of interest in improving the generation quality of commonsense reasoning tasks. Nevertheless, these approaches have seldom investigated diversity in the GCR tasks, which aims to generate alternative explanations for a real-world situation or predict all possible outcomes. Diversifying GCR is challenging as it expects to generate multiple outputs that are not only semantically different but also grounded in commonsense knowledge. In this paper, we propose MoKGE, a novel method that diversifies the generative reasoning by a mixture of expert (MoE) strategy on commonsense knowledge graphs (KG). A set of knowledge experts seek diverse reasoning on KG to encourage various generation outputs. Empirical experiments demonstrated that MoKGE can significantly improve the diversity while achieving on par performance on accuracy on two GCR benchmarks, based on both automatic and human evaluations. © 2022 Association for Computational Linguistics.",Final,
,,,"SEMPDW 2022 - Proceedings of Poster and Demo Track and Workshop Track of the 18th International Conference on Semantic Systems, co-located with 18th International Conference on Semantic Systems, SEMANTiCS 2022",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139772009&partnerID=40&md5=3641fbc211d1a6dcd01182832ae5590d,"The proceedings contain 28 papers. The topics discussed include: attribute-based access control on solid pods using privacy-friendly credentials; language-agnostic knowledge graphs for smarter multilingual chatbots; solid proof of concept in an enterprise loan request use case; applying a mapping quality framework in cloud native monitoring; misinformation detection: using linguistic cues; a semantic policy language for usage control; proposal for PORQUE, a polylingual hybrid question answering system; Wikibase as an infrastructure for community documents: the example of the disability wiki platform; combining knowledge graphs and language models to answer questions over tables; semantifying the governance of data in Europe; towards a knowledge access & representation layer; and towards knowledge graph based services in accounting use cases.",Final,
Huang J.; Zhu K.; Chang K.C.-C.; Xiong J.; Hwu W.-M.,"Huang, Jie (57226877159); Zhu, Kerui (57712860900); Chang, Kevin Chen-Chuan (7407034942); Xiong, Jinjun (7202010057); Hwu, Wen-Mei (35584943100)",57226877159; 57712860900; 7407034942; 7202010057; 35584943100,DEER: Descriptive Knowledge Graph for Explaining Entity Relationships,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143258721&partnerID=40&md5=85e1dd8ff4c0cfe031131a914f5a7366,"We propose DEER (Descriptive Knowledge Graph for Explaining Entity Relationships) - an open and informative form of modeling entity relationships. In DEER, relationships between entities are represented by free-text relation descriptions. For instance, the relationship between entities of machine learning and algorithm can be represented as “Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.” To construct DEER, we propose a self-supervised learning method to extract relation descriptions with the analysis of dependency patterns and generate relation descriptions with a transformer-based relation description synthesizing model, where no human labeling is required. Experiments demonstrate that our system can extract and generate high-quality relation descriptions for explaining entity relationships. The results suggest that we can build an open and informative knowledge graph without human annotation. © 2022 Association for Computational Linguistics.",Final,
Zhou J.; Wang B.; Yang Z.; Zhao D.; Huang K.; He R.; Hou Y.,"Zhou, Jinfeng (57558200300); Wang, Bo (56949454300); Yang, Zhitong (58040557500); Zhao, Dongming (7403490494); Huang, Kun (57614133600); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",57558200300; 56949454300; 58040557500; 7403490494; 57614133600; 19835197000; 7402198932,CR-GIS: Improving Conversational Recommendation via Goal-aware Interest Sequence Modeling,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142184991&partnerID=40&md5=91a50c4cf3d0de54107a730016d44107,"Conversational recommendation systems (CRS) aim to determine a goal item by sequentially tracking users’ interests through multi-turn conversation. In CRS, implicit patterns of user interest sequence guide the smooth transition of dialog utterances to the goal item. However, with the convenient explicit knowledge of knowledge graph (KG), existing KG-based CRS methods over-rely on the explicit separate KG links to model the user interests but ignore the rich goal-aware implicit interest sequence patterns in a dialog. In addition, interest sequence is also not fully used to generate smooth transited utterances. We propose CR-GIS with a parallel star framework. First, an interest-level star graph is designed to model the goal-aware implicit user interest sequence. Second, a hierarchical Star Transformer is designed to guide the multi-turn utterances generation with the interest-level star graph. Extensive experiments verify the effectiveness of CR-GIS in achieving more accurate recommended items with more fluent and coherent dialog utterances. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Final,
Li Y.; Long G.; Shen T.; Jiang J.,"Li, Yang (57221624650); Long, Guodong (55522990400); Shen, Tao (57210531549); Jiang, Jing (55731807500)",57221624650; 55522990400; 57210531549; 55731807500,Hierarchical Relation-Guided Type-Sentence Alignment for Long-Tail Relation Extraction with Distant Supervision,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137373819&partnerID=40&md5=ae6d6a2ea8d98e3ee2c9efdb243aeb7d,"Distant supervision uses triple facts in knowledge graphs to label a corpus for relation extraction, leading to wrong labeling and longtail problems. Some works use the hierarchy of relations for knowledge transfer to longtail relations. However, a coarse-grained relation often implies only an attribute (e.g., domain or topic) of the distant fact, making it hard to discriminate relations based solely on sentence semantics. One solution is resorting to entity types, but open questions remain about how to fully leverage the information of entity types and how to align multi-granular entity types with sentences. In this work, we propose a novel model to enrich distantlysupervised sentences with entity types. It consists of (1) a pairwise type-enriched sentence encoding module injecting both context-free and -related backgrounds to alleviate sentencelevel wrong labeling, and (2) a hierarchical type-sentence alignment module enriching a sentence with the triple fact's basic attributes to support long-tail relations. Our model achieves new state-of-the-art results in overall and long-tail performance on benchmarks. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Brayne A.; Wiatrak M.; Corneil D.,"Brayne, Angus (57225176482); Wiatrak, Maciej (57219754264); Corneil, Dane (55364626100)",57225176482; 57219754264; 55364626100,On Masked Language Models for Contextual Link Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137741482&partnerID=40&md5=696b324416f0c1d12e8419793a25f22a,"In the real world, many relational facts require context; for instance, a politician holds a given elected position only for a particular timespan. This context (the timespan) is typically ignored in knowledge graph link prediction tasks, or is leveraged by models designed specifically to make use of it (i.e. n-ary link prediction models). Here, we show that the task of n-ary link prediction is easily performed using language models, applied with a basic method for constructing cloze-style query sentences. We introduce a pre-training methodology based around an auxiliary entity-linked corpus that outperforms other popular pre-trained models like BERT, even with a smaller model. This methodology also enables n-ary link prediction without access to any n-ary training set, which can be invaluable in circumstances where expensive and time-consuming curation of n-ary knowledge graphs is not feasible. We achieve state-of-the-art performance on the primary n-ary link prediction dataset WD50K and on WikiPeople facts that include literals - typically ignored by knowledge graph embedding methods. © 2022 Association for Computational Linguistics.",Final,
Takeuchi J.; Nishida N.; Nakayama H.,"Takeuchi, Jun (58054569200); Nishida, Noriki (57132178400); Nakayama, Hideki (35230509500)",58054569200; 57132178400; 35230509500,Neural Networks in a Product of Hyperbolic Spaces,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137553330&partnerID=40&md5=5b54bf9c6e3d85ffdf394019d0a2802b,"Machine learning in hyperbolic spaces has attracted much attention in natural language processing and many other fields. In particular, Hyperbolic Neural Networks (HNNs) have improved a wide variety of tasks, from machine translation to knowledge graph embedding. Although some studies have reported the effectiveness of embedding into the product of multiple hyperbolic spaces, HNNs have mainly been constructed in a single hyperbolic space, and their extension to product spaces has not been sufficiently studied. Therefore, we propose a novel method to extend a given HNN in a single space to a product of hyperbolic spaces. We apply our method to Hyperbolic Graph Convolutional Networks (HGCNs), extending several HNNs. Our model improved the graph node classification accuracy especially on datasets with tree-like structures. The results suggest that neural networks in a product of hyperbolic spaces can be more effective than in a single space in representing structural data. © 2022 Association for Computational Linguistics.",Final,
Mirzapour M.; Ragheb W.; Saeedizade M.J.; Cousot K.; Jacquenet H.; Carbon L.; Lafourcade M.,"Mirzapour, Mehdi (57202510815); Ragheb, Waleed (57203261378); Saeedizade, Mohammad Javad (57226168029); Cousot, Kévin (57219629869); Jacquenet, Hélène (57553639100); Carbon, Lawrence (57610141400); Lafourcade, Mathieu (23094829600)",57202510815; 57203261378; 57226168029; 57219629869; 57553639100; 57610141400; 23094829600,Introducing RezoJDM16k: a French Knowledge Graph DataSet for Link Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144446093&partnerID=40&md5=ca9c0d276d91188dd3b12cdeae4d5f5e,"Knowledge graphs applications, in industry and academia, motivate substantial research directions towards large-scale information extraction from various types of resources. Nowadays, most of the available knowledge graphs are either in English or multilingual. In this paper, we introduce RezoJDM16k, a French knowledge graph dataset based on RezoJDM (Lafourcade, 2007). With 16k nodes, 832k triplets and 53 relation types, RezoJDM16k can be employed in many NLP downstream tasks for the French language such as machine translation, question-answering and recommendation systems. In addition, we provide strong knowledge graph embedding baselines that are used in link prediction task for future benchmarking. Compared to the state-of-the-art English knowledge graph datasets used in link prediction, RezoJDM16k shows a similar promising predictive behavior. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Li T.; Huang W.; Papasarantopoulos N.; Vougiouklis P.; Pan J.Z.,"Li, Tianyi (57556584900); Huang, Wenyu (57889876900); Papasarantopoulos, Nikos (57194687567); Vougiouklis, Pavlos (57195741968); Pan, Jeff Z. (8856621200)",57556584900; 57889876900; 57194687567; 57195741968; 8856621200,Task-specific Pre-training and Prompt Decomposition for Knowledge Graph Population with Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142877507&partnerID=40&md5=2d035f40d1a80d1733ce4c1016501b28,"We present a system for knowledge graph population with Language Models, evaluated on the Knowledge Base Construction from Pre-trained Language Models (LM-KBC) challenge at ISWC 2022. Our system involves task-specific pre-training to improve LM representation of the masked object tokens, prompt decomposition for progressive generation of candidate objects, among other methods for higher-quality retrieval. Our system is the winner of track 1 of the LM-KBC challenge, based on BERT LM; it achieves 55.0% F-1 score on the hidden test set of the challenge. © 2022 Copyright for this paper by its authors.",Final,
Wang X.; He Q.; Liang J.; Xiao Y.,"Wang, Xintao (57736570700); He, Qianyu (57545515600); Liang, Jiaqing (57188696905); Xiao, Yanghua (24377046200)",57736570700; 57545515600; 57188696905; 24377046200,Language Models as Knowledge Embeddings,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137862307&partnerID=40&md5=040a9eefabb4e5dd6bbdbc3294785583,"Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental results show that LMKE achieves state-of-the-art performance on KE benchmarks of link prediction and triple classification, especially for long-tail entities. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.",Final,
Zheng C.; Kordjamshidi P.,"Zheng, Chen (57219690556); Kordjamshidi, Parisa (24476235400)",57219690556; 24476235400,"Relevant CommonSense Subgraphs for ""What if..."" Procedural Reasoning",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138887378&partnerID=40&md5=ab4a527d02f929e790ba5c2d8ec9b087,"We study the challenge of learning causal reasoning over procedural text to answer ""What if..."" questions when external commonsense knowledge is required. We propose a novel multi-hop graph reasoning model to 1) efficiently extract a commonsense subgraph with the most relevant information from a large knowledge graph; 2) predict the causal answer by reasoning over the representations obtained from the commonsense subgraph and the contextual interactions between the questions and context. We evaluate our model on WIQA benchmark and achieve state-of-the-art performance compared to the recent models. © 2022 Association for Computational Linguistics.",Final,
Leemhuis M.; Özçep Ö.L.,"Leemhuis, Mena (57219057004); Özçep, Özgür L. (36515315800)",57219057004; 36515315800,A Goodman-style Betweenness Relation on Orthoframes,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140894384&partnerID=40&md5=7cba706ec3e90f59b1c48fe652ea4c89,"Understanding inductive and deductive reasoning requires in some or other form the representation of concepts. A basic assumption underlying Gärdenfors' linguistic-cognitive framework of conceptual spaces as well as the machine-learning based framework of knowledge-graph embeddings is that concepts and reasoning over them are geometrical. The main ingredient of Gärdenfors' conceptual spaces is a ternary betweenness relation which is the basis for defining concepts as convex (= betweenness-closed) sets. Though many interesting phenomena of cognitive reasoning can be explained in the framework of conceptual spaces, it is at least not obvious how to use betweenness for other, more logico-formal aspects of reasoning that, e.g., require defining logical operators. In particular, for the logical operator of negation other mathematical structures such as the orthoframes of Goldblatt have proven more useful. In this paper, we provide first ideas and results on the connection between conceptual spaces and orthoframes. The main technical result of this paper concerns the definition of a betweenness relation within an orthoframe. The construction is an adaptation of Goodman's mereology-based betweenness relation over so-called qualia to a set-theoretic betweenness relation based on an orthoframe. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)",Final,
Silvano P.; Damova M.; Oleškevičienė G.V.; Liebeskind C.; Chiarcos C.; Trajanov D.; Truică C.-O.; Apostol E.-S.; Bączkowska A.,"Silvano, Purificação (55453450500); Damova, Mariana (36615168000); Oleškevičienė, Giedrė Valūnaitė (57194015310); Liebeskind, Chaya (55761687500); Chiarcos, Christian (22333764800); Trajanov, Dimitar (8206057700); Truică, Ciprian-Octavian (56331462000); Apostol, Elena-Simona (55365937600); Bączkowska, Anna (57197523089)",55453450500; 36615168000; 57194015310; 55761687500; 22333764800; 8206057700; 56331462000; 55365937600; 57197523089,ISO-based Annotated Multilingual Parallel Corpus for Discourse Markers,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144437814&partnerID=40&md5=61e65534587e60012fb77b759e78f8b2,"Discourse markers carry information about the discourse structure and organization, and also signal local dependencies or epistemological stance of speaker. They provide instructions on how to interpret the discourse, and their study is paramount to understand the mechanism underlying discourse organization. This paper presents a new language resource, an ISO-based annotated multilingual parallel corpus for discourse markers. The corpus comprises nine languages, Bulgarian, Lithuanian, German, European Portuguese, Hebrew, Romanian, Polish, and Macedonian, with English as a pivot language. In order to represent the meaning of the discourse markers, we propose an annotation scheme of discourse relations from ISO 24617-8 with a plug-in to ISO 24617-2 for communicative functions. We describe an experiment in which we applied the annotation scheme to assess its validity. The results reveal that, although some extensions are required to cover all the multilingual data, it provides a proper representation of discourse markers value. Additionally, we report some relevant contrastive phenomena concerning discourse markers interpretation and role in discourse. This first step will allow us to develop deep learning methods to identify and extract discourse relations and communicative functions, and to represent that information as Linguistic Linked Open Data (LLOD). © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Kumar V.; Recupero D.R.; Helaoui R.; Riboni D.,"Kumar, Vivek (57203288774); Recupero, Diego Reforgiato (57206674454); Helaoui, Rim (36141897700); Riboni, Daniele (6505466404)",57203288774; 57206674454; 36141897700; 6505466404,K-LM: Knowledge Augmenting in Language Models within the Scholarly Domain,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137594707&doi=10.1109%2fACCESS.2022.3201542&partnerID=40&md5=a0e8d3dcac0d9b6bdb529bdd5f2f2b69,"The use of superior algorithms and complex architectures in language models have successfully imparted human-like abilities to machines for specific tasks. But two significant constraints, the available training data size and the understanding of domain-specific context, hamper the pre-trained language models from optimal and reliable performance. A potential solution to tackle these limitations is to equip the language models with domain knowledge. While the commonly adopted techniques use Knowledge Graphs Embeddings (KGEs) to inject domain knowledge, we provide a Knowledge Language Model (K-LM) to use the Resource Description Framework (RDF) triples directly, extracted from world knowledge bases. The proposed model works in conjunction with Generative Pretrained Transformer (GPT-2) and Bidirectional Encoder Representations from Transformers (BERT) and uses a well-defined pipeline to select, categorize, and filter the RDF triples. In addition, we introduce heuristic methods to inject domain-specific knowledge in K-LM, leveraging knowledge graphs (KGs). We tested our approaches on the classification task within the scholarly domain using two KGs, and our results show that our proposed language model has significantly outperformed the baselines and BERT for each KG. Our experimental findings also help us conclude the importance of relevance of KG used over the quantity of injected RDF triples. Also, each of our proposed methods for injecting the RDF triples has increased the overall model&#x2019;s accuracy, demonstrating that K-LM is a potential choice for domain adaptation to solve knowledge-driven problems. Author",Article in press,All Open Access; Gold Open Access
Wu X.; Huang K.-H.; Fung Y.R.; Ji H.,"Wu, Xueqing (57268252700); Huang, Kung-Hsiang (57221142716); Fung, Yi R. (57221303250); Ji, Heng (35240121900)",57268252700; 57221142716; 57221303250; 35240121900,Cross-document Misinformation Detection based on Event Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137812995&partnerID=40&md5=5163ad20bbf4a784ddd8754638aab17c,"For emerging events, human readers are often exposed to both real news and fake news. Multiple news articles may contain complementary or contradictory information that readers can leverage to help detect fake news. Inspired by this process, we propose a novel task of cross-document misinformation detection. Given a cluster of topically related news documents, we aim to detect misinformation at both document level and a more fine-grained level, event level. Due to the lack of data, we generate fake news by manipulating real news, and construct 3 new datasets with 422, 276, and 1, 413 clusters of topically related documents, respectively. We further propose a graph-based detector that constructs a cross-document knowledge graph using cross-document event coreference resolution and employs a heterogeneous graph neural network to conduct detection at two levels. We then feed the event-level detection results into the document-level detector. Experimental results show that our proposed method significantly outperforms existing methods by up to 7 F1 points on this new task. © 2022 Association for Computational Linguistics.",Final,
,,,"9th International Conference on Mining Intelligence and Knowledge Exploration, MIKE 2021",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145275306&partnerID=40&md5=257f4e89a1b197085061dff9c71bffb1,The proceedings contain 23 papers. The special focus in this conference is on Mining Intelligence and Knowledge Exploration. The topics include: An Efficient Sample Steering Strategy for Correlation Filter Tracking; a Comparative Study on Machine Learning Based Classifier Model for Wheat Seed Classification; allocation of Overdue Loans in a Sub-Saharan Africa Microfinance Institution; automatic Model for Relation Extraction from Text Documents Using Deep Learning Neural Network; polarized Extractive Summarization of Online Product Reviews; Deep Learning Based NLP Embedding Approach for Biosequence Classification; use of Attitude Verbs as a Device to Encode States of Mind: Navigating Them Compositionally in Linguistic Discourse; CAI: Complex Ontology Alignments Using Lexical Indexation; long Short-Term Memory Recurrent Neural Network for Automatic Recognition of Spoken English Digits; harnessing Energy of M-ary Hopfield Neural Network for Connectionist Temporal Sequence Decoding; Prediction of Smoking Addiction Among Youths Using Elastic Net and KNN: A Machine Learning Approach; novel Training Methods Based Artificial Neural Network for the Dynamic Prediction of the Consumed Energy; KGChain: A Blockchain-Based Approach to Secure the Knowledge Graph Completion; enhanced Group Key Distribution Protocol for Intra Group and Inter Group Communication Using Access Control Polynomial; Integrative Analysis of miRNA-mRNA Expression Data to Identify miRNA-Targets for Oral Cancer; compact Associative Classification for Up and Down Regulated Genes Using Supervised Discretization and Clustering; Assessment of Brain Tumor in Flair MRI Slice with Joint Thresholding and Segmentation; mayfly-Algorithm Selected Features for Classification of Breast Histology Images into Benign/Malignant Class; recent Trends in Human Re-identification Techniques – A Comparative Study; automatic Segmentation of Handwritten Devanagari Word Documents Enabling Accurate Recognition.,Final,
Al Hasan Rony M.R.; Usbeck R.; Lehmann J.,"Al Hasan Rony, Md Rashad (57203302415); Usbeck, Ricardo (43661711000); Lehmann, Jens (35229806900)",57203302415; 43661711000; 35229806900,DialoKG: Knowledge-Structure Aware Task-Oriented Dialogue Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137369692&partnerID=40&md5=adc2b6471f06ce17dc1c42c3504e25d6,"Task-oriented dialogue generation is challenging since the underlying knowledge is often dynamic and effectively incorporating knowledge into the learning process is hard. It is particularly challenging to generate both humanlike and informative responses in this setting. Recent research primarily focused on various knowledge distillation methods where the underlying relationship between the facts in a knowledge base is not effectively captured. In this paper, we go one step further and demonstrate how the structural information of a knowledge graph can improve the system's inference capabilities. Specifically, we propose DialoKG, a novel task-oriented dialogue system that effectively incorporates knowledge into a language model. Our proposed system views relational knowledge as a knowledge graph and introduces (1) a structure-aware knowledge embedding technique, and (2) a knowledge graph-weighted attention masking strategy to facilitate the system selecting relevant information during the dialogue generation. An empirical evaluation demonstrates the effectiveness of DialoKG over state-of-theart methods on several standard benchmark datasets. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Jia S.; Cao J.,"Jia, Shutong (58020564900); Cao, Jiuxin (14618987100)",58020564900; 14618987100,The Method for Plausibility Evaluation of Knowledge Triple Based on QA,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144231877&doi=10.1007%2f978-981-19-8300-9_25&partnerID=40&md5=78ec483efd9282477cde1b33feea2942,"At present, most of the methods for knowledge graph completion (KGC) task highly rely on external knowledge base or graph representation learning. However, how to complete this task without using any external prior knowledge is still a huge challenge and difficulty. To this end, we propose a novel framework which converts the plausibility evaluation of knowledge triple task to the question and answer (QA) task with the thought of KG-BERT and prompt learning. We also test the effect of different question types on the results. Secondly, by fine-tuning two pre-trained language models BERT-wwm-ext and ERNIE-Gram on these generated sequences, so that they can complete the QA task. We won the 5th place at CCKS 2022 track 1 rematch stage, which proved the effectiveness of our method. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Final,
Liu J.; Fan C.; Zhou F.; Xu H.,"Liu, Jin (57212493181); Fan, Chongfeng (57813939700); Zhou, Fengyu (12646806200); Xu, Huijuan (57157552100)",57212493181; 57813939700; 12646806200; 57157552100,Syntax Controlled Knowledge Graph-to-Text Generation with Order and Semantic Consistency,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137348476&partnerID=40&md5=471b5be0f70da4a7bc807ccfbe4641aa,"The knowledge graph (KG) stores a large amount of structural knowledge, while it is not easy for direct human understanding. Knowledge graph-to-text (KG-to-text) generation aims to generate easy-to-understand sentences from the KG, and at the same time, maintains semantic consistency between generated sentences and the KG. Existing KG-to-text generation methods phrase this task as a sequence-tosequence generation task with linearized KG as input and consider the consistency issue of the generated texts and KG through a simple selection between decoded sentence word and KG node word at each time step. However, the linearized KG order is commonly obtained through a heuristic search without data-driven optimization. In this paper, we optimize the knowledge description order prediction under the order supervision extracted from the caption and further enhance the consistency of the generated sentences and KG through syntactic and semantic regularization. We incorporate the Part-of-Speech (POS) syntactic tags to constrain the positions to copy words from the KG and employ a semantic context scoring function to evaluate the semantic fitness for each word in its local context when decoding each word in the generated sentence. Extensive experiments are conducted on two datasets,WebNLG and DART, and achieve state-of-the-art performances. Our code is now public available. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Knoblach J.; Acharya N.; Koranemkattil B.; Both A.; Collarana D.,"Knoblach, Judith (57926457800); Acharya, Nikhil (57926159400); Koranemkattil, Bhavya (57926306600); Both, Andreas (23966392700); Collarana, Diego (57189311534)",57926457800; 57926159400; 57926306600; 23966392700; 57189311534,Combining Knowledge Graphs and Language Models to Answer Questions over Tables,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139795435&partnerID=40&md5=4464f7e21cde82be1f268715c88353b8,"Tables remain a primary modality for organizing and presenting information to people. We interact every day with Excel sheets, CSV files, tables in PDF documents, and web tables. Providing a natural language interface to query table information is paramount for several use cases. This demo shows a solution to query semantically described tables using natural-language questions. Our solution employs knowledge graphs as a medium to integrate tables coming from heterogeneous sources. Then, a transformer-based language model analyzes a user's question and finds the answer in the semantically represented tables. During the demo session, we will show a use case developed in collaboration with DATEV eG, where tax consultants can efficiently query information from financial tables. Attendees will experience how a natural-language interface speeds up the information retrieval process from tables. They will also be allowed to ask their questions to a prepared dataset, showing the scalability of our solution. The video demo is available at https://owncloud.fraunhofer.de/index.php/s/uXFmUfzCta70rqN. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)",Final,
Yan S.,"Yan, Sixing (57814921000)",57814921000,Memory-aligned Knowledge Graph for Clinically Accurate Radiology Image Report Generation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143263380&partnerID=40&md5=84ffa813dea0931e770a76ded1dafdc1,"Automatic generating the clinically accurate radiology report from X-ray images is important but challenging. The identification of multi-grained abnormal regions in image and corresponding abnormalities is difficult for data-driven neural models. In this work, we introduce a Memory-aligned Knowledge Graph (MaKG) of clinical abnormalities to better learn the visual patterns of abnormalities and their relationships by integrating it into a deep model architecture for the report generation. We carry out extensive experiments and show that the proposed MaKG deep model can improve the clinical accuracy of the generated reports. © 2022 Association for Computational Linguistics.",Final,
Sahoo S.K.; Saha S.; Ekbal A.; Bhattacharyya P.,"Sahoo, Sovan Kumar (57220039065); Saha, Saumajit (58100559800); Ekbal, Asif (23093674100); Bhattacharyya, Pushpak (7101803108)",57220039065; 58100559800; 23093674100; 7101803108,Event-Argument Linking in Disaster Domain,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137584345&doi=10.1109%2fACCESS.2022.3197648&partnerID=40&md5=980cbc2a10491dcf231a33d3f4f7a848,"Linking event triggers with their respective arguments is an essential component for building an event extraction system. It is challenging to link event triggers with the corresponding arguments triggers when the sentence contains multiple events and arguments triggers. The task becomes even more challenging in a low-resource setup due to the unavailability of natural language processing resource and tools. In this paper, we study the event-argument linking task based on disaster event ontology in a low resource setup. We use BERT and non-BERT-based deep learning models in both monolingual and cross-lingual event-argument linking task.We also perform an ablation study of various features like position embeddings (PE), position indicator (PI), and segment ID (SI) to understand their contribution to performance improvement in non-BERT-based models. Using three different languages viz. Hindi, Bengali, and Marathi, we compare the results with multilingual BERT-based deep neural models in both monolingual and cross-lingual scenarios. We observe that the multilingual BERT-based model outperforms the best performing non-BERT-based model in cross-lingual settings. But in monolingual settings, the performance is similar in Hindi and Bengali datasets and slightly better in Marathi dataset. We choose the disaster domain due to its social implications. Our current experiments can be helpful in mining important information related to disaster events from news articles and building event knowledge graphs in low-resource languages. Author",Article in press,All Open Access; Gold Open Access
Xue B.; Li Y.; Zou L.,"Xue, Bingcong (57223986987); Li, Yanzeng (57814628700); Zou, Lei (8359099800)",57223986987; 57814628700; 8359099800,Introducing Semantic Information for Numerical Attribute Prediction over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141720781&doi=10.1007%2f978-3-031-19433-7_1&partnerID=40&md5=3b6e71d3394cc174fa017cc5edfab7c1,"Knowledge graph (KG) completion has been long studied on link prediction task to infer missing relations, while literals are paid less attention due to the non-discrete and rich-semantic challenges. Numerical attributes such as height, age and birthday are different from other literals that they can be calculated and estimated, thus have huge potential to be predicted and play important roles in a series of tasks. However, only a few researches have made preliminary attempts to predict numerical attributes on KGs with the help of the structural information or the development of embedding techniques. In this paper, we re-examine the numerical attribute prediction task over KGs, and introduce several novel methods to explore and utilize the rich semantic knowledge of language models (LMs) for this task. An effective combination strategy is also proposed to take full advantage of both structural and semantic information. Extensive experiments are conducted to show the great effectiveness of both the semantic methods and the combination strategy. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Lee J.; Lee M.-J.; Yang J.Y.; Yang E.,"Lee, Juhyuk (58375351800); Lee, Min-Joong (37102026900); Yang, June Yong (57224858803); Yang, Eunho (52265094000)",58375351800; 37102026900; 57224858803; 52265094000,Does it Really Generalize Well on Unseen Data? Systematic Evaluation of Relational Triple Extraction Methods,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138385914&partnerID=40&md5=621e61d135fad46b797798566d7fb225,"The ability to extract entities and their relations from unstructured text is essential for the automated maintenance of large-scale knowledge graphs. To keep a knowledge graph up-to-date, an extractor needs not only the ability to recall the triples it encountered during training, but also the ability to extract the new triples from the context that it has never seen before. In this paper, we show that although existing extraction models are able to easily memorize and recall already seen triples, they cannot generalize effectively for unseen triples. This alarming observation was previously unknown due to the composition of the test sets of the go-to benchmark datasets, which turns out to contain only 2% unseen data, rendering them incapable to measure the generalization performance. To separately measure the generalization performance from the memorization performance, we emphasize unseen data by rearranging datasets, sifting out training instances, or augmenting test sets. In addition to that, we present a simple yet effective augmentation technique to promote generalization of existing extraction models, and experimentally confirm that the proposed method can significantly increase the generalization performance of existing models. © 2022 Association for Computational Linguistics.",Final,
Zhang N.; Bi Z.; Liang X.; Cheng S.; Hong H.; Deng S.; Zhang Q.; Lian J.; Chen H.,"Zhang, Ningyu (55923601900); Bi, Zhen (57223797329); Liang, Xiaozhuan (57275281200); Cheng, Siyuan (57441655100); Hong, Haosen (57441674000); Deng, Shumin (57201556430); Zhang, Qiang (57223110124); Lian, Jiazhang (24553907300); Chen, Huajun (35268022500)",55923601900; 57223797329; 57275281200; 57441655100; 57441674000; 57201556430; 57223110124; 24553907300; 35268022500,ONTOPROTEIN: PROTEIN PRETRAINING WITH GENE ONTOLOGY EMBEDDING,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143658405&partnerID=40&md5=54737ec3da09c6780ecdbec1ab64c76e,"Self-supervised protein language models have proved their effectiveness in learning the proteins representations. With the increasing computational power, current protein language models pre-trained with millions of diverse sequences can advance the parameter scale from million-level to billion-level and achieve remarkable improvement. However, those prevailing approaches rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better protein representations. We argue that informative biology knowledge in KGs can enhance protein representation with external knowledge. In this work, we propose OntoProtein, the first general framework that makes use of structure in GO (Gene Ontology) into protein pre-training models. We construct a novel large-scale knowledge graph that consists of GO and its related proteins, and gene annotation texts or protein sequences describe all nodes in the graph. We propose novel contrastive learning with knowledge-aware negative sampling to jointly optimize the knowledge graph and protein embedding during pre-training. Experimental results show that OntoProtein can surpass state-of-the-art methods with pre-trained protein language models in TAPE benchmark and yield better performance compared with baselines in protein-protein interaction and protein function prediction. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.",Final,
Yu D.; Zhu C.; Fang Y.; Yu W.; Wang S.; Xu Y.; Ren X.; Yang Y.; Zeng M.,"Yu, Donghan (57219492469); Zhu, Chenguang (57210636804); Fang, Yuwei (57219638370); Yu, Wenhao (57209227271); Wang, Shuohang (57191852679); Xu, Yichong (57195953104); Ren, Xiang (58619993600); Yang, Yiming (35231480000); Zeng, Michael (57211638200)",57219492469; 57210636804; 57219638370; 57209227271; 57191852679; 57195953104; 58619993600; 35231480000; 57211638200,KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145328435&partnerID=40&md5=b74bbd1e8636ffc29165c02e0bb438d9,"Current Open-Domain Question Answering (ODQA) models typically include a retrieving module and a reading module, where the retriever selects potentially relevant passages from open-source documents for a given question, and the reader produces an answer based on the retrieved passages. The recently proposed Fusion-in-Decoder (FiD) framework is a representative example, which is built on top of a dense passage retriever and a generative reader, achieving the state-of-the-art performance. In this paper we further improve the FiD approach by introducing a knowledge-enhanced version, namely KG-FiD. Our new model uses a knowledge graph to establish the structural relationship among the retrieved passages, and a graph neural network (GNN) to re-rank the passages and select only a top few for further processing. Our experiments on common ODQA benchmark datasets (Natural Questions and TriviaQA) demonstrate that KG-FiD can achieve comparable or better performance in answer prediction than FiD, with less than 40% of the computation cost. © 2022 Association for Computational Linguistics.",Final,
Martin-Moncunill D.; Sicilia M.-A.; González L.; Rodríguez D.,"Martin-Moncunill, David (56106347900); Sicilia, Miguel-Angel (8266687800); González, Lino (57218312057); Rodríguez, Diego (57982810400)",56106347900; 8266687800; 57218312057; 57982810400,On Contrasting YAGO with GPT-J: An Experiment for Person-Related Attributes,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142770683&doi=10.1007%2f978-3-031-21422-6_17&partnerID=40&md5=dd74676383160aa96277c3da98fcbfbd,"Language models (LMs) trained or large text corpora have demonstrated their superior performance in different language related tasks in the last years. These models automatically implicitly incorporate factual knowledge that can be used to complement existing Knowledge Graphs (KGs) that in most cases are structured from human curated databases. Here we report an experiment that attempts to gain insights about the extent to which LMs can generate factual information as that present in KGs. Concretely, we have tested such process using the English Wikipedia subset of YAGO and the GPT-J model for attributes related to individuals. Results show that the generation of correct factual information depends on the generation parameters of the model and are unevenly balanced across diverse individuals. Further, the LM can be used to populate further factual information, but it requires intermediate parsing to correctly map to KG attributes. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Amaral G.; Pinnis M.; Skadiņa I.; Rodrigues O.; Simperl E.,"Amaral, Gabriel (57219027464); Pinnis, Mārcis (36603189200); Skadiņa, Inguna (36474178500); Rodrigues, Odinaldo (22433790300); Simperl, Elena (23036541000)",57219027464; 36603189200; 36474178500; 22433790300; 23036541000,Statistical and Neural Methods for Cross-lingual Entity Label Mapping in Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139036362&doi=10.1007%2f978-3-031-16270-1_4&partnerID=40&md5=ba0c5678888cb3510db42cae18e090c0,"Knowledge bases such as Wikidata amass vast amounts of named entity information, such as multilingual labels, which can be extremely useful for various multilingual and cross-lingual applications. However, such labels are not guaranteed to match across languages from an information consistency standpoint, greatly compromising their usefulness for fields such as machine translation. In this work, we investigate the application of word and sentence alignment techniques coupled with a matching algorithm to align cross-lingual entity labels extracted from Wikidata in 10 languages. Our results indicate that mapping between Wikidata’s main labels stands to be considerably improved (up to 20 points in F1-score) by any of the employed methods. We show how methods relying on sentence embeddings outperform all others, even across different scripts. We believe the application of such techniques to measure the similarity of label pairs, coupled with a knowledge base rich in high-quality entity labels, to be an excellent asset to machine translation. © 2022, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Chen Q.; Li F.-L.; Xu G.; Yan M.; Zhang J.; Zhang Y.,"Chen, Qianglong (57220892222); Li, Feng-Lin (55494492700); Xu, Guohai (57219877077); Yan, Ming (55885243600); Zhang, Ji (57216516983); Zhang, Yin (55920642700)",57220892222; 55494492700; 57219877077; 55885243600; 57216516983; 55920642700,DictBERT: Dictionary Description Knowledge Enhanced Language Model Pre-training via Contrastive Learning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137915120&partnerID=40&md5=53f18a7aa29db183e50e020f21db83d1,"Although pre-trained language models (PLMs) have achieved state-of-the-art performance on various natural language processing (NLP) tasks, they are shown to be lacking in knowledge when dealing with knowledge driven tasks. Despite the many efforts made for injecting knowledge into PLMs, this problem remains open. To address the challenge, we propose DictBERT, a novel approach that enhances PLMs with dictionary knowledge which is easier to acquire than knowledge graph (KG). During pre-training, we present two novel pre-training tasks to inject dictionary knowledge into PLMs via contrastive learning: dictionary entry prediction and entry description discrimination. In fine-tuning, we use the pre-trained DictBERT as a plugin knowledge base (KB) to retrieve implicit knowledge for identified entries in an input sequence, and infuse the retrieved knowledge into the input to enhance its representation via a novel extra-hop attention mechanism. We evaluate our approach on a variety of knowledge driven and language understanding tasks, including NER, relation extraction, CommonsenseQA, OpenBookQA and GLUE. Experimental results demonstrate that our model can significantly improve typical PLMs: it gains a substantial improvement of 0.5%, 2.9%, 9.0%, 7.1% and 3.3% on BERT-large respectively, and is also effective on RoBERTa-large. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.",Final,
Tavchioski I.; Koloski B.; Škrlj B.; Pollak S.,"Tavchioski, Ilija (57669410900); Koloski, Boshko (57222028629); Škrlj, Blaž (57191625180); Pollak, Senja (55543643800)",57669410900; 57222028629; 57191625180; 55543643800,"E8-IJS@LT-EDI-ACL2022 - BERT, AutoML and Knowledge-graph backed Detection of Depression",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137450692&partnerID=40&md5=334f6d5f1de27631ba161005c7e3b19b,"Depression is a mental illness that negatively affects a person's well-being and can, if left untreated, lead to serious consequences such as suicide. Therefore, it is important to recognize the signs of depression early. In the last decade, social media has become one of the most common places to express one's feelings. Hence, there is a possibility of text processing and applying machine learning techniques to detect possible signs of depression. In this paper, we present our approaches to solving the shared task titled Detecting Signs of Depression from Social Media Text. We explore three different approaches to solve the challenge: fine-tuning BERT model, leveraging AutoML for the construction of features and classifier selection and finally, we explore latent spaces derived from the combination of textual and knowledge-based representations. We ranked 9th out of 31 teams in the competition. Our best solution, based on knowledge graph and textual representations, was 4.9% behind the best model in terms of Macro F1, and only 1.9% behind in terms of Recall. © 2022 Association for Computational Linguistics.",Final,
Liu L.; Omidvar A.; Ma Z.; Agrawal A.; An A.,"Liu, Lixian (57880585800); Omidvar, Amin (48161526100); Ma, Zongyang (55364783500); Agrawal, Ameeta (55753479300); An, Aijun (6701725452)",57880585800; 48161526100; 55364783500; 55753479300; 6701725452,Unsupervised Knowledge Graph Generation Using Semantic Similarity Matching,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137540079&partnerID=40&md5=9a24928b40cd35dd53a1025037f4cdb3,"Knowledge Graphs (KGs) are directed labeled graphs representing entities and the relationships between them. Most prior work focuses on supervised or semi-supervised approaches which require large amounts of annotated data. While unsupervised approaches do not need labeled training data, most existing methods either generate too many redundant relations or require manual mapping of the extracted relations to a known schema. To address these limitations, we propose an unsupervised method for KG generation that requires neither labeled data nor manual mapping to the predefined relation schema. Instead, our method leverages sentence-level semantic similarity for automatically generating relations between pairs of entities. Our proposed method outperforms two baseline systems when evaluated over four datasets. © 2022 Association for Computational Linguistics.",Final,
Li D.; Li Y.; Zhang J.; Li K.; Wei C.; Cui J.; Wang B.,"Li, Dawei (57639532300); Li, Yanran (56901482700); Zhang, Jiayi (57221657218); Li, Ke (57224667571); Wei, Chen (58730846200); Cui, Jianwei (57217248343); Wang, Bin (57161232700)",57639532300; 56901482700; 57221657218; 57224667571; 58730846200; 57217248343; 57161232700,C3KG: A Chinese Commonsense Conversation Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140203747&partnerID=40&md5=19eb2fce23bd8a0d0259733924f5671e,"Existing commonsense knowledge bases often organize tuples in an isolated manner, which is deficient for commonsense conversational models to plan the next steps. To fill the gap, we curate a large-scale multi-turn human-written conversation corpus, and create the first Chinese commonsense conversation knowledge graph which incorporates both social commonsense knowledge and dialog flow information. To show the potential of our graph, we develop a graph-conversation matching approach, and benchmark two graph-grounded conversational tasks. Our code and data could be found in https://github.com/XiaoMi/C3KG. © 2022 Association for Computational Linguistics.",Final,
Li Z.; Guan S.; Jin X.; Peng W.; Lyu Y.; Zhu Y.; Bai L.; Li W.; Guo J.; Cheng X.,"Li, Zixuan (57201739412); Guan, Saiping (57196080482); Jin, Xiaolong (16417309500); Peng, Weihua (57220993199); Lyu, Yajuan (57192308367); Zhu, Yong (57212066003); Bai, Long (57219876463); Li, Wei (57221638294); Guo, Jiafeng (24174196100); Cheng, Xueqi (55855927900)",57201739412; 57196080482; 16417309500; 57220993199; 57192308367; 57212066003; 57219876463; 57221638294; 24174196100; 55855927900,Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141338313&partnerID=40&md5=2cc4065d4f8ccf56027bedc90a121459,"A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps. TKG reasoning aims to predict potential facts in the future given the historical KG sequences. One key of this task is to mine and understand evolutional patterns of facts from these sequences. The evolutional patterns are complex in two aspects, length-diversity and time-variability. Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length. Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on. Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy. Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time. Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings. © 2022 Association for Computational Linguistics.",Final,
Fu G.; Meng Z.; Han Z.; Ding Z.; Ma Y.; Schubert M.; Tresp V.; Wattenhofer R.,"Fu, Guirong (57879448200); Meng, Zhao (57221156021); Han, Zhen (57219766233); Ding, Zifeng (57260888700); Ma, Yunpu (57194413081); Schubert, Matthias (55605776884); Tresp, Volker (6603805670); Wattenhofer, Roger (6701529043)",57879448200; 57221156021; 57219766233; 57260888700; 57194413081; 55605776884; 6603805670; 6701529043,TempCaps: A Capsule Network-based Embedding Model for Temporal Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137471654&partnerID=40&md5=ae87834d169538454dc0682863c1c233,"Temporal knowledge graphs store the dynamics of entities and relations during a time period. However, typical temporal knowledge graphs often suffer from incomplete dynamics with missing facts in real-world scenarios. Hence, modeling temporal knowledge graphs to complete the missing facts is important. In this paper, we tackle the temporal knowledge graph completion task by proposing TempCaps, which is a Capsule network-based embedding model for Temporal knowledge graph completion. TempCaps models temporal knowledge graphs by introducing a novel dynamic routing aggregator inspired by Capsule Networks. Specifically, TempCaps builds entity embeddings by dynamically routing retrieved temporal relation and neighbor information. Experimental results demonstrate that TempCaps reaches state-of-the-art performance for temporal knowledge graph completion. Additional analysis also shows that TempCaps is efficient1 © 2022 Association for Computational Linguistics.",Final,
Rosner M.; Ahmadi S.; Apostol E.-S.; Bosque-Gil J.; Chiarcos C.; Dojchinovski M.; Gkirtzou K.; Gracia J.; Gromann D.; Liebeskind C.; Oleškevičienė G.V.; Sérasset G.; Truică C.-O.,"Rosner, Michael (13106151500); Ahmadi, Sina (57210119212); Apostol, Elena-Simona (55365937600); Bosque-Gil, Julia (57031866000); Chiarcos, Christian (22333764800); Dojchinovski, Milan (55453114000); Gkirtzou, Katerina (26648420600); Gracia, Jorge (55392626700); Gromann, Dagmar (55844075500); Liebeskind, Chaya (55761687500); Oleškevičienė, Giedrė Valūnaitė (57194015310); Sérasset, Gilles (8897914400); Truică, Ciprian-Octavian (56331462000)",13106151500; 57210119212; 55365937600; 57031866000; 22333764800; 55453114000; 26648420600; 55392626700; 55844075500; 55761687500; 57194015310; 8897914400; 56331462000,Cross-Lingual Link Discovery for Under-Resourced Languages,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144383081&partnerID=40&md5=52f1d7040c20319cbf2902e970584fc9,"In this paper, we provide an overview of current technologies for cross-lingual link discovery, and we discuss challenges, experiences and prospects of their application to under-resourced languages. We first introduce the goals of cross-lingual linking and associated technologies, and in particular, the role that the Linked Data paradigm (Bizer et al., 2011) applied to language data can play in this context. We define under-resourced languages with a specific focus on languages actively used on the internet, i.e., languages with a digitally versatile speaker community, but limited support in terms of language technology. We argue that languages for which considerable amounts of textual data and (at least) a bilingual word list are available, techniques for cross-lingual linking can be readily applied, and that these enable the implementation of downstream applications for under-resourced languages via the localisation and adaptation of existing technologies and resources. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
Sticha A.; Verdeja E.; Brenner P.,"Sticha, Abigail (57218477153); Verdeja, Ernesto (14059205900); Brenner, Paul (57210223297)",57218477153; 14059205900; 57210223297,Hybrid Knowledge Engineering Leveraging a Robust ML Framework to Produce an Assassination Dataset,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143444894&partnerID=40&md5=0ca0c13bd4c77603e441007d8596fba7,"Social and political researchers require robust event datasets to conduct data-driven analysis, an example being the need for trigger event datasets to analyze under what conditions and in what patterns certain trigger-type events increase the probability of mass killings. Fortunately, NLP and ML can be leveraged to create these robust datasets. In this paper we (i) outline a robust ML framework that prioritizes understandability through visualizations and generalizability through the ability to implement different ML algorithms, (ii) perform a comparative analysis of these ML tools within the framework for the coup trigger, (iii) leverage our ML framework along with a unique combination of NLP tools, such as NER and knowledge graphs, to produce a dataset for the the assassination trigger, and (iv) make this comprehensive, consolidated, and cohesive assassination dataset publicly available to provide temporal data for understanding political violence as well as training data for further sociopolitical research. © 2022 Association for Computational Linguistics.",Final,
Zheng C.; Chen X.; Xu R.; Chang B.,"Zheng, Ce (57436933700); Chen, Xudong (57437930800); Xu, Runxin (57219690250); Chang, Baobao (55837183200)",57436933700; 57437930800; 57219690250; 55837183200,A Double-Graph Based Framework for Frame Semantic Parsing,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138363104&partnerID=40&md5=32d9b27fd4dd5e6df74cc1e5554a4cf5,"Frame semantic parsing is a fundamental NLP task, which consists of three subtasks: frame identification, argument identification and role classification. Most previous studies tend to neglect relations between different subtasks and arguments and pay little attention to ontological frame knowledge defined in FrameNet. In this paper, we propose a Knowledge-guided Incremental semantic parser with Double-graph (KID). We first introduce Frame Knowledge Graph (FKG), a heterogeneous graph containing both frames and FEs (Frame Elements) built on the frame knowledge so that we can derive knowledge-enhanced representations for frames and FEs. Besides, we propose Frame Semantic Graph (FSG) to represent frame semantic structures extracted from the text with graph structures. In this way, we can transform frame semantic parsing into an incremental graph construction problem to strengthen interactions between subtasks and relations between arguments. Our experiments show that KID outperforms the previous state-of-the-art method by up to 1.7 F1-score on two FrameNet datasets. Our code is availavle at https://github.com/PKUnlp-icler/KID. © 2022 Association for Computational Linguistics.",Final,
Lesage J.; Haynie H.J.; Skirgård H.; Weber T.; Witzlack-Makarevich A.,"Lesage, Jakob (57952485300); Haynie, Hannah J. (56145667600); Skirgård, Hedvig (57193835995); Weber, Tobias (57733944800); Witzlack-Makarevich, Alena (56625279900)",57952485300; 56145667600; 57193835995; 57733944800; 56625279900,Overlooked Data in Typological Databases: What Grambank Teaches Us About Gaps in Grammars,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144454467&partnerID=40&md5=fbe018fd37e9006c12d090f3a9595aa0,"Typological databases can contain a wealth of information beyond the collection of linguistic properties across languages. This paper shows how information often overlooked in typological databases can inform the research community about the state of description of the world's languages. We illustrate this using Grambank, a morphosyntactic typological database covering 2,467 language varieties and based on 3,951 grammatical descriptions. We classify and quantify the comments that accompany coded values in Grambank. We then aggregate these comments and the coded values to derive a level of description for 17 grammatical domains that Grambank covers (negation, adnominal modification, participant marking, tense, aspect, etc.). We show that the description level of grammatical domains varies across space and time. Information about gaps and uncertainties in the descriptive knowledge of grammatical domains within and across languages is essential for a correct analysis of data in typological databases and for the study of grammatical diversity more generally. When collected in a database, such information feeds into disciplines that focus on primary data collection, such as grammaticography and language documentation. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
,,,Static and Dynamic Speaker Modeling based on Graph Neural Network for Emotion Recognition in Conversation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137597397&partnerID=40&md5=b98d7b251a4fb2c08ae1aeee5d833cb9,"Each person has a unique personality which affects how they feel and convey emotions. Hence, speaker modeling is important for the task of emotion recognition in conversation (ERC). In this paper, we propose a novel graph-based ERC model which considers both conversational context and speaker personality. We model the internal state of the speaker (personality) as Static and Dynamic speaker state, where the Dynamic speaker state is modeled with a graph neural network based encoder. Experiments on benchmark dataset shows the effectiveness of our model. Our model outperforms baseline and other graph-based methods. Analysis of results also show the importance of explicit speaker modeling. © 2022 Association for Computational Linguistics.",Final,
Liang Z.; Zhang J.; Wang L.; Qin W.; Lan Y.; Shao J.; Zhang X.,"Liang, Zhenwen (57226605808); Zhang, Jipeng (57216615058); Wang, Lei (57218275050); Qin, Wei (57214995697); Lan, Yunshi (57191379533); Shao, Jie (57002035900); Zhang, Xiangliang (9238032200)",57226605808; 57216615058; 57218275050; 57214995697; 57191379533; 57002035900; 9238032200,MWP-BERT: Numeracy-Augmented Pre-training for MathWord Problem Solving,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137357368&partnerID=40&md5=cc9d32cc7c2c378c4535d8b51f429fa9,"Math word problem (MWP) solving faces a dilemma in number representation learning. In order to avoid the number representation issue and reduce the search space of feasible solutions, existing works striving forMWPsolving usually replace real numbers with symbolic placeholders to focus on logic reasoning. However, different from common symbolic reasoning tasks like program synthesis and knowledge graph reasoning; MWP solving has extra requirements in numerical reasoning. In other words, instead of the number value itself, it is the reusable numerical property that matters more in numerical reasoning. Therefore, we argue that injecting numerical properties into symbolic placeholders with contextualized representation learning schema can provide a way out of the dilemma in the number representation issue here. In this work, we introduce this idea to the popular pre-training language model (PLM) techniques and build MWP-BERT, an effective contextual number representation PLM.We demonstrate the effectiveness of our MWP-BERT on MWP solving and several MWP-specific understanding tasks on both English and Chinese benchmarks. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Biswas R.; Portisch J.; Paulheim H.; Sack H.; Alam M.,"Biswas, Russa (57202431946); Portisch, Jan (57196471986); Paulheim, Heiko (35095438500); Sack, Harald (7102918498); Alam, Mehwish (57201532578)",57202431946; 57196471986; 35095438500; 7102918498; 57201532578,Entity Type Prediction Leveraging Graph Walks and Entity Descriptions,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141736390&doi=10.1007%2f978-3-031-19433-7_23&partnerID=40&md5=8268dc62f57362d318481351f73dd1f7,"The entity type information in Knowledge Graphs (KGs) such as DBpedia, Freebase, etc. is often incomplete due to automated generation or human curation. Entity typing is the task of assigning or inferring the semantic type of an entity in a KG. This paper presents GRAND, a novel approach for entity typing leveraging different graph walk strategies in RDF2vec together with textual entity descriptions. RDF2vec first generates graph walks and then uses a language model to obtain embeddings for each node in the graph. This study shows that the walk generation strategy and the embedding model have a significant effect on the performance of the entity typing task. The proposed approach outperforms the baseline approaches on the benchmark datasets DBpedia and FIGER for entity typing in KGs for both fine-grained and coarse-grained classes. The results show that the combination of order-aware RDF2vec variants together with the contextual embeddings of the textual entity descriptions achieve the best results. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Sarkar R.; Arcan M.; McCrae J.P.,"Sarkar, Rajdeep (57209907494); Arcan, Mihael (55453083200); McCrae, John P. (36666801700)",57209907494; 55453083200; 36666801700,KG-CRuSE: Recurrent Walks over Knowledge Graph for Explainable Conversation Reasoning using Semantic Embeddings,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144800165&partnerID=40&md5=dc116bfec7aaf56b26370f403b85e372,"Knowledge-grounded dialogue systems utilise external knowledge such as knowledge graphs to generate informative and appropriate responses. A crucial challenge of such systems is to select facts from a knowledge graph pertinent to the dialogue context for response generation. This fact selection can be formulated as path traversal over a knowledge graph conditioned on the dialogue context. Such paths can originate from facts mentioned in the dialogue history and terminate at the facts to be mentioned in the response. These walks, in turn, provide an explanation of the flow of the conversation. This work proposes KG-CRUSE, a simple, yet effective LSTM based decoder that utilises the semantic information in the dialogue history and the knowledge graph elements to generate such paths for effective conversation explanation. Extensive evaluations showed that our model outperforms the state-of-the-art models on the OpenDialKG dataset on multiple metrics. © 2022 Association for Computational Linguistics.",Final,
Hosseini P.; Broniatowski D.A.; Diab M.,"Hosseini, Pedram (57209574175); Broniatowski, David A. (15080660400); Diab, Mona (36834996500)",57209574175; 15080660400; 36834996500,Knowledge-Augmented Language Models for Cause-Effect Relation Classification,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137730963&partnerID=40&md5=4ea13a66f3cd04070d7db4908767a684,"Previous studies have shown the efficacy of knowledge augmentation methods in pretrained language models. However, these methods behave differently across domains and downstream tasks. In this work, we investigate the augmentation of pretrained language models with knowledge graph data in the cause-effect relation classification and commonsense causal reasoning tasks. After automatically verbalizing triples in ATOMIC2020, a wide coverage commonsense reasoning knowledge graph, we continually pretrain BERT and evaluate the resulting model on cause-effect pair classification and answering commonsense causal reasoning questions. Our results show that a continually pretrained language model augmented with commonsense reasoning knowledge outperforms our baselines on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset, without additional improvement in model architecture or using quality-enhanced data for fine-tuning. © 2022 Association for Computational Linguistics.",Final,
Li S.; Sridhar M.; Prakash C.S.; Cao J.; Hamza W.; McAuley J.,"Li, Shuyang (57216690344); Sridhar, Mukund (57219690792); Prakash, Chandana Satya (57699870400); Cao, Jin (57219734192); Hamza, Wael (57217164251); McAuley, Julian (14822353500)",57216690344; 57219690792; 57699870400; 57219734192; 57217164251; 14822353500,Instilling Type Knowledge in Language Models via Multi-Task QA,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137368650&partnerID=40&md5=d68b8bf83d3926c6a614ef4b5b43ec7c,"Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge-their types. Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs. We create the WikiWiki dataset: entities and passages from 10M Wikipedia articles linked to theWikidata knowledge graph with 41K types. Models trained on WikiWiki achieve state-ofthe- art performance in zero-shot dialog state tracking benchmarks, accurately infer entity types in Wikipedia articles, and can discover new types deemed useful by human judges. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Jansen P.A.,"Jansen, Peter A. (20433726100)",20433726100,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139449947&partnerID=40&md5=f663cf357eb59b614b7d5785aa561188,"Text Worlds are virtual environments for embodied agents that, unlike 2D or 3D environments, are rendered exclusively using textual descriptions. These environments offer an alternative to higher-fidelity 3D environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. This systematic survey outlines recent developments in tooling, environments, and agent modeling for Text Worlds, while examining recent trends in knowledge graphs, common sense reasoning; transfer learning of Text World performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make Text Worlds an attractive general research paradigm for natural language processing. © 2022 Association for Computational Linguistics.",Final,
Zdravkova K.,"Zdravkova, Katerina (16044345900)",16044345900,Resolving Inflectional Ambiguity of Macedonian Adjectives,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145877636&partnerID=40&md5=72daf39bc3fd7d950b665e797c6a72c6,"Macedonian adjectives are inflected for gender, number, definiteness and degree, with in average 47.98 inflections per headword. The inflection paradigm of qualificative adjectives is even richer, embracing 56.27 morphophonemic alterations. Depending on the word they were derived from, more than 600 Macedonian adjectives have an identical headword and two different word forms for each grammatical category. While non-verbal adjectives alter the root before adding the inflectional suffixes, suffixes of verbal adjectives are added directly to the root. In parallel with the morphological differences, both types of adjectives have a different translation, depending on the category of the words they have been derived from. Nouns that collocate with these adjectives are mutually disjunctive, enabling the resolution of inflectional ambiguity. They are organised as a lexical taxonomy, created using hierarchical divisive clustering. If embedded in the future spell-checking applications, this taxonomy will significantly reduce the risk of forming incorrect inflections, which frequently occur in the daily news and more often in the advertisements and social media. © European Language Resources Association (ELRA)",Final,
Zhang T.; Liu Y.; Li B.; Zhong P.; Zhang C.; Wang H.; Miao C.,"Zhang, Tong (57735050100); Liu, Yong (55954393600); Li, Boyang (55837513500); Zhong, Peixiang (57216693882); Zhang, Chen (57758181500); Wang, Hao (36663130400); Miao, Chunyan (8850060600)",57735050100; 55954393600; 55837513500; 57216693882; 57758181500; 36663130400; 8850060600,Toward Knowledge-Enriched Conversational Recommendation Systems,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142143514&partnerID=40&md5=7e8b5208bf1432e373c3fa3fc1413184,"Conversational Recommendation Systems recommend items through language based interactions with users. In order to generate naturalistic conversations and effectively utilize knowledge graphs (KGs) containing background information, we propose a novel Bag-of-Entities loss, which encourages the generated utterances to mention concepts related to the item being recommended, such as the genre or director of a movie. We also propose an alignment loss to further integrate KG entities into the response generation network. Experiments on the large-scale REDIAL dataset demonstrate that the proposed system consistently outperforms state-of-the-art baselines. © 2022 Association for Computational Linguistics.",Final,
Yasunaga M.; Bosselut A.; Ren H.; Zhang X.; Manning C.D.; Liang P.; Leskovec J.,"Yasunaga, Michihiro (57203242413); Bosselut, Antoine (57193225759); Ren, Hongyu (57207374365); Zhang, Xikun (57221160022); Manning, Christopher D. (35280197500); Liang, Percy (56646712700); Leskovec, Jure (12241436100)",57203242413; 57193225759; 57207374365; 57221160022; 35280197500; 56646712700; 12241436100,Deep Bidirectional Language-Knowledge Graph Pretraining,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141900064&partnerID=40&md5=e2b09087f4dda8309dfb74e44d3e0c8a,"Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks. Recent works show that a knowledge graph (KG) can complement text data, offering structured background knowledge that provides a useful scaffold for reasoning. However, these works are not pretrained to learn a deep fusion of the two modalities at scale, limiting the potential to acquire fully joint representations of text and KG. Here we propose DRAGON (Deep Bidirectional Language-Knowledge Graph Pretraining), a self-supervised method to pretrain a deeply joint language-knowledge foundation model from text and KG at scale. Specifically, our model takes pairs of text segments and relevant KG subgraphs as input and bidirectionally fuses information from both modalities. We pretrain this model by unifying two self-supervised reasoning tasks, masked language modeling and KG link prediction. DRAGON outperforms existing LM and LM+KG models on diverse downstream tasks including question answering across general and biomedical domains, with +5% absolute gain on average. In particular, DRAGON achieves strong performance on complex reasoning about language and knowledge (+10% on questions involving long contexts or multi-step reasoning) and low-resource QA (+8% on OBQA and RiddleSense), and new state-of-the-art results on various BioNLP tasks. Our code and trained models are available at https://github.com/michiyasunaga/dragon. © 2022 Neural information processing systems foundation. All rights reserved.",Final,
Yang S.; Gao Y.; Wang J.; Meng F.; Guo S.; Zhou L.,"Yang, Shuaisong (57454935000); Gao, Yankun (57963599200); Wang, Jingdong (57212394211); Meng, Fanqi (55426663000); Guo, Shuqiang (55471251500); Zhou, Lina (57964328600)",57454935000; 57963599200; 57212394211; 55426663000; 55471251500; 57964328600,Chinese Named Entity Recognition Method in Electricity Based on Combining Character Sequence and Word Sequence,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141829699&partnerID=40&md5=f01d82ea2ce7b841288ccf3b662badcf,"Chinese named entity recognition in the power field is critical in building a high-quality knowledge graph of power equipment fault. Since the existing entity recognition methods only focus on the features of character sequence, it isn’t easy to achieve excellent recognition results in a professional and complex electrical knowledge corpus. This paper proposes a method for Chinese named entity recognition based on character sequence and word sequence to solve this problem. The innovation lies in co-encoding character sequences and word sequences to identify various types of entities using the improved Transformer structure. First, an electricity glossary is constructed using an N-gram based unsupervised method. Then, the electricity glossary is imported into the custom dictionary of the word segmentation tool to correct the word segmentation re-sults, and the Word2Vec model is used to train the lexicon of electricity word embedding. Finally, a model based on the combination of character sequences and word sequences is used to identify Chinese named entities. In this paper, four experiments are carried out with the corpus of electrical equipment fault diagnosis as the research object. The experimental results show that compared with the BiLSTM-CRF model and the BERT-BiLSTM-CRF model, the F1 score is increased by 23.15% and 10.62%, respectively. At the same time, compared with the control experiment using only character sequence fea-tures, the F1 score is increased by 2.96%, and the precision is increased by 4.65%, which proves the effectiveness of the method proposed in this paper. © 2022.",Final,
Chen K.; Wang Y.; Li Y.; Li A.,"Chen, Kai (56181530100); Wang, Ye (57225059310); Li, Yitong (57271921100); Li, Aiping (57217320818)",56181530100; 57225059310; 57271921100; 57217320818,RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144954885&partnerID=40&md5=320183330739e0594d436b05f25f8bea,"Temporal factors are tied to the growth of facts in realistic applications, such as the progress of diseases and the development of political situation, therefore, research on Temporal Knowledge Graph (TKG) attracks much attention. In TKG, relation patterns inherent with temporality are required to be studied for representation learning and reasoning across temporal facts. However, existing methods can hardly model temporal relation patterns, nor can capture the intrinsic connections between relations when evolving over time, lacking of interpretability. In this paper, we propose a novel temporal modeling method which represents temporal entities as Rotations in Quaternion Vector Space (RotateQVS) and relations as complex vectors in Hamilton's quaternion space. We demonstrate our method can model key patterns of relations in TKG, such as symmetry, asymmetry, inverse, and can further capture time-evolved relations by theory. Empirically, we show that our method can boost the performance of link prediction tasks over four temporal knowledge graph benchmarks. © 2022 Association for Computational Linguistics.",Final,
,,,"11th European Symposium on Computational Intelligence and Mathematics, ESCIM 2019",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124042956&partnerID=40&md5=185eb7cdc14794c943e8a70303e6b517,The proceedings contain 26 papers. The special focus in this conference is on Computational Intelligence and Mathematics. The topics include: A New Community Detection Problem Based on Bipolar Fuzzy Measures; Novel Methods of FCM Model Reduction; some Implications of Interval Approach to Dimension for Network Complexity; Social Indexes Segregation Based on MEOWA and MOOWA Aggregation Operators; combining Conceptual Graphs and Sentiment Analysis for Fake News Detection; a Weakened Notion of Congruence to Reduce Concept Lattices; interactive Search by Using Minimal Generators; knowledge Implications in Multi-adjoint Concept Lattices; fuzzy Decision Support Methodology for Sustainable Packaging System Design; dynamic Maximal Covering Location Problem with Facility Types and Time Dependent Availability; some Relationships Between the Notions of f-Inclusion and f-Contradiction; decomposition Integrals for Interval-Valued Functions; relational Powerset Theories; on Some Categories Underlying Knowledge Graphs; on Two Categories of Many-Level Fuzzy Morphological Spaces; congruences on Lattices and Lattice-Valued Functions; some Roughness Features of Fuzzy Sets; implicative Linguistic Summaries; Comparison of Discrete Memetic Evolutionary Metaheuristics for TSP; syntactic Analysis of Sentences Using Deep Neural Networks; estimating Remaining Time of Business Processes with Structural Attributes of the Traces; convolutional Neural Networks in the Ovarian Cancer Detection; Analyzing the Performance of TSP Solver Methods; a Fuzzy Model to Aggregate Performance Indicators in Sports.,Final,
Wang J.; Liu J.; Chen F.; Lu T.; Huang H.; Zhao J.,"Wang, Jingchu (57821733900); Liu, Jianyi (55705849900); Chen, Feiyu (57820706500); Lu, Teng (57820967800); Huang, Hua (57821734000); Zhao, Jinmeng (57821482800)",57821733900; 55705849900; 57820706500; 57820967800; 57821734000; 57821482800,Cross-Knowledge Graph Entity Alignment via Neural Tensor Network,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135063905&doi=10.1007%2f978-981-19-2456-9_8&partnerID=40&md5=40fc23bc6398f14cd4ddf429dea13e78,"With the expansion of the current knowledge graph scale and the increase of the number of entities, a large number of knowledge graphs express the same entity in different ways, so the importance of knowledge graph fusion is increasingly manifested. Traditional entity alignment algorithms have limited application scope and low efficiency. This paper proposes an entity alignment method based on neural tensor network (NtnEA), which can obtain the inherent semantic information of text without being restricted by linguistic features and structural information, and without relying on string information. In the three cross-lingual language data sets DBPFR−EN, DBPZH−EN and DBPJP−EN of the DBP15K data set, Mean Reciprocal Rank and Hits@k are used as the alignment effect evaluation indicators for entity alignment tasks. Compared with the existing entity alignment methods of MTransE, IPTransE, AlignE and AVR-GCN, the Hit@10 values of the NtnEA method are 85.67, 79.20, and 78.93, and the MRR is 0.558, 0.511, and 0.499, which are better than traditional methods and improved 10.7% on average. © 2022, The Author(s).",Final,All Open Access; Hybrid Gold Open Access
Zhu F.; Tan L.Y.; Ng S.-K.; Bressan S.,"Zhu, Fangyi (57645670900); Tan, Lok You (57644183500); Ng, See-Kiong (7403358862); Bressan, Stéphane (6701908788)",57645670900; 57644183500; 7403358862; 6701908788,Syntax-Informed Question Answering with Heterogeneous Graph Transformer,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135844888&doi=10.1007%2f978-3-031-12423-5_2&partnerID=40&md5=196c972c01ffb193ca01f1788f732638,"Large neural language models are steadily contributing state-of-the-art performance to question answering and other natural language and information processing tasks. These models are expensive to train. We propose to evaluate whether such pre-trained models can benefit from the addition of explicit linguistics information without requiring retraining from scratch. We present a linguistics-informed question answering approach that extends and fine-tunes a pre-trained transformer-based neural language model with symbolic knowledge encoded with a heterogeneous graph transformer. We illustrate the approach by the addition of syntactic information in the form of dependency and constituency graphic structures connecting tokens and virtual vertices. A comparative empirical performance evaluation with BERT as its baseline and with Stanford Question Answering Dataset demonstrates the competitiveness of the proposed approach. We argue, in conclusion and in the light of further results of preliminary experiments, that the approach is extensible to further linguistics information including semantics and pragmatics. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Leszczynski M.; Fu D.Y.; Chen M.F.; Ré C.,"Leszczynski, Megan (57219631554); Fu, Daniel Y. (57219508129); Chen, Mayee F. (57219691463); Ré, Christopher (10739281400)",57219631554; 57219508129; 57219691463; 10739281400,TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135542721&partnerID=40&md5=bffb67f2f3c5d6099d0ca1ac2307ab98,"Entity retrieval-retrieving information about entity mentions in a query-is a key step in open-domain tasks, such as question answering or fact checking. However, state-of-the-art entity retrievers struggle to retrieve rare entities for ambiguous mentions due to biases towards popular entities. Incorporating knowledge graph types during training could help overcome popularity biases, but there are several challenges: (1) existing type-based retrieval methods require mention boundaries as input, but open-domain tasks run on unstructured text, (2) type-based methods should not compromise overall performance, and (3) type-based methods should be robust to noisy and missing types. In this work, we introduce TABi, a method to jointly train bi-encoders on knowledge graph types and unstructured text for entity retrieval for open-domain tasks. TABi leverages a type-enforced contrastive loss to encourage entities and queries of similar types to be close in the embedding space. TABi improves retrieval of rare entities on the Ambiguous Entity Retrieval (AmbER) sets, while maintaining strong overall retrieval performance on open-domain tasks in the KILT benchmark compared to state-of-the-art retrievers. TABi is also robust to incomplete type systems, improving rare entity retrieval over baselines with only 5% type coverage of the training dataset. We make our code publicly available. © 2022 Association for Computational Linguistics.",Final,
Bai J.; Wang Z.; Zhang H.; Song Y.,"Bai, Jiaxin (57211989884); Wang, Zihao (57202647584); Zhang, Hongming (57202439109); Song, Yangqiu (14039604300)",57211989884; 57202647584; 57202439109; 14039604300,Query2Particles: Knowledge Graph Reasoning with Particle Embeddings,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137322602&partnerID=40&md5=dc13879c667091ab7409805a8a47c822,"Answering complex logical queries on incomplete knowledge graphs (KGs) with missing edges is a fundamental and important task for knowledge graph reasoning. The query embedding method is proposed to answer these queries by jointly encoding queries and entities to the same embedding space. Then the answer entities are selected according to the similarities between the entity embeddings and the query embedding. As the answers to a complex query are obtained from a combination of logical operations over sub-queries, the embeddings of the answer entities may not always follow a uni-modal distribution in the embedding space. Thus, it is challenging to simultaneously retrieve a set of diverse answers from the embedding space using a single and concentrated query representation such as a vector or a hyperrectangle. To better cope with queries with diversified answers, we propose Query2Particles (Q2P), a complex KG query answering method. Q2P encodes each query into multiple vectors, named particle embeddings. By doing so, the candidate answers can be retrieved from different areas over the embedding space using the maximal similarities between the entity embeddings and any of the particle embeddings. Meanwhile, the corresponding neural logic operations are defined to support its reasoning over arbitrary first-order logic queries. The experiments show that Query2Particles achieves state-of-the-art performance on the complex query answering tasks on FB15k, FB15K-237, and NELL knowledge graphs. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Asprino L.; De Giorgis S.; Gangemi A.; Bulla L.; Marinucci L.; Mongiovì M.,"Asprino, Luigi (57191745706); De Giorgis, Stefano (57194034894); Gangemi, Aldo (55605133800); Bulla, Luana (57471277700); Marinucci, Ludovica (57210563349); Mongiovì, Misael (24339046000)",57191745706; 57194034894; 55605133800; 57471277700; 57210563349; 24339046000,Uncovering Values: Detecting Latent Moral Content from Natural Language with Explainable and Non-Trained Methods,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136089309&partnerID=40&md5=e931f5644c9f03e6594d3d1c28893713,"Moral values as commonsense norms shape our everyday individual and community behavior. The possibility to extract moral attitude rapidly from natural language is an appealing perspective that would enable a deeper understanding of social interaction dynamics and the individual cognitive and behavioral dimension. In this work we focus on detecting moral content from natural language and we test our methods on a corpus of tweets previously labeled as containing moral values or violations, according to Moral Foundation Theory. We develop and compare two different approaches: (i) a frame-based symbolic value detector based on knowledge graphs and (ii) a zero-shot machine learning model fine-tuned on a task of Natural Language Inference (NLI) and a task of emotion detection. Our approaches achieve considerable performances without the need for prior training. © 2022 Association for Computational Linguistics.",Final,
Saxena A.; Kochsiek A.; Gemulla R.,"Saxena, Apoorv (57225711426); Kochsiek, Adrian (57488409100); Gemulla, Rainer (9940328100)",57225711426; 57488409100; 9940328100,Sequence-to-Sequence Knowledge Graph Completion and Question Answering,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134708605&partnerID=40&md5=e0678e8796c500a2870f2a4e69865e89,"Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors. These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA). KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities. For downstream tasks these atomic entity representations often need to be integrated into a multi stage pipeline, limiting their utility. We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and incomplete KG question answering. We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with autoregressive decoding. Such a simple but powerful method reduces the model size up to 98% compared to conventional KGE models while keeping inference time tractable. After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning. © 2022 Association for Computational Linguistics.",Final,
Papadopoulou A.; Lison P.; Øvrelid L.; Pilán I.,"Papadopoulou, Anthi (57454595800); Lison, Pierre (35243071600); Øvrelid, Lilja (52864533500); Pilán, Ildikó (57196010474)",57454595800; 35243071600; 52864533500; 57196010474,Bootstrapping Text Anonymization Models with Distant Supervision,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135795420&partnerID=40&md5=17e7a0abb9ffa641225a4083dad522d3,"We propose a novel method to bootstrap text anonymization models based on distant supervision. Instead of requiring manually labeled training data, the approach relies on a knowledge graph expressing the background information assumed to be publicly available about various individuals. This knowledge graph is employed to automatically annotate text documents including personal data about a subset of those individuals. More precisely, the method determines which text spans ought to be masked in order to guarantee k-anonymity, assuming an adversary with access to both the text documents and the background information expressed in the knowledge graph. The resulting collection of labeled documents is then used as training data to fine-tune a pre-trained language model for text anonymization. We illustrate this approach using a knowledge graph extracted from Wikidata and short biographical texts from Wikipedia. Evaluation results with a RoBERTa-based model and a manually annotated collection of 553 summaries showcase the potential of the approach, but also unveil a number of issues that may arise if the knowledge graph is noisy or incomplete. The results also illustrate that, contrary to most sequence labeling problems, the text anonymization task may admit several alternative solutions. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.",Final,
West P.; Bhagavatula C.; Hessel J.; Hwang J.D.; Jiang L.; Le Bras R.; Lu X.; Welleck S.; Choi Y.,"West, Peter (57216690053); Bhagavatula, Chandra (57216430904); Hessel, Jack (57190382287); Hwang, Jena D. (35109145400); Jiang, Liwei (57209400459); Le Bras, Ronan (37042388500); Lu, Ximing (57222033823); Welleck, Sean (57188714884); Choi, Yejin (36172231400)",57216690053; 57216430904; 57190382287; 35109145400; 57209400459; 37042388500; 57222033823; 57188714884; 36172231400,Symbolic Knowledge Distillation: from General Language Models to Commonsense Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134018577&partnerID=40&md5=5e151b29ce792b292ceb236eeef18c63,"The common practice for training commonsense models has gone from-human-to-corpus-to-machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from-machine-to-corpus-to-machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al., 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically-as text-in addition to the resulting neural model. We distill only one aspect-the commonsense of a general language model teacher, allowing the student to be a different type of model, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model's commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and will share our new symbolic knowledge graph and commonsense models. © 2022 Association for Computational Linguistics.",Final,
Melotte S.; Ilievski F.; Zhang L.; Malte A.; Mutha N.; Morstatter F.; Mehrabi N.,"Melotte, Sara (57224965631); Ilievski, Filip (57188757237); Zhang, Linglan (57759270400); Malte, Aditya (57213191570); Mutha, Namita (57223089480); Morstatter, Fred (39061777700); Mehrabi, Ninareh (57215294085)",57224965631; 57188757237; 57759270400; 57213191570; 57223089480; 39061777700; 57215294085,Where Does Bias in Common Sense Knowledge Models Come From?,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132541197&doi=10.1109%2fMIC.2022.3170914&partnerID=40&md5=b4db3c0e4d5dd1322e75c938902f53d6,"Common Sense knowledge bases and models have been shown to embed bias. We investigate the source of such bias in a knowledge model called common sense transformer (COMET) by training it on various combinations of language models and knowledge bases. We experiment with three language models of different sizes and architectures, and two knowledge bases with different modeling principles. We use sentiment and regard as proxy measures of bias and analyze bias using three methods: overgeneralization and disparity, keyword outliers, and relational dimensions. Our results show that larger models tend to be more nuanced in their biases but are more biased than smaller models in certain categories (e.g., utility of religions), which can be attributed to the larger knowledge accumulated during pretraining. We also observe that training on a larger set of common sense knowledge typically leads to more bias, and that models generally have stronger negative regard than positive.  © 1997-2012 IEEE.",Final,
Li J.; Ruan D.,"Li, Jiajia (57872765700); Ruan, Dongru (36651585400)",57872765700; 36651585400,A Joint Extraction Strategy for Chinese Medical Text Based on Sequence Tagging,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137176909&doi=10.1109%2fICCEAI55464.2022.00011&partnerID=40&md5=b638410689d0e000a0f6e001225ee732,"The research on entities and relations extraction in medical text is the basis of constructing medical knowledge graphs. Currently the mainstream pipelined extraction method do not consider the connection between entity recognition and relation classification, and could not address the problem of the overlapping relations among the triplets. This paper proposes a joint extraction strategy of entities and relations in chinese medical based on sequence tagging, which splits the joint extraction task into two sequence tagging subtasks, namely HE and TRE, establishing the connection of subtasks through shared encoding layer and semantic information of head entity. By incorporating the pre-Trained language model RoBERTa to obtain a richer numerical representations of word vectors, then fusing word vectors and part-of-speech vectors as inputs of word representation for joint extraction, in combination with the GRU-BiLSTM model to extract entities and relations directly. Experimental results show that this model achieves 54.44% F-value on the chinese medical dataset CMeIE, which outperforms the extraction performance of other pre-Trained language models. © 2022 IEEE.",Final,
Rony M.R.A.H.; Kumar U.; Teucher R.; Kovriguina L.; Lehmann J.,"Rony, Md Rashad Al Hasan (57203302415); Kumar, Uttam (57387447300); Teucher, Roman (57803401500); Kovriguina, Liubov (56119059000); Lehmann, Jens (35229806900)",57203302415; 57387447300; 57803401500; 56119059000; 35229806900,SGPT: A Generative Approach for SPARQL Query Generation from Natural Language Questions,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134196122&doi=10.1109%2fACCESS.2022.3188714&partnerID=40&md5=3a6a3de3380a8b791f8fa681e36ee1b8,"SPARQL query generation from natural language questions is complex because it requires an understanding of both the question and underlying knowledge graph (KG) patterns. Most SPARQL query generation approaches are template-based, tailored to a specific knowledge graph and require pipelines with multiple steps, including entity and relation linking. Template-based approaches are also difficult to adapt for new KGs and require manual efforts from domain experts to construct query templates. To overcome this hurdle, we propose a new approach, dubbed SGPT, that combines the benefits of end-to-end and modular systems and leverages recent advances in large-scale language models. Specifically, we devise a novel embedding technique that can encode linguistic features from the question which enables the system to learn complex question patterns. In addition, we propose training techniques that allow the system to implicitly employ the graph-specific information (i.e., entities and relations) into the language model's parameters and generate SPARQL queries accurately. Finally, we introduce a strategy to adapt standard automatic metrics for evaluating SPARQL query generation. A comprehensive evaluation demonstrates the effectiveness of SGPT over state-of-the-art methods across several benchmark datasets.  © 2013 IEEE.",Final,All Open Access; Gold Open Access
Norabid I.A.; Fauzi F.,"Norabid, Idza Aisara (57730346200); Fauzi, Fariza (35228903000)",57730346200; 35228903000,Rule-based Text Extraction for Multimodal Knowledge Graph,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131417210&doi=10.14569%2fIJACSA.2022.0130535&partnerID=40&md5=c7b1c7c1861a4231b54684840d25ee15,"Textual information is widely integrated in visual tasks such as object/scene detection and image annotation. However, the textual information is not fully exploited, overlooking the wide background knowledge available for Web images. This work proposes a multimodal knowledge graph (KG) to represent the knowledge extracted from unstructured Web image surrounding text and to integrate the relationship between image and text entities. Existing multimodal KG works have mainly focused on advanced visual processes for extracting entities and relations from images, and only employed standard text processing techniques such as tokenization, stop word removal, and part-of-speech (POS) tagging to capture nouns only or basic subject-verb-object from text in the semantic enrichment process. Adversely, neglecting other rich information in the text. Thus, the proposed approach attempts to address this as an automatic relation extraction (RE) problem to extract all possible triples from the text information from simple to complex sentences, in constructing the multimodal KG which eventually can be used as a training seed for visual tasks. A linguistic analysis is performed on a set of Web news articles consisting of news images and their related text. The dependency relations and POS information obtained are used to formulate a set of domain-agnostic entity-relation extraction rules. A triple extractor incorporating these rules, is developed to extract the triples from a news articles dataset and construct the proposed MKG. The Precision and Recall metrics are used to evaluate the extractor’s performance. The evaluation results show that the proposed approach can extract entities and relations in the dataset with the precision score of 0.90 and recall score of 0.60. While the results are promising, the extraction rules can still be improved to capture all the knowledge © 2022. International Journal of Advanced Computer Science and Applications.All Rights Reserved.",Final,All Open Access; Gold Open Access
Rony M.R.A.H.; Chaudhuri D.; Usbeck R.; Lehmann J.,"Rony, Md Rashad Al Hasan (57203302415); Chaudhuri, Debanjan (57204174179); Usbeck, Ricardo (43661711000); Lehmann, Jens (35229806900)",57203302415; 57204174179; 43661711000; 35229806900,Tree-KGQA: An Unsupervised Approach for Question Answering Over Knowledge Graphs,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130844179&doi=10.1109%2fACCESS.2022.3173355&partnerID=40&md5=cf84b4023a5398429c7bdaca1970d05c,"Most Knowledge Graph-based Question Answering (KGQA) systems rely on training data to reach their optimal performance. However, acquiring training data for supervised systems is both time-consuming and resource-intensive. To address this, in this paper, we propose Tree-KGQA, an unsupervised KGQA system leveraging pre-trained language models and tree-based algorithms. Entity and relation linking are essential components of any KGQA system. We employ several pre-trained language models in the entity linking task to recognize the entities mentioned in the question and obtain the contextual representation for indexing. Furthermore, for relation linking we incorporate a pre-trained language model previously trained for language inference task. Finally, we introduce a novel algorithm for extracting the answer entities from a KG, where we construct a forest of interpretations and introduce tree-walking and tree disambiguation techniques. Our algorithm uses the linked relation and predicts the tree branches that eventually lead to the potential answer entities. The proposed method achieves 4.5% and 7.1% gains in F1 score in entity linking tasks on LC-QuAD 2.0 and LC-QuAD 2.0 (KBpearl) datasets, respectively, and a 5.4% increase in the relation linking task on LC-QuAD 2.0 (KBpearl). The comprehensive evaluations demonstrate that our unsupervised KGQA approach outperforms other supervised state-of-the-art methods on the WebQSP-WD test set (1.4% increase in F1 score)-without training on the target dataset.  © 2013 IEEE.",Final,All Open Access; Gold Open Access
Yang B.; Han C.; Li Y.; Zuo L.; Yu Z.,"Yang, Bowen (57385548600); Han, Cong (57208824362); Li, Yu (57219751720); Zuo, Lei (57384384200); Yu, Zhou (57205750897)",57385548600; 57208824362; 57219751720; 57384384200; 57205750897,Improving Conversational Recommendation Systems' Quality with Context-Aware Item Meta-Information,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137329568&partnerID=40&md5=8a4e6fb5dcf4f18e7a171c4195556239,"A key challenge of Conversational Recommendation Systems (CRS) is to integrate the recommendation function and the dialog generation function smoothly. Previous works employ graph neural networks with external knowledge graphs (KG) to model individual recommendation items and integrate KGs with language models through attention mechanisms for response generation. Although previous approaches prove effective, there is still room for improvement. For example, KG-based approaches only rely on entity relations and bagof- words to recommend items and neglect the information in the conversational context. We propose to improve the usage of dialog context for both recommendation and response generation using an encoding architecture along with the self-attention mechanism of transformers. In this paper, we propose a simple yet effective architecture comprising a pre-trained language model (PLM) and an item metadata encoder to integrate the recommendation and the dialog generation better. The proposed item encoder learns to map item metadata to embeddings reflecting the rich information of the item, which can be matched with dialog context. The PLM then consumes the context-aware item embeddings and dialog context to generate high-quality recommendations and responses. Experimental results on the benchmark dataset REDIAL show that our model obtains stateof- the-art results on both recommendation and response generation tasks. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Wang L.; Zhao W.; Wei Z.; Liu J.,"Wang, Liang (57546760800); Zhao, Wei (57271139200); Wei, Zhuoyu (57546760900); Liu, Jingming (57216692158)",57546760800; 57271139200; 57546760900; 57216692158,SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136148731&partnerID=40&md5=c48656f3f11180cce44d2971c6abe4f0,"Knowledge graph completion (KGC) aims to reason over known facts and infer the missing links. Text-based methods such as KG-BERT (Yao et al., 2019) learn entity representations from natural language descriptions, and have the potential for inductive KGC. However, the performance of text-based methods still largely lag behind graph embedding-based methods like TransE (Bordes et al., 2013) and RotatE (Sun et al., 2019b). In this paper, we identify that the key issue is efficient contrastive learning. To improve the learning efficiency, we introduce three types of negatives: in-batch negatives, pre-batch negatives, and self-negatives which act as a simple form of hard negatives. Combined with InfoNCE loss, our proposed model SimKGC can substantially outperform embedding-based methods on several benchmark datasets. In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19% on WN18RR, +6.8% on the Wikidata5M transductive setting, and +22% on the Wikidata5M inductive setting. Thorough analyses are conducted to gain insights into each component. Our code is available at https://github.com/intfloat/SimKGC. © 2022 Association for Computational Linguistics.",Final,
Tamper M.; Leal R.; Sinikallio L.; Leskinen P.; Tuominen J.; Hyvönen E.,"Tamper, Minna (57190293971); Leal, Rafael (57262469200); Sinikallio, Laura (57262332400); Leskinen, Petri (56730467000); Tuominen, Jouni (24386059900); Hyvönen, Eero (8435405300)",57190293971; 57262469200; 57262332400; 56730467000; 24386059900; 8435405300,Extracting Knowledge from Parliamentary Debates for Studying Political Culture and Language,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137151568&partnerID=40&md5=2c098194da52c04381ddb5cb3863961e,"This paper presents knowledge extraction and natural language processing methods used to enrich the knowledge graph of the plenary debates (textual transcripts of speeches) of the Parliament of Finland. This knowledge graph includes some 960 000 speeches (1907–2021) interlinked with a prosopographical knowledge graph about the politicians. A recent subset of the speeches was used to extract named entities and topical keywords for semantic searching and browsing the data and for data analysis. The process is based on linguistic analysis, named entity linking, and automatic subject indexing. The results were included into the ParliamentSampo knowledge graph in a SPARQL endpoint. This data can be used for studying parliamentary language and culture in Digital Humanities research and for developing applications, such as the ParliamentSampo portal. © 2022 Copyright for this paper by its authors.",Final,
Zhang K.; Wang Y.; Wang H.; Huang L.; Yang C.; Chen X.; Sun L.,"Zhang, Kai (57221087459); Wang, Yu (57222408812); Wang, Hongyi (57200625507); Huang, Lifu (57193240973); Yang, Carl (57203495794); Chen, Xun (36456894700); Sun, Lichao (57193994946)",57221087459; 57222408812; 57200625507; 57193240973; 57203495794; 36456894700; 57193994946,Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135544428&partnerID=40&md5=6a630af8e1aeccee95d99315966d7849,"Federated learning (FL) can be essential in knowledge representation, reasoning; and data mining applications over multi-source knowledge graphs (KGs). A recent study FedE first proposes an FL framework that shares entity embeddings of KGs across all clients. However, entity embedding sharing from FedE would incur a severe privacy leakage. Specifically, the known entity embedding can be used to infer whether a specific relation between two entities exists in a private client. In this paper, we introduce a novel attack method that aims to recover the original data based on the embedding information, which is further used to evaluate the vulnerabilities of FedE. Furthermore, we propose a Federated learning paradigm with privacy-preserving Relation embedding aggregation (FEDR) to tackle the privacy issue in FedE. Besides, relation embedding sharing can significantly reduce the communication cost due to its smaller size of queries. We conduct extensive experiments to evaluate FEDR with five different KG embedding models and three datasets. Compared to FedE, FEDR achieves similar utility and significant improvements regarding privacy-preserving effect and communication efficiency on the link prediction task. © 2022 Association for Computational Linguistics.",Final,
Biswas R.; Chen Y.; Paulheim H.; Sack H.; Alam M.,"Biswas, Russa (57202431946); Chen, Yiyi (57224476140); Paulheim, Heiko (35095438500); Sack, Harald (7102918498); Alam, Mehwish (57201532578)",57202431946; 57224476140; 35095438500; 7102918498; 57201532578,It’s All in the Name: Entity Typing Using Multilingual Language Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135078523&doi=10.1007%2f978-3-031-11609-4_7&partnerID=40&md5=86f6b511ee8cd7cfe91a06c7400ab18a,"The entity type information in Knowledge Graphs (KGs) of different languages plays an important role in a wide range of Natural Language Processing applications. However, the entity types in KGs are often incomplete. Multilingual entity typing is a non-trivial task if enough information is not available for the entities in a KG. In this work, multilingual neural language models are exploited to predict the type of an entity from only the name of the entity. The model has been successfully evaluated on multilingual datasets extracted from different language chapters in DBpedia namely German, French, Spanish, and Dutch. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Alam M.M.; Rony M.R.A.H.; Nayyeri M.; Mohiuddin K.; Akter M.S.T.M.; Vahdati S.; Lehmann J.,"Alam, Mirza Mohtashim (57202902190); Rony, Md Rashad Al Hasan (57203302415); Nayyeri, Mojtaba (35776892400); Mohiuddin, Karishma (57509007900); Akter, M. S. T. Mahfuja (57852007600); Vahdati, Sahar (56204337200); Lehmann, Jens (35229806900)",57202902190; 57203302415; 35776892400; 57509007900; 57852007600; 56204337200; 35229806900,Language Model Guided Knowledge Graph Embeddings,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135235115&doi=10.1109%2fACCESS.2022.3191666&partnerID=40&md5=3ca6c25328002a5853c2c4dbddd2d7b7,"Knowledge graph embedding models have become a popular approach for knowledge graph completion through predicting the plausibility of (potential) triples. This is performed by transforming the entities and relations of the knowledge graph into an embedding space. However, knowledge graphs often include further textual information stored in literal, which is ignored by such embedding models. As a consequence, the learning process stays limited to the structure and the connections between the entities, which has the potential to negatively influence the performance. We bridge this gap by leveraging the capabilities of pre-trained language models to include textual knowledge in the learning process of embedding models. This is achieved by introducing a new loss function that guides embedding models in measuring the likelihood of triples by taking such complementary knowledge into consideration. The proposed solution is a model-independent loss function that can be plugged into any knowledge graph embedding model. In this paper, Sentence-BERT and fastText are used as pre-trained language models from which the embeddings of the textual knowledge are obtained and injected into the loss function. The loss function contains a trainable slack variable that determines the degree to which the language models influence the plausibility of triples. Our experimental evaluation on six benchmarks, namely Nations, UMLS, WordNet, and three versions of CodEx confirms the advantage of using pre-trained language models for boosting the accuracy of knowledge graph embedding models. We showcase this by performing evaluations on top of the five well-known knowledge graph embedding models such as TransE, RotatE, ComplEx, DistMult, and QuatE. The results show an improvement in accuracy up to 9% on UMLS dataset for the Distmult model and 4.2% on the Nations dataset for the ComplEx model when they are guided by pre-trained language models. We additionally studied the effect of multiple factors such as the structure of the knowledge graphs and training steps and presented them as ablation studies. © 2013 IEEE.",Final,All Open Access; Gold Open Access
Zhang Y.; Zhou Z.; Yao Q.; Li Y.,"Zhang, Yongqi (57209508370); Zhou, Zhanke (57217855781); Yao, Quanming (57002177700); Li, Yong (57189401839)",57209508370; 57217855781; 57002177700; 57189401839,KGTuner: Efficient Hyper-parameter Search for Knowledge Graph Learning,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133377036&partnerID=40&md5=237dbd082096387e2a90183f715c0321,"While hyper-parameters (HPs) are important for knowledge graph (KG) learning, existing methods fail to search them efficiently. To solve this problem, we first analyze the properties of different HPs and measure the transfer ability from small subgraph to the full graph. Based on the analysis, we propose an efficient two-stage search algorithm KGTuner, which efficiently explores HP configurations on small subgraph at the first stage and transfers the top-performed configurations for fine-tuning on the large full graph at the second stage. Experiments show that our method can consistently find better HPs than the baseline algorithms within the same time budget, which achieves 9.1% average relative improvement for four embedding models on the large-scale KGs in open graph benchmark. Our code is released in https://github.com/AutoML-Research/KGTuner. © 2022 Association for Computational Linguistics.",Final,
Das N.; Sunkara M.; Bekal D.; Chau D.H.; Bodapati S.; Kirchhoff K.,"Das, Nilaksh (57203386129); Sunkara, Monica (57219759352); Bekal, Dhanush (57216971880); Chau, Duen Horng (14035167900); Bodapati, Sravan (57205738213); Kirchhoff, Katrin (7006780729)",57203386129; 57219759352; 57216971880; 14035167900; 57205738213; 7006780729,"LISTEN, KNOW AND SPELL: KNOWLEDGE-INFUSED SUBWORD MODELING FOR IMPROVING ASR PERFORMANCE OF OOV NAMED ENTITIES",-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131264183&doi=10.1109%2fICASSP43922.2022.9746748&partnerID=40&md5=257290969d43b5f4ecdf01c96378fa13,"Automatic speech recognition (ASR) is increasingly being used in specialized domains such as medical ASR and news transcription. Owing to the lack of high quality annotated speech data in such domains, off-the-shelf models are commonly employed by fine-tuning on domain-specific data. This poses a significant challenge in transcribing long-tail expressions and out-of-vocabulary (OOV) named entities. On the other hand, readily available knowledge graphs (KGs) provide semantically structured knowledge for such domain-specific named entities. In this work, we propose the Knowledge-Infused Subword Model (KISM), a novel technique for incorporating semantic context from KGs into the ASR pipeline for improving the performance of OOV named entities. Our experiments show that KISM improves OOV recall of an ASR model by 4.58% (absolute) for named entities that were not seen during training. © 2022 IEEE",Final,
Jiang J.; Zhou K.; Zhao W.X.; Wen J.-R.,"Jiang, Jinhao (57222071901); Zhou, Kun (57212192211); Zhao, Wayne Xin (36769862300); Wen, Ji-Rong (7402697777)",57222071901; 57212192211; 36769862300; 7402697777,Great Truths are Always Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137338536&partnerID=40&md5=41d72888f58faa43ccd64c029d23e645,"Commonsense reasoning in natural language is a desired ability of artificial intelligent systems. For solving complex commonsense reasoning tasks, a typical solution is to enhance pre-trained language models (PTMs) with a knowledge-aware graph neural network (GNN) encoder that models a commonsense knowledge graph (CSKG). Despite the effectiveness, these approaches are built on heavy architectures, and can't clearly explain how external knowledge resources improve the reasoning capacity of PTMs. Considering this issue, we conduct a deep empirical analysis, and find that it is indeed relation features from CSKGs (but not node features) that mainly contribute to the performance improvement of PTMs. Based on this finding, we design a simple MLP-based knowledge encoder that utilizes statistical relation paths as features. Extensive experiments conducted on five benchmarks demonstrate the effectiveness of our approach, which also largely reduces the parameters for encoding CSKGs. Our codes and data are publicly available at https://github.com/RUCAIBox/SAFE. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Final,
Huang J.; Chang K.C.-C.; Xiong J.; Hwu W.-M.,"Huang, Jie (57226877159); Chang, Kevin Chen-Chuan (7407034942); Xiong, Jinjun (7202010057); Hwu, Wen-Mei (35584943100)",57226877159; 7407034942; 7202010057; 35584943100,Open Relation Modeling: Learning to Define Relations between Entities,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130843995&partnerID=40&md5=59641079ad5a3ab10a0f8db7b2d96431,"Relations between entities can be represented by different instances, e.g., a sentence containing both entities or a fact in a Knowledge Graph (KG). However, these instances may not well capture the general relations between entities, may be difficult to understand by humans, even may not be found due to the incompleteness of the knowledge source. In this paper, we introduce the Open Relation Modeling problem-given two entities, generate a coherent sentence describing the relation between them. To solve this problem, we propose to teach machines to generate definition-like relation descriptions by letting them learn from defining entities. Specifically, we fine-tune Pre-trained Language Models (PLMs) to produce definitions conditioned on extracted entity pairs. To help PLMs reason between entities and provide additional relational knowledge to PLMs for open relation modeling, we incorporate reasoning paths in KGs and include a reasoning path selection mechanism. Experimental results show that our model can generate concise but informative relation descriptions that capture the representative characteristics of entities.. © 2022 Association for Computational Linguistics.",Final,
Yang H.; Li D.-W.; Li Z.; Yang D.; Qi J.; Wu B.,"Yang, Huifan (57822392500); Li, Da-Wei (57821635900); Li, Zekun (57219841930); Yang, Donglin (57822392600); Qi, Jinsheng (57821383700); Wu, Bin (56449782000)",57822392500; 57821635900; 57219841930; 57822392600; 57821383700; 56449782000,Open Relation Extraction via Query-Based Span Prediction,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135003694&doi=10.1007%2f978-3-031-10986-7_6&partnerID=40&md5=c8535ad90254c5a9d0d362e1c24e849d,"Open relation extraction (ORE) aims to assign semantic relationships between arguments, essential to the automatic construction of knowledge graphs. The previous methods either depend on external NLP tools (e.g., PoS-taggers) and language-specific relation formations, or suffer from inherent problems in sequence representations, thus leading to unsatisfactory extraction in diverse languages and domains. To address the above problems, we propose a Query-based Open Relation Extractor (QORE). QORE utilizes a Transformers-based language model to derive a representation of the interaction between arguments and context, and can process multilingual texts effectively. Extensive experiments are conducted on seven datasets covering four languages, showing that QORE models significantly outperform conventional rule-based systems and the state-of-the-art method LOREM [6]. Regarding the practical challenges [1] of Corpus Heterogeneity and Automation, our evaluations illustrate that QORE models show excellent zero-shot domain transferability and few-shot learning ability. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Lv X.; Lin Y.; Cao Y.; Hou L.; Li J.; Liu Z.; Li P.; Zhou J.,"Lv, Xin (57211203656); Lin, Yankai (57155321900); Cao, Yixin (57015851100); Hou, Lei (56622056400); Li, Juanzi (8304332600); Liu, Zhiyuan (57191691341); Li, Peng (57211755481); Zhou, Jie (57211746430)",57211203656; 57155321900; 57015851100; 56622056400; 8304332600; 57191691341; 57211755481; 57211746430,Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130994784&partnerID=40&md5=fa08fa467d668c27ddca2962a4bf694a,"In recent years, pre-trained language models (PLMs) have been shown to capture factual knowledge from massive texts, which encourages the proposal of PLM-based knowledge graph completion (KGC) models. However, these models are still quite behind the SOTA KGC models in terms of performance. In this work, we find two main reasons for the weak performance: (1) Inaccurate evaluation setting. The evaluation setting under the closed-world assumption (CWA) may underestimate the PLM-based KGC models since they introduce more external knowledge; (2) Inappropriate utilization of PLMs. Most PLM-based KGC models simply splice the labels of entities and relations as inputs, leading to incoherent sentences that do not take full advantage of the implicit knowledge in PLMs. To alleviate these problems, we highlight a more accurate evaluation setting under the open-world assumption (OWA), which manually checks the correctness of knowledge that is not in KGs. Moreover, motivated by prompt tuning, we propose a novel PLM-based KGC model named PKGC. The basic idea is to convert each triple and its support information into natural prompt sentences, which are further fed into PLMs for classification. Experiment results on two KGC datasets demonstrate OWA is more reliable for evaluating KGC, especially on the link prediction, and the effectiveness of our PKCG model on both CWA and OWA settings. © 2022 Association for Computational Linguistics.",Final,
Opitz D.; Hochgeschwender N.,"Opitz, Dominik (57824404500); Hochgeschwender, Nico (25645533000)",57824404500; 25645533000,From Zero to Hero: Generating Training Data for Question-To-Cypher Models,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135145550&doi=10.1145%2f3528588.3528655&partnerID=40&md5=dc52822aa01141cb84df6716c230f2df,"Graph databases employ graph structures such as nodes, attributes and edges to model and store relationships among data. To access this data, graph query languages (GQL) such as Cypher are typically used, which might be difficult to master for end-users. In the context of relational databases, sequence to SQL models, which translate natural language questions to SQL queries, have been proposed. While these Neural Machine Translation (NMT) models increase the accessibility of relational databases, NMT models for graph databases are not yet available mainly due to the lack of suitable parallel training data. In this short paper we sketch an architecture which enables the generation of synthetic training data for the graph query language Cypher.  © 2022 ACM.",Final,All Open Access; Bronze Open Access
Niu G.; Li B.; Zhang Y.; Pu S.,"Niu, Guanglin (57191197891); Li, Bo (56092633500); Zhang, Yongfei (34874069700); Pu, Shiliang (56462199300)",57191197891; 56092633500; 34874069700; 56462199300,CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,-1,,-1,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136101523&partnerID=40&md5=3e02ea03061a190953d6cfbdd1eb6dec,"Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC's performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results. © 2022 Association for Computational Linguistics.",Final,
Ouyang B.; Huang W.; Chen R.; Tan Z.; Liu Y.; Sun M.; Zhu J.,"Ouyang, Bo (57217433163); Huang, Wenbing (55899205200); Chen, Runfa (57219635215); Tan, Zhixing (57192659590); Liu, Yang (57211088579); Sun, Maosong (7403180987); Zhu, Jihong (55608293500)",57217433163; 55899205200; 57219635215; 57192659590; 57211088579; 7403180987; 55608293500,Knowledge Representation Learning with Contrastive Completion Coding,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129196883&partnerID=40&md5=9504ab74d9f52e4bfbba212a0cee399f,"Knowledge representation learning (KRL) has been used in plenty of knowledge-driven tasks. Despite fruitfully progress, existing methods still suffer from the immaturity on tackling potentially-imperfect knowledge graphs and highly-imbalanced positive-negative instances during training, both of which would hinder the performance of KRL. In this paper, we propose Contrastive Completion Coding (C3), a novel KRL framework that is composed of two functional components: 1. Hierarchical Architecture, which integrates both low-level standalone features and high-level topology-aware features to yield robust embedding for each entity/relation. 2. Normalized Contrasitive Training, which conducts normalized one-tomany contrasitive learning to emphasize different negatives with different weights, delivering better convergence compared to conventional training losses. Extensive experiments on several benchmarks verify the efficacy of the two proposed techniques and combing them together generally achieves superior performance against state-of-the-art approaches.  © 2021 Association for Computational Linguistics.",Final,
Clark T.H.; Conforti C.; Liu F.; Meng Z.; Shareghi E.; Collier N.,"Clark, Thomas Hikaru (57272025400); Conforti, Costanza (57195677058); Liu, Fangyu (57192190518); Meng, Zaiqiao (56924375000); Shareghi, Ehsan (35957521400); Collier, Nigel (7004876365)",57272025400; 57195677058; 57192190518; 56924375000; 35957521400; 7004876365,Integrating Transformers and Knowledge Graphs for Twitter Stance Detection,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138807732&partnerID=40&md5=d5e5c424abbd5a55dff79fe455607690,"Stance detection (SD) entails classifying the sentiment of a text towards a given target, and is a relevant sub-task for opinion mining and social media analysis. Recent works have explored knowledge infusion — supplementing the linguistic competence and latent knowledge of large pre-trained language models with structured knowledge graphs (KGs), yet few works have applied such methods to the SD task. In this work, we first perform stance-relevant knowledge probing on Transformers-based pre-trained models in a zero-shot setting, showing these models’ latent real-world knowledge about SD targets and their sensitivity to context. We then propose novel knowledge-enriched stance detection models. We evaluate them on two Twitter stance datasets, achieving state-of-the-art performance on both. © 2021 Association for Computational Linguistics.",Final,
Armengol-Estapé J.; Costa-jussà M.R.,"Armengol-Estapé, Jordi (57214894926); Costa-jussà, Marta R. (15519053500)",57214894926; 15519053500,Semantic and syntactic information for neural machine translation: Injecting Features to the Transformer,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106063312&doi=10.1007%2fs10590-021-09264-2&partnerID=40&md5=d5d89a430695e60e205332d60fe523a5,"Introducing factors such as linguistic features has long been proposed in machine translation to improve the quality of translations. More recently, factored machine translation has proven to still be useful in the case of sequence-to-sequence systems. In this work, we investigate whether this gains hold in the case of the state-of-the-art architecture in neural machine translation, the Transformer, instead of recurrent architectures. We propose a new model, the Factored Transformer, to introduce an arbitrary number of word features in the source sequence in an attentional system. Specifically, we suggest two variants depending on the level at which the features are injected. Moreover, we suggest two combination mechanisms for the word features and words themselves. We experiment both with classical linguistic features and semantic features extracted from a linked data database, and with two low-resource datasets. With the best-found configuration, we show improvements of 0.8 BLEU over the baseline Transformer in the IWSLT German-to-English task. Moreover, we experiment with the more challenging FLoRes English-to-Nepali benchmark, which includes both low-resource and very distant languages, and obtain an improvement of 1.2 BLEU. These improvements are achieved with linguistic and not with semantic information. © 2021, The Author(s).",Final,All Open Access; Hybrid Gold Open Access
Yang X.; Chiang M.-F.; Lee W.-C.; Chang Y.,"Yang, Xia (57286337900); Chiang, Meng-Fen (24723558400); Lee, Wang-Chien (7407085251); Chang, Yi (25824668400)",57286337900; 24723558400; 7407085251; 25824668400,Cost-Effective Knowledge Graph Reasoning for Complex Factoid Questions,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116430716&doi=10.1109%2fIJCNN52387.2021.9533753&partnerID=40&md5=dca9c8e035cec9968d2ecb18867c18ff,"The task of reasoning over knowledge graph for factoid questions has received significant interest from the research community of natural language processing. Performing this task inevitably faces the issues of question complexity and reasoning efficiency. In this paper, we investigate modern reasoning approaches over knowledge graph to tackle complex factoid questions of diverse reasoning schemas with attractive speedup in computational efficiency. To this end, we propose two evidence retrieval strategies to generate concise and informative evidence graph of high semantic-relevance and factual coverage to the question. Then, we adopt DELFT, a graph neural networks based framework that takes the linguistic structure representation of a question and the evidence graph as input, to predict the answer by reasoning over the evidence graph. We evaluate the performance across several baselines in terms of effectiveness and efficiency on two real-world datasets, MOOCQA and MetaQA. The results show the superiority of message passing paradigm in delivering a robust reasoner with better answer quality and significantly improved computational efficiency. © 2021 IEEE.",Final,
Keidar D.; Zhong M.; Zhang C.; Shrestha Y.R.; Paudel B.,"Keidar, Daphna (57221157394); Zhong, Mian (57288679100); Zhang, Ce (58502033600); Shrestha, Yash Raj (55537443500); Paudel, Bibek (57188750961)",57221157394; 57288679100; 58502033600; 55537443500; 57188750961,Towards Automatic Bias Detection in Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129205502&partnerID=40&md5=fcc3fb4dd501ed885c470ce40deec600,"With the recent surge in social applications relying on knowledge graphs, the need for techniques to ensure fairness in KG based methods is becoming increasingly evident. Previous works have demonstrated that KGs are prone to various social biases, and have proposed multiple methods for debiasing them. However, in such studies, the focus has been on debiasing techniques, while the relations to be debiased are specified manually by the user. As manual specification is itself susceptible to human cognitive bias, there is a need for a system capable of quantifying and exposing biases, that can support more informed decisions on what to debias. To address this gap in the literature, we describe a framework for identifying biases present in knowledge graph embeddings, based on numerical bias metrics. We illustrate the framework with three different bias measures on the task of profession prediction, and it can be flexibly extended to further bias definitions and applications. The relations flagged as biased can then be handed to decision makers for judgement upon subsequent debiasing.  © 2021 Association for Computational Linguistics.",Final,
Alkenani A.H.; Li Y.; Xu Y.; Zhang Q.,"Alkenani, Ahmed H. (57219898452); Li, Yuefeng (35318087600); Xu, Yue (14032389000); Zhang, Qing (57192216081)",57219898452; 35318087600; 14032389000; 57192216081,Predicting Alzheimer's Disease from Spoken and Written Language Using Fusion-Based Stacked Generalization,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107628825&doi=10.1016%2fj.jbi.2021.103803&partnerID=40&md5=90983dbab99a9fece12dd0d3df746c92,"The importance of automating the diagnosis of Alzheimer disease (AD) towards facilitating its early prediction has long been emphasized, hampered in part by lack of empirical support. Given the evident association of AD with age and the increasing aging population owing to the general well-being of individuals, there have been unprecedented estimated economic complications. Consequently, many recent studies have attempted to employ the language deficiency caused by cognitive decline in automating the diagnostic task via training machine learning (ML) algorithms with linguistic patterns and deficits. In this study, we aim to develop multiple heterogeneous stacked fusion models that harness the advantages of several base learning algorithms to improve the overall generalizability and robustness of AD diagnostic ML models, where we parallelly utilized two different written and spoken-based datasets to train our stacked fusion models. Further, we examined the effect of linking these two datasets to develop a hybrid stacked fusion model that can predict AD from written and spoken languages. Our feature spaces involved two widely used linguistic patterns: lexicosyntactics and character n-gram spaces. We firstly investigated lexicosyntactics of AD alongside healthy controls (HC), where we explored a few new lexicosyntactic features, then optimized the lexicosyntactic feature space by proposing a correlation feature selection technique that eliminates features based on their feature-feature inter-correlations and feature-target correlations according to a certain threshold. Our stacked fusion models establish benchmarks on both datasets with AUC of 98.1% and 99.47% for the spoken and written-based datasets, respectively, and corresponding accuracy and F1 score values around 95% on spoken-based dataset and around 97% on the written-based dataset. Likewise, the hybrid stacked fusion model on linked data presents an optimal performance with 99.2% AUC as well as accuracy and F1 score falling around 97%. In view of the achieved performance and enhanced generalizability of such fusion models over single classifiers, this study suggests replacing the initial traditional screening test with such models that can be embedded into an online format for a fully automated remote diagnosis. © 2021",Final,All Open Access; Bronze Open Access
,,,"10th Symposium on Languages, Applications and Technologies, SLATE 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115885924&partnerID=40&md5=8855da9e6c29cf13156f65e24652edc7,"The proceedings contain 19 papers. The topics discussed include: Derzis: a path aware linked data crawler; major minors – ontological representation of minorities by newspapers; lyntax – a grammar-based tool for linguistics; programming exercises interoperability: the case of a non-picky consumer; Mooshak’s diet update: introducing YAPExIL format to Mooshak; LeMe–PT: a medical package leaflet corpus for portuguese; towards automatic creation of annotations to foster development of named entity recognizers; semantic search of mobile applications using word embeddings; using machine learning for vulnerability detection and classification; NetLangEd, a web editor to support online comment annotation; and intelligent query answering with contextual knowledge for relational databases.",Final,
Kitanović O.; Stanković R.; Tomašević A.; Škorić M.; Babić I.; Kolonja L.,"Kitanović, Olivera (57073927100); Stanković, Ranka (56443795400); Tomašević, Aleksandra (57201578923); Škorić, Mihailo (57220089897); Babić, Ivan (57222727137); Kolonja, Ljiljana (57201583396)",57073927100; 56443795400; 57201578923; 57220089897; 57222727137; 57201583396,A data driven approach for raw material terminology,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103820701&doi=10.3390%2fapp11072892&partnerID=40&md5=360731318a031a55e570aef5cda8f653,"The research presented in this paper aims at creating a bilingual (sr-en), easily search-able, hypertext, born-digital, corpus-based terminological database of raw material terminology for dictionary production. The approach is based on linking dictionaries related to the raw material domain, both digitally born and printed, into a lexicon structure, aligning terminology from different dictionaries as much as possible. This paper presents the main features of this approach, data used for compilation of the terminological database, the procedure by which it has been generated and a mobile application for its use. Available (terminological) resources will be presented—paper dictionaries and digital resources related to the raw material domain, as well as general lexica morphological dictionaries. Resource preparation started with dictionary (retro)digitisation and corpora enlargement, followed by adding new Serbian terms to general lexica dictionaries, as well as adding bilingual terms. Dictionary development is relying on corpus analysis, details of which are also presented. Usage examples, collocations and concordances play an important role in raw material terminology, and have also been included in this research. Some important related issues discussed are collocation extraction methods, the use of domain labels, lexical and semantic relations, definitions and subentries. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Final,All Open Access; Gold Open Access
Datta S.; Mallick P.; Patil S.; Bhattacharya I.; Palshikar G.,"Datta, Soham (57264869200); Mallick, Prabir (57194761869); Patil, Sangameshwar (55545862803); Bhattacharya, Indrajit (14024110800); Palshikar, Girish (55890466600)",57264869200; 57194761869; 55545862803; 14024110800; 55890466600,Generating An Optimal Interview Question Plan Using A Knowledge Graph And Integer Linear Programming,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136031027&partnerID=40&md5=a4402637cddeec15f0e5976b558bb637,"Given the diversity of the candidates and complexity of job requirements, and since interviewing is an inherently subjective process, it is an important task to ensure consistent, uniform, efficient and objective interviews that result in high quality recruitment. We propose an interview assistant system to automatically, and in an objective manner, select an optimal set of technical questions (from question banks) personalized for a candidate. This set can help a human interviewer to plan for an upcoming interview of that candidate. We formalize the problem of selecting a set of questions as an integer linear programming problem and use standard solvers to get a solution. We use knowledge graph as background knowledge in this formulation, and derive our objective functions and constraints from it. We use candidate’s resume to personalize the selection of questions. We propose an intrinsic evaluation to compare a set of suggested questions with actually asked questions. We also use expert interviewers to comparatively evaluate our approach with a set of reasonable baselines. © 2021 Association for Computational Linguistics.",Final,
Dai D.; Zheng H.; Luo F.; Yang P.; Chang B.; Sui Z.,"Dai, Damai (57216617664); Zheng, Hua (57221144424); Luo, Fuli (57207860404); Yang, Pengcheng (57207874889); Chang, Baobao (55837183200); Sui, Zhifang (23091994600)",57216617664; 57221144424; 57207860404; 57207874889; 55837183200; 23091994600,Inductively Representing Out-of-Knowledge-Graph Entities by Optimal Estimation Under Translational Assumptions,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138492981&partnerID=40&md5=ba6def7f7161914a8f322cdb2aed682c,"Conventional Knowledge Graph Completion (KGC) assumes that all test entities appear during training. However, in real-world scenarios, Knowledge Graphs (KG) evolve fast with out-of-knowledge-graph (OOKG) entities added frequently, and we need to efficiently represent these entities. Most existing Knowledge Graph Embedding (KGE) methods cannot represent OOKG entities without costly retraining on the whole KG. To enhance efficiency, we propose a simple and effective method that inductively represents OOKG entities by their optimal estimation under translational assumptions. Moreover, given pretrained embeddings of the in-knowledge-graph (IKG) entities, our method even needs no additional learning. Experimental results on two KGC tasks with OOKG entities show that our method outperforms the previous methods by a large margin with higher efficiency. © 2021 Association for Computational Linguistics.",Final,
Zhang T.; Cai Z.; Wang C.; Li P.; Li Y.; Qiu M.; Tang C.; He X.; Huang J.,"Zhang, Taolin (57221142663); Cai, Zerui (57245833400); Wang, Chengyu (55926354300); Li, Peng (57199004980); Li, Yang (57219793158); Qiu, Minghui (55537463100); Tang, Chengguang (57219766342); He, Xiaofeng (55641972700); Huang, Jun (57199287007)",57221142663; 57245833400; 55926354300; 57199004980; 57219793158; 55537463100; 57219766342; 55641972700; 57199287007,HORNET: Enriching Pre-trained Language Representations with Heterogeneous Knowledge Sources,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119181897&doi=10.1145%2f3459637.3482436&partnerID=40&md5=04aecaaa3d768ded99a4db0e0108b8c9,"Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the language understanding abilities of deep language models by leveraging the rich semantic knowledge from knowledge graphs, other than plain pre-training texts. However, previous efforts mostly use homogeneous knowledge (especially structured relation triples in knowledge graphs) to enhance the context-aware representations of entity mentions, whose performance may be limited by the coverage of knowledge graphs. Also, it is unclear whether these KEPLMs truly understand the injected semantic knowledge due to the ""black-box'' training mechanism. In this paper, we propose a novel KEPLM named HORNET, which integrates Heterogeneous knowledge from various structured and unstructured sources into the Roberta NETwork and hence takes full advantage of both linguistic and factual knowledge simultaneously. Specifically, we design a hybrid attention heterogeneous graph convolution network (HaHGCN) to learn heterogeneous knowledge representations based on the structured relation triplets from knowledge graphs and the unstructured entity description texts. Meanwhile, we propose the explicit dual knowledge understanding tasks to help induce a more effective infusion of the heterogeneous knowledge, promoting our model for learning the complicated mappings from the knowledge graph embedding space to the deep context-aware embedding space and vice versa. Experiments show that our HORNET model outperforms various KEPLM baselines on knowledge-aware tasks including knowledge probing, entity typing and relation extraction. Our model also achieves substantial improvement over several GLUE benchmark datasets, compared to other KEPLMs. © 2021 ACM.",Final,
Zhao A.; Yu Y.,"Zhao, Anping (55429912500); Yu, Yu (57197518576)",55429912500; 57197518576,Knowledge-enabled BERT for aspect-based sentiment analysis,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107970035&doi=10.1016%2fj.knosys.2021.107220&partnerID=40&md5=3541d86561510102701e538b6ba2f04c,"To provide explainable and accurate aspect terms and the corresponding aspect–sentiment detection, it is often useful to take external domain-specific knowledge into consideration. In this work, we propose a knowledge-enabled language representation model BERT for aspect-based sentiment analysis. Specifically, our proposal leverages the additional information from a sentiment knowledge graph by injecting sentiment domain knowledge into the language representation model, which obtains the embedding vectors of entities in the sentiment knowledge graph and words in the text in a consistent vector space. In addition, the model is capable of achieving better performance with a small amount of training data by incorporating external domain knowledge into the language representation model to compensate for the limited training data. As a result, our model is able to provide explainable and detailed results for aspect-based sentiment analysis. Experimental results demonstrate the effectiveness of the proposed method, showing that the knowledge-enabled BERT is an excellent choice for solving aspect-based sentiment analysis problems. © 2021 Elsevier B.V.",Final,
Agarwal O.; Ge H.; Shakeri S.; Al-Rfou R.,"Agarwal, Oshin (57216964903); Ge, Heming (57219504794); Shakeri, Siamak (57207856389); Al-Rfou, Rami (55667617600)",57216964903; 57219504794; 57207856389; 55667617600,Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137741531&partnerID=40&md5=389ca5922dbdf38b427de8b9e7ccbeaa,"Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wikidata KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wikidata can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe. © 2021 Association for Computational Linguistics.",Final,
Jiménez Toledo J.A.; Collazos C.A.; Ortega M.,"Jiménez Toledo, Javier Alejandro (57193956863); Collazos, César A. (8568805300); Ortega, Manuel (7102616640)",57193956863; 8568805300; 7102616640,Discovery model based on analogies for teaching computer programming,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108685996&doi=10.3390%2fmath9121354&partnerID=40&md5=45d772876f32c0aac10c0371811ec847,"Teaching the fundamentals of computer programming in a first course (CS1) is a complex activity for the professor and is also a challenge for them. Nowadays, there are several teaching strategies for dealing with a CS1 at the university, one of which is the use of analogies to support the abstraction process that a student needs to carry for the appropriation of fundamental concepts. This article presents the results of applying a discovery model that allowed for the extraction of patterns, linguistic analysis, textual analytics, and linked data when using analogies for teaching the fundamental concepts of programming by professors in a CS1 in university programs that train software developers. For that reason, a discovery model based on machine learning and text mining was proposed using natural language processing techniques for semantic vector space modeling, distributional semantics, and the generation of synthetic data. The discovery process was carried out using nine supervised learning methods, three unsupervised learning methods, and one semi-supervised learning method involving linguistic analysis techniques, text analytics, and linked data. The main findings showed that professors include keywords, which are part of the technical computer terminology, in the form of verbs in the statement of the analogy and combine them in quantitative contexts with neutral or positive phrases, where numerical examples, cooking recipes, and games were the most used categories. Finally, a structure is proposed for the construction of analogies to teach programming concepts and this was validated by the professors and students. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Final,All Open Access; Gold Open Access
Wen S.; Zeng B.; Liao W.,"Wen, Song (57223244437); Zeng, Bi (7102493126); Liao, Wenxiong (57219915897)",57223244437; 7102493126; 57219915897,Named Entity Recognition for Instructions of Chinese Medicine Based on Pre-trained Language Model,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116106898&doi=10.1109%2fICNLP52887.2021.00029&partnerID=40&md5=b0bf1391797472ad7a1c8764548c5583,"Named Entity Recognition (NER) of Chinese medicine text is a basic task of constructing medical and health knowledge graph. Many scholars have researched the NER task of electronic medical records and drug names, while many factors restrict the research of NER tasks for the instructions of Chinese medicine. For example, there is no obvious boundary between words in Chinese, and it is impossible to capture the interactive information between sentences and the global information at the same time. Considering that this type of data is highly professional and there is no publicly available data set. This paper collected 1,000 pieces of instructions of Chinese medicine, then explored the effectiveness of pre-trained models in NER task in this field. The experimental results showed that compared with the experimental results of the single or joint model on the same data set, the F1 value of pre-trained model was increased by 9.65% and 8.71% respectively. © 2021 IEEE.",Final,
Xie C.; Huang W.; Liang J.; Huang C.; Xiao Y.,"Xie, Chenhao (57217270786); Huang, Wenhao (57224666624); Liang, Jiaqing (57188696905); Huang, Chengsong (57224666173); Xiao, Yanghua (24377046200)",57217270786; 57224666624; 57188696905; 57224666173; 24377046200,WebKE: Knowledge Extraction from Semi-structured Web with Pre-trained Markup Language Model,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119193860&doi=10.1145%2f3459637.3482491&partnerID=40&md5=3869810c38f15cfd695cfc9198106817,"The World Wide Web contains rich up-to-date information for knowledge graph construction. However, most current relation extraction techniques are designed for free text and thus do not handle well semi-structured web content. In this paper, we propose a novel multi-phase machine reading framework, called WebKE. It processes the web content on different granularity by first detecting areas of interest at DOM tree node level and then extracting relational triples for each area. We also propose HTMLBERT as an encoder the web content. It is a pre-trained markup language model that fully leverages the visual layout information and DOM-tree structure, without the need of hand engineered features. Experimental results show that the proposed approach outperforms state-of- the-art methods by a considerable gain. The source code is available at https://github.com/redreamality/webke. © 2021 ACM.",Final,
Chiarcos C.; Ionov M.; Glaser L.; Fäth C.,"Chiarcos, Christian (22333764800); Ionov, Maxim (57194612761); Glaser, Luis (57211408572); Fäth, Christian (57194612424)",22333764800; 57194612761; 57211408572; 57194612424,An ontology for CoNLL-RDF: Formal data structures for TSV formats in language technology,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115060956&doi=10.4230%2fOASIcs.LDK.2021.20&partnerID=40&md5=48b9e3f6a58fdd65592874fea52bd034,"In language technology and language sciences, tab-separated values (TSV) represent a frequently used formalism to represent linguistically annotated natural language, often addressed as “CoNLL formats”. A large number of such formats do exist, but although they share a number of common features, they are not interoperable, as different pieces of information are encoded differently in these dialects. CoNLL-RDF refers to a programming library and the associated data model that has been introduced to facilitate processing and transforming such TSV formats in a serialization-independent way. CoNLL-RDF represents CoNLL data, by means of RDF graphs and SPARQL update operations, but so far, without machine-readable semantics, with annotation properties created dynamically on the basis of a user-defined mapping from columns to labels. Current applications of CoNLL-RDF include linking between corpora and dictionaries [28] and knowledge graphs [36], syntactic parsing of historical languages [12, 11], the consolidation of syntactic and semantic annotations [8], a bridge between RDF corpora and a traditional corpus query language [24], and language contact studies [6]. We describe a novel extension of CoNLL-RDF, introducing a formal data model, formalized as an ontology. The ontology is a basis for linking RDF corpora with other Semantic Web resources, but more importantly, its application for transformation between different TSV formats is a major step for providing interoperability between CoNLL formats. © Christian Chiarcos, Maxim Ionov, Luis Glaser, and Christian Fäth; licensed under Creative Commons License CC-BY 4.0",Final,
Wang Y.; Zhang H.; Liu Z.; Zhou Q.,"Wang, Yashen (56245915700); Zhang, Huanhuan (57210234150); Liu, Zhirun (56333302100); Zhou, Qiang (57220842024)",56245915700; 57210234150; 56333302100; 57220842024,Hierarchical Concept-Driven Language Model,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130097821&doi=10.1145%2f3451167&partnerID=40&md5=59c5ce38fd3cd8aa61285dc4be959abc,"For guiding natural language generation, many semantic-driven methods have been proposed. While clearly improving the performance of the end-To-end training task, these existing semantic-driven methods still have clear limitations: for example, (i) they only utilize shallow semantic signals (e.g., from topic models) with only a single stochastic hidden layer in their data generation process, which suffer easily from noise (especially adapted for short-Text etc.) and lack of interpretation; (ii) they ignore the sentence order and document context, as they treat each document as a bag of sentences, and fail to capture the long-distance dependencies and global semantic meaning of a document. To overcome these problems, we propose a novel semantic-driven language modeling framework, which is a method to learn a Hierarchical Language Model and a Recurrent Conceptualization-enhanced Gamma Belief Network, simultaneously. For scalable inference, we develop the auto-encoding Variational Recurrent Inference, allowing efficient end-To-end training and simultaneously capturing global semantics from a text corpus. Especially, this article introduces concept information derived from high-quality lexical knowledge graph Probase, which leverages strong interpretability and anti-nose capability for the proposed model. Moreover, the proposed model captures not only intra-sentence word dependencies, but also temporal transitions between sentences and inter-sentence concept dependence. Experiments conducted on several NLP tasks validate the superiority of the proposed approach, which could effectively infer meaningful hierarchical concept structure of document and hierarchical multi-scale structures of sequences, even compared with latest state-of-The-Art Transformer-based models.  © 2021 Association for Computing Machinery.",Final,
Biswas R.; Sofronova R.; Sack H.; Alam M.,"Biswas, Russa (57202431946); Sofronova, Radina (57219024016); Sack, Harald (7102918498); Alam, Mehwish (57201532578)",57202431946; 57219024016; 7102918498; 57201532578,Cat2Type: Wikipedia Category Embeddings for Entity Typing in Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120878834&doi=10.1145%2f3460210.3493575&partnerID=40&md5=883e1f1bcb83b6f0fd156fa8fa8756b3,"The entity type information in Knowledge Graphs (KGs) such as DBpedia, Freebase, etc. is often incomplete due to automated generation. Entity Typing is the task of assigning or inferring the semantic type of an entity in a KG. This paper introduces an approach named Cat2Type which exploits the Wikipedia Categories to predict the missing entity types in a KG. This work extracts information from Wikipedia Category names and the Wikipedia Category graph which are the sources of rich semantic information about the entities. In Cat2Type, the characteristic features of the entities encapsulated in Wikipedia Category names are exploited using Neural Language Models. On the other hand, a Wikipedia Category graph is constructed to capture the connection between the categories. The Node level representations are learned by optimizing the neighbourhood information on the Wikipedia category graph. These representations are then used for entity type prediction via classification. The performance of Cat2Type is assessed on two real-world benchmark datasets DBpedia630k and FIGER. The experiments depict that Cat2Type obtained a significant improvement over state-of-the-art approaches.  © 2021 ACM.",Final,
Thai D.; Thirukovalluru R.; Bansal T.; McCallum A.,"Thai, Dung (57215283317); Thirukovalluru, Raghuveer (57191038759); Bansal, Trapit (56347813600); McCallum, Andrew (7003773569)",57215283317; 57191038759; 56347813600; 7003773569,Simultaneously Self-Attending to Text and Entities for Knowledge-Informed Text Representations,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138493705&partnerID=40&md5=a791dcde64e6231cee1862bd85d84d68,"Pre-trained language models have emerged as highly successful methods for learning good text representations. However, the amount of structured knowledge retained in such models, and how (if at all) it can be extracted, remains an open question. In this work, we aim at directly learning text representations which leverage structured knowledge about entities mentioned in the text. This can be particularly beneficial for downstream tasks which are knowledge-intensive. Our approach utilizes self-attention between words in the text and knowledge graph (KG) entities mentioned in the text. While existing methods require entity-linked data for pre-training, we train using a mention-span masking objective and a candidate ranking objective – which doesn’t require any entity-links and only assumes access to an alias table for retrieving candidates, enabling large-scale pre-training. We show that the proposed model learns knowledge-informed text representations that yield improvements on the downstream tasks over existing methods. © 2021 Association for Computational Linguistics.",Final,
Zhang D.; Cheng S.; Yin D.,"Zhang, Dongya (55976750200); Cheng, Siyuan (57407308100); Yin, Didi (56271351400)",55976750200; 57407308100; 56271351400,A Multi-semantic Knowledge Graph Construction Scheme Suitable for Intelligent Power Customer Service,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122643190&doi=10.1145%2f3474198.3478153&partnerID=40&md5=5a9efe94eba0ffa8e138241a4b343c60,"The most classic method of constructing knowledge graph is the Translate-based TransE model, which uses Euclidean distance as the measure in the score function. Each feature dimension participates in the calculation with the same weight, and its accuracy is limited when dealing with complex relations. Aiming at the defects of traditional models, a knowledge graph construction model, TransCD, based on cloud model for multi-semantic relationship is proposed to adapt to the construction of domain knowledge graph in power industry. By dividing the relationship into multiple semantics, the Gaussian mixture model of the relationship is constructed; The corresponding cloud model is constructed to obtain the linguistic value and certainty that can best express the relationship; The determinacy is taken as the weight and the weighted Euclidean distance is taken as the new score function. At the same time, combined with the TransD method, the space projection model of entities and relations is established through dynamic mapping matrix, which integrates the advantages of the two models and increases the ability of the model to deal with multiple semantic relations. The experimental results show that the new method is superior to Trans(E, H, R, D) in terms of link prediction and ternary classification tasks, and has advantages in the processing of multi-semantic professional knowledge in the power industry.  © 2021 ACM.",Final,
Dong T.; Tang L.; Peng J.; Zhong S.; Luo H.,"Dong, Tianyue (58423877400); Tang, Lei (57217758090); Peng, Jinye (58324071200); Zhong, Sheng (57221596253); Luo, Hangzai (7401479905)",58423877400; 57217758090; 58324071200; 57221596253; 7401479905,Knowledge Graph Construction of High-Performance Computing Learning Platform,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102367527&doi=10.1088%2f1742-6596%2f1748%2f2%2f022035&partnerID=40&md5=a0a8d953fcdaf14a7eeb8d6d4d467aa6,"With the development of intelligent education, it has become one of the more efficient learning schemes to construct the knowledge graph which can excavate the knowledge base. People generally use RDF triples and use languages such as OWL to construct knowledge graphs, but this method has problems such as limited expression ability and too much manual annotation. In this paper, we propose a framework that combines statistical language models, neural network language models, and clustering and clipping algorithms. When processing unstructured text data, unsupervised extraction of representative key words as features of the structured graphs' entities, so that the processed entity information has more accurate semantics and human learning relevance, and the method of clustering and calculating the learning rate is used to further clarify the learning order and mastery of knowledge points. We have conducted extensive experiments to collect data from the two major modules of HPC high-performance computing courses and domains as datasets, and used this framework to build many knowledge graphs which can provide practical learning. The knowledge graph of this paper can be obtained from: Https://v2.easyhpc.net:10000/knowledge Knowledge Graph Module. © Published under licence by IOP Publishing Ltd.",Final,All Open Access; Bronze Open Access
,,,"TextGraphs 2021 - Graph-Based Methods for Natural Language Processing, Proceedings of the 15th Workshop - in conjunction with the 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138698168&partnerID=40&md5=465885307d2926a39defbf10bf62c763,The proceedings contain 20 papers. The topics discussed include: bootstrapping large-scale fine-grained contextual advertising classifier from Wikipedia; modeling graph structure via relative position for text generation from knowledge graphs; entity prediction in knowledge graphs with joint embeddings; hierarchical graph convolutional networks for jointly resolving cross-document coreference of entity and event mentions; learning clause representation from dependency-anchor graph for connective prediction; selective attention based graph convolutional networks for aspect-level sentiment classification; keyword extraction using unsupervised learning on the document’s adjacency matrix; improving human text simplification with sentence fusion; and on geodesic distances and contextual embedding compression for text classification.,Final,
To N.D.; Reformat M.Z.; Yager R.R.,"To, Nhuan D. (57195642538); Reformat, Marek Z. (6603618138); Yager, Ronald R. (35618760400)",57195642538; 6603618138; 35618760400,Question-Answering System with Linguistic Summarization,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114690111&doi=10.1109%2fFUZZ45933.2021.9494389&partnerID=40&md5=fa6134a743f854fe75277129c5d0079f,"The increased popularity of Linked Open Data (LOD) and advances in Natural Language Processing techniques have led to the development of Question Answering Systems (QASs) that utilize Knowledge Graphs as data sources. QASs perform well on simple questions providing precise and concise answers. Yet, most of them cannot process answers that contain a large volume of numerical values and are not able to provide users with answers in a human-friendly format. In this paper, we propose a user-defined method for constructing linguistic summarization of multi-feature data. It selects suitable summarizers and quantifiers and works with linguistic constraints imposed on the data. The method relies on definitions of linguistic terms constructed by users using an easy and simple graphical interface. Additionally, we introduce a Context-based User-defined Weighted Averaging (CUWA) operator. It allows determining an average value of data that satisfies multiple constraints that are account for the context defined by the user. We include several illustrative examples. © 2021 IEEE.",Final,
D’Souza J.; Auer S.; Pedersen T.,"D’Souza, Jennifer (57215346447); Auer, Sören (23391879500); Pedersen, Ted (7202189744)",57215346447; 23391879500; 7202189744,SemEval-2021 Task 11: NLPCONTRIBUTIONGRAPH - Structuring Scholarly NLP Contributions for a Research Knowledge Graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132941197&partnerID=40&md5=1dbedbfb27f52772ab082550687510ea,"There is currently a gap between the natural language expression of scholarly publications and their structured semantic content modeling to enable intelligent content search. With the volume of research growing exponentially every year, a search feature operating over semantically structured content is compelling. The SemEval-2021 Shared Task NLPCONTRIBUTIONGRAPH (a.k.a. ‘the NCG task’) tasks participants to develop automated systems that structure contributions from NLP scholarly articles in the English language. Being the first-of-its-kind in the SemEval series, the task released structured data from NLP scholarly articles at three levels of information granularity, i.e. at sentence-level, phrase-level, and phrases organized as triples toward Knowledge Graph (KG) building. The sentence-level annotations comprised the few sentences about the article’s contribution. The phrase-level annotations were scientific term and predicate phrases from the contribution sentences. Finally, the triples constituted the research overview KG. For the Shared Task, participating systems were then expected to automatically classify contribution sentences, extract scientific terms and relations from the sentences, and organize them as KG triples. Overall, the task drew a strong participation demographic of seven teams and 27 participants. The best end-to-end task system classified contribution sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While the absolute performance to generate triples remains low, in the conclusion of this article, the difficulty of producing such data and as a consequence of modeling it is highlighted. © 2021 Association for Computational Linguistics.",Final,
Yasunaga M.; Ren H.; Bosselut A.; Liang P.; Leskovec J.,"Yasunaga, Michihiro (57203242413); Ren, Hongyu (57207374365); Bosselut, Antoine (57193225759); Liang, Percy (56646712700); Leskovec, Jure (12241436100)",57203242413; 57207374365; 57193225759; 56646712700; 12241436100,QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137720400&partnerID=40&md5=0a16aaa555f5e8c8abd0c56a4510103a,"The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. Here we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning; where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph-based message passing. We evaluate QA-GNN on the CommonsenseQA and OpenBookQA datasets, and show its improvement over existing LM and LM+KG models, as well as its capability to perform interpretable and structured reasoning; e.g., correctly handling negation in questions. © 2021 Association for Computational Linguistics.",Final,
Banerjee S.; Potts C.M.; Jhala A.H.; Jaselskis E.J.,"Banerjee, Siddharth (57216571320); Potts, Colin M. (58835812400); Jhala, Arnav H. (15055824300); Jaselskis, Edward J. (7003913037)",57216571320; 58835812400; 15055824300; 7003913037,Neural Language Model Based Intelligent Semantic Information Retrieval on NCDOT Projects for Knowledge Management,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132555672&doi=10.1061%2f9780784483893.096&partnerID=40&md5=6532f8b566351388905b9d3daf10822f,"The North Carolina Department of Transportation (NCDOT) created a new knowledge repository called Communicate Lessons, Exchange Advice, Record (CLEAR) as an official platform for end-users to store and retrieve knowledge. Through the CLEAR program, end-users can enter lessons learned and best practices gained in their workplace in addition to soliciting solutions to any ongoing issue. This paper briefly reviews the development of CLEAR and proposes an intelligent knowledge transference process of information on NCDOT projects using natural language processing and knowledge graphs based on neural language models developed by the CLEAR project team. The CLEAR project includes a collection of documented lessons learned and best practices. The AI model learns an inference model of the domain vocabulary from various sources such as contract documents, textbooks, and specifications. This model allows the system to make meaningful connections between lessons learned and best practices within CLEAR and the project-specific domain knowledge. The model output will initially be shown to NCDOT team members belonging to various project life cycle phases such as design, construction, and maintenance to certify the usefulness of the generated keywords and thereby the AI model in an iterative manner until the model has been appropriately fine-tuned. Necessary modifications will be made to the model based on the feedback obtained from project personnel to ensure high-quality output. In the long run, this automation in information retrieval will encourage NCDOT personnel to use the CLEAR program as a part of their routine work to improve project workflow processes. © 2021 Computing in Civil Engineering 2021 - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2021. All rights reserved.",Final,
Baumgartner M.; Dell'Aglio D.; Bernstein A.,"Baumgartner, Matthias (57204180688); Dell'Aglio, Daniele (57211275968); Bernstein, Abraham (57212626682)",57204180688; 57211275968; 57212626682,Entity Prediction in Knowledge Graphs with Joint Embeddings,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138683088&partnerID=40&md5=e9e2bd17c5867d57aa6592cb73a2d543,"Knowledge Graphs (KGs) have become increasingly popular in the recent years. However, as knowledge constantly grows and changes, it is inevitable to extend existing KGs with entities that emerged or became relevant to the scope of the KG after its creation. Research on updating KGs typically relies on extracting named entities and relations from text. However, these approaches cannot infer entities or relations that were not explicitly stated. Alternatively, embedding models exploit implicit structural regularities to predict missing relations, but cannot predict missing entities. In this article, we introduce a novel method to enrich a KG with new entities given their textual description. Our method leverages joint embedding models, hence does not require entities or relations to be named explicitly. We show that our approach can identify new concepts in a document corpus and transfer them into the KG, and we find that the performance of our method improves substantially when extended with techniques from association rule mining, text mining, and active learning.  © 2021 Association for Computational Linguistics.",Final,
Hao J.; Zhao L.; Milisavljevic-Syed J.; Ming Z.,"Hao, Jia (35796849400); Zhao, Lei (57203509549); Milisavljevic-Syed, Jelena (57215597186); Ming, Zhenjun (55540612100)",35796849400; 57203509549; 57215597186; 55540612100,Integrating and navigating engineering design decision-related knowledge using decision knowledge graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111263006&doi=10.1016%2fj.aei.2021.101366&partnerID=40&md5=e05d292e5b9c4805f77d8c0e525b720a,"Designers are usually facing a problem of finding information from a huge amount of unstructured textual documents in order to prepare for a decision to be made. The major challenge is that knowledge embedded in the textual documents are difficult to search at a semantic level and therefore not ready to support decisions in a timely manner. To address this challenge, in this paper we propose a knowledge-graph-based method for integrating and navigating decision-related knowledge in engineering design. The presented method is based on a meta-model of decision knowledge graph (mDKG) that is grounded in the compromise Decision Support Problem (cDSP) construct which is used by designers as a means to formulate design decisions linguistically and mathematically. Based on the mDKG, we propose a procedure for automatically converting word-based cDSPs to knowledge graph through natural language processing, and a procedure for rapidly and accurately navigating decision-related knowledge through divergence and convergence processes. The knowledge-graph-based method is verified using the textual data from the supply chain design domain. Results show that our method has better performance than the conventional keyword-based searching method in terms of both effectiveness and efficiency in finding the target knowledge. © 2021",Final,
Škrlj B.; Martinc M.; Lavrač N.; Pollak S.,"Škrlj, Blaž (57191625180); Martinc, Matej (57193521100); Lavrač, Nada (7004388979); Pollak, Senja (55543643800)",57191625180; 57193521100; 7004388979; 55543643800,autoBOT: evolving neuro-symbolic representations for explainable low resource text classification,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104608374&doi=10.1007%2fs10994-021-05968-x&partnerID=40&md5=59b5fd0f7b23614c0337e650f6050d25,"Learning from texts has been widely adopted throughout industry and science. While state-of-the-art neural language models have shown very promising results for text classification, they are expensive to (pre-)train, require large amounts of data and tuning of hundreds of millions or more parameters. This paper explores how automatically evolved text representations can serve as a basis for explainable, low-resource branch of models with competitive performance that are subject to automated hyperparameter tuning. We present autoBOT (automatic Bags-Of-Tokens), an autoML approach suitable for low resource learning scenarios, where both the hardware and the amount of data required for training are limited. The proposed approach consists of an evolutionary algorithm that jointly optimizes various sparse representations of a given text (including word, subword, POS tag, keyword-based, knowledge graph-based and relational features) and two types of document embeddings (non-sparse representations). The key idea of autoBOT is that, instead of evolving at the learner level, evolution is conducted at the representation level. The proposed method offers competitive classification performance on fourteen real-world classification tasks when compared against a competitive autoML approach that evolves ensemble models, as well as state-of-the-art neural language models such as BERT and RoBERTa. Moreover, the approach is explainable, as the importance of the parts of the input space is part of the final solution yielded by the proposed optimization procedure, offering potential for meta-transfer learning. © 2021, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
,,,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Demonstrations",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137609961&partnerID=40&md5=e4683e80e1edab21fd4e180bb2742562,"The proceedings contain 17 papers. The topics discussed include: PhoNLP: a joint multi-task learning model for Vietnamese part-of-speech tagging, named entity recognition and dependency parsing; machine-assisted script curation; NAMER: a node-based multitasking framework for multi-hop knowledge base question answering; DiSCoL: toward engaging dialogue systems through conversational line guided response generation; COVID-19 literature knowledge graph construction and drug repurposing report generation; multifaceted domain-specific document embeddings; improving evidence retrieval for automated explainable fact-checking; interactive plot manipulation using natural language; ActiveAnno: general-purpose document-level annotation tool with active learning integration; and TextEssence: a tool for interactive analysis of semantic shifts between corpora.",Final,
Zhou W.; Lee D.-H.; Selvam R.K.; Lee S.; Lin B.Y.; Ren X.,"Zhou, Wangchunshu (57216610544); Lee, Dong-Ho (57216623177); Selvam, Ravi Kiran (57219785879); Lee, Seyeon (57219742725); Lin, Bill Yuchen (57205548667); Ren, Xiang (58619993600)",57216610544; 57216623177; 57219785879; 57219742725; 57205548667; 58619993600,PRE-TRAINING TEXT-TO-TEXT TRANSFORMERS FOR CONCEPT-CENTRIC COMMON SENSE,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150295031&partnerID=40&md5=27d3e1e1003a8d4923b23d250f19e233,"Pre-trained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks. However, current pre-training objectives such as masked token prediction (for BERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not explicitly model the relational commonsense knowledge about everyday concepts, which is crucial to many downstream tasks that need common sense to understand or generate. To augment PTLMs with concept-centric commonsense knowledge, in this paper, we propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream datasets). Furthermore, we develop a joint pre-training framework to unify generative and contrastive objectives so that they can mutually reinforce each other. Extensive experimental results show that our method, concept-aware language model (CALM), can pack more commonsense knowledge into the parameters of a pre-trained text-to-text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks. We show that while only incrementally pre-trained on a relatively small corpus for a few steps, CALM outperforms baseline methods by a consistent margin and even comparable with some larger PTLMs, which suggests that CALM can serve as a general, “plug-and-play” method for improving the commonsense reasoning ability of a PTLM. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Final,
Chen X.; Boratko M.; Chen M.; Dasgupta S.S.; Li X.L.; McCallum A.,"Chen, Xuelu (57202439053); Boratko, Michael (57210640190); Chen, Muhao (57077271100); Dasgupta, Shib Sankar (57207859677); Li, Xiang Lorraine (57221147442); McCallum, Andrew (7003773569)",57202439053; 57210640190; 57077271100; 57207859677; 57221147442; 7003773569,Probabilistic Box Embeddings for Uncertain Knowledge Graph Reasoning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134422371&partnerID=40&md5=c52b45b6c27d16838cfa4c285572996f,"Knowledge bases often consist of facts which are harvested from a variety of sources, many of which are noisy and some of which conflict, resulting in a level of uncertainty for each triple. Knowledge bases are also often incomplete, prompting the use of embedding methods to generalize from known facts, however existing embedding methods only model triple-level uncertainty and reasoning results lack global consistency. To address these shortcomings, we propose BEUrRE, a novel uncertain knowledge graph embedding method with calibrated probabilistic semantics. BEUrRE models each entity as a box (i.e. axis-aligned hyperrectangle), and relations between two entities as affine transforms on the head and tail entity boxes. The geometry of the boxes allows for efficient calculation of intersections and volumes, endowing the model with calibrated probabilistic semantics and facilitating the incorporation of relational constraints. Extensive experiments on two benchmark datasets show that BEUrRE consistently outperforms baselines on confidence prediction and fact ranking due to it’s probabilistic calibration and ability to capture high-order dependencies among facts. © 2021 Association for Computational Linguistics.",Final,
Alam M.; Gangemi A.; Presutti V.; Reforgiato Recupero D.,"Alam, Mehwish (57201532578); Gangemi, Aldo (55605133800); Presutti, Valentina (55885160000); Reforgiato Recupero, Diego (57206674454)",57201532578; 55605133800; 55885160000; 57206674454,Semantic role labeling for knowledge graph extraction from text,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103652928&doi=10.1007%2fs13748-021-00241-7&partnerID=40&md5=46fe9ca55b6c6a35d1f57895d8bf6ea4,"This paper introduces TakeFive, a new semantic role labeling method that transforms a text into a frame-oriented knowledge graph. It performs dependency parsing, identifies the words that evoke lexical frames, locates the roles and fillers for each frame, runs coercion techniques, and formalizes the results as a knowledge graph. This formal representation complies with the frame semantics used in Framester, a factual-linguistic linked data resource. We tested our method on the WSJ section of the Peen Treebank annotated with VerbNet and PropBank labels and on the Brown corpus. The evaluation has been performed according to the CoNLL Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. The obtained precision, recall, and F1 values indicate that TakeFive is competitive with other existing methods such as SEMAFOR, Pikes, PathLSTM, and FRED. We finally discuss how to combine TakeFive and FRED, obtaining higher values of precision, recall, and F1 measure. © 2021, The Author(s).",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Sun C.; Yang Z.; Wang L.; Zhang Y.; Lin H.; Wang J.,"Sun, Cong (57201741324); Yang, Zhihao (16029941200); Wang, Lei (57191903778); Zhang, Yin (58406138500); Lin, Hongfei (24468572400); Wang, Jian (55934279300)",57201741324; 16029941200; 57191903778; 58406138500; 24468572400; 55934279300,Deep learning with language models improves named entity recognition for PharmaCoNER,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121464479&doi=10.1186%2fs12859-021-04260-y&partnerID=40&md5=afb785d1c3c18d57164fe67df8aedded,"Background: The recognition of pharmacological substances, compounds and proteins is essential for biomedical relation extraction, knowledge graph construction, drug discovery, as well as medical question answering. Although considerable efforts have been made to recognize biomedical entities in English texts, to date, only few limited attempts were made to recognize them from biomedical texts in other languages. PharmaCoNER is a named entity recognition challenge to recognize pharmacological entities from Spanish texts. Because there are currently abundant resources in the field of natural language processing, how to leverage these resources to the PharmaCoNER challenge is a meaningful study. Methods: Inspired by the success of deep learning with language models, we compare and explore various representative BERT models to promote the development of the PharmaCoNER task. Results: The experimental results show that deep learning with language models can effectively improve model performance on the PharmaCoNER dataset. Our method achieves state-of-the-art performance on the PharmaCoNER dataset, with a max F1-score of 92.01%. Conclusion: For the BERT models on the PharmaCoNER dataset, biomedical domain knowledge has a greater impact on model performance than the native language (i.e., Spanish). The BERT models can obtain competitive performance by using WordPiece to alleviate the out of vocabulary limitation. The performance on the BERT model can be further improved by constructing a specific vocabulary based on domain knowledge. Moreover, the character case also has a certain impact on model performance. © 2021, The Author(s).",Final,All Open Access; Gold Open Access; Green Open Access
Rezayi S.; Zhao H.; Kim S.; Rossi R.A.; Lipka N.; Li S.,"Rezayi, Saed (54788206400); Zhao, Handong (56915061800); Kim, Sungchul (57193625251); Rossi, Ryan A. (57197077642); Lipka, Nedim (25927367600); Li, Sheng (55812663300)",54788206400; 56915061800; 57193625251; 57197077642; 25927367600; 55812663300,EDGE: Enriching Knowledge Graph Embeddings with External Text,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129946220&partnerID=40&md5=55a0200f90349e3ad5c1c4324d872e29,"Knowledge graphs suffer from sparsity which degrades the quality of representations generated by various methods. While there is an abundance of textual information throughout the web and many existing knowledge bases, aligning information across these diverse data sources remains a challenge in the literature. Previous work has partially addressed this issue by enriching knowledge graph entities based on “hard” co-occurrence of words present in the entities of the knowledge graphs and external text, while we achieve “soft” augmentation by proposing a knowledge graph enrichment and embedding framework named EDGE. Given an original knowledge graph, we first generate a rich but noisy augmented graph using external texts in semantic and structural level. To distill the relevant knowledge and suppress the introduced noise, we design a graph alignment term in a shared embedding space between the original and augmented graph. To enhance the embedding learning on the augmented graph, we further regularize the locality relationship of target entity based on negative sampling. Experimental results on four benchmark datasets demonstrate the robustness and effectiveness of EDGE in link prediction and node classification. © 2021 Association for Computational Linguistics.",Final,
Shailabh S.; Chaurasia S.; Modi A.,"Shailabh, Shashank (57221598704); Chaurasia, Sajal (57223817430); Modi, Ashutosh (57198358059)",57221598704; 57223817430; 57198358059,KnowGraph@IITK at SemEval-2021 Task 11: Building Knowledge Graph for NLP Research,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138911453&partnerID=40&md5=db1baf7afb9eee8d4eec09bf0bfb407a,"Research in Natural Language Processing is making rapid advances, resulting in the publication of a large number of research papers. Finding relevant research papers and their contribution to the domain is a challenging problem. In this paper, we address this challenge via the SemEval 2021 Task 11: NLPContributionGraph, by developing a system for a research paper contributions-focused knowledge graph over Natural Language Processing literature. The task is divided into three sub-tasks: extracting contribution sentences that show important contributions in the research article, extracting phrases from the contribution sentences, and predicting the information units in the research article together with triplet formation from the phrases. The proposed system is agnostic to the subject domain and can be applied for building a knowledge graph for any area. We found that transformer-based language models can significantly improve existing techniques and utilized the SciBERT-based model. Our first sub-task uses Bidirectional LSTM (BiLSTM) stacked on top of SciBERT model layers, while the second sub-task uses Conditional Random Field (CRF) on top of SciBERT with BiLSTM. The third sub-task uses a combined SciBERT based neural approach with heuristics for information unit prediction and triplet formation from the phrases. Our system achieved F1 score of 0.38, 0.63 and 0.76 in end-to-end pipeline testing, phrase extraction testing and triplet extraction testing respectively. © 2021 Association for Computational Linguistics.",Final,
Yang S.; Tang R.,"Yang, Shihan (57222517369); Tang, Rui (57223049341)",57222517369; 57223049341,Learning Knowledge Uncertainty from the Pretrained Language Model,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127282607&doi=10.1145%2f3503928.3503936&partnerID=40&md5=3e232919acbf16ed8d0cdf2904fb4ae9,"Uncertain knowledge graphs, with each fact assigned a confdence value between 0 and 1, is a kind of graph structured knowledge bases. Knowledge representation is the foundation for most of knowledge-driven applications, in which knowledge are encoded into a continuous vector space for rapidly computing. Unfortunately, it is still a big challenge to encode meaningful knowledge features into the embedding space, such as uncertainty, inferring structures, and commonsense knowledge. An uncertain knowledge graphs embedding model, UKGEbert, is proposed to embed latent commonsense semantics by the pretrained natural language model. In the model, each knowledge fact is treated as a short sentence, which is fed into BERT for training. After that, the model learns uncertainty distribution of knowledge confdence by the recurrent neural network. Experiments on several benchmark datasets show that an e?ective prediction of confdence can help enhancing ability of knowledge inferring in the embedding space. Furthermore, the model achieves state of the art in several main metrics on the link prediction task of uncertain knowledge graphs. © 2021 Association for Computing Machinery. All rights reserved.",Final,
Gillis-Webber F.,"Gillis-Webber, Frances (57204543421)",57204543421,"Antonio Pareja-Lora, María Blume, Barbara C. Lust & Christian Chiarcos (eds.), Development of linguistic linked open data resources for collaborative dataintensive research in the language sciences. Cambridge: The MIT Press, 2019. Pp. xxi + 247.",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172873741&doi=10.1017%2fS0022226721000189&partnerID=40&md5=1149786755a839c28590d7a163b8b84b,[No abstract available],Final,
Chang D.; Lin E.; Brandt C.; Taylor R.A.,"Chang, David (57198890682); Lin, Eric (57356734900); Brandt, Cynthia (35513998400); Taylor, Richard Andrew (57223661992)",57198890682; 57356734900; 35513998400; 57223661992,Incorporating domain knowledge into language models by using graph convolutional networks for assessing semantic textual similarity: Model development and performance comparison,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120171749&doi=10.2196%2f23101&partnerID=40&md5=75cd7707fc3f80c27955fa4d85f4c2a5,"Background: Although electronic health record systems have facilitated clinical documentation in health care, they have also introduced new challenges, such as the proliferation of redundant information through the use of copy and paste commands or templates. One approach to trimming down bloated clinical documentation and improving clinical summarization is to identify highly similar text snippets with the goal of removing such text. Objective: We developed a natural language processing system for the task of assessing clinical semantic textual similarity. The system assigns scores to pairs of clinical text snippets based on their clinical semantic similarity. Methods: We leveraged recent advances in natural language processing and graph representation learning to create a model that combines linguistic and domain knowledge information from the MedSTS data set to assess clinical semantic textual similarity. We used bidirectional encoder representation from transformers (BERT)-based models as text encoders for the sentence pairs in the data set and graph convolutional networks (GCNs) as graph encoders for corresponding concept graphs that were constructed based on the sentences. We also explored techniques, including data augmentation, ensembling, and knowledge distillation, to improve the model's performance, as measured by the Pearson correlation coefficient (r). Results: Fine-tuning the BERT_base and ClinicalBERT models on the MedSTS data set provided a strong baseline (Pearson correlation coefficients: 0.842 and 0.848, respectively) compared to those of the previous year's submissions. Our data augmentation techniques yielded moderate gains in performance, and adding a GCN-based graph encoder to incorporate the concept graphs also boosted performance, especially when the node features were initialized with pretrained knowledge graph embeddings of the concepts (r=0.868). As expected, ensembling improved performance, and performing multisource ensembling by using different language model variants, conducting knowledge distillation with the multisource ensemble model, and taking a final ensemble of the distilled models further improved the system's performance (Pearson correlation coefficients: 0.875, 0.878, and 0.882, respectively). Conclusions: This study presents a system for the MedSTS clinical semantic textual similarity benchmark task, which was created by combining BERT-based text encoders and GCN-based graph encoders in order to incorporate domain knowledge into the natural language processing pipeline. We also experimented with other techniques involving data augmentation, pretrained concept embeddings, ensembling, and knowledge distillation to further increase our system's performance. Although the task and its benchmark data set are in the early stages of development, this study, as well as the results of the competition, demonstrates the potential of modern language model-based systems to detect redundant information in clinical notes. © 2021 JMIR Publications Inc.. All rights reserved.",Final,All Open Access; Gold Open Access; Green Open Access
Ghader P.B.; Zakerinia H.; Baghshah M.S.,"Ghader, Parishad Behnam (57904568600); Zakerinia, Hossein (36953495300); Baghshah, Mahdieh Soleymani (15845103800)",57904568600; 36953495300; 15845103800,MG-BERT: Multi-Graph Augmented BERT for Masked Language Modeling,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138753413&partnerID=40&md5=39d1d23e290290991166e50857dc2612,"Pre-trained models like Bidirectional Encoder Representations from Transformers (BERT), have recently made a big leap forward in Natural Language Processing (NLP) tasks. However, there are still some shortcomings in the Masked Language Modeling (MLM) task performed by these models. In this paper, we first introduce a multi-graph including different types of relations between words. Then, we propose Multi-Graph augmented BERT (MG-BERT) model that is based on BERT. MG-BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs. The proposed model also employs a dynamic sentence graph to capture local context effectively. Experimental results demonstrate that our model can considerably enhance the performance in the MLM task.  © 2021 Association for Computational Linguistics.",Final,
Liu S.; Yang H.; Li J.; Kolmanič S.,"Liu, Shuang (56181255000); Yang, Hui (57209840388); Li, Jiayi (57209840367); Kolmanič, Simon (6506199017)",56181255000; 57209840388; 57209840367; 6506199017,Chinese Named Entity Recognition Method in History and Culture Field Based on BERT,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116145191&doi=10.1007%2fs44196-021-00019-8&partnerID=40&md5=bd32588f248387cf4b66cb5334894b0f,"With rapid development of the Internet, people have undergone tremendous changes in the way they obtain information. In recent years, knowledge graph is becoming a popular tool for the public to acquire knowledge. For knowledge graph of Chinese history and culture, most researchers adopted traditional named entity recognition methods to extract entity information from unstructured historical text data. However, the traditional named entity recognition method has certain defects, and it is easy to ignore the association between entities. To extract entities from a large amount of historical and cultural information more accurately and efficiently, this paper proposes one named entity recognition model combining Bidirectional Encoder Representations from Transformers and Bidirectional Long Short-Term Memory-Conditional Random Field (BERT-BiLSTM-CRF). First, a BERT pre-trained language model is used to encode a single character to obtain a vector representation corresponding to each character. Then one Bidirectional Long Short-Term Memory (BiLSTM) layer is applied to semantically encode the input text. Finally, the label with the highest probability is output through the Conditional Random Field (CRF) layer to obtain each character’s category. This model uses the Bidirectional Encoder Representations from Transformers (BERT) pre-trained language model to replace the static word vectors trained in the traditional way. In comparison, the BERT pre-trained language model can dynamically generate semantic vectors according to the context of words, which improves the representation ability of word vectors. The experimental results prove that the model proposed in this paper has achieved excellent results in the task of named entity recognition in the field of historical culture. Compared with the existing named entity identification methods, the precision rate, recall rate, and F1 value have been significantly improved. © 2021, The Author(s).",Final,All Open Access; Gold Open Access
Ribeiro L.F.R.; Schmitt M.; Schütze H.; Gurevych I.,"Ribeiro, Leonardo F.R. (57216620788); Schmitt, Martin (57207571714); Schütze, Hinrich (7003432991); Gurevych, Iryna (24474583400)",57216620788; 57207571714; 7003432991; 24474583400,Investigating Pretrained Language Models for Graph-to-Text Generation,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137979788&partnerID=40&md5=33024d1f6c45bd0b047fb63d23298b91,"Graph-to-text generation aims to generate fluent texts from graph-based data. In this paper, we investigate two recent pretrained language models (PLMs) and analyze the impact of different task-adaptive pretraining strategies for PLMs in graph-to-text generation. We present a study across three graph domains: meaning representations, Wikipedia knowledge graphs (KGs) and scientific KGs. We show that approaches based on PLMs BART and T5 achieve new state-of-the-art results and that task-adaptive pretraining strategies improve their performance even further. We report new state-of-the-art BLEU scores of 49.72 on AMR-LDC2017T10, 59.70 on WebNLG, and 25.66 on AGENDA datasets - a relative improvement of 31.8%, 4.5%, and 42.4%, respectively, with our models generating significantly more fluent texts than human references. In an extensive analysis, we identify possible reasons for the PLMs’ success on graph-to-text tasks. Our findings suggest that the PLMs benefit from similar facts seen during pretraining or fine-tuning, such that they perform well even when the input graph is reduced to a simple bag of node and edge labels. © 2021 Association for Computational Linguistics.",Final,
,,,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137667450&partnerID=40&md5=22aa7c64399d61859b123222e57052aa,The proceedings contain 476 papers. The topics discussed include: knowledge router: learning disentangled representations for knowledge graphs; distantly supervised relation extraction with sentence reconstruction and knowledge base priors; cross-task instance representation interactions and label dependencies for joint information extraction with graph convolutional networks; abstract meaning representation guided graph encoding and decoding for joint information extraction; a frustratingly easy approach for entity and relation extraction; event time extraction and propagation via graph attention networks; probing word translations in the transformer and trading decoder for encoder layers; automatic generation of contrast sets from scene graphs: probing the compositional consistency of GQA; multilingual language models predict human reading behavior; and do syntactic probes probe syntax? experiments with jabberwocky probing.,Final,
Biswas R.; Sofronova R.; Alam M.; Sack H.,"Biswas, Russa (57202431946); Sofronova, Radina (57219024016); Alam, Mehwish (57201532578); Sack, Harald (7102918498)",57202431946; 57219024016; 57201532578; 7102918498,Contextual language models for knowledge graph completion,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119402984&partnerID=40&md5=da78ec552b908dc18a2356ad70666ff0,"Knowledge Graphs (KGs) have become the backbone of various machine learning based applications over the past decade. However, the KGs are often incomplete and inconsistent. Several representation learning based approaches have been introduced to complete the missing information in KGs. Besides, Neural Language Models (NLMs) have gained huge momentum in NLP applications. However, exploiting the contextual NLMs to tackle the Knowledge Graph Completion (KGC) task is still an open research problem. In this paper, a GPT-2 based KGC model is proposed and is evaluated on two benchmark datasets. The initial results obtained from the fine-tuning of the GPT-2 model for triple classification strengthens the importance of usage of NLMs for KGC. Also, the impact of contextual language models for KGC has been discussed. © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Petzold R.; Gesese G.A.; Bogdanova V.; Zylowski T.; Sack H.; Alam M.,"Petzold, Rick (57374714900); Gesese, Genet Asefa (57209473942); Bogdanova, Viktoria (57219749343); Zylowski, Thorsten (57219930989); Sack, Harald (7102918498); Alam, Mehwish (57201532578)",57374714900; 57209473942; 57219749343; 57219930989; 7102918498; 57201532578,Challenges of applying knowledge graph and their embeddings to a real-world use-case,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121327107&partnerID=40&md5=47eade7a19900b65523e49ddaf658f74,"Different Knowledge Graph Embedding (KGE) models have been proposed so far which are trained on some specific KG completion tasks such as link prediction and evaluated on datasets which are mainly created for such purpose. Mostly, the embeddings learnt on link prediction tasks are not applied for downstream tasks in real-world use-cases such as data available in different companies/organizations. In this paper, the challenges with enriching a KG which is generated from a real-world relational database (RDB) about companies, with information from external sources such as Wikidata and learning representations for the KG are presented. Moreover, a comparative analysis is presented between the KGEs and various text embeddings on some downstream clustering tasks. The results of experiments indicate that in use-cases like the one used in this paper, where the KG is highly skewed, it is beneficial to use text embeddings or language models instead of KGEs. © 2021 Copyright for this paper by its authors.",Final,
,,,"EEKE 2021 - Proceedings of the 2nd Workshop on on Extraction and Evaluation of Knowledge Entities from Scientific Documents, co-located with JCDL 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122957171&partnerID=40&md5=bb132ef2e146f333908d1fc7043327be,The proceedings contain 14 papers. The topics discussed include: joint entity and relation extraction from scientific documents: role of linguistic information and entity types; classification of URLs citing research artifacts in scholarly documents based on distributed representations; design and implementation of keyphrase extraction engine for Chinese scientific literature; keyword extraction and technology entity extraction for disruptive technology policy texts; detecting cross-language plagiarism using open knowledge graphs; the correlation between content novelty and scientific impact; automatic generation of research highlights from scientific abstracts; and differential analysis on performance of scientific collaborations with the evolution of entity popularity.,Final,
Yuan J.; Wei Z.; Zhao D.; Zhang Q.; Jiang C.,"Yuan, Jian (57313371200); Wei, Zhongyu (51666060600); Zhao, Donghua (14049423200); Zhang, Qi (57203621188); Jiang, Changjian (57220544961)",57313371200; 51666060600; 14049423200; 57203621188; 57220544961,Leveraging Argumentation Knowledge Graph for Interactive Argument Pair Identification,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123937778&partnerID=40&md5=2e70d5d7c7a86a6e194f3cb6d625fcf3,"Interactive argument pair identification is essential in the context of dialogical argumentation mining. Existing research treats it as a problem of sentence matching and largely relies on textual information to compute the similarities. However, the interaction of opinions usually involves the background of the topic and requires reasoning of knowledge, which is beyond textual information. In this paper, we propose to leverage external knowledge to enhance the identification of interactive argument pairs. We construct the argumentation knowledge graph from the discussion thread of the target topic in the online forum. The interaction between the original argument and the reply is then represented as the path of concepts in the knowledge graph. In practice, we utilize Graph Convolutional Network (GCN) to learn the concept representation in the knowledge graph and use a Transformer-based encoder to learn the representation of paths. Finally, an information alignment network is employed to capture the interaction of textual information of conceptual information (both entity-level and path-level). Experiment results indicate that our model achieves state-of-the-art performance in the benchmark dataset. Further analysis demonstrates the effectiveness of our model for enforcing knowledge reasoning through paths in the knowledge graph. © 2021 Association for Computational Linguistics",Final,
Sharma M.; Brownstein J.S.; Ramakrishnan N.,"Sharma, Mandar (57221150296); Brownstein, John S. (8872411400); Ramakrishnan, Naren (35507966200)",57221150296; 8872411400; 35507966200,T3: Domain-Agnostic Neural Time-series Narration,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125190339&doi=10.1109%2fICDM51629.2021.00165&partnerID=40&md5=11aa9b696ab1a5905ce8a8e781c2ab24,"The task of generating rich and fluent narratives that aptly describe the characteristics, trends, and anomalies of time-series data is invaluable to the sciences (geology, meteorology, epidemiology) or finance (trades, stocks). The efforts for time-series narration hitherto are domain-specific and use predefined templates that offer consistency but lead to mechanical narratives. We present {T}^{3} (Time-series-To-Text), a domain-agnostic neural framework for time-series narration, that couples the representation of essential time-series elements in the form of a dense knowledge graph and the translation of said knowledge graph into rich and fluent narratives through the transfer-learning capabilities of PLMs (Pre-trained Language Models). To the best of our knowledge, {T}^{3} is the first investigation of the use of neural strategies for time-series narration. We showcase that {T}^{3} can improve the lexical diversity of the generated narratives by up to 65.38% while still maintaining grammatical integrity. The performance and practicality of {T}^{3} is further validated through an expert review (n=21) where 76.2% of participating experts wary of auto-generated narratives favored {T}^{3} as a deployable system for time-series narration due to its rich and diverse narratives. Our code-base and the datasets used with detailed instructions for reproducibility is publicly hosted 1.1https://github.com/Mandar-Sharma/TCube  © 2021 IEEE.",Final,
Mondal I.; Hou Y.; Jochim C.,"Mondal, Ishani (57192681255); Hou, Yufang (55746803800); Jochim, Charles (36666513800)",57192681255; 55746803800; 36666513800,End-to-End NLP Knowledge Graph Construction,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123952099&partnerID=40&md5=173f19a29e307233867f6ea2a34ca6bf,"This paper studies the end-to-end construction of an NLP Knowledge Graph (KG) from scientific papers. We focus on extracting four types of relations: evaluatedOn between tasks and datasets, evaluatedBy between tasks and evaluation metrics, as well as coreferent and related relations between the same type of entities. For instance, “F1 score” is coreferent with “F-measure”. We introduce novel methods for each of these relation types and apply our final framework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a large-scale KG, which can facilitate automatically constructing scientific leaderboards for the NLP community. The results of our experiments indicate that the resulting KG contains high-quality information. © 2021 Association for Computational Linguistics",Final,
Dash S.; Rossiello G.; Bagchi S.; Mihindukulasooriya N.; Gliozzo A.,"Dash, Sarthak (57196468028); Rossiello, Gaetano (57190124913); Bagchi, Sugato (7102840811); Mihindukulasooriya, Nandana (56406504100); Gliozzo, Alfio (55893529800)",57196468028; 57190124913; 7102840811; 56406504100; 55893529800,Open Knowledge Graphs Canonicalization using Variational Autoencoders,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127419682&partnerID=40&md5=5cbf3affea18e9ec2edcf1d5fb83455b,"Noun phrases and Relation phrases in open knowledge graphs are not canonicalized, leading to an explosion of redundant and ambiguous subject-relation-object triples. Existing approaches to solve this problem take a two-step approach. First, they generate embedding representations for both noun and relation phrases, then a clustering algorithm is used to group them using the embeddings as features. In this work, we propose Canonicalizing Using Variational Autoencoders (CUVA), a joint model to learn both embeddings and cluster assignments in an end-to-end approach, which leads to a better vector representation for the noun and relation phrases. Our evaluation over multiple benchmarks shows that CUVA outperforms the existing state-of-the-art approaches. Moreover, we introduce CANONICNELL, a novel dataset to evaluate entity canonicalization systems. © 2021 Association for Computational Linguistics",Final,
Yang J.; Shi Y.; Tong X.; Wang R.; Chen T.; Ying X.,"Yang, Jinfa (57214872614); Shi, Yongjie (57193810663); Tong, Xin (57205367654); Wang, Robin (57545586100); Chen, Taiyan (57658287600); Ying, Xianghua (7004495215)",57214872614; 57193810663; 57205367654; 57545586100; 57658287600; 7004495215,Improving Knowledge Graph Embedding Using Affine Transformations of Entities Corresponding to Each Relation,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129183322&partnerID=40&md5=2052366ba89cf79f8796d79b556c8617,"To find a suitable embedding for a knowledge graph remains a big challenge nowadays. By using previous knowledge graph embedding methods, every entity in a knowledge graph is usually represented as a k-dimensional vector. As we know, an affine transformation can be expressed in the form of a matrix multiplication followed by a translation vector. In this paper, we firstly utilize a set of affine transformations related to each relation to operate on entity vectors, and then these transformed vectors are used for performing embedding with previous methods. The main advantage of using affine transformations is their good geometry properties with interpretability. Our experimental results demonstrate that the proposed intuitive design with affine transformations provides a statistically significant increase in performance with adding a few extra processing steps or adding a limited number of additional variables. Taking TransE as an example, we employ the scale transformation (the special case of an affine transformation), and only introduce k additional variables for each relation. Surprisingly, it even outperforms RotatE to some extent on various data sets. We also introduce affine transformations into RotatE, Distmult and ComplEx, respectively, and each one outperforms its original method.  © 2021 Association for Computational Linguistics.",Final,
Cheng Z.; Wu J.; Ji B.; Liu H.,"Cheng, Zheng (55448887900); Wu, Jiaju (55814451200); Ji, Bin (57203015802); Liu, Huijun (57207734469)",55448887900; 55814451200; 57203015802; 57207734469,Pre-trained Language Model based Medical Named Entity Recognition,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128031341&doi=10.1109%2fCAC53003.2021.9727616&partnerID=40&md5=0377ca8ac655d5d9dbb5fda40718b595,"Medical named entity recognition is an important part of structuring Chinese electronic medical records and construction of medical knowledge graph. The CCKS2019 conference organized a medical named entity recognition evaluation task to extract six types of medical entities from unstructured Chinese electronic medical records. Based on the data set of this evaluation task, pre-trained language model based entity recognition approaches are studied First, select the BiLSTM-CRF model based on random initialized word embedding as the baseline system; secondly, apply wordlvec to the baseline system; thirdly, apply ELMo to the baseline system. Experimental results show that the pre-trained language model is comparable to the best approach of this evaluation task, and the context-related pre-trained language model performs better. © 2021 IEEE",Final,
Ke P.; Ji H.; Ran Y.; Cui X.; Wang L.; Song L.; Zhu X.; Huang M.,"Ke, Pei (57207855637); Ji, Haozhe (57221149893); Ran, Yu (57225221574); Cui, Xin (57225215494); Wang, Liwei (57196330292); Song, Linfeng (57198355269); Zhu, Xiaoyan (7406185137); Huang, Minlie (7404260571)",57207855637; 57221149893; 57225221574; 57225215494; 57196330292; 57198355269; 7406185137; 7404260571,JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123440627&partnerID=40&md5=a0e3f46e988aa244ae1be9d1b61a2a19,"Existing pre-trained models for knowledge-graph-to-text (KG-to-text) generation simply fine-tune text-to-text pre-trained models such as BART or T5 on KG-to-text datasets, which largely ignore the graph structure during encoding and lack elaborate pre-training tasks to explicitly model graph-text alignments. To tackle these problems, we propose a graph-text joint representation learning model called JointGT. During encoding, we devise a structure-aware semantic aggregation module which is plugged into each Transformer layer to preserve the graph structure. Furthermore, we propose three new pre-training tasks to explicitly enhance the graph-text alignment including respective text/graph reconstruction, and graph-text alignment in the embedding space via Optimal Transport. Experiments show that JointGT obtains new state-of-the-art performance on various KG-to-text datasets. © 2021 Association for Computational Linguistics",Final,
Liu B.; Scells H.; Zuccon G.; Hua W.; Zhao G.,"Liu, Bing (57224313253); Scells, Harrisen (57195629881); Zuccon, Guido (25927778100); Hua, Wen (55183678300); Zhao, Genghong (57313929200)",57224313253; 57195629881; 25927778100; 55183678300; 57313929200,ActiveEA: Active Learning for Neural Entity Alignment,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127385854&partnerID=40&md5=7403a12b95986c36889518303416ea26,"Entity Alignment (EA) aims to match equivalent entities across different Knowledge Graphs (KGs) and is an essential step of KG fusion. Current mainstream methods - neural EA models - rely on training with seed alignment, i.e., a set of pre-aligned entity pairs which are very costly to annotate. In this paper, we devise a novel Active Learning (AL) framework for neural EA, aiming to create highly informative seed alignment to obtain more effective EA models with less annotation cost. Our framework tackles two main challenges encountered when applying AL to EA: (1) How to exploit dependencies between entities within the AL strategy. Most AL strategies assume that the data instances to sample are independent and identically distributed. However, entities in KGs are related. To address this challenge, we propose a structure-aware uncertainty sampling strategy that can measure the uncertainty of each entity as well as its impact on its neighbour entities in the KG. (2) How to recognise entities that appear in one KG but not in the other KG (i.e., bachelors). Identifying bachelors would likely save annotation budget. To address this challenge, we devise a bachelor recognizer paying attention to alleviate the effect of sampling bias. Empirical results show that our proposed AL strategy can significantly improve sampling quality with good generality across different datasets, EA models and amount of bachelors. © 2021 Association for Computational Linguistics",Final,
Zhang Z.; Zhang Z.; Zhou Y.; Wu L.; Wu S.; Han X.; Dou D.; Che T.; Yan D.,"Zhang, Zeru (57223967088); Zhang, Zijie (57205739732); Zhou, Yang (55043481500); Wu, Lingfei (56937260100); Wu, Sixing (57226035165); Han, Xiaoying (55450946200); Dou, Dejing (22733517600); Che, Tianshi (57559010500); Yan, Da (37103277300)",57223967088; 57205739732; 55043481500; 56937260100; 57226035165; 55450946200; 22733517600; 57559010500; 37103277300,Adversarial Attack against Cross-lingual Knowledge Graph Alignment,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127384001&partnerID=40&md5=ea50cd9cfb1e8b74caa8b43e1723173a,"Recent literatures have shown that knowledge graph (KG) learning models are highly vulnerable to adversarial attacks. However, there is still a paucity of vulnerability analyses of cross-lingual entity alignment under adversarial attacks. This paper proposes an adversarial attack model with two novel attack techniques to perturb the KG structure and degrade the quality of deep cross-lingual entity alignment. First, an entity density maximization method is employed to hide the attacked entities in dense regions in two KGs, such that the derived perturbations are unnoticeable. Second, an attack signal amplification method is developed to reduce the gradient vanishing issues in the process of adversarial attacks for further improving the attack effectiveness. © 2021 Association for Computational Linguistics",Final,
Moghimifar F.; Qu L.; Zhuo Y.; Haffari G.; Baktashmotlagh M.,"Moghimifar, Farhad (57188715951); Qu, Lizhen (57196124952); Zhuo, Yue (57224633389); Haffari, Gholamreza (24338096600); Baktashmotlagh, Mahsa (53163146000)",57188715951; 57196124952; 57224633389; 24338096600; 53163146000,Neural-Symbolic Commonsense Reasoner with Relation Predictors,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122190172&partnerID=40&md5=20bcbb2ac4b128f8eb8e9b550aaed92d,"Commonsense reasoning aims to incorporate sets of commonsense facts, retrieved from Commonsense Knowledge Graphs (CKG), to draw conclusion about ordinary situations. The dynamic nature of commonsense knowledge postulates models capable of performing multi-hop reasoning over new situations. This feature also results in having large-scale sparse Knowledge Graphs, where such reasoning process is needed to predict relations between new events. However, existing approaches in this area are limited by considering CKGs as a limited set of facts, thus rendering them unfit for reasoning over new unseen situations and events. In this paper, we present a neural-symbolic reasoner, which is capable of reasoning over large-scale dynamic CKGs. The logic rules for reasoning over CKGs are learned during training by our model. In addition to providing interpretable explanation, the learned logic rules help to generalise prediction to newly introduced events. Experimental results on the task of link prediction on CKGs prove the effectiveness of our model by outperforming the state-of-the-art models. © 2021 Association for Computational Linguistics.",Final,
Qin X.; Lu Y.; Chen Y.; Rao Y.,"Qin, Xiaorui (55987121800); Lu, Yuyin (57262955500); Chen, Yufu (57257905600); Rao, Yanghui (55753260800)",55987121800; 57262955500; 57257905600; 55753260800,Lifelong Learning of Topics and Domain-Specific Word Embeddings,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123936955&partnerID=40&md5=99d07d8f071a321a31b2cdde50bc910a,"Lifelong topic models mainly focus on in-domain text streams in which each chunk only contains documents from a single domain. To overcome data diversity of the in-domain corpus, most of the existing methods exploit the information from limited sources in a separate and heuristic manner. In this study, we develop a lifelong collaborative model (LCM) based on non-negative matrix factorization to accurately learn topics and domain-specific word embeddings. LCM particularly investigates: (1) developing a knowledge graph based on the semantic relationships among words in the lifelong learning process, so as to accumulate global context information discovered by topic models and local context information reflected by context word embeddings from previous domains, and (2) developing a subword graph based on byte pair encoding and pairwise word relationships to exploit subword information of words in the current in-domain corpus. To the best of our knowledge, we are the first to collaboratively learn topics and word embeddings via lifelong learning. Experiments on real-world in-domain text streams validate the effectiveness of our method. © 2021 Association for Computational Linguistics",Final,
Zhou Y.; Geng X.; Shen T.; Pei J.; Zhang W.; Jiang D.,"Zhou, Yucheng (57262453900); Geng, Xiubo (57216694637); Shen, Tao (57210531549); Pei, Jian (35273378100); Zhang, Wenqiang (56593812000); Jiang, Daxin (57226177359)",57262453900; 57216694637; 57210531549; 35273378100; 56593812000; 57226177359,Modeling Event-Pair Relations in External Knowledge Graphs for Script Reasoning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123936277&partnerID=40&md5=5aa223be49aead8257f3dc299b9e8981,"Script reasoning infers subsequent events from a given event chain, which involves the ability to understand relations between events. A human-labeled script reasoning dataset is usually of small size with limited event relations, which highlights the necessity to leverage external eventuality knowledge graphs (KG) consisting of numerous triple facts to describe the inferential relation between events. Existing methods adopt a retrieval and integration paradigm to focus merely on the graph triples that have event overlap with a script, but ignore much more supportive triples in the KG with similar inferential patterns, leading to under-exploiting. To fully exploit the KG, we propose a knowledge model to learn the inferential relations between events from the whole eventuality KG and then support downstream models by directly capturing the relation between events in a script. We further present a neural script adapter to extend the knowledge model for inferring the associated relations between an event chain and a subsequent event candidate. We evaluate the proposed approach on a popular multi-choice narrative cloze task for script reasoning and achieve new state-ofthe-art accuracy, compared with baselines either incorporating external KG or not. © 2021 Association for Computational Linguistics",Final,
Orogat A.; El-Roby A.,"Orogat, Abdelghny (57192382907); El-Roby, Ahmed (55975785300)",57192382907; 55975785300,Cbench: Demonstrating comprehensive evaluation of questianswering systems over knowledge graphs through deep analysis of benchmarks,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119964973&doi=10.14778%2f3476311.3476326&partnerID=40&md5=fc7681a9f7ee0026a1f009cff40527ed,"A plethora of question answering (QA) systems that retrieve answers to natural language questions from knowledge graphs have been developed in recent years. However, choosing a benchmark to accurately assess the quality of a question answering system is a challenging task due to the high degree of variations among the available benchmarks with respect to their fine-grained properties. In this demonstration, we introduce CBench, an extensible, and more informative benchmarking suite for analyzing benchmarks and evaluating QA systems. CBench can be used to analyze existing benchmarks with respect to several fine-grained linguistic, syntactic, and structural properties of the questions and queries in the benchmarks. Moreover, CBench can be used to facilitate the evaluation of QA systems using a set of popular benchmarks that can be augmented with other user-provided benchmarks. CBench not only evaluates a QA system based on popular single-number metrics but also gives a detailed analysis of the linguistic, syntactic, and structural properties of answered and unanswered questions to help the developers of QA systems to better understand where their system excels and where it struggles. © The authors.",Final,
Zhao H.; Sha Y.; Leng J.; Pan X.; Xue Z.; Ma Q.; Liang Y.,"Zhao, Hanyu (57203149266); Sha, Yuan (57425828200); Leng, Jiahong (57232986100); Pan, Xiang (57231843700); Xue, Zhao (57232299500); Ma, Quanyue (57232758300); Liang, Yangxiao (57231609500)",57203149266; 57425828200; 57232986100; 57231843700; 57232299500; 57232758300; 57231609500,A Chinese Machine Reading Comprehension Dataset Automatic Generated Based on Knowledge Graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123430011&partnerID=40&md5=504c6d768d6d07246b63654888c6c9a6,"Machine reading comprehension (MRC) is a typical natural language processing (NLP) task and has developed rapidly in the last few years. Various reading comprehension datasets have been built to support MRC studies. However, large-scale and high-quality datasets are rare due to the high complexity and huge workforce cost of making such a dataset. Besides, most reading comprehension datasets are in English, and Chinese datasets are insufficient. In this paper, we propose an automatic method for MRC dataset generation, and build the largest Chinese medical reading comprehension dataset presently named CMedRC. Our dataset contains I7k questions generated by our automatic method and some seed questions. We obtain the corresponding answers from a medical knowledge graph and manually check all of them. Finally, we test BiLSTM and BERT-based pre-trained language models (PLMs) on our dataset and propose a baseline for the following studies. Results show that the automatic MRC dataset generation method is considerable for future model improvements. © 2021 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License",Final,
Magnusson I.H.; Friedman S.E.,"Magnusson, Ian H. (57954033500); Friedman, Scott E. (58387903900)",57954033500; 58387903900,Extracting Fine-Grained Knowledge Graphs of Scientific Claims: Dataset and Transformer-Based Results,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125988598&partnerID=40&md5=f60bd171d7cace16b9cdf7be2a8c8406,"Recent transformer-based approaches demonstrate promising results on relational scientific information extraction. Existing datasets focus on high-level description of how research is carried out. Instead we focus on the subtleties of how experimental associations are presented by building SciClaim, a dataset of scientific claims drawn from Social and Behavior Science (SBS), PubMed, and CORD-19 papers. Our novel graph annotation schema incorporates not only coarse-grained entity spans as nodes and relations as edges between them, but also fine-grained attributes that modify entities and their relations, for a total of 12,738 labels in the corpus. By including more label types and more than twice the label density of previous datasets, SciClaim captures causal, comparative, predictive, statistical, and proportional associations over experimental variables along with their qualifications, subtypes, and evidence. We extend work in transformer-based joint entity and relation extraction to effectively infer our schema, showing the promise of fine-grained knowledge graphs in scientific claims and beyond. © 2021 Association for Computational Linguistics",Final,
Galetzka F.; Rose J.; Schlangen D.; Lehmann J.,"Galetzka, Fabian (57219810600); Rose, Jewgeni (57190172160); Schlangen, David (13605349800); Lehmann, Jens (35229806900)",57219810600; 57190172160; 13605349800; 35229806900,Space efficient context encoding for non-task-oriented dialogue generation with graph attention transformer,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118958237&partnerID=40&md5=ac84d066e7f640f139f6346ae3f79290,"To improve the coherence and knowledge retrieval capabilities of non-task-oriented dialogue systems, recent Transformer-based models aim to integrate fixed background context. This often comes in the form of knowledge graphs, and the integration is done by creating pseudo utterances through paraphrasing knowledge triples, added into the accumulated dialogue context. However, the context length is fixed in these architectures, which restricts how much background or dialogue context can be kept. In this work, we propose a more concise encoding for background context structured in the form of knowledge graphs, by expressing the graph connections through restrictions on the attention weights. The results of our human evaluation show that this encoding reduces space requirements without negative effects on the precision of reproduction of knowledge and perceived consistency. Further, models trained with our proposed context encoding generate dialogues that are judged to be more comprehensive and interesting. © 2021 Association for Computational Linguistics",Final,
Xu Y.; Haihong E.; Meina S.; Song W.; Lv X.; Haotian W.; Jinrui Y.,"Xu, Youri (57221150929); Haihong, E. (36679915000); Meina, Song (8419354200); Song, Wenyu (57224078019); Lv, Xiaodong (57224087481); Haotian, Wang (57498377300); Jinrui, Yang (56374712900)",57221150929; 36679915000; 8419354200; 57224078019; 57224087481; 57498377300; 56374712900,RTFE: A Recursive Temporal Fact Embedding Framework for Temporal Knowledge Graph Completion,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123490502&partnerID=40&md5=beaae063b40106607ef410bd5681b2b9,"Static knowledge graph (SKG) embedding (SKGE) has been studied intensively in the past years. Recently, temporal knowledge graph (TKG) embedding (TKGE) has emerged. In this paper, we propose a Recursive Temporal Fact Embedding (RTFE) framework to transplant SKGE models to TKGs and to enhance the performance of existing TKGE models for TKG completion. Different from previous work which ignores the continuity of states of TKG in time evolution, we treat the sequence of graphs as a Markov chain, which transitions from the previous state to the next state. RTFE takes the SKGE to initialize the embeddings of TKG. Then it recursively tracks the state transition of TKG by passing updated parameters/features between timestamps. Specifically, at each timestamp, we approximate the state transition as the gradient update process. Since RTFE learns each timestamp recursively, it can naturally transit to future timestamps. Experiments on five TKG datasets show the effectiveness of RTFE. © 2021 Association for Computational Linguistics.",Final,
He L.; Zheng S.; Yang T.; Zhang F.,"He, Lei (57657656400); Zheng, Suncong (55838664300); Yang, Tao (57217802442); Zhang, Feng (57192385420)",57657656400; 55838664300; 57217802442; 57192385420,KLMo: Knowledge Graph Enhanced Pretrained Language Model with Fine-Grained Relationships,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129143207&partnerID=40&md5=f05c9e8d996190a1fc9743615176acb0,"Interactions between entities in knowledge graph (KG) provide rich knowledge for language representation learning. However, existing knowledge-enhanced pretrained language models (PLMs) only focus on entity information and ignore the fine-grained relationships between entities. In this work, we propose to incorporate KG (including both entities and relations) into the language learning process to obtain KG-enhanced pretrained Language Model, namely KLMo. Specifically, a novel knowledge aggregator is designed to explicitly model the interaction between entity spans in text and all entities and relations in a contextual KG. An relation prediction objective is utilized to incorporate relation information by distant supervision. An entity linking objective is further utilized to link entity spans in text to entities in KG. In this way, the structured knowledge can be effectively integrated into language representations. Experimental results demonstrate that KLMo achieves great improvements on several knowledge-driven tasks, such as entity typing and relation classification, comparing with the state-of-the-art knowledge-enhanced PLMs.  © 2021 Association for Computational Linguistics.",Final,
Wang P.; Ilievski F.; Chen M.; Ren X.,"Wang, Peifeng (57219735249); Ilievski, Filip (57188757237); Chen, Muhao (57077271100); Ren, Xiang (58619993600)",57219735249; 57188757237; 57077271100; 58619993600,Do Language Models Perform Generalizable Commonsense Inference?,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123931773&partnerID=40&md5=8d11a4eacbc4c2c03b4a60386c3c6663,"Inspired by evidence that pretrained language models (LMs) encode commonsense knowledge, recent work has applied LMs to automatically populate commonsense knowledge graphs (CKGs). However, there is a lack of understanding on their generalization to multiple CKGs, unseen relations, and novel entities. This paper analyzes the ability of LMs to perform generalizable commonsense inference, in terms of knowledge capacity, transferability, and induction. Our experiments with these three aspects show that: (1) LMs can adapt to different schemas defined by multiple CKGs but fail to reuse the knowledge to generalize to new relations. (2) Adapted LMs generalize well to unseen subjects, but less so on novel objects. Future work should investigate how to improve the transferability and induction of commonsense mining from LMs. © 2021 Association for Computational Linguistics",Final,
,,,"LDK 2021 - Proceedings of the Workshops and Tutorials - Language Data and Knowledge, co-located with the Language, Data and Knowledge Conference, LDK 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126053629&partnerID=40&md5=9d7d562ef516606608b91753a7aa7ad1,The proceedings contain 14 papers. The topics discussed include: nose-first. towards an olfactory gaze for digital art history; sentiment analysis meets linguistic linked data: an overview of the state of the art; extending general sentiment lexicon to specific domains in (semi-)automatic manner; multilingual knowledge systems as linguistic linked open data for European language grid; LOD-connected offensive language ontology and tagset enrichment; extending and using a sentiment lexicon for Latin in a linked data framework; aspect-based sentiment analysis of conference review forms with LD-enabled review criteria; and from meaning to perception - exploring the space between word and odor perception embeddings.,Final,
Sun H.; Zhong J.; Ma Y.; Han Z.; He K.,"Sun, Haohai (57267496800); Zhong, Jialun (57226185301); Ma, Yunpu (57194413081); Han, Zhen (57219766233); He, Kun (57204773777)",57267496800; 57226185301; 57194413081; 57219766233; 57204773777,TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122720554&partnerID=40&md5=269d46d0d00baf1f95ad18cac640f548,"Temporal knowledge graph (TKG) reasoning is a crucial task that has gained increasing research interest in recent years. Most existing methods focus on reasoning at past timestamps to complete the missing facts, and there are only a few works of reasoning on known TKGs to forecast future facts. Compared with the completion task, the forecasting task is more difficult and faces two main challenges: (1) how to effectively model the time information to handle future timestamps? (2) how to make inductive inference to handle previously unseen entities that emerge over time? To address these challenges, we propose the first reinforcement learning method for forecasting. Specifically, the agent travels on historical knowledge graph snapshots to search for the answer. Our method defines a relative time encoding function to capture the timespan information, and we design a novel time-shaped reward based on Dirichlet distribution to guide the model learning. Furthermore, we propose a novel representation method for unseen entities to improve the inductive inference ability of the model. We evaluate our method for this link prediction task at future timestamps. Extensive experiments on four benchmark datasets demonstrate substantial performance improvement meanwhile with higher explainability, less calculation, and fewer parameters when compared with existing state-of-the-art methods. © 2021 Association for Computational Linguistics",Final,
Gupte A.; Sapre S.; Sonawane S.,"Gupte, Athang (57454920200); Sapre, Saumitra (57454660100); Sonawane, Sheetal (57191854431)",57454920200; 57454660100; 57191854431,Knowledge Graph Generation From Text Using Neural Machine Translation Techniques,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124691907&doi=10.1109%2fICCICT50803.2021.9510164&partnerID=40&md5=a892191626cbf06c9dfc1b24955d1523,"As the applications of data science become pervasive in daily life, there arises a dire need to represent data in machine-understandable forms like knowledge graphs. Over the years, there have been numerous developments in extracting entities and their relations for augmenting knowledge graphs, but many of them depend on external dependencies like dependency parsers and part-of-speech taggers. These approaches, while indeed accomplishing this task, induce a certain degree of inflexibility in their implementation. Recent explorations in this domain have attempted to utilize Neural Machine Translation techniques to convert natural language to SPARQL queries, with a focus on information retrieval from pre-established Knowledge Graphs. We explore in detail, the variety of approaches followed for SPARQL machine translation, with a keen focus on insertion of extracted knowledge into the graphs. As part of our research, we curated a dataset- Scientists-100, extracted from Dbpedia, for the task of translation of natural language to SPARQL insertion statements. We also propose two models – an Attention RNN and a Transformer for the same. These models achieve an accuracy of 99.27% and a 98.61% respectively on the dataset. In addition to this, we present a metric for examining the syntactic accuracy of the generated SPARQL statements. Our models exhibit 99.25% and 98.71% syntactic accuracy as calculated on the same. © 2021 IEEE.",Final,
Bhardwaj P.; Kelleher J.; Costabello L.; O'Sullivan D.,"Bhardwaj, Peru (57202714534); Kelleher, John (14035902400); Costabello, Luca (53979719800); O'Sullivan, Declan (57202521703)",57202714534; 14035902400; 53979719800; 57202521703,Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127393463&partnerID=40&md5=d242936c9234d2b8297eaedfff53d1a6,"Despite the widespread use of Knowledge Graph Embeddings (KGE), little is known about the security vulnerabilities that might disrupt their intended behaviour. We study data poisoning attacks against KGE models for link prediction. These attacks craft adversarial additions or deletions at training time to cause model failure at test time. To select adversarial deletions, we propose to use the model-agnostic instance attribution methods from Interpretable Machine Learning, which identify the training instances that are most influential to a neural model's predictions on test instances. We use these influential triples as adversarial deletions. We further propose a heuristic method to replace one of the two entities in each influential triple to generate adversarial additions. Our experiments show that the proposed strategies outperform the state-of-art data poisoning attacks on KGE models and improve the MRR degradation due to the attacks by up to 62% over the baselines. © 2021 Association for Computational Linguistics",Final,
Yan J.; Raman M.; Chan A.; Zhang T.; Rossi R.; Zhao H.; Kim S.; Lipka N.; Ren X.,"Yan, Jun (57220869711); Raman, Mrigank (57219792284); Chan, Aaron (57195415267); Zhang, Tianyu (57226474084); Rossi, Ryan (57197077642); Zhao, Handong (56915061800); Kim, Sungchul (57193625251); Lipka, Nedim (25927367600); Ren, Xiang (58619993600)",57220869711; 57219792284; 57195415267; 57226474084; 57197077642; 56915061800; 57193625251; 25927367600; 58619993600,Learning Contextualized Knowledge Structures for Commonsense Reasoning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123931176&partnerID=40&md5=878613c97512174c4b0a888ee9cbd72f,"Recently, knowledge graph (KG) augmented models have achieved noteworthy success on various commonsense reasoning tasks. However, KG edge (fact) sparsity and noisy edge extraction/generation often hinder models from obtaining useful knowledge to reason over. To address these issues, we propose a new KG-augmented model: Hybrid Graph Network (HGN). Unlike prior methods, HGN learns to jointly contextualize extracted and generated knowledge by reasoning over both within a unified graph structure. Given the task input context and an extracted KG subgraph, HGN is trained to generate embeddings for the subgraph's missing edges to form a “hybrid” graph, then reason over the hybrid graph while filtering out context-irrelevant edges. We demonstrate HGN's effectiveness through considerable performance gains across four commonsense reasoning benchmarks, plus a user study on edge validness and helpfulness. © 2021 Association for Computational Linguistics",Final,
Zhang J.; Yang Y.; Chen C.; He L.; Yu Z.,"Zhang, Jun (57221657949); Yang, Yan (56493572100); Chen, Chengcai (57211167830); He, Liang (35758919600); Yu, Zhou (57205750897)",57221657949; 56493572100; 57211167830; 35758919600; 57205750897,KERS: A Knowledge-Enhanced Framework for Recommendation Dialog Systems with Multiple Subgoals,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129147419&partnerID=40&md5=657df07e2f245e2199b8e9e6b83a5463,"Recommendation dialogs require the system to build a social bond with users to gain trust and develop affinity in order to increase the chance of a successful recommendation. It is beneficial to divide up, such conversations with multiple subgoals (such as social chat, question answering, recommendation, etc.), so that the system can retrieve appropriate knowledge with better accuracy under different subgoals. In this paper, we propose a unified framework for common knowledge-based multi-subgoal dialog: knowledge-enhanced multi-subgoal driven recommender system (KERS). We first predict a sequence of subgoals and use them to guide the dialog model to select knowledge from a sub-set of existing knowledge graph. We then propose three new mechanisms to filter noisy knowledge and to enhance the inclusion of cleaned knowledge in the dialog response generation process. Experiments show that our method obtains stateof-the-art results on DuRecDial dataset in both automatic and human evaluation.  © 2021 Association for Computational Linguistics.",Final,
Wang Q.; Wang H.; Lyu Y.; Zhu Y.,"Wang, Quan (55584980300); Wang, Haifeng (57192674011); Lyu, Yajuan (57192308367); Zhu, Yong (57212066003)",55584980300; 57192674011; 57192308367; 57212066003,Link Prediction on N-ary Relational Facts: A Graph-based Approach,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122718610&partnerID=40&md5=65edb87cb361e50d7e96ec7d9cd8b5af,"Link prediction on knowledge graphs (KGs) is a key research topic. Previous work mainly focused on binary relations, paying less attention to higher-arity relations although they are ubiquitous in real-world KGs. This paper considers link prediction upon n-ary relational facts and proposes a graph-based approach to this task. The key to our approach is to represent the nary structure of a fact as a small heterogeneous graph, and model this graph with edge-biased fully-connected attention. The fully-connected attention captures universal inter-vertex interactions, while with edge-aware attentive biases to particularly encode the graph structure and its heterogeneity. In this fashion, our approach fully models global and local dependencies in each n-ary fact, and hence can more effectively capture associations therein. Extensive evaluation verifies the effectiveness and superiority of our approach. It performs substantially and consistently better than current state-of-the-art across a variety of n-ary relational benchmarks. Our code is publicly available. © 2021 Association for Computational Linguistics",Final,
Meng Z.; Liu F.; Clark T.H.; Shareghi E.; Collier N.,"Meng, Zaiqiao (56924375000); Liu, Fangyu (57192190518); Clark, Thomas Hikaru (57272025400); Shareghi, Ehsan (35957521400); Collier, Nigel (7004876365)",56924375000; 57192190518; 57272025400; 35957521400; 7004876365,Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into BERT,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127429015&partnerID=40&md5=36ccf7005d04817835a061d2fbb04fc5,"Infusing factual knowledge into pretrained models is fundamental for many knowledge-intensive tasks. In this paper, we propose Mixture-of-Partitions (MoP), an infusion approach that can handle a very large knowledge graph (KG) by partitioning it into smaller sub-graphs and infusing their specific knowledge into various BERT models using lightweight adapters. To leverage the overall factual knowledge for a target task, these sub-graph adapters are further fine-tuned along with the underlying BERT through a mixture layer. We evaluate our MoP with three biomedical BERTs (SciBERT, BioBERT, PubmedBERT) on six downstream tasks (inc. NLI, QA, Classification), and the results show that our MoP consistently enhances the underlying BERTs in task performance, and achieves new SOTA performances on five evaluated datasets. © 2021 Association for Computational Linguistics",Final,
Lopez V.; Yadav N.; Picco G.; Vejsbjerg I.; Carroll E.; Brady S.; Sbodio M.L.; Hoang L.T.; Wei M.; Segrave J.,"Lopez, Vanessa (8928407100); Yadav, Nagesh (57196235954); Picco, Gabriele (57217259095); Vejsbjerg, Inge (57201634998); Carroll, Eoin (57437435600); Brady, Seamus (57437870400); Sbodio, Marco Luca (55886127400); Hoang, Lam Thanh (57437579400); Wei, Miao (57437296000); Segrave, John (57437579500)",8928407100; 57196235954; 57217259095; 57201634998; 57437435600; 57437870400; 55886127400; 57437579400; 57437296000; 57437579500,Towards Protecting Vital Healthcare Programs by Extracting Actionable Knowledge from Policy,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123927590&partnerID=40&md5=f0b01cc026c403704f7778a8776e6667,"In challenging economic times, obtaining value for money by ensuring financial integrity and fairer distribution of services are among the top priorities for social and health-care systems globally. However, healthcare billing policies are complex and identifying non-compliance is often narrow-scope, manual and expensive. Maintaining 'integrity' is a challenge - ensuring that scarce resources get to those in need and are not lost to fraud and waste. Our approach fuses recent advances in dependency parsing with a policy ontology to convert the content of regulatory healthcare policy into human-friendly policy rules, that are amenable to machine-execution, with human oversight. We describe the ontology-guided transformation of textual patterns into a semantically-meaningful knowledge graph of rules, outline our experiments and evaluate results against policy rules obtained from professional investigators. The aim is to make a policy-compliance 'landscape' visible to healthcare programs - helping them identify Fraud, Waste or Abuse. © 2021 Association for Computational Linguistics",Final,
,,,"Proceedings - 2021 International Conference on Computers, Information Processing and Advanced Education, CIPAE 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123359414&partnerID=40&md5=51bea9939f489690dbf51679021f9b61,The proceedings contain 9 papers. The topics discussed include: from DBpedia and WordNet hierarchies to LinkedIn and twitter; a linked data model for multimodal sentiment and emotion analysis; seeing is correcting: curating lexical resources using social interfaces; Sar-graphs: a linked linguistic knowledge resource connecting facts with language; reconciling heterogeneous descriptions of language resources; digital representation of rights for language resources; linking four heterogeneous language resources as linked data; EVALution 1.0: an evolving semantic dataset for training and evaluation of distributional semantic models; and linguistic linked data in Chinese: the case of Chinese WordNet.,Final,
Grotto F.; Sprugnoli R.; Fantoli M.; Simi M.; Cecchini F.M.; Passarotti M.,"Grotto, Francesco (58022659200); Sprugnoli, Rachele (15077007200); Fantoli, Margherita (57219712732); Simi, Maria (7005175069); Cecchini, Flavio Massimiliano (57170316600); Passarotti, Marco (56957111300)",58022659200; 15077007200; 57219712732; 7005175069; 57170316600; 56957111300,"The annotation of liber abbaci, a domain-specific Latin resource",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121240982&partnerID=40&md5=d758776447520a3c166ebbe45637d778,"The Liber Abbaci (13th century) is a milestone in the history of mathematics and accounting. Due to the late stage of Latin, its features and its very specialized content, it also represents a unique resource for scholars working on Latin corpora. In this paper we present the annotation and linking work carried out in the frame of the project Fibonacci 1202-2021. A gold-standard lemmatization and part-of-speech tagging allow us to elaborate some first observations on the linguistic and historical features of the text, and to link the text to the Lila Knowledge Base, that has as its goal to make distributed linguistic resources for Latin interoperable by following the principles of the Linked Data paradigm. Starting from this specific case, we discuss the importance of annotating and linking scientific and technical texts, in order to (a) compare and search them together with other (non-technical) Latin texts (b) train, apply and evaluate NLP resources on a non-standard variety of Latin. The paper also describes the fruitful interaction and coordination between NLP experts and traditional Latin scholars on a project requiring a large range of expertise. © 2021 for this paper by its author. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Tseng W.-T.; Wu C.-Y.; Hsu Y.-C.; Chen B.,"Tseng, Wan-Ting (57264690100); Wu, Chin-Ying (57537657600); Hsu, Yung-Chang (57264317600); Chen, Berlin (35267845800)",57264690100; 57537657600; 57264317600; 35267845800,FAQ Retrieval using Question-Aware Graph Convolutional Network and Conualized Language Model,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126653247&partnerID=40&md5=e354aee0b9e37f22d988678fa16e78ff,"Frequently asked question (FAQ) retrieval, which seeks to provide the most relevant question, or question-answer (QA) pair, in response to a user's query, has found its applications in widespread use cases. More recently, methods based on bidirectional encoder representations from Transformers (BERT) and its variants, which typically take the word embeddings of a question in training time (or query in test time) as the input to predict relevant answers, have shown good promise for FAQ retrieval. However, these BERT-based methods do not pay enough attention to the global information specifically about an FAQ task. To cater for this, we in this paper put forward a question-aware graph convolutional network (QGCN) to induce vector embeddings of vocabulary words, thereby encapsulating the global question-question, question-word and word-word relations which can be used to augment the embeddings derived from BERT for better F AQ retrieval. Meanwhile, we also investigate leverage domain-specific knowledge graphs to enrich the question and query embeddings (denoted by K-BERT). Finally, we conduct extensive experiments to evaluate the utility of the proposed approaches on two publicly-available FAQ datasets (viz. TaipeiQA and StackF AQ), where the associated results confirm the promising efficacy of the proposed approach in comparison to some top-of-the-line methods.  © 2021 APSIPA.",Final,
Jo Y.; Yoo H.; Bak J.; Oh A.; Reed C.; Hovy E.,"Jo, Yohan (57118936400); Yoo, Haneul (57274452100); Bak, Jinyeong (55747333100); Oh, Alice (35190968400); Reed, Chris (7402210486); Hovy, Eduard (6602910705)",57118936400; 57274452100; 55747333100; 35190968400; 7402210486; 6602910705,Knowledge-Enhanced Evidence Retrieval for Counterargument Generation,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128538303&partnerID=40&md5=22a3e1e1f65f2b998415f242ed3dd795,"Finding counterevidence to statements is key to many tasks, including counterargument generation. We build a system that, given a statement, retrieves counterevidence from diverse sources on the Web. At the core of this system is a natural language inference (NLI) model that determines whether a candidate sentence is valid counterevidence or not. Most NLI models to date, however, lack proper reasoning abilities necessary to find counterevidence that involves complex inference. Thus, we present a knowledge-enhanced NLI model that aims to handle causality- and example-based inference by incorporating knowledge graphs. Our NLI model outperforms baselines for NLI tasks, especially for instances that require the targeted inference. In addition, this NLI model further improves the counterevidence retrieval system, notably finding complex counterevidence better.  © 2021 Association for Computational Linguistics.",Final,
Ushio A.; Camacho-Collados J.; Schockaert S.,"Ushio, Asahi (57225292428); Camacho-Collados, Jose (56899042300); Schockaert, Steven (8886625200)",57225292428; 56899042300; 8886625200,Distilling Relation Embeddings from Pre-trained Language Models,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127374277&partnerID=40&md5=6553d1ca98f99f18e79adafc5fac75fc,"Pre-trained language models have been found to capture a surprisingly rich amount of lexical knowledge, ranging from commonsense properties of everyday concepts to detailed factual knowledge about named entities. Among others, this makes it possible to distill high-quality word vectors from pre-trained language models. However, it is currently unclear to what extent it is possible to distill relation embeddings, i.e. vectors that characterize the relationship between two words. Such relation embeddings are appealing because they can, in principle, encode relational knowledge in a more fine-grained way than is possible with knowledge graphs. To obtain relation embeddings from a pre-trained language model, we encode word pairs using a (manually or automatically generated) prompt, and we fine-tune the language model such that relationally similar word pairs yield similar output vectors. We find that the resulting relation embeddings are highly competitive on analogy (unsupervised) and relation classification (supervised) benchmarks, even without any task-specific fine-tuning. © 2021 Association for Computational Linguistics",Final,
D’Souza J.; Auer S.,"D’Souza, Jennifer (57215346447); Auer, Sören (23391879500)",57215346447; 23391879500,Pattern-Based Acquisition of Scientific Entities from Scholarly Article Titles,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121912565&doi=10.1007%2f978-3-030-91669-5_31&partnerID=40&md5=10fb3630d5e737196f0b7137d140c6b8,"We describe a rule-based approach for the automatic acquisition of salient scientific entities from Computational Linguistics (CL) scholarly article titles. Two observations motivated the approach: (i) noting salient aspects of an article’s contribution in its title; and (ii) pattern regularities capturing the salient terms that could be expressed in a set of rules. Only those lexico-syntactic patterns were selected that were easily recognizable, occurred frequently, and positionally indicated a scientific entity type. The rules were developed on a collection of 50,237 CL titles covering all articles in the ACL Anthology. In total, 19,799 research problems, 18,111 solutions, 20,033 resources, 1,059 languages, 6,878 tools, and 21,687 methods were extracted at an average precision of 75%. © 2021, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Zhou J.; Hu S.; Lv X.; Yang C.; Liu Z.; Xu W.; Jiang J.; Li J.; Sun M.,"Zhou, Jie (56939394300); Hu, Shengding (57219757560); Lv, Xin (57211203656); Yang, Cheng (57001472900); Liu, Zhiyuan (57191691341); Xu, Wei (57226693028); Jiang, Jie (57226121879); Li, Juanzi (8304332600); Sun, Maosong (7403180987)",56939394300; 57219757560; 57211203656; 57001472900; 57191691341; 57226693028; 57226121879; 8304332600; 7403180987,"KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123410051&partnerID=40&md5=f0d6416d1d065c08ccff8d54815e6380,"A comprehensive knowledge graph (KG) contains an instance-level entity graph and an ontology-level concept graph. The two-view KG provides a testbed for models to “simulate” human's abilities on knowledge abstraction, concretization, and completion (KACC), which are crucial for human to recognize the world and manage learned knowledge. Existing studies mainly focus on partial aspects of KACC. In order to promote thorough analyses for KACC abilities of models, we propose a unified KG benchmark by improving existing benchmarks in terms of dataset scale, task coverage, and difficulty. Specifically, we collect new datasets that contain larger concept graphs, abundant cross-view links as well as dense entity graphs. Based on the datasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA), multi-hop knowledge concretization (MKC) and then design a comprehensive benchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical triples as harder samples. The experimental results of existing methods demonstrate the challenges of our benchmark. The resource is available at https://github.com/thunlp/KACC. © 2021 Association for Computational Linguistics",Final,
Tran H.; Phan L.; Anibal J.; Nguyen B.T.; Nguyen T.-S.,"Tran, Hieu (57211019955); Phan, Long (57221840013); Anibal, James (57212803374); Nguyen, Binh T. (57215042363); Nguyen, Truong-Son (57221840686)",57211019955; 57221840013; 57212803374; 57215042363; 57221840686,SPBERT: an Efficient Pre-training BERT on SPARQL Queries for Question Answering over Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121820120&doi=10.1007%2f978-3-030-92185-9_42&partnerID=40&md5=61d0f01c00c902d36511d33f8d8549dc,"Knowledge Graph is becoming increasingly popular and necessary during the past years. In order to address the lack of structural information of SPARQL query language, we propose SPBERT, a transformer-based language model pre-trained on massive SPARQL query logs. By incorporating masked language modeling objectives and the word structural objective, SPBERT can learn general-purpose representations in both natural language and SPARQL query language. We investigate how SPBERT and encoder-decoder architecture can be adapted for Knowledge-based QA corpora. We conduct exhaustive experiments on two additional tasks, including SPARQL Query Construction and Answer Verbalization Generation. The experimental results show that SPBERT can obtain promising results, achieving state-of-the-art BLEU scores on several of these tasks. © 2021, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Nadgeri A.; Bastos A.; Singh K.; Mulang I.O.; Hoffart J.; Shekarpour S.; Saraswat V.,"Nadgeri, Abhishek (57211270068); Bastos, Anson (57219792936); Singh, Kuldeep (57212017864); Mulang, Isaiah Onando (57200275670); Hoffart, Johannes (35339183000); Shekarpour, Saeedeh (55298471100); Saraswat, Vijay (57225738356)",57211270068; 57219792936; 57212017864; 57200275670; 35339183000; 55298471100; 57225738356,KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121312954&partnerID=40&md5=a9c986a66d334d840ee0ba11c886e9af,"We present a novel method for relation extraction (RE) from a single sentence, mapping the sentence and two given entities to a canonical fact in a knowledge graph (KG). Especially in this presumed sentential RE setting, the context of a single sentence is often sparse. This paper introduces the KGPool method to address this sparsity, dynamically expanding the context with additional facts from the KG. It learns the representation of these facts (entity alias, entity descriptions, etc.) using neural methods, supplementing the sentential context. Unlike existing methods that statically use all expanded facts, KGPool conditions this expansion on the sentence. We study the efficacy of KGPool by evaluating it with different neural models and KGs (Wikidata and NYT Freebase). Our experimental evaluation on standard datasets shows that by feeding the KGPool representation into a Graph Neural Network, the overall method is significantly more accurate than state-of-the-art methods. © 2021 Association for Computational Linguistics",Final,
Shi J.; Cao S.; Hou L.; Li J.; Zhang H.,"Shi, Jiaxin (57192174048); Cao, Shulin (57211208299); Hou, Lei (56622056400); Li, Juanzi (8304332600); Zhang, Hanwang (55366935100)",57192174048; 57211208299; 56622056400; 8304332600; 55366935100,TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125464082&partnerID=40&md5=48e8ff1eaad9be308ccb777b7628a8b0,"Multi-hop Question Answering (QA) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. The relations can be represented in terms of labels in knowledge graph (e.g., spouse) or text in text corpus (e.g., they have been married for 26 years). Existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. The former is hard to optimize, and the latter lacks interpretability. In this paper, we propose TransferNet, an effective and transparent model for multi-hop QA, which supports both label and text relations in a unified framework. TransferNet jumps across entities at multiple steps. At each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. We carry out extensive experiments on three datasets and demonstrate that TransferNet surpasses the state-of-the-art models by a large margin. In particular, on MetaQA, it achieves 100% accuracy in 2-hop and 3-hop questions. By qualitative analysis, we show that TransferNet has transparent and interpretable intermediate results. © 2021 Association for Computational Linguistics",Final,
Narvala H.; McDonald G.; Ounis I.,"Narvala, Hitarth (57218706311); McDonald, Graham (55585265600); Ounis, Iadh (8061165800)",57218706311; 55585265600; 8061165800,RelDiff: Enriching Knowledge Graph Relation Representations for Sensitivity Classification,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127445032&partnerID=40&md5=c9e60abf89945169fe07195116f7f7e9,"The relationships that exist between entities can be a reliable indicator for classifying sensitive information, such as commercially sensitive information. For example, the relation person-IsDirectorOf-company can indicate whether an individual's salary should be considered as sensitive personal information. Representations of such relations are often learned using a knowledge graph to produce embeddings for relation types, generalised across different entity-pairs. However, a relation type may or may not correspond to a sensitivity depending on the entities that participate to the relation. Therefore, generalised relation embeddings are typically insufficient for classifying sensitive information. In this work, we propose a novel method for representing entities and relations within a single embedding to better capture the relationship between the entities. Moreover, we show that our proposed entity-relation-entity embedding approach can significantly improve (McNemar's test, p < 0.05) the effectiveness of sensitivity classification, compared to classification approaches that leverage relation embedding approaches from the literature (0.426 F1 vs 0.413 F1).  © 2021 Association for Computational Linguistics.",Final,
Pan Z.; Wang P.,"Pan, Zhe (57205406978); Wang, Peng (56182131700)",57205406978; 56182131700,Hyperbolic Hierarchy-Aware Knowledge Graph Embedding for Link Prediction,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129122429&partnerID=40&md5=d6a4dad3637c67f32d99dd08464907dc,"Knowledge graph embedding (KGE) using low-dimensional representations to predict missing information is widely applied in knowledge completion. Existing embedding methods are mostly built on Euclidean space, which are difficult to handle hierarchical structures. Hyperbolic embedding methods have shown the promise of high fidelity and concise representation for hierarchical data. However, the logical patterns in knowledge graphs are not considered well in these methods. To address this problem, we propose a novel KGE model with extended Poincaré Ball and polar coordinate system to capture hierarchical structures. We use the tangent space and exponential transformation to initialize and map the corresponding vectors to the Poincaré Ball in hyperbolic space. To solve the boundary conditions, the boundary is stretched and zoomed by expanding the modulus length in the Poincaré Ball. We optimize our model using polar coordinate and changing operators in the extended Poincaré Ball. Experiments achieve new state-of-the-art results on part of link prediction tasks, which demonstrates the effectiveness of our method.  © 2021 Association for Computational Linguistics.",Final,
Weber L.; Garda S.; Münchmeyer J.; Leser U.,"Weber, Leon (57194978942); Garda, Samuele (57204801990); Münchmeyer, Jannes (57193733023); Leser, Ulf (6602717727)",57194978942; 57204801990; 57193733023; 6602717727,"Extend, don't rebuild: Phrasing conditional graph modification as autoregressive sequence labelling",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127386907&partnerID=40&md5=a58423378b341204efe2b9231f4d86a8,"Deriving and modifying graphs from natural language text has become a versatile basis technology for information extraction with applications in many subfields, such as semantic parsing or knowledge graph construction. A recent work used this technique for modifying scene graphs (He et al., 2020), by first encoding the original graph and then generating the modified one based on this encoding. In this work, we show that we can considerably increase performance on this problem by phrasing it as graph extension instead of graph generation. We propose the first model for the resulting graph extension problem based on autoregressive sequence labelling. On three scene graph modification data sets, this formulation leads to improvements in accuracy over the state-of-the-art between 13 and 26 percentage points. Furthermore, we introduce a novel data set from the biomedical domain which has much larger linguistic variability and more complex graphs than the scene graph modification data sets. For this data set, the state-of-the art fails to generalize, while our model can produce meaningful predictions. © 2021 Association for Computational Linguistics",Final,
Saparina I.; Osokin A.,"Saparina, Irina (57219506895); Osokin, Anton (57210766875)",57219506895; 57210766875,SPARQLing Database Queries from Intermediate Question Decompositions,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121765965&partnerID=40&md5=1bc1f6aa39ef7cc7a0af363ae2610ef1,"To translate natural language questions into executable database queries, most approaches rely on a fully annotated training set. Annotating a large dataset with queries is difficult as it requires query-language expertise. We reduce this burden using grounded in databases intermediate question representations. These representations are simpler to collect and were originally crowdsourced within the Break dataset (Wolfson et al., 2020). Our pipeline consists of two parts: a neural semantic parser that converts natural language questions into the intermediate representations and a non-trainable transpiler to the SPARQL query language (a standard language for accessing knowledge graphs and semantic web). We chose SPARQL because its queries are structurally closer to our intermediate representations (compared to SQL). We observe that the execution accuracy of queries constructed by our model on the challenging Spider dataset is comparable with the state-of-the-art text-to-SQL methods trained with annotated SQL queries. Our code and data are publicly available. © 2021 Association for Computational Linguistics",Final,
Wang K.; Liu Y.; Lin D.; Sheng Q.Z.,"Wang, Kai (57198953952); Liu, Yu (58611028900); Lin, Dan (57192194176); Sheng, Quan Z. (57208669610)",57198953952; 58611028900; 57192194176; 57208669610,Hyperbolic Geometry is Not Necessary: Lightweight Euclidean-Based Models for Low-Dimensional Knowledge Graph Embeddings,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129160133&partnerID=40&md5=2eefce6461c4df30394431e51d658f81,"Recent knowledge graph embedding (KGE) models based on hyperbolic geometry have shown great potential in a low-dimensional embedding space. However, the necessity of hyperbolic space in KGE is still questionable, because the calculation based on hyperbolic geometry is much more complicated than Euclidean operations. In this paper, based on the state-of-the-art hyperbolic-based model RotH, we develop two lightweight Euclideanbased models, called RotL and Rot2L. The RotL model simplifies the hyperbolic operations while keeping the flexible normalization effect. Utilizing a novel two-layer stacked transformation and based on RotL, the Rot2L model obtains an improved representation capability, yet costs fewer parameters and calculations than RotH. The experiments on link prediction show that Rot2L achieves the stateof-the-art performance on two widely-used datasets in low-dimensional knowledge graph embeddings. Furthermore, RotL achieves similar performance as RotH but only requires half of the training time.  © 2021 Association for Computational Linguistics.",Final,
Jin C.; Cui R.; Zhao Y.,"Jin, Cheng (57346194900); Cui, Rongyi (7006666334); Zhao, Yahui (36835985500)",57346194900; 7006666334; 36835985500,Research on Chinese-Korean Entity Alignment Method Combining TransH and GAT,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119434099&doi=10.1007%2f978-981-16-6471-7_10&partnerID=40&md5=d92f6b09239d2c9fd43656d20c5cb0bd,"Cross-language entity alignment is one of the important techniques for carrying out linguistic research and constructing a multilingual knowledge graph. At present, there is a lack of research content for Chinese and Korean bilingualism in the field of knowledge graphs. At the same time, mainstream entity alignment methods are susceptible to the impact of data set size and graph structure heterogeneity. This paper proposes a cross-language entity alignment model that combines GAT and TransH, which can alleviate the negative impact of the model on the number of data sets and the heterogeneous graph structure. Firstly, this article uses crawlers to collect and sort out a high-quality Chinese-Korean aligned bilingual data set for training the alignment model; secondly, using the model proposed in this article, through learning the structure and relationship characteristics of the bilingual knowledge graph, automatically discover the existence of cross-language entities with the same semantics. Experiments show that this method has a high accuracy rate. When tested on the Chinese-Korean alignment data set, Hits@1, Hits@5 and Hits@10 reached 49.62%, 80.89% and 91.76%, respectively. © 2021, Springer Nature Singapore Pte Ltd.",Final,
Wu J.; Zhou H.,"Wu, Junjie (57222270369); Zhou, Hao (56898234800)",57222270369; 56898234800,Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123735934&partnerID=40&md5=5cbc3e9949d8ad57d580d8ef9f2f9eb9,"Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat. To address this problem, we propose a dynamic knowledge graph-based topical conversation model (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human’s ability to form logical relationships between known and unknown topics during a conversation. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation. To the best of our knowledge, this is the first attempt to dynamically form knowledge graphs between chatting topics to assist dialog topic management during a conversation. Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines. © 2021 Association for Computational Linguistics.",Final,
Liu R.; Lin Z.; Tan Y.; Wang W.,"Liu, Rui (57216694134); Lin, Zheng (54581207500); Tan, Yutong (57437214100); Wang, Weiping (57272010000)",57216694134; 54581207500; 57437214100; 57272010000,Enhancing Zero-shot and Few-shot Stance Detection with Commonsense Knowledge Graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123926444&partnerID=40&md5=355f436705a7fb3630d8b20b85616584,"In this paper, we consider a realistic scenario on stance detection with more application potential, i.e., zero-shot and few-shot stance detection, which identifies stances for a wide range of topics with no or very few training examples. Conventional data-driven approaches are not applicable to the above zero-shot and few-shot scenarios. For human beings, commonsense knowledge is a crucial element of understanding and reasoning. In the absence of annotated data and cryptic expression of users' stance, we believe that introducing commonsense relational knowledge as support for reasoning can further improve the generalization and reasoning ability of the model in the zero-shot and few-shot scenarios. Specifically, we introduce a commonsense knowledge enhanced model to exploit both the structural-level and semantic-level information of the relational knowledge. Extensive experiments demonstrate that our model outperforms the state-of-the-art methods on zero-shot and few-shot stance detection task. © 2021 Association for Computational Linguistics",Final,
,,,"Deep Learning Inside Out: 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, DeeLIO 2021 - Proceedings, co-located with the Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL-HLT 2021",-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123695556&partnerID=40&md5=6217a12b1232d2946bb43e505b691ccb,The proceedings contain 14 papers. The topics discussed include: transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors; reconstructing implicit knowledge with language models; investigating the effect of background knowledge on natural questions; augmenting topic aware knowledge-grounded conversations with dynamic built knowledge graphs; what makes my model perplexed? a linguistic investigation on neural language models perplexity; how do BERT embeddings organize linguistic knowledge?; enhancing multiple-choice question answering with causal knowledge; and low anisotropy sense retrofitting (LASeR) : towards isotropic and sense enriched representations.,Final,
Montella S.; Rojas-Barahona L.; Heinecke J.,"Montella, Sebastien (57221631074); Rojas-Barahona, Lina (26653813700); Heinecke, Johannes (34570373300)",57221631074; 26653813700; 34570373300,Hyperbolic Temporal Knowledge Graph Embeddings with Relational and Time Curvatures,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123927493&partnerID=40&md5=756b52ebc319ca5b3d96d22fb059c65b,"Knowledge Graph (KG) completion has been excessively studied with a massive number of models proposed for the Link Prediction (LP) task. The main limitation of such models is their insensitivity to time. Indeed, the temporal aspect of stored facts is often ignored. To this end, more and more works consider time as a parameter to complete KGs. In this paper, we first demonstrate that, by simply increasing the number of negative samples, the recent ATTH model can achieve competitive or even better performance than the state-of-the-art on Temporal KGs (TKGs), albeit its nontemporality. We further propose HERCULES, a time-aware extension of ATTH model, which defines the curvature of a Riemannian manifold as the product of both relation and time. Our experiments show that both HERCULES and ATTH achieve competitive or new state-of-the-art performances on ICEWS04 and ICEWS05-15 datasets. Therefore, one should raise awareness when learning TKGs representations to identify whether time truly boosts performances. © 2021 Association for Computational Linguistics",Final,
Risch J.; Hager P.; Krestel R.,"Risch, Julian (57015160900); Hager, Philipp (57879750900); Krestel, Ralf (23008868200)",57015160900; 57879750900; 23008868200,Multifaceted Domain-Specific Document Embeddings,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128691240&partnerID=40&md5=852372653def73339ded0a1d9abc51bf,"Current document embeddings require large training corpora but fail to learn high-quality representations when confronted with a small number of domain-specific documents and rare terms. Further, they transform each document into a single embedding vector, making it hard to capture different notions of document similarity or explain why two documents are considered similar. In this work, we propose our Faceted Domain Encoder, a novel approach to learn multifaceted embeddings for domain-specific documents. It is based on a Siamese neural network architecture and leverages knowledge graphs to further enhance the embeddings even if only a few training samples are available. The model identifies different types of domain knowledge and encodes them into separate dimensions of the embedding, thereby enabling multiple ways of finding and comparing related documents in the vector space. We evaluate our approach on two benchmark datasets and find that it achieves the same embedding quality as state-of-the-art models while requiring only a tiny fraction of their training data. © 2021 Association for Computational Linguistics.",Final,
Xu J.; Zhang J.; Ke X.; Dong Y.; Chen H.; Li C.; Liu Y.,"Xu, Jingwen (57657657900); Zhang, Jing (57216205138); Ke, Xirui (57221159407); Dong, Yuxiao (49963255100); Chen, Hong (56154659700); Li, Cuiping (55696006300); Liu, Yongbin (56496782000)",57657657900; 57216205138; 57221159407; 49963255100; 56154659700; 55696006300; 56496782000,P-INT: A Path-based Interaction Model for Few-shot Knowledge Graph Completion,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127031845&partnerID=40&md5=b9c312ecdb4b2ec77160884d6c10bf0a,"Few-shot knowledge graph completion is to infer the unknown facts (i.e., query head-tail entity pairs) of a given relation with only a few observed reference entity pairs. Its general process is to first encode the implicit relation of an entity pair and then match the relation of a query entity pair with the relations of the reference entity pairs. Most existing methods have thus far encoded an entity pair and matched entity pairs by using the direct neighbors of concerned entities. In this paper, we propose the P-INT model for effective few-shot knowledge graph completion. First, P-INT infers and leverages the paths that can expressively encode the relation of two entities. Second, to capture the fine grained matches, P-INT calculates the interactions of paths instead of mixing them for each entity pair. Extensive experimental results demonstrate that P-INT outperforms the state-of-the-art baselines by 11.2- 14.2% in terms of Hits@1. Our codes and datasets are online now1.  © 2021 Association for Computational Linguistics.",Final,
Dziri N.; Madotto A.; Zaiane O.; Bose A.J.,"Dziri, Nouha (57216440679); Madotto, Andrea (57163980500); Zaiane, Osmar (6602849837); Bose, Avishek Joey (57209182963)",57216440679; 57163980500; 6602849837; 57209182963,Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127106950&partnerID=40&md5=5e49171e88fccec81243103cf5a10b9f,"Dialogue systems powered by large pre-trained language models exhibit an innate ability to deliver fluent and natural-sounding responses. Despite their impressive performance, these models are fitful and can often generate factually incorrect statements impeding their widespread adoption. In this paper, we focus on the task of improving faithfulness and reducing hallucination of neural dialogue systems to known facts supplied by a Knowledge Graph (KG). We propose NEURAL PATH HUNTER which follows a generate-then-refine strategy whereby a generated response is amended using the KG. NEURAL PATH HUNTER leverages a separate token-level fact critic to identify plausible sources of hallucination followed by a refinement stage that retrieves correct entities by crafting a query signal that is propagated over a k-hop subgraph. We empirically validate our proposed approach on the OpenDialKG dataset (Moon et al., 2019) against a suite of metrics and report a relative improvement of faithfulness over dialogue responses by 20.35% based on FeQA (Durmus et al., 2020). The code is available at https://github.com/nouhadziri/Neural-Path-Hunter. © 2021 Association for Computational Linguistics",Final,
Xu C.; Su F.; Lehmann J.,"Xu, Chengjin (57195741972); Su, Fenglong (57452650700); Lehmann, Jens (35229806900)",57195741972; 57452650700; 35229806900,Time-aware Graph Neural Networks for Entity Alignment between Temporal Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127405108&partnerID=40&md5=8e5b283aa835bb8e8430843cde5817c2,"Entity alignment aims to identify equivalent entity pairs between different knowledge graphs (KGs). Recently, the availability of temporal KGs (TKGs) that contain time information created the need for reasoning over time in such TKGs. Existing embedding-based entity alignment approaches disregard time information that commonly exists in many large-scale KGs, leaving much room for improvement. In this paper, we focus on the task of aligning entity pairs between TKGs and propose a novel Time-aware Entity Alignment approach based on Graph Neural Networks (TEA-GNN). We embed entities, relations and timestamps of different KGs into a vector space and use GNNs to learn entity representations. To incorporate both relation and time information into the GNN structure of our model, we use a time-aware attention mechanism which assigns different weights to different nodes with orthogonal transformation matrices computed from embeddings of the relevant relations and timestamps in a neighborhood. Experimental results on multiple real-world TKG datasets show that our method significantly outperforms the state-of-the-art methods due to the inclusion of time information. © 2021 Association for Computational Linguistics",Final,
Lin Y.; Wang H.; Chen J.; Wang T.; Liu Y.; Ji H.; Liu Y.; Natarajan P.,"Lin, Ying (57196123106); Wang, Han (58608180500); Chen, Jiangning (57223735496); Wang, Tong (57221095004); Liu, Yue (57204189368); Ji, Heng (35240121900); Liu, Yang (57218455754); Natarajan, Premkumar (8601591400)",57196123106; 58608180500; 57223735496; 57221095004; 57204189368; 35240121900; 57218455754; 8601591400,Personalized Entity Resolution with Dynamic Heterogeneous Knowledge Graph Representations,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123285573&partnerID=40&md5=c6bbfd1d9444dac0d275a47df359fd9f,"The growing popularity of Virtual Assistants poses new challenges for Entity Resolution, the task of linking mentions in text to their referent entities in a knowledge base. Specifically, in the shopping domain, customers tend to mention the entities implicitly (e.g., “organic milk”) rather than use the entity names explicitly, leading to a large number of candidate products. Meanwhile, for the same query, different customers may expect different results. For example, with “add milk to my cart”, a customer may refer to a certain product from his/her favorite brand, while some customers may want to re-order products they regularly purchase. Moreover, new customers may lack persistent shopping history, which requires us to enrich the connections between customers through products and their attributes. To address these issues, we propose a new framework that leverages personalized features to improve the accuracy of product ranking. We first build a cross-source heterogeneous knowledge graph from customer purchase history and product knowledge graph to jointly learn customer and product embeddings. After that, we incorporate product, customer, and history representations into a neural reranking model to predict which candidate is most likely to be purchased by a specific customer. Experiment results show that our model substantially improves the accuracy of the top ranked candidates by 24.6% compared to the state-of-the-art product search model. © 2021 Association for Computational Linguistics",Final,
Nayyeri M.; Xu C.; Hoffmann F.; Alam M.M.; Lehmann J.; Vahdati S.,"Nayyeri, Mojtaba (35776892400); Xu, Chengjin (57195741972); Hoffmann, Franca (56692241600); Alam, Mirza Mohtashim (57202902190); Lehmann, Jens (35229806900); Vahdati, Sahar (56204337200)",35776892400; 57195741972; 56692241600; 57202902190; 35229806900; 56204337200,Knowledge Graph Representation Learning using Ordinary Differential Equations,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127439653&partnerID=40&md5=b782e355c00ca3e4281a08e56570ac74,"Knowledge Graph Embeddings (KGEs) have shown promising performance on link prediction tasks by mapping the entities and relations from a knowledge graph into a geometric space. The capability of KGEs in preserving graph characteristics including structural aspects and semantics, highly depends on the design of their score function, as well as the inherited abilities from the underlying geometry. Many KGEs use the Euclidean geometry which renders them incapable of preserving complex structures and consequently causes wrong inferences by the models. To address this problem, we propose a neuro differential KGE that embeds nodes of a KG on the trajectories of Ordinary Differential Equations (ODEs). To this end, we represent each relation (edge) in a KG as a vector field on several manifolds. We specifically parameterize ODEs by a neural network to represent complex manifolds and complex vector fields on the manifolds. Therefore, the underlying embedding space is capable to assume the shape of various geometric forms to encode heterogeneous subgraphs. Experiments on synthetic and benchmark datasets using state-of-the-art KGE models justify the ODE trajectories as a means to enable structure preservation and consequently avoiding wrong inferences. © 2021 Association for Computational Linguistics",Final,
Zhang Z.; Wang H.; Zhao H.; Tong H.; Ji H.,"Zhang, Zixuan (57331625300); Wang, Hongwei (57192964118); Zhao, Han (57001574800); Tong, Hanghang (7201360533); Ji, Heng (35240121900)",57331625300; 57192964118; 57001574800; 7201360533; 35240121900,EventKE: Event-Enhanced Knowledge Graph Embedding,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129144330&partnerID=40&md5=e0bfc2cacc2d8a5373f9527a88da056f,"Relations in most of the traditional knowledge graphs (KGs) only reflect static and factual connections, but fail to represent the dynamic activities and state changes about entities. In this paper, we emphasize the importance of incorporating events in KG representation learning, and propose an event-enhanced KG embedding model EventKE. Specifically, given the original KG, we first incorporate event nodes by building a heterogeneous network, where entity nodes and event nodes are distributed on the two sides of the network interconnected by event argument links. We then use entity-entity relations from the original KG and event-event temporal links to innerconnect entity and event nodes respectively. We design a novel and effective attentionbased message passing method, which is conducted on entity-entity, event-entity, and eventevent relations to fuse the event information into KG embeddings. Experimental results on real-world datasets demonstrate that events can greatly improve the quality of the KG embeddings on multiple downstream tasks.  © 2021 Association for Computational Linguistics.",Final,
Kong L.; Winestock C.; Bhatia P.,"Kong, Luyang (57224818780); Winestock, Christopher (57207856536); Bhatia, Parminder (57209095435)",57224818780; 57207856536; 57209095435,Zero-shot Medical Entity Retrieval without Annotation: Learning From Rich Knowledge Graph Semantics,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121943938&partnerID=40&md5=0ee259b2df3185d7a61876835097282b,"Medical entity retrieval is an integral component for understanding and communicating information across various health systems. Current approaches tend to work well on specific medical domains but generalize poorly to unseen sub-specialties. This is of increasing concern under a public health crisis as new medical conditions and drug treatments come to light frequently. Zero-shot retrieval is challenging due to the high degree of ambiguity and variability in medical corpora, making it difficult to build an accurate similarity measure between mentions and concepts. Medical knowledge graphs (KG), however, contain rich semantics including large numbers of synonyms as well as its curated graphical structures. To take advantage of this valuable information, we propose a suite of learning tasks designed for training efficient zero-shot entity retrieval models. Without requiring any human annotation, our knowledge graph enriched architecture significantly outperforms common zero-shot benchmarks including BM25 and Clinical BERT with 7% to 30% higher recall across multiple major medical ontologies, such as UMLS, SNOMED and ICD-10. © 2021 Association for Computational Linguistics",Final,
Oliya A.; Saffari A.; Sen P.; Ayoola T.,"Oliya, Armin (57271974800); Saffari, Amir (23490141200); Sen, Priyanka (57219587178); Ayoola, Tom (57272114100)",57271974800; 23490141200; 57219587178; 57272114100,End-to-End Entity Resolution and Question Answering Using Differentiable Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126281582&partnerID=40&md5=1a3ccbaab395d86b4a41fbde40a4827b,"Recently, end-to-end (E2E) trained models for question answering over knowledge graphs (KGQA) have delivered promising results using only a weakly supervised dataset. However, these models are trained and evaluated in a setting where hand-annotated question entities are supplied to the model, leaving the important and non-trivial task of entity resolution (ER) outside the scope of E2E learning. In this work, we extend the boundaries of E2E learning for KGQA to include the training of an ER component. Our model only needs the question text and the answer entities to train, and delivers a stand-alone QA model that does not require an additional ER component to be supplied during runtime. Our approach is fully differentiable, thanks to its reliance on a recent method for building differentiable KGs (Cohen et al., 2020). We evaluate our E2E trained model on two public datasets and show that it comes close to baseline models that use hand-annotated entities. © 2021 Association for Computational Linguistics",Final,
Cai J.; Zhang Z.; Wu F.; Wang J.,"Cai, Jianyu (57219748598); Zhang, Zhanqiu (57213065152); Wu, Feng (7403465570); Wang, Jie (57479579700)",57219748598; 57213065152; 7403465570; 57479579700,Deep Cognitive Reasoning Network for Multi-hop Question Answering over Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123929820&partnerID=40&md5=7f59c9dd799adb64198903eefc11ab57,"Knowledge Graphs (KGs) provide human knowledge with nodes and edges being entities and relations among them, respectively. Multi-hop question answering over KGs-which aims to find answer entities of given questions through reasoning paths in KGs-has attracted great attention from both academia and industry recently. However, this task remains challenging, as it requires to accurately identify answers in a large candidate entity set, of which the size grows exponentially with the number of reasoning hops. To tackle this problem, we propose a novel Deep Cognitive Reasoning Network (DCRN), which is inspired by the dual process theory in cognitive science. Specifically, DCRN consists of two phases-the unconscious phase and the conscious phase. The unconscious phase first retrieves informative evidence from candidate entities by leveraging their semantic information. Then, the conscious phase accurately identifies answers by performing sequential reasoning according to the graph structure on the retrieved evidence. Experiments demonstrate that DCRN significantly outperforms state-of-the-art methods on benchmark datasets. © 2021 Association for Computational Linguistics",Final,
Sen P.; Saffari A.; Oliya A.,"Sen, Priyanka (57219587178); Saffari, Amir (23490141200); Oliya, Armin (57271974800)",57219587178; 23490141200; 57271974800,Expanding End-to-End Question Answering on Differentiable Knowledge Graphs with Intersection,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127457194&partnerID=40&md5=0469fd550201c420ac41608d930d42dd,"End-to-end question answering using a differentiable knowledge graph is a promising technique that requires only weak supervision, produces interpretable results, and is fully differentiable. Previous implementations of this technique (Cohen et al., 2020) have focused on single-entity questions using a relation following operation. In this paper, we propose a model that explicitly handles multiple-entity questions by implementing a new intersection operation, which identifies the shared elements between two sets of entities. We find that introducing intersection improves performance over a baseline model on two datasets, WebQuestionsSP (69.6% to 73.3% Hits@1) and ComplexWebQuestions (39.8% to 48.7% Hits@1), and in particular, improves performance on questions with multiple entities by over 14% on WebQuestionsSP and by 19% on ComplexWebQuestions. © 2021 Association for Computational Linguistics",Final,
Glass M.; Rossiello G.; Chowdhury M.F.M.; Gliozzo A.,"Glass, Michael (57210396534); Rossiello, Gaetano (57190124913); Chowdhury, Md Faisal Mahbub (55604498400); Gliozzo, Alfio (55893529800)",57210396534; 57190124913; 55604498400; 55893529800,Robust Retrieval Augmented Generation for Zero-shot Slot Filling,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121620598&partnerID=40&md5=464214c8c940d3c69f1bd25bd77d6c12,"Automatically inducing high quality knowledge graphs from a given collection of documents still remains a challenging problem in AI. One way to make headway for this problem is through advancements in a related task known as slot filling. In this task, given an entity query in form of [ENTITY, SLOT, ?], a system is asked to 'fill' the slot by generating or extracting the missing value exploiting evidence extracted from relevant passage(s) in the given document collection. The recent works in the field try to solve this task in an end-to-end fashion using retrieval-based language models. In this paper, we present a novel approach to zero-shot slot filling that extends dense passage retrieval with hard negatives and robust training procedures for retrieval augmented generation models. Our model reports large improvements on both T-REx and zsRE slot filling datasets, improving both passage retrieval and slot value generation, and ranking at the top-1 position in the KILT leaderboard. Moreover, we demonstrate the robustness of our system showing its domain adaptation capability on a new variant of the TACRED dataset for slot filling, through a combination of zero/few-shot learning. We release the source code and pre-trained models. © 2021 Association for Computational Linguistics",Final,
Xiao J.; Wang L.; Dernoncourt F.; Bui T.; Sun T.; Han J.,"Xiao, Jinfeng (57193614861); Wang, Lidan (57214446961); Dernoncourt, Franck (55827671700); Bui, Trung (57189374262); Sun, Tong (57219699023); Han, Jiawei (24325399900)",57193614861; 57214446961; 55827671700; 57189374262; 57219699023; 24325399900,Open-Domain Question Answering with Pre-Constructed Question Spaces,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119701896&partnerID=40&md5=0e80f451f5879cf0575b0a1af1b62eac,"Open-domain question answering aims at locating the answers to user-generated questions in massive collections of documents. Retriever-readers and knowledge graph approaches are two big families of solutions to this task. A retriever-reader first applies information retrieval techniques to locate a few passages that are likely to be relevant, and then feeds the retrieved text to a neural network reader to extract the answer. Alternatively, knowledge graphs can be constructed and queried to answer users’ questions. We propose an algorithm with a novel reader-retriever design that differs from both families. Our reader-retriever first uses an offline reader to read the corpus and generate collections of all answerable questions associated with their answers, and then uses an online retriever to respond to user queries by searching the pre-constructed question spaces for answers that are most likely to be asked in the given way. We further combine one retriever-reader and two reader-retrievers into a hybrid model called R6 for the best performance. Experiments with large-scale public datasets show that R6 achieves state-of-the-art accuracy. © 2021 Association for Computational Linguistics.",Final,
Liu T.; Fang Q.; Ding W.; Li H.; Wu Z.; Liu Z.,"Liu, Tianqiao (57209222567); Fang, Qiang (57220666759); Ding, Wenbiao (57207458619); Li, Hang (57209638434); Wu, Zhongqin (57221862355); Liu, Zitao (56101750800)",57209222567; 57220666759; 57207458619; 57209638434; 57221862355; 56101750800,Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127435789&partnerID=40&md5=6b1e42ce8a009baf31a60b2fddaf091a,"There is an increasing interest in the use of mathematical word problem (MWP) generation in educational assessment. Different from standard natural question generation, MWP generation needs to maintain the underlying mathematical operations between quantities and variables, while at the same time ensuring the relevance between the output and the given topic. To address above problem, we develop an end-to-end neural model to generate diverse MWPs in real-world scenarios from commonsense knowledge graph and equations. The proposed model (1) learns both representations from edge-enhanced Levi graphs of symbolic equations and commonsense knowledge; (2) automatically fuses equation and commonsense knowledge information via a self-planning module when generating the MWPs. Experiments on an educational gold-standard set and a large-scale generated MWP set show that our approach is superior on the MWP generation task, and it outperforms the SOTA models in terms of both automatic evaluation metrics, i.e., BLEU-4, ROUGE-L, Self-BLEU, and human evaluation metrics, i.e., equation relevance, topic relevance, and language coherence. To encourage reproducible results, we make our code and MWP dataset public available at https://github.com/tal-ai/MaKE_EMNLP2021. © 2021 Association for Computational Linguistics",Final,
Zhou D.; Xiang Y.; Zhang L.; Ye C.; Zhang Q.-W.; Cao Y.,"Zhou, Deyu (36989177000); Xiang, Yanzheng (57657994000); Zhang, Linhai (57210853648); Ye, Chenchen (57219742086); Zhang, Qian-Wen (57205549636); Cao, Yunbo (22033688400)",36989177000; 57657994000; 57210853648; 57219742086; 57205549636; 22033688400,A Divide-And-Conquer Approach for Multi-label Multi-hop Relation Detection in Knowledge Base Question Answering,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129154826&partnerID=40&md5=e293ccf2b670971d7988f62296c47db7,"Relation detection in knowledge base question answering, aims to identify the path(s) of relations starting from the topic entity node that is linked to the answer node in knowledge graph. Such path might consist of multiple relations, which we call multi-hop. Moreover, for a single question, there may exist multiple relation paths to the correct answer, which we call multi-label. However, most of existing approaches only detect one single path to obtain the answer without considering other correct paths, which might affect the final performance. Therefore, in this paper, we propose a novel divide-and-conquer approach for multi-label multi-hop relation detection (DCMLMH) by decomposing it into head relation detection and conditional relation path generation. In specific, a novel path sampling mechanism is proposed to generate diverse relation paths for the inference stage. A majority-vote policy is employed to detect final KB answer. Comprehensive experiments were conducted on the FreebaseQA benchmark dataset. Experimental results show that the proposed approach not only outperforms other competitive multi-label baselines, but also has superiority over some state-of-art KBQA methods.  © 2021 Association for Computational Linguistics.",Final,
Chen S.; Liu X.; Gao J.; Jiao J.; Zhang R.; Ji Y.,"Chen, Sanxing (57221150032); Liu, Xiaodong (57207781831); Gao, Jianfeng (55702627000); Jiao, Jian (36470257500); Zhang, Ruofei (7404864946); Ji, Yangfeng (56303294900)",57221150032; 57207781831; 55702627000; 36470257500; 7404864946; 56303294900,HittER: Hierarchical Transformers for Knowledge Graph Embeddings,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123505213&partnerID=40&md5=3a79dfbafb57d3724d7102f0c1eef100,"This paper examines the challenging problem of learning representations of entities and relations in a complex multi-relational knowledge graph. We propose HittER, a Hierarchical Transformer model to jointly learn Entity-relation composition and Relational contextualization based on a source entity's neighborhood. Our proposed model consists of two different Transformer blocks: the bottom block extracts features of each entity-relation pair in the local neighborhood of the source entity and the top block aggregates the relational information from outputs of the bottom block. We further design a masked entity prediction task to balance information from the relational context and the source entity itself. Experimental results show that HittER achieves new state-of-the-art results on multiple link prediction datasets. We additionally propose a simple approach to integrate HittER into BERT and demonstrate its effectiveness on two Freebase factoid question answering datasets. © 2021 Association for Computational Linguistics",Final,
Hou Z.; Jin X.; Li Z.; Bai L.,"Hou, Zhongni (57437579600); Jin, Xiaolong (16417309500); Li, Zixuan (57201739412); Bai, Long (57219876463)",57437579600; 16417309500; 57201739412; 57219876463,Rule-Aware Reinforcement Learning for Knowledge Graph Reasoning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123957688&partnerID=40&md5=647cd8f31f9f260f78652b7cb84a0a6b,"Multi-hop reasoning is an effective and explainable approach to predicting missing facts in Knowledge Graphs (KGs). It usually adopts the Reinforcement Learning (RL) framework and searches over the KG to find an evidential path. However, due to the large exploration space, the RL-based model struggles with the serious sparse reward problem and needs to make a lot of trials. Moreover, its exploration can be biased towards spurious paths that coincidentally lead to correct answers. To solve both problems, we propose a simple but effective RL-based method called RARL (Rule-Aware RL). It injects high quality symbolic rules into the model's reasoning process and employs partially random beam search, which can not only increase the probability of paths getting rewards, but also alleviate the impact of spurious paths. Experimental results show that it outperforms existing multi-hop methods in terms of Hit@1 and MRR. © 2021 Association for Computational Linguistics",Final,
Stegmüller J.; Bauer-Marquart F.; Meuschke N.; Ruas T.; Schubotz M.; Gipp B.,"Stegmüller, Johannes (57351935300); Bauer-Marquart, Fabian (57224948205); Meuschke, Norman (43461919400); Ruas, Terry (35204056800); Schubotz, Moritz (49864565600); Gipp, Bela (25928380000)",57351935300; 57224948205; 43461919400; 35204056800; 49864565600; 25928380000,Detecting Cross-Language Plagiarism using Open Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122950798&partnerID=40&md5=fb98377d549a93dbf6bc3ae032756746,"Identifying cross-language plagiarism is challenging, especially for distant language pairs and sense-for-sense translations. We introduce the new multilingual retrieval model Cross-Language Ontology-Based Similarity Analysis (CL-OSA) for this task. CL-OSA represents documents as entity vectors obtained from the open knowledge graph Wikidata. Opposed to other methods, CL-OSA does not require computationally expensive machine translation, nor pre-training using comparable or parallel corpora. It reliably disambiguates homonyms and scales to allow its application to Web-scale document collections. We show that CL-OSA outperforms state-of-the-art methods for retrieving candidate documents from five large, topically diverse test corpora that include distant language pairs like Japanese-English. For identifying cross-language plagiarism at the character level, CL-OSA primarily improves the detection of sense-for-sense translations. For these challenging cases, CL-OSA's performance in terms of the well-established PlagDet score exceeds that of the best competitor by more than factor two. The code and data of our study are openly available. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Zhang J.; Qin B.; Zhang Y.; Zhou J.; Wang H.,"Zhang, Jian (57216968887); Qin, Bo (58590156900); Zhang, Yufei (57211170611); Zhou, Junhua (57193167689); Wang, Hongwei (54785526500)",57216968887; 58590156900; 57211170611; 57193167689; 54785526500,A Framework for Effective Knowledge Extraction from A Data Space Formed by Unstructured Technical Reports using Pre-Trained Models,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128791563&doi=10.1109%2fICEBE52470.2021.00028&partnerID=40&md5=072efdefcb96b2c2cbb10c0b125644bc,"The transformation of unstructured data into triples is a key task in knowledge graph construction. It remains a great challenge to complete this task on technical reports. In this work, we propose a framework for effectively structuring data structuring in knowledge graph construction from a data space formed by technical reports. This framework specifically consist of two pre-Trained language models to provide the embed dings and a sequence labeling model to tag the entity labels. The pre-Trained models, i.e.The Flair embedding and the BERT model, are employed to combine the output vectors to downstream tasks. To evaluate the proposed method, we conduct named entity recognition experiments using the status reports of complex equipment in nuclear power plants. The evaluation shows the framework achieves remarkable improvement on F1 score. This paper details the framework, the experiments, and the evaluation of the proposed method.  © 2021 IEEE.",Final,
Pan W.; Wei W.; Mao X.-L.,"Pan, Weiran (57274527700); Wei, W. (56126506200); Mao, Xian-Ling (56949703000)",57274527700; 56126506200; 56949703000,Context-aware Entity Typing in Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129164233&partnerID=40&md5=c148a737dc8f376ccc58ed39f5f1a18f,"Knowledge graph entity typing aims to infer entities' missing types in knowledge graphs which is an important but under-explored issue. This paper proposes a novel method for this task by utilizing entities' contextual information. Specifically, we design two inference mechanisms: i) N2T: independently use each neighbor of an entity to infer its type; ii) Agg2T: aggregate the neighbors of an entity to infer its type. Those mechanisms will produce multiple inference results, and an exponentially weighted pooling method is used to generate the final inference result. Furthermore, we propose a novel loss function to alleviate the false-negative problem during training. Experiments on two real-world KGs demonstrate the effectiveness of our method. The source code and data of this paper can be obtained from https://github.com/ CCIIPLab/CET.  © 2021 Association for Computational Linguistics.",Final,
Xu Y.; Fang M.; Chen L.; Du Y.; Zhang C.,"Xu, Yunqiu (58459003600); Fang, Meng (55445603900); Chen, Ling (36676911100); Du, Yali (57196119744); Zhang, Chengqi (7405493634)",58459003600; 55445603900; 36676911100; 57196119744; 7405493634,Generalization in Text-based Games via Hierarchical Reinforcement Learning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129137686&partnerID=40&md5=9992541f81021759937f5c193d8e697f,"Deep reinforcement learning provides a promising approach for text-based games in studying natural language communication between humans and artificial agents. However, the generalization still remains a big challenge as the agents depend critically on the complexity and variety of training tasks. In this paper, we address this problem by introducing a hierarchical framework built upon the knowledge graph-based RL agent. In the high level, a meta-policy is executed to decompose the whole game into a set of subtasks specified by textual goals, and select one of them based on the KG. Then a subpolicy in the low level is executed to conduct goal-conditioned reinforcement learning. We carry out experiments on games with various difficulty levels and show that the proposed method enjoys favorable generalizability.  © 2021 Association for Computational Linguistics.",Final,
Wang Q.; Li M.; Wang X.; Parulian N.; Han G.; Ma J.; Tu J.; Lin Y.; Zhang H.; Liu W.; Chauhan A.; Guan Y.; Li B.; Li R.; Song X.; Fung Y.R.; Ji H.; Han J.; Chang S.-F.; Pustejovsky J.; Rah J.; Liem D.; Elsayed A.; Palmer M.; Voss C.; Schneider C.; Onyshkevych B.,"Wang, Qingyun (57207885167); Li, Manling (57221139513); Wang, Xuan (57203976646); Parulian, Nikolaus (57210570303); Han, Guangxing (56440740500); Ma, Jiawei (57203315503); Tu, Jingxuan (57219761092); Lin, Ying (57196123106); Zhang, Haoran (57210975604); Liu, Weili (57219635610); Chauhan, Aabhas (57219633331); Guan, Yingjun (57200615927); Li, Bangzheng (57218713400); Li, Ruisong (57219762024); Song, Xiangchen (57219766212); Fung, Yi R. (57221303250); Ji, Heng (35240121900); Han, Jiawei (24325399900); Chang, Shih-Fu (57224206893); Pustejovsky, James (6602448845); Rah, Jasmine (57219762247); Liem, David (6701787778); Elsayed, Ahmed (57224805620); Palmer, Martha (7401916649); Voss, Clare (7004570831); Schneider, Cynthia (57224818837); Onyshkevych, Boyan (57343399600)",57207885167; 57221139513; 57203976646; 57210570303; 56440740500; 57203315503; 57219761092; 57196123106; 57210975604; 57219635610; 57219633331; 57200615927; 57218713400; 57219762024; 57219766212; 57221303250; 35240121900; 24325399900; 57224206893; 6602448845; 57219762247; 6701787778; 57224805620; 7401916649; 7004570831; 57224818837; 57343399600,COVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122303251&partnerID=40&md5=b47c5ae96c919dad48dbd68c9fad458f,"To combat COVID-19, both clinicians and scientists need to digest vast amounts of relevant biomedical knowledge in scientific literature to understand the disease mechanism and related biological functions. We have developed a novel and comprehensive knowledge discovery framework, COVID-KG to extract fine-grained multimedia knowledge elements (entities and their visual chemical structures, relations and events) from scientific literature. We then exploit the constructed multimedia knowledge graphs (KGs) for question answering and report generation, using drug repurposing as a case study. Our framework also provides detailed contextual sentences, subfigures, and knowledge subgraphs as evidence. All of the data, KGs, reports, resources, and shared services are publicly available2 © 2021 Association for Computational Linguistics.",Final,
Vroe S.B.D.; Guillou L.; Stanojevíc M.; McKenna N.; Steedman M.,"Vroe, Sander Bijl De (57275414500); Guillou, Liane (57192207990); Stanojevíc, Milǒs (56577734500); McKenna, Nick (57223894172); Steedman, Mark (6602901918)",57275414500; 57192207990; 56577734500; 57223894172; 6602901918,Modality and Negation in Event Extraction,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119311913&partnerID=40&md5=7dac12446c69166987156b85a5e7d8cc,"Language provides speakers with a rich system of modality for expressing thoughts about events, without being committed to their actual occurrence. Modality is commonly used in the political news domain, where both actual and possible courses of events are discussed. NLP systems struggle with these semantic phenomena, often incorrectly extracting events which did not happen, which can lead to issues in downstream applications. We present an opendomain, lexicon-based event extraction system that captures various types of modality. This information is valuable for Question Answering, Knowledge Graph construction and Factchecking tasks, and our evaluation shows that the system is sufficiently strong to be used in downstream applications.  ©2021 Association for Computational Linguistics.",Final,
Han Z.; Zhang G.; Ma Y.; Tresp V.,"Han, Zhen (57219766233); Zhang, Gengyuan (57558748400); Ma, Yunpu (57194413081); Tresp, Volker (6603805670)",57219766233; 57558748400; 57194413081; 6603805670,Time-dependent Entity Embedding is not All You Need: A Re-evaluation of Temporal Knowledge Graph Completion Models under a Unified Framework,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125690222&partnerID=40&md5=e4780a12b44fbb04770389e362652c27,"Various temporal knowledge graph (KG) completion models have been proposed in the recent literature. The models usually contain two parts, a temporal embedding layer and a score function derived from existing static KG modeling approaches. Since the approaches differ along several dimensions, including different score functions and training strategies, the individual contributions of different temporal embedding techniques to model performance are not always clear. In this work, we systematically study six temporal embedding approaches and empirically quantify their performance across a wide range of configurations with about 4000 experiments and 19000 GPU hours. We classify the temporal embeddings into two classes: (1) timestamp embeddings and (2) time-dependent entity embeddings. Despite the common belief that the latter is more expressive, an extensive experimental study shows that timestamp embeddings can achieve on-par or even better performance with significantly fewer parameters. Moreover, we find that when trained appropriately, the relative performance differences between various temporal embeddings often shrink and sometimes even reverse when compared to prior results. For example, TTransE (Leblay and Chekol, 2018), one of the first temporal KG models, can outperform more recent architectures on ICEWS datasets. To foster further research, we provide the first unified open-source framework for temporal KG completion models with full composability, where temporal embeddings, score functions, loss functions, regularizers, and the explicit modeling of reciprocal relations can be combined arbitrarily. © 2021 Association for Computational Linguistics",Final,
Zhou J.; Wang B.; He R.; Hou Y.,"Zhou, Jinfeng (57558200300); Wang, Bo (56949454300); He, Ruifang (19835197000); Hou, Yuexian (7402198932)",57558200300; 56949454300; 19835197000; 7402198932,CRFR: Improving Conversational Recommender Systems via Flexible Fragments Reasoning on Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121719019&partnerID=40&md5=0f435bdf852ed76da968802c25240594,"Although paths of user interests shift in knowledge graphs (KGs) can benefit conversational recommender systems (CRS), explicit reasoning on KGs has not been well considered in CRS, due to the complex of high-order and incomplete paths. We propose CRFR, which effectively does explicit multi-hop reasoning on KGs with a conversational context-based reinforcement learning model. Considering the incompleteness of KGs, instead of learning single complete reasoning path, CRFR flexibly learns multiple reasoning fragments which are likely contained in the complete paths of interests shift. A fragments-aware unified model is then designed to fuse the fragments information from item-oriented and concept-oriented KGs to enhance the CRS response with entities and words from the fragments. Extensive experiments demonstrate CRFR's SOTA performance on recommendation, conversation and conversation interpretability. © 2021 Association for Computational Linguistics",Final,
Zhang Y.; Liang H.; Jatowt A.; Lei W.; Wei X.; Jiang N.; Yang Z.,"Zhang, Yao (57208656743); Liang, Hongru (57203502035); Jatowt, Adam (14826985000); Lei, Wenqiang (57667856900); Wei, Xin (57219792221); Jiang, Ning (57264662700); Yang, Zhenglu (7405435962)",57208656743; 57203502035; 14826985000; 57667856900; 57219792221; 57264662700; 7405435962,GMH: A General Multi-hop Reasoning Model for KG Completion,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127417085&partnerID=40&md5=dd9819c502398125b8dd62c48343474d,"Knowledge graphs are essential for numerous downstream natural language processing applications, but are typically incomplete with many facts missing. This results in research efforts on multi-hop reasoning task, which can be formulated as a search process and current models typically perform short distance reasoning. However, the long-distance reasoning is also vital with the ability to connect the superficially unrelated entities. To the best of our knowledge, there lacks a general framework that approaches multi-hop reasoning in mixed long-short distance reasoning scenarios. We argue that there are two key issues for a general multi-hop reasoning model: i) where to go, and ii) when to stop. Therefore, we propose a general model which resolves the issues with three modules: 1) the local-global knowledge module to estimate the possible paths, 2) the differentiated action dropout module to explore a diverse set of paths, and 3) the adaptive stopping search module to avoid over searching. The comprehensive results on three datasets demonstrate the superiority of our model with significant improvements against baselines in both short and long distance reasoning scenarios. © 2021 Association for Computational Linguistics",Final,
Wang F.; Xie Y.; Zhang K.; Xia R.; Zhang Y.,"Wang, Fang (57236806900); Xie, Yongqiang (57732473200); Zhang, Kai (57235680600); Xia, Rui (57216748606); Zhang, Yunchao (57237088500)",57236806900; 57732473200; 57235680600; 57216748606; 57237088500,Bert-based Knowledge Graph Completion Algorithm for Few-Shot,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126857542&doi=10.1109%2fBDEIM55082.2021.00051&partnerID=40&md5=4811782d840963840144c9bc90432cf5,"Knowledge graphs have shown increasing value in semantic search, intelligent Q&A, data analysis, natural language processing, visual understanding, IoT devices, etc. It is undeniable that knowledge graphs have become the mandatory path for the artificial intelligence fields development. However, the information contained in existing knowledge graphs is incomplete, which attracts a large number of researchers to enhance the completeness of knowledge graphs utilizing knowledge graph completion methods. Most traditional embedding-based knowledge graph completion models use structural information within data-rich triples from the knowledge graph is limited by the long-tail distribution of the relations in the triples. To address this problem, we propose a Bert-based knowledge graph completion algorithm for few-shot knowledge graphs, with the main goal of implementing the knowledge graph completion task with only a few sample triples of training instances. We improve the baseline model GMatching for handling few-shot knowledge graphs by introducing the Bert pre-trained linguistic representation model to enhance the semantic representation of entities and relations in the triples. Through experiments, we demonstrate that our improved model B-GMatching achieves good results.  © 2021 IEEE.",Final,
Wang J.; Li X.; Tan Z.; Zhao X.; Xiao W.,"Wang, Junxing (57645627400); Li, Xinyi (56457212300); Tan, Zhen (56318807800); Zhao, Xiang (55598203500); Xiao, Weidong (56424780600)",57645627400; 56457212300; 56318807800; 55598203500; 56424780600,Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128910567&partnerID=40&md5=369d71f7882c69d9335636733e24464c,"Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform reasoning on knowledge graphs. However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths. © 2021 Association for Computational Linguistics.",Final,
Aigo K.; Tsunakawa T.; Nishida M.; Nishimura M.,"Aigo, Kosuke (57216741206); Tsunakawa, Takashi (27267955700); Nishida, Masafumi (7403124107); Nishimura, Masafumi (7403650916)",57216741206; 27267955700; 7403124107; 7403650916,Question Generation using Knowledge Graphs with the T5 Language Model and Masked Self-Attention,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123503789&doi=10.1109%2fGCCE53005.2021.9621874&partnerID=40&md5=0ce5bc0a9ff1182c2b3f44ca8f82e504,"Question generation is helpful for understanding reading comprehension, spontaneous questioning in chatting systems, and expanding datasets for answering questions. In previous studies, many models have been used to generate questions from contexts, but none was suitable in large-length contexts. To overcome this challenge, we generated questions from an intermediate representation of a context, such as knowledge graphs. In this study, we focused on developing questions using knowledge graphs with the T5 language model. We used the language model to create questions using the knowledge graph and mask the self-attention of the encoder to train the model by explicitly preserving the graph's structure. As a result of the automatic evaluation, the T5 language model with and without mask was comparable with the bidirectional Graph2Seq model (G2S), known as the QG model, using knowledge graphs. More-over, the masked language model was slightly better than the non-masked model in t5-small on four benchmarks. The code and data are publicly available at https://github.com/Macho000/T5-for-KGQG. © 2021 IEEE.",Final,
Saebi M.; Pusateri E.; Meghawat A.; Van Gysel C.,"Saebi, Mandana (57196186064); Pusateri, Ernest (57192916890); Meghawat, Aaksha (57195941221); Van Gysel, Christophe (57140847000)",57196186064; 57192916890; 57195941221; 57140847000,A discriminative entity-aware language model for virtual assistants,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119198552&doi=10.21437%2fInterspeech.2021-1767&partnerID=40&md5=8537c1b6379ae17bd0b1b69e1d44821d,"High-quality automatic speech recognition (ASR) is essential for virtual assistants (VAs) to work well. However, ASR often performs poorly on VA requests containing named entities. In this work, we start from the observation that many ASR errors on named entities are inconsistent with real-world knowledge. We extend previous discriminative n-gram language modeling approaches to incorporate real-world knowledge from a Knowledge Graph (KG), using features that capture entity type-entity and entity-entity relationships. We apply our model through an efficient lattice rescoring process, achieving relative sentence error rate reductions of more than 25% on some synthesized test sets covering less popular entities, with minimal degradation on a uniformly sampled VA test set.  Copyright © 2021 ISCA.",Final,All Open Access; Green Open Access
Dalal D.,"Dalal, Dhairya (57371760600)",57371760600,Knowledge augmented language models for causal question answering,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121137603&partnerID=40&md5=a2b76c001813760b3b290b87017964b3,"The task of causal question answering broadly involves reasoning about causal relations and causality over a provided premise. Causal question answering can be expressed across a variety of tasks including commonsense question answering, procedural reasoning; reading comprehension, and abductive reasoning. Transformer-based pretrained language models have shown great promise across many natural language processing (NLP) applications. However, these models are reliant on distributional knowledge learned during the pretraining process and are limited in their causal reasoning capabilities. Causal knowledge, often represented as cause-effect triples in a knowledge graph, can be used to augment and improve the causal reasoning capabilities of language models. There is limited work exploring the efficacy of causal knowledge for question answering tasks. We consider the challenge of structuring causal knowledge in language models and developing a unified model that can solve a broad set of causal question answering tasks. Copyright © 2021 for this paper by its authors.",Final,
Duan H.; Yang Y.; Tam K.Y.,"Duan, Hanyu (57657972600); Yang, Yi (57204940195); Tam, Kar Yan (55667247700)",57657972600; 57204940195; 55667247700,Learning Numeracy: A Simple Yet Effective Number Embedding Approach Using Knowledge Graph,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129126025&partnerID=40&md5=58bbd84557f7b70a03cccf77e883031f,"Numeracy plays a key role in natural language understanding. However, existing NLP approaches, either traditional word2vec approach or contextualized transformer-based language models, fail to learn numeracy. As the result, the performance of these models is limited when they are applied to number-intensive applications in clinical and financial domains. In this work, we propose a simple number embedding approach based on knowledge graph. We construct a knowledge graph consisting of number entities and magnitude relations. Knowledge graph embedding method is then applied to obtain number vectors. Our approach is easy to implement, and experiment results on various numeracy-related NLP tasks demonstrate the effectiveness and efficiency of our method.  © 2021 Association for Computational Linguistics.",Final,
Cheng K.; Yang Z.; Zhang M.; Sun Y.,"Cheng, Kewei (56829905100); Yang, Ziqing (57219622094); Zhang, Ming (57853084000); Sun, Yizhou (25823970300)",56829905100; 57219622094; 57853084000; 25823970300,UniKER: A Unified Framework for Combining Embedding and Definite Horn Rule Reasoning for Knowledge Graph Inference,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124370757&partnerID=40&md5=8e72bbeffbf1daa9c042984645f46fd8,"Knowledge graph inference has been studied extensively due to its wide applications. It has been addressed by two lines of research, i.e., the more traditional logical rule reasoning and the more recent knowledge graph embedding (KGE). Several attempts have been made to combine KGE and logical rules for better knowledge graph inference. Unfortunately, they either simply treat logical rules as additional constraints into KGE loss or use probabilistic models to approximate the exact logical inference (i.e., MAX-SAT). Even worse, both approaches need to sample ground rules to tackle the scalability issue, as the total number of ground rules is intractable in practice, making them less effective in handling logical rules. In this paper, we propose a novel framework UniKER to address these challenges by restricting logical rules to be definite Horn rules, which can fully exploit the knowledge in logical rules and enable the mutual enhancement of logical rule-based reasoning and KGE in an extremely efficient way. Extensive experiments have demonstrated that our approach is superior to existing state-of-the-art algorithms in terms of both efficiency and effectiveness. © 2021 Association for Computational Linguistics",Final,
Marion P.; Nowak P.K.; Piccinno F.,"Marion, Pierre (57212679521); Nowak, Paweł Krzysztof (57217096800); Piccinno, Francesco (57501734300)",57212679521; 57217096800; 57501734300,Structured Context and High-Coverage Grammar for Conversational Question Answering over Knowledge Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127450010&partnerID=40&md5=5a5ab17531e122b7bda43f483b580f09,"We tackle the problem of weakly-supervised conversational Question Answering over large Knowledge Graphs using a neural semantic parsing approach. We introduce a new Logical Form (LF) grammar that can model a wide range of queries on the graph while remaining sufficiently simple to generate supervision data efficiently. Our Transformer-based model takes a JSON-like structure as input, allowing us to easily incorporate both Knowledge Graph and conversational contexts. This structured input is transformed to lists of embeddings and then fed to standard attention layers. We validate our approach, both in terms of grammar coverage and LF execution accuracy, on two publicly available datasets, CSQA and ConvQuestions, both grounded in Wikidata. On CSQA, our approach increases the coverage from 80% to 96.2%, and the LF execution accuracy from 70.6% to 75.6%, with respect to previous state-of-the-art results. On ConvQuestions, we achieve competitive results with respect to the state-of-the-art. © 2021 Association for Computational Linguistics",Final,
Yao H.; Wu Y.; Al-Shedivat M.; Xing E.P.,"Yao, Huaxiu (57196217415); Wu, Yingxin (57271882200); Al-Shedivat, Maruan (56114502900); Xing, Eric P. (57685890100)",57196217415; 57271882200; 56114502900; 57685890100,Knowledge-Aware Meta-learning for Low-Resource Text Classification,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127431230&partnerID=40&md5=bdb5ecb6d466f7b85b6844f469908f6d,"Meta-learning has achieved great success in leveraging the historical learned knowledge to facilitate the learning process of the new task. However, merely learning the knowledge from the historical tasks, adopted by current meta-learning algorithms, may not generalize well to testing tasks when they are not well-supported by training tasks. This paper studies a low-resource text classification problem and bridges the gap between meta-training and meta-testing tasks by leveraging the external knowledge bases. Specifically, we propose KGML to introduce additional representation for each sentence learned from the extracted sentence-specific knowledge graph. The extensive experiments on three datasets demonstrate the effectiveness of KGML under both supervised adaptation and unsupervised adaptation settings. © 2021 Association for Computational Linguistics",Final,
Zhao Y.; Zhou H.; Xie R.; Zhuang F.; Li Q.; Liu J.,"Zhao, Yu (56645105400); Zhou, Han (57381391500); Xie, Ruobing (57155801500); Zhuang, Fuzhen (23391452500); Li, Qing (57193025628); Liu, Ji (50561432500)",56645105400; 57381391500; 57155801500; 23391452500; 57193025628; 50561432500,Incorporating Global Information in Local Attention for Knowledge Representation Learning,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123927936&partnerID=40&md5=6532141a35e790a9771f014795d091fe,"Graph Attention Networks (GATs) have proven a promising model that takes advantage of localized attention mechanism to perform knowledge representation learning (KRL) on graph-structure data, e.g., Knowledge Graphs (KGs). While such approaches model entities' local pairwise importance, they lack the capability to model global importance relative to other entities of KGs. This causes such models to miss critical information in tasks where global information is also a significant component for the task, such as in knowledge representation learning. To address the issue, we allow the proper incorporation of global information into the GAT family of models through the use of scaled entity importance, which is calculated by an attention-based global random walk algorithm. In the context of KRL, incorporating global information boosts performance significantly. Experimental results on KG entity prediction against the state-of-the-arts sufficiently demonstrate the effectiveness of our proposed model. © 2021 Association for Computational Linguistics",Final,
Hosseini M.J.; Cohen S.B.; Johnson M.; Steedman M.,"Hosseini, Mohammad Javad (57216617622); Cohen, Shay B. (36684767400); Johnson, Mark (55574223118); Steedman, Mark (6602901918)",57216617622; 36684767400; 55574223118; 6602901918,Open-Domain Contextual Link Prediction and its Complementarity with Entailment Graphs,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128554936&partnerID=40&md5=c58f3fd5bf46bb26ffb737ceadbf398a,"An open-domain knowledge graph (KG) has entities as nodes and natural language relations as edges, and is constructed by extracting (subject, relation, object) triples from text. The task of open-domain link prediction is to infer missing relations in the KG. Previous work has used standard link prediction for the task. Since triples are extracted from text, we can ground them in the larger textual context in which they were originally found. However, standard link prediction methods only rely on the KG structure and ignore the textual context that each triple was extracted from. In this paper, we introduce the new task of opendomain contextual link prediction which has access to both the textual context and the KG structure to perform link prediction. We build a dataset for the task and propose a model for it. Our experiments show that context is crucial in predicting missing relations. We also demonstrate the utility of contextual link prediction in discovering context-independent entailments between relations, in the form of entailment graphs (EG), in which the nodes are the relations. The reverse holds too: contextindependent EGs assist in predicting relations in context.  © 2021 Association for Computational Linguistics.",Final,
Church K.; Bian Y.,"Church, Kenneth (54790587800); Bian, Yuchen (57194511886)",54790587800; 57194511886,Data Collection vs. Knowledge Graph Completion: What is Needed to Improve Coverage?,-1,,-1,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127318628&partnerID=40&md5=dab6b085abdec5984ac4e838d32bc5eb,"This survey/position paper discusses ways to improve coverage of resources such as WordNet. Rapp estimated correlations, ρ, between corpus statistics and psycholinguistic norms. ρ improves with quantity (corpus size) and quality (balance). 1M words are enough for simple estimates (unigram frequencies), but at least 100M are required for pairs of words (word associations, edges). Knowledge Graph Completion (KGC) attempts to learn missing links in WN18. Unfortunately, WN18 is flawed with information leaking from train to test. More seriously, WN18 is based on SemCor (just 200k words) and dated (collected in 1960s). KGC cannot learn anything that happened since the 1960s, or associations requiring 100M words. © 2021 Association for Computational Linguistics",Final,
Ilvovsky D.; Kirillovich A.; Galitsky B.,"Ilvovsky, Dmitry (55967196200); Kirillovich, Alexander (55994716700); Galitsky, Boris (6603420071)",55967196200; 55994716700; 6603420071,Controlling chat bot multi-document navigation with the extended discourse trees,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113148971&partnerID=40&md5=511d2abb7f948e617be6afa14c70c75c,"In this paper we learn how to manage a dialogue relying on discourse of its utterances. We define extended discourse trees, introduce means to manipulate with them, and outline scenarios of multi-document navigation to extend the abilities of the interactive information retrieval-based chat bot. We also provide evaluation results of the comparison between conventional search and chat bot enriched with the multi-document navigation. © 2020, Institute for Bulgarian Language. All rights reserved.",Final,
Lei D.; Jiang G.; Gu X.; Sun K.; Mao Y.; Ren X.,"Lei, Deren (57216694233); Jiang, Gangrong (57219761651); Gu, Xiaotao (57206880502); Sun, Kexuan (57202515513); Mao, Yuning (57207854266); Ren, Xiang (58619993600)",57216694233; 57219761651; 57206880502; 57202515513; 57207854266; 58619993600,Learning collaborative agents with rule guidance for knowledge graph reasoning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106112533&partnerID=40&md5=b525355c7827db58ae9b3ef82aa19b2c,"Walk-based models have shown their advantages in knowledge graph (KG) reasoning by achieving decent performance while providing interpretable decisions. However, the sparse reward signals offered by the KG during traversal are often insufficient to guide a sophisticated walk-based reinforcement learning (RL) model. An alternate approach is to use traditional symbolic methods (e.g., rule induction), which achieve good performance but can be hard to generalize due to the limitation of symbolic representation. In this paper, we propose RuleGuider, which leverages high-quality rules generated by symbolic-based methods to provide reward supervision for walk-based agents. Experiments on benchmark datasets show that RuleGuider improves the performance of walk-based models without losing interpretability. © 2020 Association for Computational Linguistics.",Final,
Qiao L.; Yan J.; Meng F.; Yang Z.; Zhou J.,"Qiao, Lin (57221153125); Yan, Jianhao (57219741978); Meng, Fandong (55847567500); Yang, Zhendong (57221156880); Zhou, Jie (57211746430)",57221153125; 57219741978; 55847567500; 57221156880; 57211746430,A sentiment-controllable topic-to-essay generator with topic knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108643415&partnerID=40&md5=4bba9f75387d4fc4e1315fe19d27810e,"Generating a vivid, novel, and diverse essay with only several given topic words is a challenging task of natural language generation. In previous work, there are two problems left unsolved: neglect of sentiment beneath the text and insufficient utilization of topic-related knowledge. Therefore, we propose a novel Sentiment-Controllable topic-to-essay generator with a Topic Knowledge Graph enhanced decoder, named SCTKG, which is based on the conditional variational autoencoder (CVAE) framework. We firstly inject the sentiment information into the generator for controlling sentiment for each sentence, which leads to various generated essays. Then we design a Topic Knowledge Graph enhanced decoder. Unlike existing models that use knowledge entities separately, our model treats knowledge graph as a whole and encodes more structured, connected semantic information in the graph to generate a more relevant essay. Experimental results show that our SCTKG can generate sentiment controllable essays and outperform the state-of-the-art approach in terms of topic relevance, fluency, and diversity on both automatic and human evaluation. © 2020 Association for Computational Linguistics",Final,
Zhang H.; Ro J.; Sproat R.,"Zhang, Hao (57192482935); Ro, Jae (57221321725); Sproat, Richard (55884410500)",57192482935; 57221321725; 55884410500,Semi-supervised URL Segmentation with Recurrent Neural Networks Pre-trained on Knowledge Graph Entities,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124644774&partnerID=40&md5=a84dd0e9a93af317f5e6f3a8484e151a,"Breaking domain names such as openresearch into component words open and research is important for applications like Text-to-Speech synthesis and web search. We link this problem to the classic problem of Chinese word segmentation and show the effectiveness of a tagging model based on Recurrent Neural Networks (RNNs) using characters as input. To compensate for the lack of training data, we propose a pre-training method on concatenated entity names in a large knowledge database. Pre-training improves the model by 33% and brings the sequence accuracy to 85%. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Fisher J.; Mittal A.; Palfrey D.; Christodoulopoulos C.,"Fisher, Joseph (57669877300); Mittal, Arpit (57205403729); Palfrey, Dave (57216416167); Christodoulopoulos, Christos (24490919800)",57669877300; 57205403729; 57216416167; 24490919800,Debiasing knowledge graph embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102550225&partnerID=40&md5=4187ddf9b90589ffda9d9da3db28e7d1,"It has been shown that knowledge graph embeddings encode potentially harmful social biases, such as the information that women are more likely to be nurses, and men more likely to be bankers. As graph embeddings begin to be used more widely in NLP pipelines, there is a need to develop training methods which remove such biases. Previous approaches to this problem both significantly increase the training time, by a factor of eight or more, and decrease the accuracy of the model substantially. We present a novel approach, in which all embeddings are trained to be neutral to sensitive attributes such as gender by default using an adversarial loss. We then add sensitive attributes back on in whitelisted cases. Training time only marginally increases over a baseline model, and the debiased embeddings perform almost as accurately in the triple prediction task as their non-debiased counterparts. © 2020 Association for Computational Linguistics.",Final,
Zhang Z.; Chen J.; Chen X.; Liu H.; Xiang Y.; Liu B.; Zheng Y.,"Zhang, Ziheng (57220158275); Chen, Jiaoyan (55827415100); Chen, Xi (57218347633); Liu, Hualuo (57212370128); Xiang, Yuejia (57224544026); Liu, Bo (58736968800); Zheng, Yefeng (8062522600)",57220158275; 55827415100; 57218347633; 57212370128; 57224544026; 58736968800; 8062522600,An Industry Evaluation of Embedding-based Entity Alignment,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149628227&doi=10.18653%2fv1%2f2020.coling-industry.17&partnerID=40&md5=b48e3a8de1d943218f01cffa3579cc87,"Embedding-based entity alignment has been widely investigated in recent years, but most proposed methods still rely on an ideal supervised learning setting with a large number of unbiased seed mappings for training and validation, which significantly limits their usage. In this study, we evaluate those state-of-the-art methods in an industrial context, where the impact of seed mappings with different sizes and different biases is explored. Besides the popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a new industrial benchmark that is extracted from two heterogeneous knowledge graphs (KGs) under deployment for medical applications. The experimental results enable the analysis of the advantages and disadvantages of these alignment methods and the further discussion of suitable strategies for their industrial deployment. © COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Industry Track.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Han Z.; Chen P.; Ma Y.; Tresp V.,"Han, Zhen (57219766233); Chen, Peng (57220898410); Ma, Yunpu (57194413081); Tresp, Volker (6603805670)",57219766233; 57220898410; 57194413081; 6603805670,DyERNIE: Dynamic evolution of Riemannian manifold embeddings for temporal knowledge graph completion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106631806&partnerID=40&md5=dca421e59338d889b75a6a5c1e9ed615,"There has recently been increasing interest in learning representations of temporal knowledge graphs (KGs), which record the dynamic relationships between entities over time. Temporal KGs often exhibit multiple simultaneous non-Euclidean structures, such as hierarchical and cyclic structures. However, existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the Euclidean space, which might not capture such intrinsic structures very well. To this end, we propose DyERNIE, a non-Euclidean embedding approach that learns evolving entity representations in a product of Riemannian manifolds, where the composed spaces are estimated from the sectional curvatures of underlying data. Product manifolds enable our approach to better reflect a wide variety of geometric structures on temporal KGs. Besides, to capture the evolutionary dynamics of temporal KGs, we let the entity representations evolve according to a velocity vector defined in the tangent space at each timestamp. We analyze in detail the contribution of geometric spaces to representation learning of temporal KGs and evaluate our model on temporal knowledge graph completion tasks. Extensive experiments on three real-world datasets demonstrate significantly improved performance, indicating that the dynamics of multi-relational graph data can be more properly modeled by the evolution of embeddings on Riemannian manifolds. © 2020 Association for Computational Linguistics.",Final,
Ji H.; Ke P.; Huang S.; Wei F.; Zhu X.; Huang M.,"Ji, Haozhe (57221149893); Ke, Pei (57207855637); Huang, Shaohan (57188864311); Wei, Furu (23995914700); Zhu, Xiaoyan (7406185137); Huang, Minlie (7404260571)",57221149893; 57207855637; 57188864311; 23995914700; 7406185137; 7404260571,Language generation with multi-hop reasoning on commonsense knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098817089&partnerID=40&md5=80402872e9e00ba5fec13b8a9d624528,"Despite the success of generative pre-trained language models on a series of text generation tasks, they still suffer in cases where reasoning over underlying commonsense knowledge is required during generation. Existing approaches that integrate commonsense knowledge into generative pre-trained language models simply transfer relational knowledge by post-training on individual knowledge triples while ignoring rich connections within the knowledge graph. We argue that exploiting both the structural and semantic information of the knowledge graph facilitates commonsense-aware text generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow (GRF) that enables pre-trained models with dynamic multi-hop reasoning on multi-relational paths extracted from the external commonsense knowledge graph. We empirically show that our model outperforms existing baselines on three text generation tasks that require reasoning over commonsense knowledge. We also demonstrate the effectiveness of the dynamic multi-hop reasoning module with reasoning paths inferred by the model that provide rationale to the generation. © 2020 Association for Computational Linguistics",Final,
Zhang K.; Zhao X.; Zhuang L.; Xie Q.; Zan H.,"Zhang, Kunli (55009135800); Zhao, Xu (57221238881); Zhuang, Lei (8536867400); Xie, Qi (57220203668); Zan, Hongying (23391538300)",55009135800; 57221238881; 8536867400; 57220203668; 23391538300,Konwledge-Enabled Diagnosis Assistant Based on Obstetric EMRs and Knowledge Graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123939827&partnerID=40&md5=5d0b15278887dfb3a59bf924d31809e6,"The obstetric Electronic Medical Record (EMR) contains a large amount of medical data and health information. It plays a vital role in improving the quality of the diagnosis assistant service. In this paper, we treat the diagnosis assistant as a multi-label classification task and propose a Knowledge-Enabled Diagnosis Assistant (KEDA) model for the obstetric diagnosis assistant. We utilize the numerical information in EMRs and the external knowledge from Chinese Obstetric Knowledge Graph (COKG) to enhance the text representation of EMRs. Specifically, the bidirectional maximum matching method and similarity-based approach are used to obtain the entities set contained in EMRs and linked to the COKG. The final knowledge representation is obtained by a weight-based disease prediction algorithm, and it is fused with the text representation through a linear weighting method. Experiment results show that our approach can bring about +3.53 F1 score improvements upon the strong BERT baseline in the diagnosis assistant task. © 2020 China National Conference on Computational Linguistics",Final,
Wei Z.; Su J.; Wang Y.; Tian Y.; Chang Y.,"Wei, Zhepei (57204102854); Su, Jianlin (57219790529); Wang, Yue (57212028385); Tian, Yuan (56413511300); Chang, Yi (25824668400)",57204102854; 57219790529; 57212028385; 56413511300; 25824668400,A novel cascade binary tagging framework for relational triple extraction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117945770&partnerID=40&md5=a4b72f26eb794c4cf9a7f2d133656c17,"Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CASREL) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CASREL framework already outperforms state-ofthe-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online. © 2020 Association for Computational Linguistics",Final,
Jin W.; Qu M.; Jin X.; Ren X.,"Jin, Woojeong (57193517627); Qu, Meng (57052330900); Jin, Xisen (57219495630); Ren, Xiang (58619993600)",57193517627; 57052330900; 57219495630; 58619993600,Recurrent event network: Autoregressive structure inference over temporal knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100977301&partnerID=40&md5=d41f28eb272c9aeb1caed0e55ab548fa,"Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-NET employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RE-NET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets. © 2020 Association for Computational Linguistics",Final,
Xu T.; Zhang F.,"Xu, Tiange (57222119559); Zhang, Fu (25633410200)",57222119559; 25633410200,A brief review of relation extraction based on pre-trained language models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101593411&doi=10.3233%2fFAIA200755&partnerID=40&md5=9a457194ffeda1d710e025446035ec19,"Relation extraction is to extract the semantic relation between entity pairs in text, and it is a key point in building Knowledge Graphs and information extraction. The rapid development of deep learning in recent years has resulted in rich research results in relation extraction tasks. At present, the accuracy of relation extraction tasks based on pre-trained language models such as BERT exceeds the methods based on Convolutional or Recurrent Neural Networks. This review mainly summarizes the research progress of pre-trained language models such as BERT in supervised learning and distant supervision relation extraction. In addition, the directions for future research and some comparisons and analyses are discussed in our whole survey. The survey may help readers understand and catch some key techniques about the issue, and identify some future research directions. © 2020 The authors and IOS Press.",Final,All Open Access; Hybrid Gold Open Access
He B.; Zhou D.; Xiao J.; Jiang X.; Liu Q.; Yuan N.J.; Xu T.,"He, Bin (57221014343); Zhou, Di (57219630626); Xiao, Jinghui (57219628606); Jiang, Xin (55960978700); Liu, Qun (56181387900); Yuan, Nicholas Jing (55818206900); Xu, Tong (56330270200)",57221014343; 57219630626; 57219628606; 55960978700; 56181387900; 55818206900; 56330270200,BERT-MK: Integrating graph contextualized knowledge into pre-trained language models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106741988&partnerID=40&md5=6fb832505647133fbe428aaf69cbcd20,"Complex node interactions are common in knowledge graphs (KGs), and these interactions can be considered as contextualized knowledge exists in the topological structure of KGs. Traditional knowledge representation learning (KRL) methods usually treat a single triple as a training unit, neglecting the usage of graph contextualized knowledge. To utilize these unexploited graph-level knowledge, we propose an approach to model subgraphs in a medical KG. Then, the learned knowledge is integrated with a pre-trained language model to do the knowledge generalization. Experimental results demonstrate that our model achieves the state-of-the-art performance on several medical NLP tasks, and the improvement above MedERNIE indicates that graph contextualized knowledge is beneficial. ©2020 Association for Computational Linguistics",Final,
Chen D.; Li Y.; Lei K.; Shen Y.,"Chen, Daoyuan (57200530014); Li, Yaliang (56273199400); Lei, Kai (55440390400); Shen, Ying (56763084800)",57200530014; 56273199400; 55440390400; 56763084800,Relabel the noise: Joint extraction of entities and relations via cooperative multiagents,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106558030&partnerID=40&md5=2cddc1ef3858b5806ce9ac20e798dd66,"Distant supervision based methods for entity and relation extraction have received increasing popularity due to the fact that these methods require light human annotation efforts. In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation. We propose a joint extraction approach to address this problem by re-labeling noisy instances with a group of cooperative multiagents. To handle noisy instances in a fine-grained manner, each agent in the cooperative group evaluates the instance by calculating a continuous confidence score from its own perspective; To leverage the correlations between these two extraction tasks, a confidence consensus module is designed to gather the wisdom of all agents and re-distribute the noisy training set with confidence-scored labels. Further, the confidences are used to adjust the training losses of extractors. Experimental results on two real-world datasets verify the benefits of re-labeling noisy instance, and show that the proposed model significantly outperforms the state-of-the-art entity and relation extraction methods. © 2020 Association for Computational Linguistics",Final,
Ghosal D.; Hazarika D.; Roy A.; Majumder N.; Mihalcea R.; Poria S.,"Ghosal, Deepanway (57202045793); Hazarika, Devamanyu (57200336259); Roy, Abhinaba (57194596045); Majumder, Navonil (57203239752); Mihalcea, Rada (8619220500); Poria, Soujanya (55316592700)",57202045793; 57200336259; 57194596045; 57203239752; 8619220500; 55316592700,KinGDOM: Knowledge-guided domain adaptation for sentiment analysis,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117936483&partnerID=40&md5=e53f06a71e4fc1fb818204a8cf2a84a8,"Cross-domain sentiment analysis has received significant attention in recent years, prompted by the need to combat the domain gap between different applications that make use of sentiment analysis. In this paper, we take a novel perspective on this task by exploring the role of external commonsense knowledge. We introduce a new framework, KinGDOM, which utilizes the ConceptNet knowledge graph to enrich the semantics of a document by providing both domain-specific and domain-general background concepts. These concepts are learned by training a graph convolutional autoencoder that leverages inter-domain concepts in a domain-invariant manner. Conditioning a popular domain-adversarial baseline method with these learned concepts helps improve its performance over state-of-the-art approaches, demonstrating the efficacy of our proposed framework. © 2020 Association for Computational Linguistics",Final,
Kim B.; Hong T.; Ko Y.; Seo J.,"Kim, Bosung (56125114400); Hong, Taesuk (57883640000); Ko, Youngjoong (8082612400); Seo, Jungyun (7401783816)",56125114400; 57883640000; 8082612400; 7401783816,Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110987236&partnerID=40&md5=2819503a5861357d01f49d729cc83568,"As research on utilizing human knowledge in natural language processing has attracted considerable attention in recent years, knowledge graph (KG) completion has come into the spotlight. Recently, a new knowledge graph completion method using a pre-trained language model, such as KG-BERT, was presented and showed high performance. However, its scores in ranking metrics such as Hits@k are still behind state-of-the-art models. We claim that there are two main reasons: 1) failure in sufficiently learning relational information in knowledge graphs, and 2) difficulty in picking out the correct answer from lexically similar candidates. In this paper, we propose an effective multi-task learning method to overcome the limitations of previous works. By combining relation prediction and relevance ranking tasks with our target link prediction, the proposed model can learn more relational properties in KGs and properly perform even when lexical similarity occurs. Experimental results show that we not only largely improve the ranking performances compared to KG-BERT but also achieve the state-of-the-art performances in Mean Rank and Hits@10 on the WN18RR dataset. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Moghimifar F.; Qu L.; Zhuo Y.; Baktashmotlagh M.; Haffari G.,"Moghimifar, Farhad (57188715951); Qu, Lizhen (57196124952); Zhuo, Yue (57224633389); Baktashmotlagh, Mahsa (53163146000); Haffari, Gholamreza (24338096600)",57188715951; 57196124952; 57224633389; 53163146000; 24338096600,COSMO: Conditional SEQ2SEQ-based Mixture Model for Zero-Shot Commonsense Question Answering,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105304158&partnerID=40&md5=b7076ab82594ed5047d8744148c7cb6d,"Commonsense reasoning refers to the ability of evaluating a social situation and acting accordingly. Identification of the implicit causes and effects of a social context is the driving capability which can enable machines to perform commonsense reasoning. The dynamic world of social interactions requires context-dependent on-demand systems to infer such underlying information. However, current approaches in this realm lack the ability to perform commonsense reasoning upon facing an unseen situation, mostly due to incapability of identifying a diverse range of implicit social relations. Hence they fail to estimate the correct reasoning path. In this paper, we present Conditional SEQ2SEQ-based Mixture model (COSMO), which provides us with the capabilities of dynamic and diverse content generation. We use COSMO to generate context-dependent clauses, which form a dynamic Knowledge Graph (KG) on-the-fly for commonsense reasoning. To show the adaptability of our model to context-dependant knowledge generation, we address the task of zero-shot commonsense question answering. The empirical results indicate an improvement of up to +5.2% over the state-of-the-art models. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Yu Q.; Li Z.; Sheng J.; Sun J.; Slamu W.,"Yu, Qing (57198511410); Li, Zhe (57219283979); Sheng, Jiabao (57219278229); Sun, Jing (57220041974); Slamu, Wushour (57198779487)",57198511410; 57219283979; 57219278229; 57220041974; 57198779487,YuQ: A Chinese-Uyghur Medical-Domain Neural Machine Translation Dataset Towards Knowledge-Driven,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101493886&doi=10.1007%2f978-981-33-6162-1_4&partnerID=40&md5=1cbd17989db9fb1126b1fcce7c11384c,"Recent advances of deep learning have been successful in delivering state-of-the-art performance in medical analysis, However, deep neural networks (DNNs) require a large amount of training data with a high-quality annotation which is not available or expensive in the field of the medical domain. The research of medical domain neural machine translation (NMT) is largely limited due to the lack of parallel sentences that consist of medical domain background knowledge annotations. To this end, we propose a Chinese-Uyghur NMT knowledge-driven dataset, YuQ, which refers to a ground medical domain knowledge graphs. Our corpus 65K parallel sentences from the medical domain 130K utterances. By introduce medical domain glossary knowledge to the training model, we can win the challenge of low translation accuracy in Chinese-Uyghur machine translation professional terms. We provide several benchmark models. Ablation study results show that the models can be enhanced by introducing domain knowledge. © 2020, Springer Nature Singapore Pte Ltd.",Final,
Han J.; Cheng B.; Wang X.,"Han, Jiale (57219554169); Cheng, Bo (35239463100); Wang, Xu (57219556125)",57219554169; 35239463100; 57219556125,Open domain question answering based on text enhanced knowledge graph with hyperedge infusion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103277164&partnerID=40&md5=886b09d592842d3691336ab2d1cbd5fc,"The incompleteness of knowledge base (KB) is a vital factor limiting the performance of question answering (QA). This paper proposes a novel QA method by leveraging text information to enhance the incomplete KB. The model enriches the entity representation through semantic information contained in the text, and employs graph convolutional networks to update the entity status. Furthermore, to exploit the latent structural information of text, we treat the text as hyperedges connecting entities among it to complement the deficient relations in KB, and hypergraph convolutional networks are further applied to reason on the hypergraph-formed text. Extensive experiments on the WebQuestionsSP benchmark with different KB settings prove the effectiveness of our model. ©2020 Association for Computational Linguistics",Final,
,,,Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118457349&partnerID=40&md5=799b1a2e1226380b0c0326dc17e5473d,"The proceedings contain 447 papers. The topics discussed include: summarizing Chinese medical answer with graph convolution networks and question-focused dual attention; stay hungry, stay focused: generating informative and specific questions in information-seeking conversations; adapting BERT for word sense disambiguation with gloss selection objective and example sentences; adversarial text generation via sequence contrast discrimination; GRACE: gradient harmonized and cascaded labeling for aspect-based sentiment analysis; reducing sentiment bias in language models via counterfactual evaluation; improving text understanding via deep syntax-semantics communication; gruen for evaluating linguistic quality of generated text; and a greedy bit-flip training algorithm for binarized knowledge graph embeddings.",Final,
Niu G.; Li B.; Zhang Y.; Pu S.; Li J.,"Niu, Guanglin (57191197891); Li, Bo (56092633500); Zhang, Yongfei (34874069700); Pu, Shiliang (56462199300); Li, Jingyang (57219635578)",57191197891; 56092633500; 34874069700; 56462199300; 57219635578,AutoETER: Automated entity type representation for knowledge graph embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116465821&partnerID=40&md5=3627a6e4d638a42346d048c8b879b93b,"Recent advances in Knowledge Graph Embedding (KGE) allow for representing entities and relations in continuous vector spaces. Some traditional KGE models leveraging additional type information can improve the representation of entities which however totally rely on the explicit types or neglect the diverse type representations specific to various relations. Besides, none of the existing methods is capable of inferring all the relation patterns of symmetry, inversion and composition as well as the complex properties of 1-N, N-1 and N-N relations, simultaneously. To explore the type information for any KG, we develop a novel KGE framework with Automated Entity TypE Representation (AutoETER), which learns the latent type embedding of each entity by regarding each relation as a translation operation between the types of two entities with a relation-aware projection mechanism. Particularly, our designed automated type representation learning mechanism is a pluggable module which can be easily incorporated with any KGE model. Besides, our approach could model and infer all the relation patterns and complex relations. Experiments on four datasets demonstrate the superior performance of our model compared to state-of-the-art baselines on link prediction tasks, and the visualization of type clustering provides clearly the explanation of type embeddings and verifies the effectiveness of our model. ©2020 Association for Computational Linguistics",Final,
Xu C.; Nayyeri M.; Alkhoury F.; Yazdi H.S.; Lehmann J.,"Xu, Chengjin (57195741972); Nayyeri, Mojtaba (35776892400); Alkhoury, Fouad (57219492895); Yazdi, Hamed Shariat (54883989600); Lehmann, Jens (35229806900)",57195741972; 35776892400; 57219492895; 54883989600; 35229806900,TeRo: A Time-aware Knowledge Graph Embedding via Temporal Rotation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128475059&partnerID=40&md5=f9b3bd15333c80d3ef07c98740c13eff,"In the last few years, there has been a surge of interest in learning representations of entities and relations in knowledge graph (KG). However, the recent availability of temporal knowledge graphs (TKGs) that contain time information for each fact created the need for reasoning over time in such TKGs. In this regard, we present a new approach of TKG embedding, TeRo, which defines the temporal evolution of entity embedding as a rotation from the initial time to the current time in the complex vector space. Specially, for facts involving time intervals, each relation is represented as a pair of dual complex embeddings to handle the beginning and the end of the relation, respectively. We show our proposed model overcomes the limitations of the existing KG embedding models and TKG embedding models and has the ability of learning and inferring various relation patterns over time. Experimental results on four different TKGs show that TeRo significantly outperforms existing state-of-the-art models for link prediction. In addition, we analyze the effect of time granularity on link prediction over TKGs, which as far as we know has not been investigated in previous literature. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Liu Z.; Cao Y.; Pan L.; Li J.; Liu Z.; Chua T.-S.,"Liu, Zhiyuan (57213431299); Cao, Yixin (57015851100); Pan, Liangming (57114093200); Li, Juanzi (8304332600); Liu, Zhiyuan (57191691341); Chua, Tat-Seng (7101702977)",57213431299; 57015851100; 57114093200; 8304332600; 57191691341; 7101702977,"Exploring and evaluating attributes, values, and structures for entity alignment",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107271702&partnerID=40&md5=479343dc44a25a4c0ff5f193446c6a02,"Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performance by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our method achieves significant improvements (5.10% on average Hits@1 in DBP15k) over 12 baselines in cross-lingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/thunlp/explore-and-evaluate. © 2020 Association for Computational Linguistics",Final,
Safavi T.; Koutra D.; Meij E.,"Safavi, Tara (57201134239); Koutra, Danai (49861458400); Meij, Edgar (23398197500)",57201134239; 49861458400; 23398197500,Evaluating the calibration of knowledge graph embeddings for trustworthy link prediction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100911448&partnerID=40&md5=d51377f1764744b256287d91f79f0a7f,"Little is known about the trustworthiness of predictions made by knowledge graph embedding (KGE) models. In this paper we take initial steps toward this direction by investigating the calibration of KGE models, or the extent to which they output confidence scores that reflect the expected correctness of predicted knowledge graph triples. We first conduct an evaluation under the standard closed-world assumption (CWA), in which predicted triples not already in the knowledge graph are considered false, and show that existing calibration techniques are effective for KGE under this common but narrow assumption. Next, we introduce the more realistic but challenging open-world assumption (OWA), in which unobserved predictions are not considered true or false until ground-truth labels are obtained. Here, we show that existing calibration techniques are much less effective under the OWA than the CWA, and provide explanations for this discrepancy. Finally, to motivate the utility of calibration for KGE from a practitioner's perspective, we conduct a unique case study of human-AI collaboration, showing that calibrated predictions can improve human performance in a knowledge graph completion task. © 2020 Association for Computational Linguistics.",Final,
Albooyeh M.; Goel R.; Kazemi S.M.,"Albooyeh, Marjan (57219525360); Goel, Rishab (57217417168); Kazemi, Seyed Mehran (56394110200)",57219525360; 57217417168; 56394110200,Out-of-sample representation learning for knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116873752&partnerID=40&md5=7b02fc990289188b65efb85e557fc38d,"Many important problems can be formulated as reasoning in knowledge graphs. Representation learning has proved extremely effective for transductive reasoning; in which one needs to make new predictions for already observed entities. This is true for both attributed graphs (where each entity has an initial feature vector) and non-attributed graphs (where the only initial information derives from known relations with other entities). For out-of-sample reasoning; where one needs to make predictions for entities that were unseen at training time, much prior work considers attributed graph. However, this problem is surprisingly under-explored for non-attributed graphs. In this paper, we study the out-of-sample representation learning problem for non-attributed knowledge graphs, create benchmark datasets for this task, develop several models and baselines, and provide empirical analyses and comparisons of the proposed models and baselines. © 2020 Association for Computational Linguistics",Final,
Elhammadi S.; Lakshmanan L.V.S.; Ng R.; Simpson M.; Huai B.; Wang Z.; Wang L.,"Elhammadi, Sarah (58133702400); Lakshmanan, Laks V.S. (57190421393); Ng, Raymond (7102153783); Simpson, Michael (56419365400); Huai, Baoxing (55959581300); Wang, Zhefeng (56285986500); Wang, Lanjun (57203399842)",58133702400; 57190421393; 7102153783; 56419365400; 55959581300; 56285986500; 57203399842,A High Precision Pipeline for Financial Knowledge Graph Construction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149618049&partnerID=40&md5=b892b836c2e0ccc11b67acb970402197,"Motivated by applications such as question answering, fact checking, and data integration, there is significant interest in constructing knowledge graphs by extracting information from unstructured information sources, particularly text documents. Knowledge graphs have emerged as a standard for structured knowledge representation, whereby entities and their inter-relations are represented and conveniently stored as (subject, predicate, object) triples in a graph that can be used to power various downstream applications. The proliferation of financial news sources reporting on companies, markets, currencies, and stocks presents an opportunity for extracting valuable knowledge about this crucial domain. In this paper, we focus on constructing a knowledge graph automatically by information extraction from a large corpus of financial news articles. For that purpose, we develop a high precision knowledge extraction pipeline tailored for the financial domain. This pipeline combines multiple information extraction techniques with a financial dictionary that we built, all working together to produce over 342,000 compact extractions from over 288,000 financial news articles, with a precision of 78% at the top-100 extractions. The extracted triples are stored in a knowledge graph making them readily available for use in downstream applications. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Chami I.; Wolf A.; Juan D.-C.; Sala F.; Ravi S.; Ré C.,"Chami, Ines (57194282386); Wolf, Adva (57219789298); Juan, Da-Cheng (17434353500); Sala, Frederic (55653075600); Ravi, Sujith (57551243700); Ré, Christopher (10739281400)",57194282386; 57219789298; 17434353500; 55653075600; 57551243700; 10739281400,Low-dimensional hyperbolic knowledge graph embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117937041&partnerID=40&md5=d0e6ff3d5d2628afd474be846f743bc3,"Knowledge graph (KG) embeddings learn low-dimensional representations of entities and relations to predict missing facts. KGs often exhibit hierarchical and logical patterns which must be preserved in the embedding space. For hierarchical data, hyperbolic embedding methods have shown promise for high-fidelity and parsimonious representations. However, existing hyperbolic embedding methods do not account for the rich logical patterns in KGs. In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns. Our approach combines hyperbolic reflections and rotations with attention to model complex relational patterns. Experimental results on standard KG benchmarks show that our method improves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in mean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that different geometric transformations capture different types of relations while attention-based transformations generalize to multiple relations. In high dimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR and 57.7% on YAGO3-10. © 2020 Association for Computational Linguistics",Final,
Zhao Y.; Zhang A.; Xie R.; Liu K.; Wang X.,"Zhao, Yu (56645105400); Zhang, Anxiang (57216039112); Xie, Ruobing (57155801500); Liu, Kang (55729555700); Wang, Xiaojie (35235644100)",56645105400; 57216039112; 57155801500; 55729555700; 35235644100,Connecting embeddings for knowledge graph entity typing,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106689565&partnerID=40&md5=430ce7fc2acb47f2b653ea5870792a56,"Knowledge graph (KG) entity typing aims at inferring possible missing entity type instances in KG, which is a very significant but still under-explored subtask of knowledge graph completion. In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs. Specifically, we present two distinct knowledge-driven effective mechanisms of entity type inference. Accordingly, we build two novel embedding models to realize the mechanisms. Afterward, a joint model with them is used to infer missing entity type instances, which favors inferences that agree with both entity type instances and triple knowledge in KGs. Experimental results on two real-world datasets (Freebase and YAGO) demonstrate the effectiveness of our proposed mechanisms and models for improving KG entity typing. The source code and data of this paper can be obtained from: https://github.com/Adam1679/ConnectE. © 2020 Association for Computational Linguistics",Final,
Wang Q.; Zeng Q.; Huang L.; Knight K.; Ji H.; Rajani N.F.,"Wang, Qingyun (57207885167); Zeng, Qi (57219741203); Huang, Lifu (57193240973); Knight, Kevin (7202745471); Ji, Heng (35240121900); Rajani, Nazneen Fatema (37075761000)",57207885167; 57219741203; 57193240973; 7202745471; 35240121900; 37075761000,ReviewRobot: Explainable Paper Review Generation based on Knowledge Synthesis,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101832027&partnerID=40&md5=01ba648138ba7c7de7fbbe85787cd123,"To assist human review process, we build a novel ReviewRobot to automatically assign a review score and write comments for multiple categories such as novelty and meaningful comparison. A good review needs to be knowledgeable, namely that the comments should be constructive and informative to help improve the paper; and explainable by providing detailed evidence. ReviewRobot achieves these goals via three steps: (1) We perform domain-specific Information Extraction to construct a knowledge graph (KG) from the target paper under review, a related work KG from the papers cited by the target paper, and a background KG from a large collection of previous papers in the domain. (2) By comparing these three KGs, we predict a review score and detailed structured knowledge as evidence for each review category. (3) We carefully select and generalize human review sentences into templates, and apply these templates to transform the review scores and evidence into natural language comments. Experimental results show that our review score predictor reaches 71.4%-100% accuracy. Human assessment by domain experts shows that 41.7%-70.5% of the comments generated by ReviewRobot are valid and constructive, and better than human-written ones for 20% of the time. Thus, ReviewRobot can serve as an assistant for paper reviewers, program chairs and authors. © 2020 Association for Computational Linguistics",Final,
Chen Y.; Sun W.,"Chen, Yufei (57258121400); Sun, Weiwei (57198849621)",57258121400; 57198849621,Parsing into variable-in-situ logico-semantic graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117921242&partnerID=40&md5=3dc9b31b21a5b2e25b1a0dc2af857d2d,"We propose variable-in-situ logico-semantic graphs to bridge the gap between semantic graph and logical form parsing. The new type of graph-based meaning representation allows us to include analysis for scope-related phenomena, such as quantification, negation and modality, in a way that is consistent with the state-of-the-art underspecification approach. Moreover, the well-formedness of such a graph is clear, since model-theoretic interpretation is available. We demonstrate the effectiveness of this new perspective by developing a new state-of-the-art semantic parser for Minimal Recursion Semantics. At the core of this parser is a novel neural graph rewriting system which combines the strengths of Hyperedge Replacement Grammar, a knowledge-intensive model, and Graph Neural Networks, a data-intensive model. Our parser achieves an accuracy of 92.39% in terms of ELEMENTARY DEPENDENCY MATCH, which is a 2.88 point improvement over the best data-driven model in the literature. The output of our parser is highly coherent: at least 91% graphs are valid, in that they allow at least one sound scope-resolved logical form. © 2020 Association for Computational Linguistics",Final,
Liu L.; Liu J.; Zhang W.; Chi Z.; Shi W.; Huang Y.,"Liu, Liting (57203548459); Liu, Jie (56336428900); Zhang, Wenzheng (57271507900); Chi, Ziming (57313267100); Shi, Wenxuan (55453922900); Huang, Yalou (35169678300)",57203548459; 56336428900; 57271507900; 57313267100; 55453922900; 35169678300,Hiring now: A skill-aware multi-attention model for job posting generation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117900446&partnerID=40&md5=562af9eb2166e67bb0ecb618e63d9a04,"Writing a good job posting is a critical step in the recruiting process, but the task is often more difficult than many people think. It is challenging to specify the level of education, experience, relevant skills per the company information and job description. To this end, we propose a novel task of Job Posting Generation (JPG) that is cast as a conditional text generation problem to generate job requirements according to the job descriptions. To deal with this task, we devise a data-driven global Skill-Aware Multi-Attention generation model, named SAMA. Specifically, to model the complex mapping relationships between input and output, we design a hierarchical decoder that we first label the job description with multiple skills, then we generate a complete text guided by the skill labels. At the same time, to exploit the prior knowledge about the skills, we further construct a skill knowledge graph to capture the global prior knowledge of skills and refine the generated results. The proposed approach is evaluated on real-world job posting data. Experimental results clearly demonstrate the effectiveness of the proposed method. © 2020 Association for Computational Linguistics",Final,
Xu W.; Zheng S.; He L.; Shao B.; Yin J.; Liu T.-Y.,"Xu, Wentao (57218551927); Zheng, Shun (57199261878); He, Liang (57693571500); Shao, Bin (57852869500); Yin, Jian (35316639800); Liu, Tie-Yan (57221068510)",57218551927; 57199261878; 57693571500; 57852869500; 35316639800; 57221068510,SEEK: Segmented embedding of knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106664738&partnerID=40&md5=5f2bd0e278bf0f1d136ce2abc59dc6e9,"In recent years, knowledge graph embedding becomes a pretty hot research topic of artificial intelligence and plays increasingly vital roles in various downstream applications, such as recommendation and question answering. However, existing methods for knowledge graph embedding can not make a proper trade-off between the model complexity and the model expressiveness, which makes them still far from satisfactory. To mitigate this problem, we propose a lightweight modeling framework that can achieve highly competitive relational expressiveness without increasing the model complexity. Our framework focuses on the design of scoring functions and highlights two critical characteristics: 1) facilitating sufficient feature interactions; 2) preserving both symmetry and antisymmetry properties of relations. It is noteworthy that owing to the general and elegant design of scoring functions, our framework can incorporate many famous existing methods as special cases. Moreover, extensive experiments on public benchmarks demonstrate the efficiency and effectiveness of our framework. Source codes and data can be found at https://github.com/Wentao-Xu/SEEK. © 2020 Association for Computational Linguistics",Final,
Shen T.; Mao Y.; He P.; Long G.; Trischler A.; Chen W.,"Shen, Tao (57210531549); Mao, Yi (57210641199); He, Pengcheng (57205508983); Long, Guodong (55522990400); Trischler, Adam (56853702700); Chen, Weizhu (23007589000)",57210531549; 57210641199; 57205508983; 55522990400; 56853702700; 23007589000,Exploiting structured knowledge in text via graph-guided representation learning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106164020&partnerID=40&md5=8e6384fcca0ff56f309431419ac32f17,"In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition, we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective that is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmarks, including question answering and knowledge base completion. © 2020 Association for Computational Linguistics.",Final,
Wang S.; Wei X.; dos Santos C.N.; Wang Z.; Nallapati R.; Arnold A.; Xiang B.; Yu P.S.,"Wang, Shen (57189844395); Wei, Xiaokai (57313794700); dos Santos, Cícero Nogueira (55665418300); Wang, Zhiguo (53664832900); Nallapati, Ramesh (6508289357); Arnold, Andrew (36160997100); Xiang, Bing (7005065960); Yu, Philip S. (7402366049)",57189844395; 57313794700; 55665418300; 53664832900; 6508289357; 36160997100; 7005065960; 7402366049,H2KGAT: Hierarchical hyperbolic knowledge graph attention network,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117970216&partnerID=40&md5=150b38d013af2ef7abfbe15b18a9a07a,"Knowledge Graphs encode rich relationships among large number of entities. Embedding entities and relations in low-dimensional space has shed light on representing knowledge graphs and reasoning over them, e.g., predicting missing relations between pairs of entities. Existing knowledge graph embedding approaches concentrate on modeling symmetry/asymmetry, inversion, and composition typed relations but overlook the hierarchical nature of relations. Recent studies have observed that there exist rich semantic hierarchical relations in knowledge graphs such as WordNet, where synsets are linked together in a hierarchy. To fill this gap, in this paper, we propose Hierarchical Hyperbolic Knowledge Graph Attention Network (H2KGAT), a novel knowledge graph embedding framework, which is able to better model and infer hierarchical relation patterns. Specifically, H2KGAT defines each entity in a hyperbolic polar embedding space. In addition, we propose an attentional neural context aggregator to enhance embedding learning, which can adaptively integrate the relational context. Our empirical study offers insights into the efficacy of modeling the semantic hierarchies in knowledge graphs, and we achieve significant performance gains compared to existing state-of-the-art methods on benchmark datasets for link prediction task, particularly at low dimensionality. © 2020 Association for Computational Linguistics",Final,
Das R.; Godbole A.; Monath N.; Zaheer M.; McCallum A.,"Das, Rajarshi (57199967575); Godbole, Ameya (57216851910); Monath, Nicholas (57195598636); Zaheer, Manzil (56898793200); McCallum, Andrew (7003773569)",57199967575; 57216851910; 57195598636; 56898793200; 7003773569,Probabilistic case-based reasoning for open-world knowledge graph completion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114908658&partnerID=40&md5=079d4207efa8e9a440664a054e031f90,"A case-based reasoning (CBR) system solves a new problem by retrieving ‘cases’ that are similar to the given problem. If such a system can achieve high accuracy, it is appealing owing to its simplicity, interpretability, and scalability. In this paper, we demonstrate that such a system is achievable for reasoning in knowledge-bases (KBs). Our approach predicts attributes for an entity by gathering reasoning paths from similar entities in the KB. Our probabilistic model estimates the likelihood that a path is effective at answering a query about the given entity. The parameters of our model can be efficiently computed using simple path statistics and require no iterative optimization. Our model is non-parametric, growing dynamically as new entities and relations are added to the KB. On several benchmark datasets our approach significantly outperforms other rule learning approaches and performs comparably to state-of-the-art embedding-based approaches. Furthermore, we demonstrate the effectiveness of our model in an “open-world” setting where new entities arrive in an online fashion, significantly outperforming state-of-the-art approaches and nearly matching the best offline method. © 2020 Association for Computational Linguistics",Final,
Zhao Z.; Papalexakis E.E.; Ma X.,"Zhao, Zhenjie (57208521157); Papalexakis, Evangelos E. (36987222700); Ma, Xiaojuan (56242668800)",57208521157; 36987222700; 56242668800,Learning physical common sense as knowledge graph completion via BERT data augmentation and constrained tucker factorization,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117826724&partnerID=40&md5=98f7f19055ae90c226441359c62c98ee,"Physical common sense plays an essential role in the cognition abilities of robots for human-robot interaction. Machine learning methods have shown promising results on physical commonsense learning in natural language processing but still suffer from model generalization. In this paper, we formulate physical commonsense learning as a knowledge graph completion problem to better use the latent relationships among training samples. Compared with completing general knowledge graphs, completing a physical commonsense knowledge graph has three unique characteristics: training data are scarce, not all facts can be mined from existing texts, and the number of relationships is small. To deal with these problems, we first use a pre-training language model BERT to augment training data, and then employ constrained tucker factorization to model complex relationships by constraining types and adding negative relationships. We compare our method with existing state-of-the-art knowledge graph embedding methods and show its superior performance. © 2020 Association for Computational Linguistics",Final,
Stewart M.; Liu W.,"Stewart, Michael (57196713433); Liu, Wei (36077178500)",57196713433; 36077178500,Seq2KG: An end-to-end neural model for domain agnostic knowledge graph (not text graph) construction from text,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104651859&partnerID=40&md5=b6bc02d172c25b1db434ecd16ac178c4,"Knowledge Graph Construction (KGC) from text unlocks information held within unstructured text and is critical to a wide range of downstream applications. General approaches to KGC from text are heavily reliant on the existence of knowledge bases, yet most domains do not even have an external knowledge base readily available. In many situations this results in information loss as a wealth of key information is held within ""non-entities"". Domain-specific approaches to KGC typically adopt unsupervised pipelines, using carefully crafted linguistic and statistical patterns to extract co-occurred noun phrases as triples, essentially constructing text graphs rather than true knowledge graphs. In this research, for the first time, in the same flavour as Collobert et al.'s seminal work of ""Natural language processing (almost) from scratch"" in 2011, we propose a Seq2KG model attempting to achieve ""Knowledge graph construction (almost) from scratch"". An end-to-end Sequence to Knowledge Graph (Seq2KG) neural model jointly learns to generate triples and resolves entity types as a multi-label classification task through deep learning neural networks. In addition, a novel evaluation metric that takes both semantic and structural closeness into account is developed for measuring the performance of triple extraction. We show that our end-toend Seq2KG model performs on par with a state of the art rule-based system which outperformed other neural models and won the first prize of the first Knowledge Graph Contest in 2019. A new annotation scheme and three high-quality manually annotated datasets are available to help promote this direction of research. © 2020 17th International Conference on Principles of Knowledge Representation and reasoning; KR 2020. All rights reserved.",Final,
Sun T.; Shao Y.; Qiu X.; Guo Q.; Hu Y.; Huang X.; Zhang Z.,"Sun, Tianxiang (57219186113); Shao, Yunfan (57216966749); Qiu, Xipeng (56291171900); Guo, Qipeng (56106079600); Hu, Yaru (57221157075); Huang, Xuanjing (8983710700); Zhang, Zheng (58847371600)",57219186113; 57216966749; 56291171900; 56106079600; 57221157075; 8983710700; 58847371600,CoLAKE: Contextualized Language and Knowledge Embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149653814&partnerID=40&md5=a7314088c8b555fb420e70853b9eef3a,"With the emerging branch of incorporating factual knowledge into pre-trained language models such as BERT, most existing models consider shallow, static, and separately pre-trained entity embeddings, which limits the performance gains of these models. Few works explore the potential of deep contextualized knowledge representation when injecting knowledge. In this paper, we propose the Contextualized Language and Knowledge Embedding (CoLAKE), which jointly learns contextualized representation for both language and knowledge with the extended MLM objective. Instead of injecting only entity embeddings, CoLAKE extracts the knowledge context of an entity from large-scale knowledge bases. To handle the heterogeneity of knowledge context and language context, we integrate them in a unified data structure, word-knowledge graph (WK graph). CoLAKE is pre-trained on large-scale WK graphs with the modified Transformer encoder. We conduct experiments on knowledge-driven tasks, knowledge probing tasks, and language understanding tasks. Experimental results show that CoLAKE outperforms previous counterparts on most of the tasks. Besides, CoLAKE achieves surprisingly high performance on our synthetic task called word-knowledge graph completion, which shows the superiority of simultaneously contextualizing language and knowledge representation. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Li J.; Wang R.; Zhang N.; Zhang W.; Yang F.; Chen H.,"Li, Juan (57203789570); Wang, Ruoxu (57215719884); Zhang, Ningyu (55923601900); Zhang, Wen (56902283700); Yang, Fan (57313119500); Chen, Huajun (35268022500)",57203789570; 57215719884; 55923601900; 56902283700; 57313119500; 35268022500,Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102118016&partnerID=40&md5=51cc3eac6552e8cfc3902daa2a124127,"Relation classification aims to extract semantic relations between entity pairs from the sentences. However, most existing methods can only identify seen relation classes that occurred during training. To recognize unseen relations at test time, we explore the problem of zero-shot relation classification. Previous work regards the problem as reading comprehension or textual entailment, which have to rely on artificial descriptive information to improve the understandability of relation types. Thus, rich semantic knowledge of the relation labels is ignored. In this paper, we propose a novel logic-guided semantic representation learning model for zero-shot relation classification. Our approach builds connections between seen and unseen relations via implicit and explicit semantic representations with knowledge graph embeddings and logic rules. Extensive experimental results demonstrate that our method can generalize to unseen relation types and achieve promising improvements. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Broscheit S.; Ruffinelli D.; Kochsiek A.; Betz P.; Gemulla R.,"Broscheit, Samuel (56039831000); Ruffinelli, Daniel (57195074131); Kochsiek, Adrian (57488409100); Betz, Patrick (57316782600); Gemulla, Rainer (9940328100)",56039831000; 57195074131; 57488409100; 57316782600; 9940328100,LibKGE A knowledge graph embedding library for reproducible research,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104158972&partnerID=40&md5=16eeaa532f4c025f519c39be711365e4,"LIBKGE1 is an open-source PyTorch-based library for training, hyperparameter optimization, and evaluation of knowledge graph embedding models for link prediction. The key goals of LIBKGE are to enable reproducible research, to provide a framework for comprehensive experimental studies, and to facilitate analyzing the contributions of individual components of training methods, model architectures, and evaluation methods. LIBKGE is highly configurable and every experiment can be fully reproduced with a single configuration file. Individual components are decoupled to the extent possible so that they can be mixed and matched with each other. Implementations in LIBKGE aim to be as efficient as possible without leaving the scope of Python/Numpy/PyTorch. A comprehensive logging mechanism and tooling facilitates indepth analysis. LIBKGE provides implementations of common knowledge graph embedding models and training methods, and new ones can be easily added. A comparative study (Ruffinelli et al., 2020) showed that LIBKGE reaches competitive to state-of-the-art performance for many models with a modest amount of automatic hyperparameter tuning. © 2020 Association for Computational Linguistics.",Final,
Saxena A.; Tripathi A.; Talukdar P.,"Saxena, Apoorv (57225711426); Tripathi, Aditay (57651497400); Talukdar, Partha (25652280700)",57225711426; 57651497400; 25652280700,Improving multi-hop question answering over knowledge graphs using knowledge base embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112819069&partnerID=40&md5=5ebdc3946534f7a845014f9dba8877e5,"Knowledge Graphs (KG) are multi-relational graphs consisting of entities as nodes and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multi-hop KGQA has attempted to handle KG sparsity using relevant external text, which isn't always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a pre-specified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA's effectiveness over other state-of-the-art baselines. © 2020 Association for Computational Linguistics",Final,
Nguyen D.Q.; Nguyen T.D.; Phung D.,"Nguyen, Dai Quoc (56283158300); Nguyen, Tu Dinh (55884481900); Phung, Dinh (7003397144)",56283158300; 55884481900; 7003397144,A relational memory-based embedding model for triple classification and search personalization,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112864870&partnerID=40&md5=f8f63e897a049666524321d72a51e1f9,"Knowledge graph embedding methods often suffer from a limitation of memorizing valid triples to predict new ones for triple classification and search personalization problems. To this end, we introduce a novel embedding model, named R-MeN, that explores a relational memory network to encode potential dependencies in relationship triples. R-MeN considers each triple as a sequence of 3 input vectors that recurrently interact with a memory using a transformer self-attention mechanism. Thus R-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector. Consequently, R-MeN feeds these 3 returned vectors to a convolutional neural network-based decoder to produce a scalar score for the triple. Experimental results show that our proposed R-MeN obtains state-of-the-art results on SEARCH17 for the search personalization task, and on WN11 and FB13 for the triple classification task. © 2020 Association for Computational Linguistics",Final,
Galkin M.; Trivedi P.; Maheshwari G.; Usbeck R.; Lehmann J.,"Galkin, Mikhail (56118894800); Trivedi, Priyansh (57196191623); Maheshwari, Gaurav (57196185548); Usbeck, Ricardo (43661711000); Lehmann, Jens (35229806900)",56118894800; 57196191623; 57196185548; 43661711000; 35229806900,Message passing for hyper-relational knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106090678&partnerID=40&md5=2c3b2bd917e330477b16ca0898fb6e99,"Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder - STARE capable of modeling such hyper-relational KGs. Unlike existing approaches, STARE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset - WD50K. Our experiments demonstrate that STARE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations. © 2020 Association for Computational Linguistics.",Final,
Huang K.-H.; Yang M.; Peng N.,"Huang, Kung-Hsiang (57221142716); Yang, Mu (57208208012); Peng, Nanyun (57204466260)",57221142716; 57208208012; 57204466260,Biomedical event extraction with hierarchical knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109732300&partnerID=40&md5=b63ec3f726a966a65e8732cea4e2f988,"Biomedical event extraction is critical in understanding biomolecular interactions described in scientific corpus. One of the main challenges is to identify nested structured events that are associated with non-indicative trigger words. We propose to incorporate domain knowledge from Unified Medical Language System (UMLS) to a pre-trained language model via a hierarchical graph representation encoded by a proposed Graph Edge-conditioned Attention Networks (GEANet). To better recognize the trigger words, each sentence is first grounded to a sentence graph based on a jointly modeled hierarchical knowledge graph from UMLS. The grounded graphs are then propagated by GEANet, a novel graph neural networks for enhanced capabilities in inferring complex events. On BioNLP 2011 GENIA Event Extraction task, our approach achieved 1.41% F1 and 3.19% F1 improvements on all events and complex events, respectively. Ablation studies confirm the importance of GEANet and hierarchical KG. ©2020 Association for Computational Linguistics",Final,
Liu Y.; Wang P.; Li Y.; Shao Y.; Xu Z.,"Liu, Yuzhang (57224457023); Wang, Peng (56182131700); Li, Yingtai (58133911300); Shao, Yizhan (57340426600); Xu, Zhongkai (57215420207)",57224457023; 56182131700; 58133911300; 57340426600; 57215420207,AprilE: Attention with Pseudo Residual Connection for Knowledge Graph Embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135079616&partnerID=40&md5=0c1c8bfeebcba8efb182e8182ef5e725,"Knowledge graph embedding maps entities and relations into low-dimensional vector space. However, it is still challenging for many existing methods to model diverse relational patterns, especially symmetric and antisymmetric relations. To address this issue, we propose a novel model, AprilE, which employs triple-level self-attention and pseudo residual connection to model relational patterns. The triple-level self-attention treats head entity, relation, and tail entity as a sequence and captures the dependency within a triple. At the same time the pseudo residual connection retains primitive semantic features. Furthermore, to deal with symmetric and antisymmetric relations, two schemas of score function are designed via a position-adaptive mechanism. Experimental results on public datasets demonstrate that our model can produce expressive knowledge embedding and significantly outperforms most of the state-of-the-art works. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Wu J.; Cao M.; Cheung J.C.K.; Hamilton W.L.,"Wu, Jiapeng (57221156951); Cao, Meng (57216696278); Cheung, Jackie Chi Kit (51664627900); Hamilton, William L. (56096744700)",57221156951; 57216696278; 51664627900; 56096744700,TeMP: Temporal message passing for temporal knowledge graph completion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103368714&partnerID=40&md5=9e2624056e48427b5943cf67a8bf6244,"Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental and challenging task. Previous works have approached this problem by augmenting methods for static knowledge graphs to leverage time-dependent representations. However, these methods do not explicitly leverage multi-hop structural information and temporal facts from recent time steps to enhance their predictions. Additionally, prior work does not explicitly address the temporal sparsity and variability of entity distributions in TKGs. We propose the Temporal Message Passing (TeMP) framework to address these challenges by combining graph neural networks, temporal dynamics models, data imputation and frequency-based gating techniques. Experiments on standard TKG tasks show that our approach provides substantial gains compared to the previous state of the art, achieving a 10.7% average relative improvement in Hits@10 across three standard benchmarks. Our analysis also reveals important sources of variability both within and across TKG datasets, and we introduce several simple but strong baselines that outperform the prior state of the art in certain settings. © 2020 Association for Computational Linguistics",Final,
Eberts M.; Pech K.; Ulges A.,"Eberts, Markus (57188726866); Pech, Kevin (58133910500); Ulges, Adrian (8231074700)",57188726866; 58133910500; 8231074700,ManyEnt: A Dataset for Few-shot Entity Typing,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108659477&partnerID=40&md5=c87bb89674b94cc47d3b00426a210a5b,"We introduce ManyEnt, a benchmark for entity typing models in few-shot scenarios. ManyEnt offers a rich typeset, with a fine-grain variant featuring 256 entity types and a coarse-grain one with 53 entity types. Both versions have been derived from the Wikidata knowledge graph in a semi-automatic fashion. We also report results for two baselines using BERT, reaching up to 70.68% accuracy (10-way 1-shot). © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Feng Y.; Chen X.; Lin B.Y.; Wang P.; Yan J.; Ren X.,"Feng, Yanlin (57216702935); Chen, Xinyue (57216695782); Lin, Bill Yuchen (57205548667); Wang, Peifeng (57219735249); Yan, Jun (57220869711); Ren, Xiang (58619993600)",57216702935; 57216695782; 57205548667; 57219735249; 57220869711; 58619993600,Scalable multi-hop relational reasoning for knowledge-aware question answering,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106108628&partnerID=40&md5=1de6dd7317d0329648c9dd14d033d6a0,"Existing work that augment question answering (QA) models with external knowledge (e.g., knowledge graphs) either struggle to model multi-hop relations efficiently, or lack transparency into the model's prediction rationale. In this paper, we propose a novel knowledge-aware approach that equips pretrained language models (PTLMs) with a multi-hop relational reasoning module, named multi-hop graph relation network (MHGRN). It performs multi-hop, multi-relational reasoning over subgraphs extracted from external knowledge graphs. The proposed reasoning module unifies path-based reasoning methods and graph neural networks and results in better interpretability and scalability. We also empirically show its effectiveness and scalability on CommonsenseQA and OpenbookQA datasets, and interpret its behaviors with case studies, with the code for experiments released. © 2020 Association for Computational Linguistics",Final,
,,,"14th Linguistic Annotation Workshop, LAW 2020 - Proceedings",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180792456&partnerID=40&md5=bca242f643417ff5ec2c8eb2dc3b07e5,"The proceedings contain 17 papers. The topics discussed include: provenance for linguistic corpora through nanopublications; a sentiment-annotated dataset of English causal connectives; a novel annotation schema for conversational humor: capturing the cultural nuances in Kanyasulkam; modeling ambiguity with many annotators and self-assessments of annotator certainty; representation problems in linguistic annotations: ambiguity, variation, uncertainty, error and bias; understanding the tradeoff between cost and quality of expert annotations for keyphrase extraction; Cookpad parsed corpus: linguistic annotations of Japanese recipes; modelling and annotating interlinear glossed text from 280 different endangered languages as linked data with LIGT; and supersense and sensibility: proxy tasks for semantic annotation of prepositions.",Final,
Guan S.; Jin X.; Guo J.; Wang Y.; Cheng X.,"Guan, Saiping (57196080482); Jin, Xiaolong (16417309500); Guo, Jiafeng (24174196100); Wang, Yuanzhuo (57195838928); Cheng, Xueqi (55855927900)",57196080482; 16417309500; 24174196100; 57195838928; 55855927900,NeuInfer: Knowledge inference on N-ary facts,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102163159&partnerID=40&md5=cbb956ce9cb444a52d94fc9d0b97c1b4,"Knowledge inference on knowledge graph has attracted extensive attention, which aims to find out connotative valid facts in knowledge graph and is very helpful for improving the performance of many downstream applications. However, researchers have mainly poured attention to knowledge inference on binary facts. The studies on n-ary facts are relatively scarcer, although they are also ubiquitous in the real world. Therefore, this paper addresses knowledge inference on n-ary facts. We represent each n-ary fact as a primary triple coupled with a set of its auxiliary descriptive attribute-value pair(s). We further propose a neural network model, NeuInfer, for knowledge inference on n-ary facts. Besides handling the common task to infer an unknown element in a whole fact, NeuInfer can cope with a new type of task, flexible knowledge inference. It aims to infer an unknown element in a partial fact consisting of the primary triple coupled with any number of its auxiliary description(s). Experimental results demonstrate the remarkable superiority of NeuInfer. © 2020 Association for Computational Linguistics",Final,
Wang Z.; Yang J.; Ye X.,"Wang, Zhichun (55211881600); Yang, Jinjian (57217636371); Ye, Xiaoju (57217635409)",55211881600; 57217636371; 57217635409,Knowledge graph alignment with entity-pair embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106570528&partnerID=40&md5=b9e50314304f1e48f7a6d0e26be29796,"Knowledge Graph (KG) alignment is to match entities in different KGs, which is important to knowledge fusion and integration. Recently, a number of embedding-based approaches for KG alignment have been proposed and achieved promising results. These approaches first embed entities in low-dimensional vector spaces, and then obtain entity alignments by computations on their vector representations. Although continuous improvements have been achieved by recent work, the performances of existing approaches are still not satisfactory. In this work, we present a new approach that directly learns embeddings of entity-pairs for KG alignment. Our approach first generates a pair-wise connectivity graph (PCG) of two KGs, whose nodes are entity-pairs and edges correspond to relation-pairs; it then learns node (entity-pair) embeddings of the PCG, which are used to predict equivalent relations of entities. To get desirable embeddings, a convolutional neural network is used to generate similarity features of entity-pairs from their attributes; and a graph neural network is employed to propagate the similarity features and get the final embeddings of entity-pairs. Experiments on five real-world datasets show that our approach can achieve the state-of-the-art KG alignment results. © 2020 Association for Computational Linguistics",Final,
Schmitt M.; Sharifzadeh S.; Tresp V.; Schütze H.,"Schmitt, Martin (57207571714); Sharifzadeh, Sahand (57216762372); Tresp, Volker (6603805670); Schütze, Hinrich (7003432991)",57207571714; 57216762372; 6603805670; 7003432991,An unsupervised joint system for text generation from knowledge graphs and semantic parsing,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100496876&partnerID=40&md5=101d4042f2154ace4ce11f4a68a0b908,"Knowledge graphs (KGs) can vary greatly from one domain to another. Therefore supervised approaches to both graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graph-text data; at the same time, adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and thus (2) does not need to rely on domain adaptation techniques to work well in different domains. To this end, we present the first approach to unsupervised text generation from KGs and show simultaneously how it can be used for unsupervised semantic parsing. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text↔graph conversion tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives. © 2020 Association for Computational Linguistics.",Final,
Vegupatti M.; Nickles M.; Chakravarthi B.R.,"Vegupatti, Mani (57216784876); Nickles, Matthias (6602772470); Chakravarthi, Bharathi Raja (57201188126)",57216784876; 6602772470; 57201188126,Simple question answering over a domain-specific knowledge graph using BERT by transfer learning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099350031&partnerID=40&md5=da37865989bb4ffe22c24e4d1378337b,"We build and evaluate a baseline for simple question answering over a domain-specific knowledge graph by using a pretrained open-domain language model BERT. Training a neural network from scratch needs a large annotated dataset whereas transfer learning adapts a pretrained language model and allows task-specific fine-tuning with limited-data. However, building a domain-specific language model needs a large amount of domain-specific text, resource, and time for pretraining. But open-domain language models such as BERT are readily available for use. Hence, we evaluate the open-domain pretrained BERT for creating a domain-specific question answering baseline model that requires less amount of training data. In this work, we built a BioMed domain simple question answering system by fine-tuning the open-domain BERT with a manually curated dataset of -600 questions from the Drugbank knowledge graph published by Bio2RDF. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Liu Y.; Zhang S.; Song R.; Feng S.; Xiao Y.,"Liu, Ye (57219824963); Zhang, Sheng (57219632653); Song, Rui (35185614100); Feng, Suo (57207965172); Xiao, Yanghua (24377046200)",57219824963; 57219632653; 35185614100; 57207965172; 24377046200,Knowledge-guided open attribute value extraction with reinforcement learning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118453193&partnerID=40&md5=784222ec90b38b7904c3cce7994ec32e,"Open attribute value extraction for emerging entities is an important but challenging task. A lot of previous works formulate the problem as a question-answering (QA) task. While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph (KG), which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning (RL) framework for open attribute value extraction. Informed by relevant knowledge in KG, we trained a deep Q-network to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 - 27.8%. © 2020 Association for Computational Linguistics.",Final,
Kim J.; Choi K.-S.,"Kim, Jiseong (35317686900); Choi, Key-Sun (7403949200)",35317686900; 7403949200,Unsupervised Fact Checking by Counter-Weighted Positive and Negative Evidential Paths in A Knowledge Graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147025685&partnerID=40&md5=d2235a28089ca6fc498beb8f4a141b2d,"Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction algorithms that extract factual statements from unstructured textual data to populate the existing knowledge graphs. Traditional fact checking by experts or crowds is increasingly difficult to keep pace with the volume of newly created misinformation in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. We view this problem as a truth scoring task in a knowledge graph. We present a novel rule-based approach that finds positive and negative evidential paths in a knowledge graph for a given factual statement, and calculates a truth score for the given statement by unsupervised ensemble of the found positive and negative evidential paths. For example, we can determine the factual statement “United States is the birth place of Barack Obama” as truthful if there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph. For another example, we can determine the factual statement “Canada is the nationality of Barack Obama” as untruthful if there is the negative evidential path (Barack Obama, nationality, United States) ∧ (United States, ≠, Canada) in a knowledge graph. For evaluating on a real-world situation, we constructed an evaluation dataset by labeling truth or untruth label on factual statements that were extracted from Wikipedia texts by using the state-of-the-art BERT-based information extraction system. Our evaluation results show that our approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two different standard datasets. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Ahrabian K.; Feizi A.; Salehi Y.; Hamilton W.L.; Bose A.J.,"Ahrabian, Kian (57204606639); Feizi, Aarash (57221141528); Salehi, Yasmin (57221147602); Hamilton, William L. (56096744700); Bose, Avishek Joey (57209182963)",57204606639; 57221141528; 57221147602; 56096744700; 57209182963,Structure aware negative sampling in knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106375639&partnerID=40&md5=33d3637913833249ca7dbdcce25b147c,"Learning low-dimensional representations for entities and relations in knowledge graphs using contrastive estimation represents a scalable and effective method for inferring connectivity patterns. A crucial aspect of contrastive learning approaches is the choice of corruption distribution that generates hard negative samples, which force the embedding model to learn discriminative representations and find critical characteristics of observed data. While earlier methods either employ too simple corruption distributions, i.e. uniform, yielding easy uninformative negatives or sophisticated adversarial distributions with challenging optimization schemes, they do not explicitly incorporate known graph structure resulting in suboptimal negatives. In this paper, we propose Structure Aware Negative Sampling (SANS), an inexpensive negative sampling strategy that utilizes the rich graph structure by selecting negative samples from a node's k-hop neighborhood. Empirically, we demonstrate that SANS finds semantically meaningful negatives and is competitive with SOTA approaches while requires no additional parameters nor difficult adversarial optimization. © 2020 Association for Computational Linguistics",Final,
Zhao Y.; Xiang L.; Zhu J.; Zhang J.; Zhou Y.; Zong C.,"Zhao, Yang (57202271643); Xiang, Lu (56181323400); Zhu, Junnan (57200415905); Zhang, Jiajun (51666026800); Zhou, Yu (57169094000); Zong, Chengqing (7005615574)",57202271643; 56181323400; 57200415905; 51666026800; 57169094000; 7005615574,Knowledge Graph Enhanced Neural Machine Translation via Multi-task Learning on Sub-entity Granularity,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109060758&partnerID=40&md5=3b7c9825e89ea81af3b2852cec52973a,"Previous studies combining knowledge graph (KG) with neural machine translation (NMT) have two problems: i) Knowledge under-utilization: they only focus on the entities that appear in both KG and training sentence pairs, making much knowledge in KG unable to be fully utilized. ii) Granularity mismatch: the current KG methods utilize the entity as the basic granularity, while NMT utilizes the sub-word as the granularity, making the KG different to be utilized in NMT. To alleviate above problems, we propose a multi-task learning method on sub-entity granularity. Specifically, we first split the entities in KG and sentence pairs into sub-entity granularity by using joint BPE. Then we utilize the multi-task learning to combine the machine translation task and knowledge reasoning task. The extensive experiments on various translation tasks have demonstrated that our method significantly outperforms the baseline models in both translation quality and handling the entities. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Lv X.; Han X.; Hou L.; Li J.; Liu Z.; Zhang W.; Zhang Y.; Kong H.; Wu S.,"Lv, Xin (57211203656); Han, Xu (57205548124); Hou, Lei (56622056400); Li, Juanzi (8304332600); Liu, Zhiyuan (57191691341); Zhang, Wei (57970839200); Zhang, Yichi (57268270800); Kong, Hao (57211751697); Wu, Suhui (57211750693)",57211203656; 57205548124; 56622056400; 8304332600; 57191691341; 57970839200; 57268270800; 57211751697; 57211750693,Dynamic anticipation and completion for multi-hop reasoning over sparse knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106093724&partnerID=40&md5=0b595c739ece8cc988490b61e324c823,"Multi-hop reasoning has been widely studied in recent years to seek an effective and interpretable method for knowledge graph (KG) completion. Most previous reasoning methods are designed for dense KGs with enough paths between entities, but cannot work well on those sparse KGs that only contain sparse paths for reasoning. On the one hand, sparse KGs contain less information, which makes it difficult for the model to choose correct paths. On the other hand, the lack of evidential paths to target entities also makes the reasoning process difficult. To solve these problems, we propose a multi-hop reasoning model named DacKGR over sparse KGs, by applying novel dynamic anticipation and completion strategies: (1) The anticipation strategy utilizes the latent prediction of embedding-based models to make our model perform more potential path search over sparse KGs. (2) Based on the anticipation information, the completion strategy dynamically adds edges as additional actions during the path search, which further alleviates the sparseness problem of KGs. The experimental results on five datasets sampled from Freebase, NELL and Wikidata show that our method outperforms state-of-the-art baselines. Our codes and datasets can be obtained from https://github.com/THU-KEG/DacKGR. © 2020 Association for Computational Linguistics",Final,
Xu C.; Nayyeri M.; Chen Y.-Y.; Lehmann J.,"Xu, Chengjin (57195741972); Nayyeri, Mojtaba (35776892400); Chen, Yung-Yu (57223092413); Lehmann, Jens (35229806900)",57195741972; 35776892400; 57223092413; 35229806900,Knowledge Graph Embeddings in Geometric Algebras,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122420556&partnerID=40&md5=d55ad1d01c060c43b162e8a58a9b9c96,"Knowledge graph (KG) embedding aims at embedding entities and relations in a KG into a low dimensional latent representation space. Existing KG embedding approaches model entities and relations in a KG by utilizing real-valued, complex-valued, or hypercomplex-valued (Quaternion or Octonion) representations, all of which are subsumed into a geometric algebra. In this work, we introduce a novel geometric algebra-based KG embedding framework, GeomE, which utilizes multivector representations and the geometric product to model entities and relations. Our framework subsumes several state-of-the-art KG embedding approaches and is advantageous with its ability of modeling various key relation patterns, including (anti-)symmetry, inversion and composition, rich expressiveness with higher degree of freedom as well as good generalization capacity. Experimental results on multiple benchmark knowledge graphs show that the proposed approach outperforms existing state-of-the-art models for link prediction. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Huang H.; Long G.; Shen T.; Jiang J.; Zhang C.,"Huang, Hao (57221155317); Long, Guodong (55522990400); Shen, Tao (57210531549); Jiang, Jing (55731807500); Zhang, Chengqi (7405493634)",57221155317; 55522990400; 57210531549; 55731807500; 7405493634,RatE: Relation-Adaptive Translating Embedding for Knowledge Graph Completion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116535588&partnerID=40&md5=67869bd04c951f59037dac1da771ea94,"Many graph embedding approaches have been proposed for knowledge graph completion via link prediction. Among those, translating embedding approaches enjoy the advantages of lightweight structure, high efficiency and great interpretability. Especially when extended to complex vector space, they show the capability in handling various relation patterns including symmetry, antisymmetry, inversion and composition. However, previous translating embedding approaches defined in complex vector space suffer from two main issues: 1) representing and modeling capacities of the model are limited by the translation function with rigorous multiplication of two complex numbers; and 2) embedding ambiguity caused by one-to-many relations is not explicitly alleviated. In this paper, we propose a relation-adaptive translation function built upon a novel weighted product in complex space, where the weights are learnable, relation-specific and independent to embedding size. The translation function only requires eight more scalar parameters each relation, but improves expressive power and alleviates embedding ambiguity problem. Based on the function, we then present our Relation-adaptive translating Embedding (RatE) approach to score each graph triple. Moreover, a novel negative sampling method is proposed to utilize both prior knowledge and self-adversarial learning for effective optimization. Experiments verify RatE achieves state-of-the-art performance on four link prediction benchmarks. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Zhang L.; Yu M.; Gao T.; Yu Y.,"Zhang, Lu (57216898783); Yu, Mo (35174012000); Gao, Tian (56462051800); Yu, Yue (55600801300)",57216898783; 35174012000; 56462051800; 55600801300,MCMH: Learning multi-chain multi-hop rules for knowledge graph reasoning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104799957&partnerID=40&md5=7e89fc0b560e554aced52752363532a0,"Multi-hop reasoning approaches over knowledge graphs infer a missing relationship between entities with a multi-hop rule, which corresponds to a chain of relationships. We extend existing works to consider a generalized form of multi-hop rules, where each rule is a set of relation chains. To learn such generalized rules efficiently, we propose a two-step approach that first selects a small set of relation chains as a rule and then evaluates the confidence of the target relationship by jointly scoring the selected chains. A game-theoretical framework is proposed to this end to simultaneously optimize the rule selection and prediction steps. Empirical results show that our multi-chain multi-hop (MCMH) rules result in superior results compared to the standard single-chain approaches, justifying both our formulation of generalized rules and the effectiveness of the proposed learning framework. © 2020 Association for Computational Linguistics",Final,
Huang L.; Wu L.; Wang L.,"Huang, Luyang (57216689008); Wu, Lingfei (56937260100); Wang, Lu (36642672900)",57216689008; 56937260100; 36642672900,Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117881390&partnerID=40&md5=2fc67c9bc84698e16717aaf96f726320,"Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encoders-a sequential document encoder and a graph-structured encoder-to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are fine-tuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors. © 2020 Association for Computational Linguistics",Final,
Gardères F.; Ziaeefard M.; Abeloos B.; Lecue F.,"Gardères, François (57321915800); Ziaeefard, Maryam (36622428200); Abeloos, Baptiste (57110456500); Lecue, Freddy (15136250600)",57321915800; 36622428200; 57110456500; 15136250600,ConceptBert: Concept-aware representation for visual question answering,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118430585&partnerID=40&md5=8fe1049edc7798b913b187323616fe35,"Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Current works in VQA focus on questions which are answerable by direct analysis of the question and image alone. We present a concept-aware algorithm, ConceptBert, for questions which require common sense, or basic factual knowledge from external structured content. Given an image and a question in natural language, ConceptBert requires visual elements of the image and a Knowledge Graph (KG) to infer the correct answer. We introduce a multi-modal representation which learns a joint Concept-Vision-Language embedding. We exploit ConceptNet KG for encoding the common sense knowledge and evaluate our methodology on the Outside Knowledge-VQA (OK-VQA) and VQA datasets. Our code is available at https://github.com/ZiaMaryam/ConceptBERT © 2020 Association for Computational Linguistics",Final,
"Logan R.L., IV; Gardner M.; Singh S.","Logan, Robert L. (57212308172); Gardner, Matt (56577280400); Singh, Sameer (58124003300)",57212308172; 56577280400; 58124003300,On importance sampling-based evaluation of latent language models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117907707&partnerID=40&md5=f50034fd5c2ecfa94124117fbdb6478c,"Language models that use additional latent structures (e.g., syntax trees, coreference chains, and knowledge graph links) provide several advantages over traditional language models. However, likelihood-based evaluation of these models is often intractable as it requires marginalizing over the latent space. Existing methods avoid this issue by using importance sampling. Although this approach has asymptotic guarantees, analysis is rarely conducted on the effect of decisions such as sample size, granularity of sample aggregation, and the proposal distribution on the reported estimates. In this paper, we measure the effect these factors have on perplexity estimates for three different latent language models. In addition, we elucidate subtle differences in how importance sampling is applied, which can have substantial effects on the final estimates, as well as provide theoretical results that reinforce the validity of importance sampling for evaluating latent language models. © 2020 Association for Computational Linguistics",Final,
Lan L.T.H.; Tuan T.M.; Ngan T.T.; Son L.H.; Giang N.L.; Ngoc V.T.N.; Hai P.V.,"Lan, Luong Thi Hong (57204976143); Tuan, Tran Manh (56967755300); Ngan, Tran Thi (57163323900); Son, Le Hoang (36601294900); Giang, Nguyen Long (55181519200); Ngoc, Vo Truong Nhu (57194606733); Hai, Pham Van (37662188200)",57204976143; 56967755300; 57163323900; 36601294900; 55181519200; 57194606733; 37662188200,A new complex fuzzy inference system with fuzzy knowledge graph and extensions in decision making,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102810607&doi=10.1109%2fACCESS.2020.3021097&partnerID=40&md5=193866b4217a6ba6bea49fa915c9976a,"Context and Background: Complex fuzzy theory has a strong practical implication in many real-world applications. Complex Fuzzy Inference System (CFIS) is a powerful technique to overcome the challenges of uncertain, periodic data. However, a question is raised for CFIS: How can we deduce and predict the result in case there is little knowledge about data information and rule base? This is significance because many real applications do not have enough knowledge of rule base for inference so that the performance of systems may be low. Thus, it is necessary to have an approximate reasoning method to represent and derive final results. Motivation: Recently, the Mamdani Complex Fuzzy Inference System (M-CFIS) has been proposed with a specific inference mechanism according to the Mamdani type. A new improvement so-called the Mamdani Complex Fuzzy Inference System with Rule Reduction (M-CFIS-R) has been designed to utilize granular computing with complex similarity measures to reduce the rule base so as to gain better performance in decision-making problems. However in M-CFIS-R, testing data are checked by matching with each rule in the rule base, which leads to a high cost of computational time. Besides, if the testing data contain records that are not inferred by the rule base, the output cannot be generated. This happens in real commerce systems in which the rule base is small at the time of creation and needs to feed with new rules. Methodology: In order to handle those issues, this article first time proposes the Fuzzy Knowledge Graph to represent the rule base in terms of linguistic labels and their relationships according to the rule set. An adjacent matrix of Fuzzy Knowledge Graph is generated for inference. When a record in the Testing dataset is given, it would be fuzzified and labelled. Each component in the record is checked with the Fuzzy Knowledge Graph by the inference mechanism in approximate reasoning called Fast Inference Search Algorithm. Then, we derive the label of the new record by the Max-Min operator. Besides, we also propose four extensions of Mamdani Complex Fuzzy Inference System Rule Reduction including Sugeno Complex Fuzzy Inference Systems, Tsukamoto Complex Fuzzy Inference Systems, Complex Fuzzy Measures and Complex Fuzzy Integrals in M-CFIS-R. Results: The experiments on the UCI Machine Learning datasets show that the proposed method classifies samples as correctly as M-CFIS-R with very lower run time (6.45 times on average). The experiments are performed through many tests via 2 main scenarios. Conclusion: The proposed system has good performance in reducing the computational time of inference with acceptable accuracy. It has ability to work with systems having limited knowledge and rule base. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Final,All Open Access; Gold Open Access
Ren F.; Li J.; Zhang H.; Liu S.; Li B.; Ming R.; Bai Y.,"Ren, Feiliang (16022889400); Li, Juchen (58133700900); Zhang, Huihui (57219389114); Liu, Shilei (57219760167); Li, Bochao (57283583100); Ming, Ruicheng (57219753502); Bai, Yujia (58133701000)",16022889400; 58133700900; 57219389114; 57219760167; 57283583100; 57219753502; 58133701000,Knowledge Graph Embedding with Atrous Convolution and Residual Learning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149675515&partnerID=40&md5=e8e3fb785047931cc1a57f4e10ba7b70,"Knowledge graph embedding is an important task and it will benefit lots of downstream applications. Currently, deep neural networks based methods achieve state-of-the-art performance. However, most of these existing methods are very complex and need much time for training and inference. To address this issue, we propose a simple but effective atrous convolution based knowledge graph embedding method. Compared with existing state-of-the-art methods, our method has following main characteristics. First, it effectively increases feature interactions by using atrous convolutions. Second, to address the original information forgotten issue and vanishing/exploding gradient issue, it uses the residual learning method. Third, it has simpler structure but much higher parameter efficiency. We evaluate our method on six benchmark datasets with different evaluation metrics. Extensive experiments show that our model is very effective. On these diverse datasets, it achieves better results than the compared state-of-the-art methods on most of evaluation metrics. The source codes of our model could be found at https://github.com/neukg/AcrE. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Lim J.; Oh D.; Jang Y.; Yang K.; Lim H.,"Lim, Jungwoo (57221322721); Oh, Dongsuk (57211283137); Jang, Yoonna (57221320495); Yang, Kisu (57219590501); Lim, Heuiseok (36028297500)",57221322721; 57211283137; 57221320495; 57219590501; 36028297500,I Know What You Asked: Graph Path Learning using AMR for Commonsense Reasoning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118300409&partnerID=40&md5=eadee729d499c80896a1b7306f37ec1a,"CommonsenseQA is a task in which a correct answer is predicted through commonsense reasoning with pre-defined knowledge. Most previous works have aimed to improve the performance with distributed representation without considering the process of predicting the answer from the semantic representation of the question. To shed light upon the semantic interpretation of the question, we propose an AMR-ConceptNet-Pruned (ACP) graph. The ACP graph is pruned from a full integrated graph encompassing Abstract Meaning Representation (AMR) graph generated from input questions and an external commonsense knowledge graph, ConceptNet (CN). Then the ACP graph is exploited to interpret the reasoning path as well as to predict the correct answer on the CommonsenseQA task. This paper presents the manner in which the commonsense reasoning process can be interpreted with the relations and concepts provided by the ACP graph. Moreover, ACP-based models are shown to outperform the baselines. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Bevilacqua M.; Navigli R.,"Bevilacqua, Michele (57212348104); Navigli, Roberto (6507102454)",57212348104; 6507102454,Breaking through the 80% glass ceiling: Raising the state of the art in word sense disambiguation by incorporating knowledge graph information,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117498076&partnerID=40&md5=b3ef95b5c9a5d18a766cc0b7b6dd4b44,"Neural architectures are the current state of the art in Word Sense Disambiguation (WSD). However, they make limited use of the vast amount of relational information encoded in Lexical Knowledge Bases (LKB). We present Enhanced WSD Integrating Synset Embeddings and Relations (EWISER), a neural supervised architecture that is able to tap into this wealth of knowledge by embedding information from the LKB graph within the neural architecture, and to exploit pretrained synset embeddings, enabling the network to predict synsets that are not in the training set. As a result, we set a new state of the art on almost all the evaluation settings considered, also breaking through, for the first time, the 80% ceiling on the concatenation of all the standard all-words English WSD evaluation benchmarks. On multilingual all-words WSD, we report state-of-the-art results by training on nothing but English. © 2020 Association for Computational Linguistics",Final,
Wang S.; Wei Z.; Fan Z.; Huang Z.; Sun W.; Zhang Q.; Huang X.,"Wang, Siyuan (57218333522); Wei, Zhongyu (51666060600); Fan, Zhihao (57204472851); Huang, Zengfeng (42261693300); Sun, Weijian (57219733102); Zhang, Qi (57203621188); Huang, Xuanjing (8983710700)",57218333522; 51666060600; 57204472851; 42261693300; 57219733102; 57203621188; 8983710700,PathQG: Neural question generation from facts,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109540289&partnerID=40&md5=0858e6c6c56ce1069bcc3c7d8ce02c56,"Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions. © 2020 Association for Computational Linguistics.",Final,
Hayashi K.; Kishimoto K.; Shimbo M.,"Hayashi, Katsuhiko (55628535930); Kishimoto, Koki (57208473741); Shimbo, Masashi (8226981900)",55628535930; 57208473741; 8226981900,A greedy bit-flip training algorithm for binarized knowledge graph embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118437417&partnerID=40&md5=51ec77423a583114109dafcd1e545b4a,"This paper presents a simple and effective discrete optimization method for training binarized knowledge graph embedding model B-CP. Unlike the prior work using a SGD-based method and quantization of real-valued vectors, the proposed method directly optimizes binary embedding vectors by a series of bit flipping operations. On the standard knowledge graph completion tasks, the BCP model trained with the proposed method achieved comparable performance with that trained with SGD as well as state-of-the-art real-valued models with similar embedding dimensions. © 2020 Association for Computational Linguistics",Final,
Zhang Z.; Liu X.; Zhang Y.; Su Q.; Sun X.; He B.,"Zhang, Zhiyuan (57205407081); Liu, Xiaoqian (57212230482); Zhang, Yi (56803995800); Su, Qi (55224417600); Sun, Xu (55744667900); He, Bin (57221014343)",57205407081; 57212230482; 56803995800; 55224417600; 55744667900; 57221014343,Pretrain-KGE: Learning knowledge representation from pretrained language models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106358658&partnerID=40&md5=e5da2b0b8b86d1fae0a8ebde4a62aff9,"Conventional knowledge graph embedding (KGE) often suffers from limited knowledge representation, leading to performance degradation especially on the low-resource problem. To remedy this, we propose to enrich knowledge representation via pretrained language models by leveraging world knowledge from pretrained models. Specifically, we present a universal training framework named Pretrain-KGE consisting of three phases: semantic-based fine-tuning phase, knowledge extracting phase and KGE training phase. Extensive experiments show that our proposed Pretrain-KGE can improve results over KGE models, especially on solving the low-resource problem. © 2020 Association for Computational Linguistics",Final,
Broscheit S.; Gashteovski K.; Wang Y.; Gemulla R.,"Broscheit, Samuel (56039831000); Gashteovski, Kiril (57210585423); Wang, Yanjie (57204188119); Gemulla, Rainer (9940328100)",56039831000; 57210585423; 57204188119; 9940328100,Can we predict new facts with open knowledge graph embeddings? A benchmark for open link prediction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098809822&partnerID=40&md5=2f4755d567cd197093fffc0e05583c17,"Open Information Extraction systems extract (“subject text”, “relation text”, “object text”) triples from raw text. Some triples are textual versions of facts, i.e., non-canonicalized mentions of entities and relations. In this paper, we investigate whether it is possible to infer new facts directly from the open knowledge graph without any canonicalization or any supervision from curated knowledge. For this purpose, we propose the open link prediction task, i.e., predicting test facts by completing (“subject text”, “relation text”, ?) questions. An evaluation in such a setup raises the question if a correct prediction is actually a new fact that was induced by reasoning over the open knowledge graph or if it can be trivially explained. For example, facts can appear in different paraphrased textual variants, which can lead to test leakage. To this end, we propose an evaluation protocol and a methodology for creating the open link prediction benchmark OLPBENCH. We performed experiments with a prototypical knowledge graph embedding model for open link prediction. While the task is very challenging, our results suggests that it is possible to predict genuinely new facts, which can not be trivially explained. © 2020 Association for Computational Linguistics",Final,
Xie Z.; Zhou G.; Liu J.; Huang J.X.,"Xie, Zhiwen (57190001632); Zhou, Guangyou (54581936100); Liu, Jin (55978402400); Huang, Jimmy Xiangji (57189975304)",57190001632; 54581936100; 55978402400; 57189975304,ReInceptionE: Relation-aware inception network with joint local-global structural information for knowledge graph embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116659764&partnerID=40&md5=01da65a9a90b717d5caf26297c21252a,"The goal of Knowledge graph embedding (KGE) is to learn how to represent the low-dimensional vectors for entities and relations based on the observed triples. The conventional shallow models are limited to their expressiveness. ConvE (Dettmers et al., 2018) takes advantage of CNN and improves the expressive power with parameter efficient operators by increasing the interactions between head and relation embeddings. However, there is no structural information in the embedding space of ConvE, and the performance is still limited by the number of interactions. The recent KBGAT (Nathani et al., 2019) provides another way to learn embeddings by adaptively utilizing structural information. In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE). Specifically, we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings. Then, we propose to use a relation-aware attention mechanism to enrich the query embedding with the local neighborhood and global entity information. Experimental results on both WN18RR and FB15k-237 datasets demonstrate that ReInceptionE achieves competitive performance compared with state-of-the-art methods. © 2020 Association for Computational Linguistics",Final,
Banerjee P.; Baral C.,"Banerjee, Pratyay (57216612145); Baral, Chitta (7004928552)",57216612145; 7004928552,Self-supervised knowledge triplet learning for zero-shot question answering,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099810077&partnerID=40&md5=923557d7b4307909d7280409e37ea35d,"The aim of all Question Answering (QA) systems is to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias, making systems focus more on the bias than the actual task. This work proposes Knowledge Triplet Learning (KTL), a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge. We propose using KTL to perform zero-shot question answering, and our experiments show considerable improvements over large pre-trained transformer language models. © 2020 Association for Computational Linguistics",Final,
Sun Z.; Chen M.; Hu W.; Wang C.; Dai J.; Zhang W.,"Sun, Zequn (57191745946); Chen, Muhao (57077271100); Hu, Wei (57191221527); Wang, Chengming (57219027671); Dai, Jian (57219590712); Zhang, Wei (57970839200)",57191745946; 57077271100; 57191221527; 57219027671; 57219590712; 57970839200,Knowledge association with hyperbolic knowledge graph embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105050787&partnerID=40&md5=4fd5a66fbfc9e4c35073ae52427d17e1,"Capturing associations for knowledge graphs (KGs) through entity alignment, entity type inference and other related tasks benefits NLP applications with comprehensive knowledge representations. Recent related methods built on Euclidean embeddings are challenged by the hierarchical structures and different scales of KGs. They also depend on high embedding dimensions to realize enough expressiveness. Differently, we explore with low-dimensional hyperbolic embeddings for knowledge association. We propose a hyperbolic relational graph neural network for KG embedding and capture knowledge associations with a hyperbolic transformation. Extensive experiments on entity alignment and type inference demonstrate the effectiveness and efficiency of our method. © 2020 Association for Computational Linguistics",Final,
Li D.; Hu B.; Chen Q.; Peng W.; Wang A.,"Li, Dongfang (57211977863); Hu, Baotian (55647462200); Chen, Qingcai (57207818164); Peng, Weihua (57220993199); Wang, Anqi (57321760400)",57211977863; 55647462200; 57207818164; 57220993199; 57321760400,Towards medical machine reading comprehension with structural knowledge and plain text,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100236546&partnerID=40&md5=15e2103d03284c26bdf2a9017c3d48a6,"Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the lack of extensive training data and professional structural knowledge neglect. As an effort, we first collect a large scale medical multi-choice question dataset (more than 21k instances) for the National Licensed Pharmacist Examination in China. It is a challenging medical examination with a passing rate of less than 14.2% in 2018. Then we propose a novel reading comprehension model KMQA, which can fully exploit the structural medical knowledge (i.e., medical knowledge graph) and the reference medical plain text (i.e., text snippets retrieved from reference books). The experimental results indicate that the KMQA outperforms existing competitive models with a large margin and passes the exam with 61.8% accuracy rate on the test set. © 2020 Association for Computational Linguistics",Final,
Sarkar R.; Goswami K.; Arcan M.; McCrae J.P.,"Sarkar, Rajdeep (57209907494); Goswami, Koustava (57219787194); Arcan, Mihael (55453083200); McCrae, John P. (36666801700)",57209907494; 57219787194; 55453083200; 36666801700,Suggest me a movie for tonight: Leveraging Knowledge Graphs for Conversational Recommendation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149647732&partnerID=40&md5=a30d65e9ada7c0612c0702a719799312,"Conversational recommender systems focus on the task of suggesting products to users based on the conversation flow. Recently, the use of external knowledge in the form of knowledge graphs has shown to improve the performance in recommendation and dialogue systems. Information from knowledge graphs aids in enriching those systems by providing additional information such as closely related products and textual descriptions of the items. However, knowledge graphs are incomplete since they do not contain all factual information present on the web. Furthermore, when working on a specific domain, knowledge graphs in its entirety contribute towards extraneous information and noise. In this work, we study several subgraph construction methods and compare their performance across the recommendation task. We incorporate pre-trained embeddings from the subgraphs along with positional embeddings in our models. Extensive experiments show that our method has a relative improvement of at least 5.62% compared to the state-of-the-art on multiple metrics on the recommendation task. © 2020 COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference. All rights reserved.",Final,
Tang Y.; Huang J.; Wang G.; He X.; Zhou B.,"Tang, Yun (57209885757); Huang, Jing (57211716889); Wang, Guangtao (57216613192); He, Xiaodong (37085932700); Zhou, Bowen (7401906756)",57209885757; 57211716889; 57216613192; 37085932700; 7401906756,Orthogonal relation transforms with graph context modeling for knowledge graph embedding,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113630245&partnerID=40&md5=773d3a5f643952998938b66d3a72ba84,"Distance-based knowledge graph embeddings have shown substantial improvement on the knowledge graph link prediction task, from TransE to the latest state-of-the-art RotatE. However, complex relations such as N-to-1, 1-to-N and N-to-N still remain challenging to predict. In this work, we propose a novel distance-based approach for knowledge graph link prediction. First we extend the RotatE from 2D complex domain to high dimensional space with orthogonal transforms to model relations. The orthogonal transform embedding for relations keeps the capability for modeling symmetric/anti-symmetric, inverse and compositional relations while achieves better modeling capacity. Second, the graph context is integrated into distance scoring functions directly. Specifically, graph context is explicitly modeled via two directed context representations. Each node embedding in knowledge graph is augmented with two context representations, which are computed from the neighboring outgoing and incoming nodes/edges respectively. The proposed approach improves prediction accuracy on the difficult N-to-1, 1-to-N and N-to-N cases. Our experimental results show that it achieves state-of-the-art results on two common benchmarks FB15k-237 and WNRR-18, especially on FB15k-237 which has many high in-degree nodes. Code available at https://github.com/JD-AI-Research-Silicon-Valley/KGEmbedding-OTE. © 2020 Association for Computational Linguistics",Final,
Usip P.U.; Ijebu F.F.; Dan E.A.,"Usip, P.U. (57193409813); Ijebu, F.F. (57209796934); Dan, E.A. (57226133653)",57193409813; 57209796934; 57226133653,A spatiotemporal knowledge bank from rape news articles for decision support,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098253496&doi=10.1007%2f978-3-030-65384-2_11&partnerID=40&md5=a7473ee4b0c5873dbd5b6edbaa4928db,"Rape cases have been on the increase during the COVID’19 pandemic. All News media including the online Newsfeed report these cases around our communities. It is important for intending visitors or residents to be properly informed of specific locations and the times these occurrences are predominant. Our proposed model is aimed at providing a spatiotemporal knowledge bank useful for personal, governmental and/or organizational decision support on occurrences like rape and armed robbery. This model uses a hybrid of preposition enabled natural language processing (PeNLP) parser and ontology-based approach for spatiotemporal data extraction from online news publications to create the knowledge bank for decision support systems (DSS). Protégé is used in the development of the ontology and the resulting graph shows the knowledge bank entities. The result from the PeNLP parser stored in the knowledge bank follows the domain categorization modeled in the graph. The Precision, Recall and F-measure in spatial feature extraction were 100%, 88.89% and 94.12% respectively. The average Precision, Recall and F-measure of our model in temporal feature extraction is 100%. These results represent a successful extraction of spatiotemporal features from online news reports necessary for reasoning in any DSS. © Springer Nature Switzerland AG 2020.",Final,
Cao Y.; Liu Z.; Li C.; Liu Z.; Li J.; Chua T.-S.,"Cao, Yixin (57015851100); Liu, Zhiyuan (57213431299); Li, Chengjiang (57200332248); Liu, Zhiyuan (57191691341); Li, Juanzi (8304332600); Chua, Tat-Seng (7101702977)",57015851100; 57213431299; 57200332248; 57191691341; 8304332600; 7101702977,Multi-channel graph neural network for entity alignment,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079558383&partnerID=40&md5=64dc5d77c2c5bb6493afbf65a734f87d,"Entity alignment typically suffers from the issues of structural heterogeneity and limited seed alignments. In this paper, we propose a novel Multi-channel Graph Neural Network model (MuGNN) to learn alignment-oriented knowledge graph (KG) embeddings by robustly encoding two KGs via multiple channels. Each channel encodes KGs via different relation weighting schemes with respect to self-attention towards KG completion and cross-KG attention for pruning exclusive entities respectively, which are further combined via pooling techniques. Moreover, we also infer and transfer rule knowledge for completing two KGs consistently. MuGNN is expected to reconcile the structural differences of two KGs, and thus make better use of seed alignments. Extensive experiments on five publicly available datasets demonstrate our superior performance (5% Hits@1 up on average). Source code and data used in the experiments can be accessed at https://github.com/thunlp/MuGNN. © 2019 Association for Computational Linguistics",Final,
Wu W.; Guo Z.; Zhou X.; Wu H.; Zhang X.; Lian R.; Wang H.,"Wu, Wenquan (57212065561); Guo, Zhen (57212062976); Zhou, Xiangyang (57192070492); Wu, Hua (7405584325); Zhang, Xiyuan (57216621355); Lian, Rongzhong (57204210310); Wang, Haifeng (57192674011)",57212065561; 57212062976; 57192070492; 7405584325; 57216621355; 57204210310; 57192674011,Proactive human-machine conversation with explicit conversation goals,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084072500&partnerID=40&md5=c8c271ac709cf166e1a5f7a3c2be9908,"Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy: it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new dataset named DuConv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a knowledge graph and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. DuConv enables a very challenging task as the model needs to both understand dialogue and plan over the given knowledge graph. We establish baseline results on this dataset (about 270K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The baseline systems along with the dataset are publicly available. © 2019 Association for Computational Linguistics",Final,
Sheng Y.; Wu T.; Wang X.,"Sheng, Yongpan (57190747968); Wu, Tianxing (56405802900); Wang, Xin (56034125000)",57190747968; 56405802900; 56034125000,Incorporating term definitions for taxonomic relation identification,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080936718&doi=10.1007%2f978-3-030-41407-8_1&partnerID=40&md5=8844e2c236e08252d5503cf1d18609ee,"Taxonomic relations (also called “is-A” relations) are key components in taxonomies, semantic hierarchies and knowledge graphs. Previous works on identifying taxonomic relations are mostly based on linguistic and distributional approaches. However, these approaches are limited by the availability of a large enough corpus that can cover all terms of interest and provide sufficient contextual information to represent their meanings. Therefore, the generalization abilities of the approaches are far from satisfactory. In this paper, we propose a novel neural network model to enhance the semantic representations of term pairs by encoding their respective definitions for the purpose of taxonomic relation identification. This has two main benefits: (i) Definitional sentences represent specified corpus-independent meanings of terms, hence definition-driven approaches have a great generalization capability to identify unseen terms and taxonomic relations which are not expressed in domain specificity of the training data; (ii) Global contextual information from a large corpus and definitions in the sense level can provide richer interpretation of terms from a broader knowledge base perspective, and benefit the accurate prediction for the taxonomic relations of term pairs. The experimental results show that our model outperforms several competitive baseline methods in terms of F-score on both specific and open domain datasets. © Springer Nature Switzerland AG 2020.",Final,
Fan J.; Liu X.; Dong S.; Hu J.,"Fan, Jianye (57218596572); Liu, Xiaofeng (56331159300); Dong, Shoubin (7402016703); Hu, Jinlong (35100245500)",57218596572; 56331159300; 7402016703; 35100245500,Enriching pre-trained language model with dependency syntactic information for chemical-protein interaction extraction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089718804&doi=10.1007%2f978-3-030-56725-5_5&partnerID=40&md5=7a37281f21c0a0d3ce20370a65ee0717,"Automatic extraction of chemical-protein interactions (CPI) included in biomedical literature plays an important role in many biomedical applications such as drug discovery, knowledge discovery, and biomedical knowledge graph construction. However, CPIs in long and complicated sentences are difficult to extract. Most of the existing methods mainly focus on the sequence information rather than syntactic information, which is also conducive to CPI extraction. In this paper, a pre-trained language model based approach with dependency syntactic information is proposed to improve the performance of CPI extraction. Firstly the approach extracts generalized dependency syntactic information based on the characteristics of CPI data. Then, BERT is adopted to generate the contextual representation of sequence information and syntactic information and the mean-pooling method is used to aggregate the context representation. Finally, the sequence information and syntactic information are fused and mapped to the category feature space through a fully-connected layer. The evaluation on the original ChemProt corpus demonstrates that in comparison to other pre-trained model-based methods, our method can achieve better performance. © Springer Nature Switzerland AG 2020.",Final,
Shakirova L.; Falileeva M.; Kirillovich A.; Lipachev E.; Nevzorova O.; Nevzorov V.,"Shakirova, Liliana (56998615300); Falileeva, Marina (57204181811); Kirillovich, Alexander (55994716700); Lipachev, Evgeny (6505830683); Nevzorova, Olga (6506234633); Nevzorov, Vladimir (55995074700)",56998615300; 57204181811; 55994716700; 6505830683; 6506234633; 55995074700,Modeling and evaluation of the mathematical educational ontology,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078420073&partnerID=40&md5=9fc7568243cdfccad84821eb628956d2,"In this paper, we discuss the current stage of development of the educational mathematical ontology OntoMathEdu, firstly presented by us at INTED 2019 and CICM 2019. This ontology is intended to be used as a Linked Open Data hub for mathematical education, a linguistic resource for intelligent mathematical language processing and an end-user reference educational database. The ontology is organized in three layers: a foundational ontology layer, a domain ontology layer and a linguistic layer. The domain ontology layer contains language-independent concepts, covering secondary school mathematics curriculum. The linguistic layer provides linguistic grounding for these concepts, and the foundation ontology layer provides them with meta-ontological annotations. Our current work is dedicated to development of prerequisite relationships of the OntoMathEdu ontology. We introduce these relationships by manual arrangement of the concepts of OntoMathEdu by educational levels. After that, we conduct preliminary evaluation of the ontology. The ontology will be used as a foundation of the new digital educational platform of Kazan Federal University. Copyright © 2020 for this paper by its authors.",Final,
Zhang H.; Liu Z.; Xiong C.; Liu Z.,"Zhang, Houyu (57221139203); Liu, Zhenghao (57194902552); Xiong, Chenyan (56405071400); Liu, Zhiyuan (57191691341)",57221139203; 57194902552; 56405071400; 57191691341,Grounded conversation generation as guided traverses in commonsense knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091800791&partnerID=40&md5=c03b8bf73a31d033e0bd92a39a830a31,"Human conversations naturally evolve around related concepts and scatter to multi-hop concepts. This paper presents a new conversation generation model, ConceptFlow, which leverages commonsense knowledge graphs to explicitly model conversation flows. By grounding conversations to the concept space, ConceptFlow represents the potential conversation flow as traverses in the concept space along commonsense relations. The traverse is guided by graph attentions in the concept graph, moving towards more meaningful directions in the concept space, in order to generate more semantic and informative responses. Experiments on Reddit conversations demonstrate ConceptFlow's effectiveness over previous knowledge-aware conversation models and GPT-2 based models while using 70% fewer parameters, confirming the advantage of explicit modeling conversation structures. All source codes of this work are available at https://github.com/thunlp/ConceptFlow. © 2020 Association for Computational Linguistics",Final,
Teo D.,"Teo, Don (57211408670)",57211408670,TR at SemEval-2020 Task 4: Exploring the Limits of Language-model-based Common Sense Validation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095372454&partnerID=40&md5=8d46de3e580634ddb3eb99610be6e196,"In this paper, we present our submission for subtask A of the Common Sense Validation and Explanation (ComVE) shared task. We examine the ability of large-scale pre-trained language models to distinguish commonsense from non-commonsense statements. We also explore the utility of external resources that aim to supplement the world knowledge inherent in such language models, including commonsense knowledge graph embedding models, word concreteness ratings, and text-to-image generation models. We find that such resources provide insignificant gains to the performance of fine-tuned language models. We also provide a qualitative analysis of the limitations of the language model fine-tuned to this task. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.",Final,
Satyapanich T.; Ferraro F.; Finin T.,"Satyapanich, Taneeya (56928297500); Ferraro, Francis (53979619700); Finin, Tim (57207497232)",56928297500; 53979619700; 57207497232,Casie: Extracting cybersecurity event information from text,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098372345&partnerID=40&md5=baa79526a7c424d87a5bfc9a1e9ad0be,"We present CASIE, a system that extracts information about cybersecurity events from text and populates a semantic model, with the ultimate goal of integration into a knowledge graph of cybersecurity data. It was trained on a new corpus of 1,000 English news articles from 2017-2019 that are labeled with rich, event-based annotations and that covers both cyberattack and vulnerability-related events. Our model defines five event subtypes along with their semantic roles and 20 event-relevant argument types (e.g., file, device, software, money). CASIE uses different deep neural networks approaches with attention and can incorporate rich linguistic features and word embeddings. We have conducted experiments on each component in the event detection pipeline and the results show that each subsystem performs well. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Zhou H.; Zheng C.; Huang K.; Huang M.; Zhu X.,"Zhou, Hao (56898234800); Zheng, Chujie (57216613056); Huang, Kaili (57219488353); Huang, Minlie (7404260571); Zhu, Xiaoyan (7406185137)",56898234800; 57216613056; 57219488353; 7404260571; 7406185137,KdConv: A Chinese multi-domain dialogue dataset towards multi-turn knowledge-driven conversation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095313536&partnerID=40&md5=a34adb78c5296528c5b186be43ecc781,"The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consists of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available. © 2020 Association for Computational Linguistics",Final,
Chen W.; Hakami H.; Bollegala D.,"Chen, Wenye (57218264307); Hakami, Huda (57003240000); Bollegala, Danushka (13006618600)",57218264307; 57003240000; 13006618600,Learning to Compose Relational Embeddings in Knowledge Graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088517199&doi=10.1007%2f978-981-15-6168-9_5&partnerID=40&md5=0449b6f5b4d97fe073ce77da3412a14a,"Knowledge Graph Embedding methods learn low-dimensional representations for entities and relations in knowledge graphs, which can be used to infer previously unknown relations between pairs of entities in the knowledge graph. This is particularly useful for expanding otherwise sparse knowledge graphs. However, the relation types that can be predicted using knowledge graph embeddings are confined to the set of relations that already exists in the KG. Often the set of relations that exist between two entities are not independent, and it is possible to predict what other relations are likely to exist between two entities by composing the embeddings of the relations in which each entity participates. We introduce relation composition as the task of inferring embeddings for unseen relations by combining existing relations in a knowledge graph. Specifically, we propose a supervised method to compose relational embeddings for novel relations using pre-trained relation embeddings for existing relations. Our experimental results on a previously proposed benchmark dataset for relation composition ranking and triple classification show that the proposed supervised relation composition method outperforms several unsupervised relation composition methods. © 2020, Springer Nature Singapore Pte Ltd.",Final,
Zhang Z.; Han X.; Liu Z.; Jiang X.; Sun M.; Liu Q.,"Zhang, Zhengyan (57196122281); Han, Xu (57205548124); Liu, Zhiyuan (57191691341); Jiang, Xin (55960978700); Sun, Maosong (7403180987); Liu, Qun (56181387900)",57196122281; 57205548124; 57191691341; 55960978700; 7403180987; 56181387900,ErniE: Enhanced language representation with informative entities,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084078111&partnerID=40&md5=cfe166d215db5d03ec646d13bc3f4770,"Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/ERNIE. © 2019 Association for Computational Linguistics",Final,
Santos R.L.S.; Pardo T.A.S.,"Santos, Roney Lira de Sales (57203985465); Pardo, Thiago Alexandre Salgueiro (36817139400)",57203985465; 36817139400,Fact-checking for Portuguese: Knowledge graph and google search-based methods,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081616236&doi=10.1007%2f978-3-030-41505-1_19&partnerID=40&md5=1aab550cc355f2520b7f151572314314,"The propagation of fake news may influence a large number of people on a wide range of subjects. Once the spread of fake news reached a critical point, relevant initiatives to fight them have emerged. In this paper, we adapt from English a knowledge graph-based method for fact-checking and propose a new one based on Google search, following content-based strategies for tackling deception in Portuguese, differently from what has been previously done in linguistic-based approaches. Our results are promising and indicate new ways to deal with the deceptive content detection issue. © Springer Nature Switzerland AG 2020.",Final,
Hayashi H.; Hu Z.; Xiong C.; Neubig G.,"Hayashi, Hiroaki (57196274164); Hu, Zecong (57207855744); Xiong, Chenyan (56405071400); Neubig, Graham (36141167700)",57196274164; 57207855744; 56405071400; 36141167700,Latent relation language models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095149010&partnerID=40&md5=0136dc85f139a9219c38f6db0fa02f90,"In this paper, we propose Latent Relation Language Models (LRLMs), a class of language models that parameterizes the joint distribution over the words in a document and the entities that occur therein via knowledge graph relations. This model has a number of attractive properties: it not only improves language modeling performance, but is also able to annotate the posterior probability of entity spans for a given text through relations. Experiments demonstrate empirical improvements over both word-based language models and a previous approach that incorporates knowledge graph information. Qualitative analysis further demonstrates the proposed model’s ability to learn to predict appropriate relations in context. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
"Logan R.L., IV; Liu N.F.; Peters M.E.; Gardner M.; Singh S.","Logan, Robert L. (57212308172); Liu, Nelson F. (57216614606); Peters, Matthew E. (57200338146); Gardner, Matt (56577280400); Singh, Sameer (58124003300)",57212308172; 57216614606; 57200338146; 56577280400; 58124003300,Barack's wife Hillary: Using knowledge graphs for fact-aware language modeling,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084035303&partnerID=40&md5=bae32a9cf40bc8c2a3755d5922ecfdb9,"Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset,1 a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark (Merity et al., 2017). In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language models' ability to complete sentences requiring factual knowledge, and show that the KGLM outperforms even very large language models in generating facts. © 2019 Association for Computational Linguistics",Final,
Zhang Y.; Lin J.; Fan Y.; Jin P.; Liu Y.; Liu B.,"Zhang, Yice (57437294100); Lin, Jiaxuan (57438012800); Fan, Yang (57437868200); Jin, Peng (57437294200); Liu, Yuanchao (56300984000); Liu, Bingquan (7408692701)",57437294100; 57438012800; 57437868200; 57437294200; 56300984000; 7408692701,CN-HIT-IT.NLP at SemEval-2020 Task 4: Enhanced Language Representation with Multiple Knowledge Triples,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095294470&partnerID=40&md5=6fa25dd23ddba5a67a5ba70ac7c8603d,"This paper describes our system that participated in the SemEval-2020 task 4: Commonsense Validation and Explanation. For this task, it is obvious that external knowledge, such as knowledge graph, can help the model understand commonsense in natural language statements. But how to select the right triples for statements remains unsolved, so how to reduce the interference of irrelevant triples on model performance is a research focus. This paper adopt a modified K-BERT as the language encoder, to enhance language representation through triples from knowledge graphs. Experiments show that our method is better than models without external knowledge, and is slightly better than the original K-BERT. We got an accuracy score of 0.97 in subtaskA, ranking 1/45, and got an accuracy score of 0.948, ranking 2/35. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.",Final,
Xu K.; Wang L.; Yu M.; Feng Y.; Song Y.; Wang Z.; Yu D.,"Xu, Kun (55712650500); Wang, Liwei (57196330292); Yu, Mo (35174012000); Feng, Yansong (55387599700); Song, Yan (57204467546); Wang, Zhiguo (53664832900); Yu, Dong (35764924800)",55712650500; 57196330292; 35174012000; 55387599700; 57204467546; 53664832900; 35764924800,Cross-lingual knowledge graph alignment via graph matching neural network,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079550280&partnerID=40&md5=ca439438b26346433600d0cfcc5272aa,"Previous cross-lingual knowledge graph (KG) alignment studies rely on entity embeddings derived only from monolingual KG structural information, which may fail at matching entities that have different facts in two KGs. In this paper, we introduce the topic entity graph, a local sub-graph of an entity, to represent entities with their contextual information in KG. From this view, the KB-alignment task can be formulated as a graph matching problem; and we further propose a graph-attention based solution, which first matches all entities in two topic entity graphs, and then jointly model the local matching information to derive a graph-level matching vector. Experiments show that our model outperforms previous state-of-the-art methods by a large margin. © 2019 Association for Computational Linguistics",Final,
He Q.; Wu L.; Yin Y.; Cai H.,"He, Qizhen (57223908774); Wu, Liang (57223916299); Yin, Yida (58728919300); Cai, Heming (57223908777)",57223908774; 57223916299; 58728919300; 57223908777,Knowledge-graph augmented word representations for named entity recognition,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098019752&partnerID=40&md5=83fe92acb1ee71d8ed39c7646e1226a3,"By modeling the context information, ELMo and BERT have successfully improved the state-of-the-art of word representation, and demonstrated their effectiveness on the Named Entity Recognition task. In this paper, in addition to such context modeling, we propose to encode the prior knowledge of entities from an external knowledge base into the representation, and introduce a Knowledge-Graph Augmented Word Representation or KAWR for named entity recognition. Basically, KAWR provides a kind of knowledge-aware representation for words by 1) encoding entity information from a pre-trained KG embedding model with a new recurrent unit (GERU), and 2) strengthening context modeling from knowledge wise by providing a relation attention scheme based on the entity relations defined in KG. We demonstrate that KAWR, as an augmented version of the existing linguistic word representations, promotes F1 scores on 5 datasets in various domains by +0.46~+2.07. Better generalization is also observed for KAWR on new entities that cannot be found in the training sets. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Bansal T.; Juan D.-C.; Ravi S.; McCallum A.,"Bansal, Trapit (56347813600); Juan, Da-Cheng (17434353500); Ravi, Sujith (57551243700); McCallum, Andrew (7003773569)",56347813600; 17434353500; 57551243700; 7003773569,A2n: Attending to neighbors for knowledge graph inference,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081175263&partnerID=40&md5=bef89cb633300e5988f7c9aa2db16bd1,"State-of-the-art models for knowledge graph completion aim at learning a fixed embedding representation of entities in a multirelational graph which can generalize to infer unseen entity relationships at test time. This can be sub-optimal as it requires memorizing and generalizing to all possible entity relationships using these fixed representations. We thus propose a novel attention-based method to learn query-dependent representation of entities which adaptively combines the relevant graph neighborhood of an entity leading to more accurate KG completion. The proposed method is evaluated on two benchmark datasets for knowledge graph completion, and experimental results show that the proposed model performs competitively or better than existing state-of-the-art, including recent methods for explicit multi-hop reasoning. Qualitative probing offers insight into how the model can reason about facts involving multiple hops in the knowledge graph, through the use of neighborhood attention. © 2019 Association for Computational Linguistics",Final,
Omeliyanenko J.; Zehe A.; Hettinger L.; Hotho A.,"Omeliyanenko, Janna (57220023388); Zehe, Albin (57191032011); Hettinger, Lena (57188686114); Hotho, Andreas (8227931000)",57220023388; 57191032011; 57188686114; 8227931000,LM4KG: Improving Common Sense Knowledge Graphs with Language Models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096518759&doi=10.1007%2f978-3-030-62419-4_26&partnerID=40&md5=268308697613bb851121c4e7c7d77e41,"Language Models (LMs) and Knowledge Graphs (KGs) are both active research areas in Machine Learning and Semantic Web. While LMs have brought great improvements for many downstream tasks on their own, they are often combined with KGs providing additionally aggregated, well structured knowledge. Usually, this is done by leveraging KGs to improve LMs. But what happens if we turn this around and use LMs to improve KGs? In this paper, we propose a method enabling the use of the knowledge inherently encoded in LMs to automatically improve explicit knowledge represented in common sense KGs. Edges in these KGs represent relations between concepts, but the strength of the relations is often not clear. We propose to transform KG relations to natural language sentences, allowing us to utilize the information contained in large LMs to rate these sentences through a new perplexity-based measure, Refined Edge WEIGHTing (REWEIGHT). We test our scoring scheme REWEIGHT on the popular LM BERT to produce new weights for the edges in the well-known ConceptNet KG. By retrofitting existing word embeddings to our modified ConceptNet, we create ConceptNet NumBERTbatch embeddings and show that these outperform the original ConceptNet Numberbatch on multiple established semantic similarity datasets. © 2020, Springer Nature Switzerland AG.",Final,
Bosselut A.; Rashkin H.; Sap M.; Malaviya C.; Celikyilmaz A.; Choi Y.,"Bosselut, Antoine (57193225759); Rashkin, Hannah (57193243019); Sap, Maarten (56419784900); Malaviya, Chaitanya (57207861690); Celikyilmaz, Asli (35614300300); Choi, Yejin (36172231400)",57193225759; 57193243019; 56419784900; 57207861690; 35614300300; 36172231400,CoMET: Commonsense transformers for automatic knowledge graph construction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084040907&partnerID=40&md5=f7e9dc21d41a91b6d7646b53e4952c17,"We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods. © 2019 Association for Computational Linguistics",Final,
Malaviya C.; Bhagavatula C.; Bosselut A.; Choi Y.,"Malaviya, Chaitanya (57207861690); Bhagavatula, Chandra (57216430904); Bosselut, Antoine (57193225759); Choi, Yejin (36172231400)",57207861690; 57216430904; 57193225759; 36172231400,Commonsense knowledge base completion with structural and semantic context,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096576022&partnerID=40&md5=040ff026aa3ed1ced90b6a0c7aa2cb1b,"Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and ConceptNet) poses unique challenges compared to the much studied conventional knowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form text to represent nodes, resulting in orders of magnitude more nodes compared to conventional KBs (∼18x more nodes in ATOMIC compared to Freebase (FB15K-237)). Importantly, this implies significantly sparser graph structures — a major challenge for existing KB completion methods that assume densely connected graphs over a relatively smaller set of nodes. In this paper, we present novel KB completion models that can address these challenges by exploiting the structural and semantic context of nodes. Specifically, we investigate two key ideas: (1) learning from local graph structure, using graph convolutional networks and automatic graph densification and (2) transfer learning from pre-trained language models to knowledge graphs for enhanced contextual representation of knowledge. We describe our method to incorporate information from both these sources in a joint model and provide the first empirical results for KB completion on ATOMIC and evaluation with ranking metrics on ConceptNet. Our results demonstrate the effectiveness of language model representations in boosting link prediction performance and the advantages of learning from local graph structure (+1.5 points in MRR for ConceptNet) when training on subgraphs for computational efficiency. Further analysis on model predictions shines light on the types of commonsense knowledge that language models capture well. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Yang X.; Tiddi I.,"Yang, Xinran (57220751232); Tiddi, Ilaria (55596365700)",57220751232; 55596365700,Creative storytelling with language models and knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097546218&partnerID=40&md5=3914a7c1b9edb0fdd9c889dd3a8ed304,"Automated story generation is a popular and well-recognized task in the field of natural language processing. The emergence of pre-trained language models based on large Transformer architectures shows the great capability of text generation. However, language models are limited when the generation requires explicit clues within the context. In this research, we study how to combine knowledge graphs with language models, and build a creative story generation system named DICE. DICE uses external knowledge graphs to provide context clues and implicit knowledge to generate coherent and creative stories. The evaluation shows that our approach can effectively inject the knowledge from knowledge graphs into the stories automatically generated by the language model. © 2020 CEUR-WS. All rights reserved.",Final,
Chen J.; Wang A.; Jiang H.; Feng S.; Li C.; Xiao Y.,"Chen, Jiangjie (57209507608); Wang, Ao (57209503509); Jiang, Haiyun (58833312700); Feng, Suo (57207965172); Li, Chenguang (57775611000); Xiao, Yanghua (24377046200)",57209507608; 57209503509; 58833312700; 57207965172; 57775611000; 24377046200,Ensuring readability and data-fidelity using head-modifier templates in deep type description generation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084037465&partnerID=40&md5=cac18f242fee6906066b34c20adb8312,"A type description is a succinct noun compound which helps human and machines to quickly grasp the informative and distinctive information of an entity. Entities in most knowledge graphs (KGs) still lack such descriptions, thus calling for automatic methods to supplement such information. However, existing generative methods either overlook the grammatical structure or make factual mistakes in generated texts. To solve these problems, we propose a head-modifier template-based method to ensure the readability and data fidelity of generated type descriptions. We also propose a new dataset and two automatic metrics for this task. Experiments show that our method improves substantially compared with baselines and achieves state-of-the-art performance on both datasets. © 2019 Association for Computational Linguistics",Final,
Sun Z.; Vashishth S.; Sanyal S.; Talukdar P.; Yang Y.,"Sun, Zhiqing (57210638438); Vashishth, Shikhar (57191342794); Sanyal, Soumya (57219586798); Talukdar, Partha (25652280700); Yang, Yiming (35231480000)",57210638438; 57191342794; 57219586798; 25652280700; 35231480000,A re-evaluation of knowledge graph completion methods,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098405169&partnerID=40&md5=e3d5c395420e90ff76a233644858e32c,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available. © 2020 Association for Computational Linguistics",Final,
Gromann D.,"Gromann, Dagmar (55844075500)",55844075500,"Neural language models for the multilingual, transcultural, and multimodal Semantic Web",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079061830&doi=10.3233%2fSW-190373&partnerID=40&md5=d7387d7460b3f99c2c4689e2fb855069,"A vision of a truly multilingual Semantic Web has found strong support with the Linguistic Linked Open Data community. Standards, such as OntoLex-Lemon, highlight the importance of explicit linguistic modeling in relation to ontologies and knowledge graphs. Nevertheless, there is room for improvement in terms of automation, usability, and interoperability. Neural Language Models have achieved several breakthroughs and successes considerably beyond Natural Language Processing (NLP) tasks and recently also in terms of multimodal representations. Several paths naturally open up to port these successes to the Semantic Web, from automatically translating linguistic information associated with structured knowledge resources to multimodal question-answering with machine translation. Language is also an important vehicle for culture, an aspect that deserves considerably more attention. Building on existing approaches, this article envisions joint forces between Neural Language Models and Semantic Web technologies for multilingual, transcultural, and multimodal information access and presents open challenges and opportunities in this direction. © 2020-IOS Press and the authors. All rights reserved.",Final,
Gong P.; Liu J.; Yang Y.; He H.,"Gong, Peizhu (57221124408); Liu, Jin (57196289455); Yang, Yihe (57205021174); He, Huihua (57216764088)",57221124408; 57196289455; 57205021174; 57216764088,Towards Knowledge Enhanced Language Model for Machine Reading Comprehension,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098272414&doi=10.1109%2fACCESS.2020.3044308&partnerID=40&md5=d21eb52d52816118ac8b83407888c247,"Machine reading comprehension is a crucial and challenging task in natural language processing (NLP). Recently, knowledge graph (KG) embedding has gained massive attention as it can effectively provide side information for downstream tasks. However, most previous knowledge-based models do not take into account the structural characteristics of the triples in KGs, and only convert them into vector representations for direct accumulation, leading to deficiencies in knowledge extraction and knowledge fusion. In order to alleviate this problem, we propose a novel deep model KCF-NET, which incorporates knowledge graph representations with context as the basis for predicting answers by leveraging capsule network to encode the intrinsic spatial relationship in triples of KG. In KCF-NET, we fine-tune BERT, a highly performance contextual language representation model, to capture complex linguistic phenomena. Besides, a novel fusion structure based on multi-head attention mechanism is designed to balance the weight of knowledge and context. To evaluate the knowledge expression and reading comprehension ability of our model, we conducted extensive experiments on multiple public datasets such as WN11, FB13, SemEval-2010 Task 8 and SQuAD. Experimental results show that KCF-NET achieves state-of-the-art results in both link prediction and MRC tasks with negligible parameter increase compared to BERT-Base, and gets competitive results in triple classification task with significantly reduced model size. © 2013 IEEE.",Final,All Open Access; Gold Open Access
Bansky P.; Edelstein E.; Pan J.Z.; Wyner A.,"Bansky, Patrik (57215414288); Edelstein, Elspeth (57204806756); Pan, Jeff Z. (8856621200); Wyner, Adam (7006211789)",57215414288; 57204806756; 8856621200; 7006211789,A dynamic and informative intelligent survey system based on knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080855703&doi=10.1007%2f978-3-030-41407-8_15&partnerID=40&md5=5dad630b8c17207f7cf46c3a141424c5,"In the paper we propose a dynamic and informative solution to an intelligent survey system that is based on knowledge graph. To illustrate our proposal, we focus on ordering the questions of the questionnaire component by their acceptance, along with conditional triggers that further customise participants’ experience, making the system dynamic. Evaluation of the system shows that the dynamic component can be beneficial in terms of lowering the number of questions asked and improving the quality of data, allowing more informative data to be collected in a survey of equivalent length. Fine-grained analysis allows assessment of the interaction of specific variables, as well as of individual respondents rather than just global results. The paper explores and evaluates two algorithms for the presentation of survey questions, leading to additional insights about how to improve the system. © Springer Nature Switzerland AG 2020.",Final,All Open Access; Green Open Access
Naresh Kumar D.; Deepak G.; Santhanavijayan A.,"Naresh Kumar, D. (57215896737); Deepak, Gerard (57217039816); Santhanavijayan, A. (55042923700)",57215896737; 57217039816; 55042923700,A Novel Semantic Approach for Intelligent Response Generation using Emotion Detection Incorporating NPMI Measure,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084501270&doi=10.1016%2fj.procs.2020.03.320&partnerID=40&md5=87640ffce4e04e49bdeedec74357d023,"Expressions and emotions are the most common way of communication in day-to-day life. In the age of Artificial Intelligence and technological advancements, the entire human race finds itself amidst many software driven voice-assistants. The only reason AI cannot excel and spread its limits is that humans can interpret, understand and express in the form of emotions and these AI-driven systems cannot. Hence, there is a need for a proper methodology for the interpretation of emotions based on both text and speech. In order to accomplish this task, a light weight computational linguistic semantic approach has been proposed for detecting emotions and generating response incorporating NPMI and NAVA words, bridging the gap between Semantics and Natural Language Processing. Experimentations are conducted for the real-word TDIL dataset for emotions such as joy, sorrow, anger, disgust, and fear. The proposed approach yields an accuracy of 96.155% for the emotion joy and 82.44 % for fear which definitely is the best-in-class accuracy for such systems. © 2020 The Authors. Published by Elsevier B.V.",Final,All Open Access; Gold Open Access
Oliveri I.; Ardito L.; Rizzo G.; Morisio M.,"Oliveri, Isabeau (57220925792); Ardito, Luca (36184897700); Rizzo, Giuseppe (57194127652); Morisio, Maurizio (6701428565)",57220925792; 36184897700; 57194127652; 6701428565,Creativity embedding: A vector to characterise and classify plausible triples in deep learning NLP models,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097864462&partnerID=40&md5=a6d41c3076df8406bafc12883a8154da,"In this paper we define the creativity embedding of a text based on four self-assessment creativity metrics, namely diversity, novelty, serendipity and magnitude, knowledge graphs, and neural networks. We use as basic unit the notion of triple (head, relation, tail). We investigate if additional information about creativity improves natural language processing tasks. In this work, we focus on triple plausibility task, exploiting BERT model and a WordNet11 dataset sample. Contrary to our hypothesis, we do not detect increase in the performance. Copyright © 2020 for this paper by its authors.",Final,
Hosseini M.J.; Cohen S.B.; Johnson M.; Steedman M.,"Hosseini, Mohammad Javad (57216617622); Cohen, Shay B. (36684767400); Johnson, Mark (55574223118); Steedman, Mark (6602901918)",57216617622; 36684767400; 55574223118; 6602901918,Duality of link prediction and entailment graph induction,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084090774&partnerID=40&md5=e55d3b1d597f291c3b3278c8d2e0014c,"Link prediction and entailment graph induction are often treated as different problems. In this paper, we show that these two problems are actually complementary. We train a link prediction model on a knowledge graph of assertions extracted from raw text. We propose an entailment score that exploits the new facts discovered by the link prediction model, and then form entailment graphs between relations. We further use the learned entailments to predict improved link prediction scores. Our results show that the two tasks can benefit from each other. The new entailment score outperforms prior state-of-the-art results on a standard entialment dataset and the new link prediction scores show improvements over the raw link prediction scores. © 2019 Association for Computational Linguistics",Final,
Yang Z.; Zhu C.; Sachidananda V.; Darve E.,"Yang, Ziyi (57216615298); Zhu, Chenguang (57210636804); Sachidananda, Vin (57208439583); Darve, Eric (6603264115)",57216615298; 57210636804; 57208439583; 6603264115,Embedding imputation with grounded language information,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084066541&partnerID=40&md5=f3073d456559e02b92b4e75f708ba968,"Due to the ubiquitous use of embeddings as input representations for a wide range of natural language tasks, imputation of embeddings for rare and unseen words is a critical problem in language processing. Embedding imputation involves learning representations for rare or unseen words during the training of an embedding model, often in a post-hoc manner. In this paper, we propose an approach for embedding imputation which uses grounded information in the form of a knowledge graph. This is in contrast to existing approaches which typically make use of vector space properties or subword information. We propose an online method to construct a graph from grounded information and design an algorithm to map from the resulting graphical structure to the space of the pre-trained embeddings. Finally, we evaluate our approach on a range of rare and unseen word tasks across various domains and show that our model can learn better representations. For example, on the Card-660 task our method improves Pearson's and Spearman's correlation coefficients upon the state-of-the-art by 11% and 17.8% respectively using GloVe embeddings. © 2019 Association for Computational Linguistics",Final,
Safavi T.; Koutra D.,"Safavi, Tara (57201134239); Koutra, Danai (49861458400)",57201134239; 49861458400,CODEX: A comprehensive knowledge graph completion Benchmark,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098215062&partnerID=40&md5=af8a417e113a9753e783abd4f354b79b,"We present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CODEX comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CODEX, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CODEX dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CODEX for five extensively tuned embedding models. Finally, we differentiate CODEX from the popular FB15K-237 knowledge graph completion dataset by showing that CODEX covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs. © 2020 Association for Computational Linguistics.",Final,
Paranjpe A.P.; Bhowmik R.; De Melo G.,"Paranjpe, Atharva Prabhat (57219947131); Bhowmik, Rajarshi (57207858094); De Melo, Gerard (23088528100)",57219947131; 57207858094; 23088528100,Facts that matter: Dynamic fact retrieval for entity-centric search queries,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096231754&partnerID=40&md5=e6d7a8042d69c51274f26e32a3634c17,"Entity-centric queries constitute a significant proportion of all search queries processed by the popular search engines. Answering such queries often involves selecting facts pertaining to an entity from an underlying knowledge graph. Prior work on this draws on hand-crafted features that require scanning the entire knowledge graph beforehand. Instead, we propose a neural method that exploits the linguistic and semi-linguistic nature of the entity search queries and the facts, and can hence be applied dynamically to entirely new sets of candidate facts. We optimize our model using a pairwise loss function to correctly predict the relevance and importance scores for each fact for a given query entity, while the overall fact ranking is based on a linear combination of these scores. We show that our simple approach outperforms previous work, ensuring better fact retrieval for entity-centric search queries. © 2020 CEUR-WS. All rights reserved.",Final,
Halike A.; Abiderexiti K.; Yibulayin T.,"Halike, Ayiguli (57214761803); Abiderexiti, Kahaerjiang (55977386600); Yibulayin, Tuergen (35119649600)",57214761803; 55977386600; 35119649600,Semi-automatic corpus expansion and extraction of uyghur-named entities and relations based on a hybrid method,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079035010&doi=10.3390%2finfo11010031&partnerID=40&md5=da2537c978af69c328a8600a11cff1c2,"Relation extraction is an important task with many applications in natural language processing, such as structured knowledge extraction, knowledge graph construction, and automatic question answering system construction. However, relatively little past work has focused on the construction of the corpus and extraction of Uyghur-named entity relations, resulting in a very limited availability of relation extraction research and a deficiency of annotated relation data. This issue is addressed in the present article by proposing a hybrid Uyghur-named entity relation extraction method that combines a conditional random field model for making suggestions regarding annotation based on extracted relations with a set of rules applied by human annotators to rapidly increase the size of the Uyghur corpus. We integrate our relation extraction method into an existing annotation tool, and, with the help of human correction, we implement Uyghur relation extraction and expand the existing corpus. The effectiveness of our proposed approach is demonstrated based on experimental results by using an existing Uyghur corpus, and our method achieves a maximum weighted average between precision and recall of 61.34%. The method we proposed achieves state-of-the-art results on entity and relation extraction tasks in Uyghur. © 2020 by the authors.",Final,All Open Access; Gold Open Access
Zhang H.; Song Y.; Song Y.; Yu D.,"Zhang, Hongming (57202439109); Song, Yan (57204467546); Song, Yangqiu (14039604300); Yu, Dong (35764924800)",57202439109; 57204467546; 14039604300; 35764924800,Knowledge-aware pronoun coreference resolution,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084067622&partnerID=40&md5=2fab17b684e76fb87b4559693d457880,"Resolving pronoun coreference requires knowledge support, especially for particular domains (e.g., medicine). In this paper, we explore how to leverage different types of knowledge to better resolve pronoun coreference with a neural model. To ensure the generalization ability of our model, we directly incorporate knowledge in the format of triplets, which is the most common format of modern knowledge graphs, instead of encoding it with features or rules as that in conventional approaches. Moreover, since not all knowledge is helpful in certain contexts, to selectively use them, we propose a knowledge attention module, which learns to select and use informative knowledge based on contexts, to enhance our model. Experimental results on two datasets from different domains prove the validity and effectiveness of our model, where it outperforms state-of-the-art baselines by a large margin. Moreover, since our model learns to use external knowledge rather than only fitting the training data, it also demonstrates superior performance to baselines in the cross-domain setting. © 2019 Association for Computational Linguistics",Final,
Sachan M.,"Sachan, Mrinmaya (36094978300)",36094978300,Knowledge graph embedding compression,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098370483&partnerID=40&md5=d8157474f411ba58de517ed40574f73e,"Knowledge graph (KG) representation learning techniques that learn continuous embeddings of entities and relations in the KG have become popular in many AI applications. With a large KG, the embeddings consume a large amount of storage and memory. This is problematic and prohibits the deployment of these techniques in many real world settings. Thus, we propose an approach that compresses the KG embedding layer by representing each entity in the KG as a vector of discrete codes and then composes the embeddings from these codes. The approach can be trained end-to-end with simple modifications to any existing KG embedding technique. We evaluate the approach on various standard KG embedding evaluations and show that it achieves 50-1000x compression of embeddings with a minor loss in performance. The compressed embeddings also retain the ability to perform various reasoning tasks such as KG inference. © 2020 Association for Computational Linguistics",Final,
Mukhamedshin D.; Nevzorova O.; Kirillovich A.,"Mukhamedshin, Damir (57194654368); Nevzorova, Olga (6506234633); Kirillovich, Alexander (55994716700)",57194654368; 6506234633; 55994716700,"Using FLOSS for Storing, Processing and Linking Corpus Data",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085060386&doi=10.1007%2f978-3-030-47240-5_17&partnerID=40&md5=645ca7f130cf9a0d594bc56643c68089,"Corpus data is widely used to solve different linguistic, educational and applied problems. The Tatar corpus management system (http://tugantel.tatar) is specifically developed for Turkic languages. The functionality of our corpus management system includes a search of lexical units, morphological and lexical search, a search of syntactic units, a search of N-grams and others. The search is performed using open source tools (database management system MariaDB, Redis data store). This article describes the process of choosing FLOSS for the main components of our system and also processing a search query and building a linked open dataset based on corpus data. © 2020, IFIP International Federation for Information Processing.",Final,All Open Access; Bronze Open Access; Green Open Access
Chiarcos C.; Fäth C.; Abromeit F.,"Chiarcos, Christian (22333764800); Fäth, Christian (57194612424); Abromeit, Frank (57198810784)",22333764800; 57194612424; 57198810784,Annotation interoperability for the post-ISOCat era,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094531110&partnerID=40&md5=77114483d62fb6bce0a1b3ffbed5d4ee,"With this paper, we provide an overview over ISOCat successor solutions and annotation standardization efforts since 2010, and we describe the low-cost harmonization of post-ISOCat vocabularies by means of modular, linked ontologies: The CLARIN Concept Registry, LexInfo, Universal Parts of Speech, Universal Dependencies and UniMorph are linked with the Ontologies of Linguistic Annotation and through it with ISOCat, the GOLD ontology, the Typological Database Systems ontology and a large number of annotation schemes. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
Soares L.B.; FitzGerald N.; Ling J.; Kwiatkowski T.,"Soares, Livio Baldini (57216610257); FitzGerald, Nicholas (57217780299); Ling, Jeffrey (57216611810); Kwiatkowski, Tom (51665167200)",57216610257; 57217780299; 57216611810; 51665167200,Matching the blanks: Distributional similarity for relation learning,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079536261&partnerID=40&md5=c65cc795f689df7463f4370683e78c90,"General purpose relation extractors, which can model arbitrary relations, are a core aspiration in information extraction. Efforts have been made to build general purpose extractors that represent relations with their surface forms, or which jointly embed surface forms with relations from an existing knowledge graph. However, both of these approaches are limited in their ability to generalize. In this paper, we build on extensions of Harris' distributional hypothesis to relations, as well as recent advances in learning text representations (specifically, BERT), to build task agnostic relation representations solely from entity-linked text. We show that these representations significantly outperform previous work on exemplar based relation extraction (FewRel) even without using any of that task's training data. We also show that models initialized with our task agnostic representations, and then tuned on supervised relation extraction datasets, significantly outperform the previous methods on SemEval 2010 Task 8, KBP37, and TACRED. © 2019 Association for Computational Linguistics.",Final,
Grubišić A.; Stankov S.; Žitko B.; Šarić-Grgić I.; Gašpar A.; Tomaš S.; Brajković E.; Vasić D.,"Grubišić, Ani (24485216400); Stankov, Slavomir (7004012806); Žitko, Branko (24485775500); Šarić-Grgić, Ines (57190032480); Gašpar, Angelina (57218312001); Tomaš, Suzana (24279057100); Brajković, Emil (56205769200); Vasić, Daniel (57126955700)",24485216400; 7004012806; 24485775500; 57190032480; 57218312001; 24279057100; 56205769200; 57126955700,Declarative knowledge extraction in the ac&nl tutor,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088748576&doi=10.1007%2f978-3-030-50788-6_22&partnerID=40&md5=44da20a39d2ce28af637d6d95c903ee1,"Automatic knowledge acquisition is a rather complex and challenging task. This paper focuses on the description and evaluation of a semi-automatic authoring tool (SAAT) that has been developed as a part of the Adaptive Courseware based on Natural Language AC&NL Tutor project. The SAAT analyzes a natural language text and, as a result of the declarative knowledge extraction process, it generates domain knowledge that is presented in a form of natural language sentences, questions and domain knowledge graphs. Generated domain knowledge presents expert knowledge in the intelligent tutoring system Tutomat. The natural language processing techniques are applied and the tool’s functionalities are thoroughly explained. This tool is, to our knowledge, the only one that enables natural language question and sentence generation of different levels of complexity. Using an unstructured and unprocessed Wikipedia text in computer science, evaluation of domain knowledge extraction algorithm, i.e. the correctness of extraction outcomes and the effectiveness of extraction methods, was performed. The SAAT outputs were compared with the gold standard, manually developed by two experts. The results showed that 68.7% of detected errors referred to the performance of the integrated linguistic resources, such as CoreNLP, Senna, WordNet, whereas 31.3% of errors referred to the proposed extraction algorithms. © Springer Nature Switzerland AG 2020.",Final,
Chiarcos C.; Glaser L.,"Chiarcos, Christian (22333764800); Glaser, Luis (57211408572)",22333764800; 57211408572,A tree extension for CoNLL-RDF,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512746&partnerID=40&md5=799b8e3545181d57c12c09256db0720f,"The technological bridges between knowledge graphs and natural language processing are of utmost importance for the future development of language technology. CoNLL-RDF is a technology that provides such a bridge for popular one-word-per-line formats with tab-separated values (TSV) that are widely used in NLP (e.g., the CoNLL Shared Tasks), annotation (Universal Dependencies, Unimorph), corpus linguistics (Corpus WorkBench, CWB) and digital lexicography (SketchEngine): Every empty-line separated table (usually a sentence) is parsed into an graph, can be freely manipulated and enriched using standard graph technology, and then be serialized back into in a TSV format, RDF or other formats. An important limitation is that CoNLL-RDF provides native support for word-level annotations only. This does include dependency syntax and semantic role annotations, but neither phrase structures nor text structure. We describe the extension of the CoNLL-RDF technology stack for two vocabulary extensions of CoNLL-TSV, the bracket notation used in earlier CoNLL Shared Tasks and the extension with XML markup elements featured by CWB and SketchEngine. In order to represent the necessary extensions of the CoNLL vocabulary in an adequate fashion, we employ the POWLA vocabulary for representing and navigating in tree structures. © European Language Resources Association (ELRA), licensed under CC-BY-NC",Final,
,,,"22nd International Conference on Human-Computer Interaction,HCII 2020",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092909334&partnerID=40&md5=6ef9e1ffbf60ebd063a108e004e3e415,"The proceedings contain 140 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Human Factors Evaluation Principals for Civil Aircraft Flight Deck Controls Design and Integration; reviewing and Predicting Human-Machine Cooperation Based on Knowledge Graph Analysis; Adoption of the HTA Technique in the Open Source Software Development Process; exploring the Digital Native Assessment Scale as an Indicator for Building More Effective User Experiences; the Aware User Experience Model, Its Method of Construction and Derived Heuristics; is It Possible to Predict Human Perception of Video Quality? The Assessment of Sencogi Quality Metric; play to Improve: Gamifying Usability Evaluations in Virtual Reality; assessing the Human Factor of Cybersecurity: Can Surveys Tell the Truth?; creating a Feedback Loop Between Persona Development and User Research Towards Better Technology Acceptance; investigating a Design Space for Developing Design Thinking in Electronic Healthcare Records; research on Kansei of Visual Literacy of Regional Cultural Experience in Product Shaping Design; research on Servicesecape Innovation Methods Based on Design Thinking; cocreating Value with Customers: A Case Study of a Technology-Based Startup; strategies for Smart Service Prototypes - Implications for the Requirements Elicitation in the Early Development Stages; an Integrated Framework of Product Kansei Decision-Making Based on Hesitant Linguistic Fuzzy Term Sets; positioning Participant Engagement in Participatory Design; Increasing Awareness of Avalanche DANGER: Redesigning a Bulletin; explore an Evolution of Physical Education Based on Virtual Reality Lab for Traditional Ethnic Minorities’ Sports; information Design to Save Lives: Visualizing Data in the Design of Overdose Kits.",Final,
,,,"14th International Conference on Computational Processing of the Portuguese Language, PROPOR 2020",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081626719&partnerID=40&md5=dfe6645fad91d0755bd1c45efbb819f4,"The proceedings contain 41 papers. The special focus in this conference is on Computational Processing of the Portuguese Language. The topics include: Aligning IATE criminal terminology to SUMO; the construction of a corpus from the Brazilian historical-biographical dictionary; making the most of synthetic parallel texts: Portuguese-Chinese neural machine translation enhanced with back-translation; leveraging on semantic textual similarity for developing a Portuguese dialogue system; fake news detection on fake.br using hierarchical attention networks; Screening of email box in Portuguese with SVM at Banco do Brasil; back to the feature, in entailment detection and similarity measurement for Portuguese; emoji prediction for Portuguese; vitality analysis of the linguistic atlas of Brazil on Twitter; fact-checking for Portuguese: Knowledge graph and google search-based methods; comparison of heterogeneous feature sets for intonation verification; extraction and use of structured and unstructured features for the recommendation of urban resources; a Portuguese dataset for evaluation of semantic question answering; exploring the potentiality of semantic features for paraphrase detection; portuguese language models and word embeddings: Evaluating on semantic similarity tasks; relation extraction for competitive intelligence; evaluating methods of different paradigms for subjectivity classification in portuguese; sentence compression for Portuguese; an investigation of pre-trained embeddings in dependency parsing; segmentation of words written in the latin alphabet: A systematic review; a deep learning model of common sense knowledge for augmenting natural language processing tasks in Portuguese language; the biovisualspeech European Portuguese sibilants corpus; linguistic analysis model for monitoring user reaction on satirical news for Brazilian Portuguese; word embeddings at post-editing.",Final,
Yu H.; Jiang R.; Zhou B.; Li A.,"Yu, Han (57212576076); Jiang, Rong (35072647900); Zhou, Bin (55501961000); Li, Aiping (57217320818)",57212576076; 35072647900; 55501961000; 57217320818,Knowledge-Infused Pre-trained Models for KG Completion,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096553199&doi=10.1007%2f978-3-030-62005-9_20&partnerID=40&md5=0e38e9e4b4d338835a2b1eba3a840d6a,"Knowledge graphs (KG) are the basis for many artificial intelligence applications but still suffer from incompleteness. In this paper, we introduce a novel method for KG completion task by knowledge-infused pre-trained language models. We represent each triple in the KG as textual sequences and transform the KG completion task into a sentence classification task that fits the input of the language model. Our KG completion framework based on the knowledge-infused pre-trained language model which can capture both linguistic information and factual knowledge to compute the plausible of the triples. Experiments show that our method achieves better results than previous state-of-the-art on multiple benchmark datasets. © 2020, Springer Nature Switzerland AG.",Final,
,,,"18th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems, IPMU 2020",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086243491&partnerID=40&md5=f12e0e3bc7259e9067c26bc89ae4266b,"The proceedings contain 175 papers. The special focus in this conference is on Information Processing and Management of Uncertainty in Knowledge-Based Systems. The topics include: Investigation of Ranking Methods Within the Military Value of Information (VoI) Problem Domain; combining Multi-Agent Systems and Subjective Logic to Develop Decision Support Systems; decision Under Ignorance: A Comparison of Existing Criteria; multi-agent Systems and Voting: How Similar Are Voting Procedures; softening the Robustness of Optimization Problems: A New Budgeted Uncertainty Approach; hierarchical Reasoning and Knapsack Problem Modelling to Design the Ideal Assortment in Retail; towards Multi-perspective Conformance Checking with Aggregation Operations; on the Impact of Fuzzy Constraints in the Variable Size and Cost Bin Packing Problem; artificial Bee Colony Algorithm Applied to Dynamic Flexible Job Shop Problems; fuzzy Memories of Enrique Hector Ruspini (1942–2019); from Truth Degree Comparison Games to Sequents-of-Relations Calculi for Gödel Logic; ordinal Graph-Based Games; on Relevance of Linguistic Summaries – A Case Study from the Agro-Food Domain; data-Driven Classifiers for Predicting Grass Growth in Northern Ireland: A Case Study; forecasting Electricity Consumption in Residential Buildings for Home Energy Management Systems; solving Dynamic Delivery Services Using Ant Colony Optimization; acoustic Feature Selection with Fuzzy Clustering, Self Organizing Maps and Psychiatric Assessments; concept Membership Modeling Using a Choquet Integral; using Topic Information to Improve Non-exact Keyword-Based Search for Mobile Applications; a Graph Theory Approach to Fuzzy Rule Base Simplification; from Eliza to Siri and Beyond; MaTED: Metadata-Assisted Twitter Event Detection System; Image-Based World-perceiving Knowledge Graph (WpKG) with Imprecision; maximal Clique Based Influence Maximization in Networks.",Final,
Ionov M.; Stein F.; Sehgal S.; Chiarcos C.,"Ionov, Maxim (57194612761); Stein, Florian (57220205384); Sehgal, Sagar (57220203253); Chiarcos, Christian (22333764800)",57194612761; 57220205384; 57220203253; 22333764800,cqp4rdf: Towards a Suite for RDF-Based Corpus Linguistics,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097293798&doi=10.1007%2f978-3-030-62327-2_20&partnerID=40&md5=610f4896ecfbcca305f259d48fdb01e4,"In this paper, we present cqp4rdf, a set of tools for creating and querying corpora with linguistic annotations. cqp4rdf builds on CQP, an established corpus query language widely used in the areas of computational lexicography and empirical linguistics, and allows to apply it to corpora represented in RDF. This is in line with the emerging trend of RDF-based corpus formats that provides several benefits over more traditional ways, such as support for virtually unlimited types of annotation, linking of corpus elements between multiple datasets, and simultaneously querying distributed language resources and corpora with different annotations. On the other hand, application support tailored for such corpora is virtually nonexistent, leaving corpus linguist with SPARQL as the query language. Being extremely powerful, it has a relatively steep learning curve, especially for people without computer science background. At the same time, using query languages designed for classic corpus management software limits the vast possibilities of RDF-based corpora. We present the middle ground aiming to bridge the gap: the interface that allows to query RDF corpora and explore the results in a linguist-friendly way. © 2020, Springer Nature Switzerland AG.",Final,
,,,"22nd International Conference on Human-Computer Interaction,HCII 2020",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092889722&partnerID=40&md5=6a699b817a7cfdd7b3e0637be92e02f5,"The proceedings contain 140 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Human Factors Evaluation Principals for Civil Aircraft Flight Deck Controls Design and Integration; reviewing and Predicting Human-Machine Cooperation Based on Knowledge Graph Analysis; Adoption of the HTA Technique in the Open Source Software Development Process; exploring the Digital Native Assessment Scale as an Indicator for Building More Effective User Experiences; the Aware User Experience Model, Its Method of Construction and Derived Heuristics; is It Possible to Predict Human Perception of Video Quality? The Assessment of Sencogi Quality Metric; play to Improve: Gamifying Usability Evaluations in Virtual Reality; assessing the Human Factor of Cybersecurity: Can Surveys Tell the Truth?; creating a Feedback Loop Between Persona Development and User Research Towards Better Technology Acceptance; investigating a Design Space for Developing Design Thinking in Electronic Healthcare Records; research on Kansei of Visual Literacy of Regional Cultural Experience in Product Shaping Design; research on Servicesecape Innovation Methods Based on Design Thinking; cocreating Value with Customers: A Case Study of a Technology-Based Startup; strategies for Smart Service Prototypes - Implications for the Requirements Elicitation in the Early Development Stages; an Integrated Framework of Product Kansei Decision-Making Based on Hesitant Linguistic Fuzzy Term Sets; positioning Participant Engagement in Participatory Design; Increasing Awareness of Avalanche DANGER: Redesigning a Bulletin; explore an Evolution of Physical Education Based on Virtual Reality Lab for Traditional Ethnic Minorities’ Sports; information Design to Save Lives: Visualizing Data in the Design of Overdose Kits.",Final,
Nevzorova O.; Shakirova L.; Falileeva M.; Kirillovich A.; Nevzorov V.; Lipachev E.,"Nevzorova, Olga (6506234633); Shakirova, Liliana (56998615300); Falileeva, Marina (57204181811); Kirillovich, Alexander (55994716700); Nevzorov, Vladimir (55995074700); Lipachev, Evgeny (6505830683)",6506234633; 56998615300; 57204181811; 55994716700; 55995074700; 6505830683,OntoMathEdu educational mathematical ontology: Annotation of concepts,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092283061&partnerID=40&md5=21a48296ed0f050160d7e8f8a3867403,"This work is dedicated to population of the OntoMathEdu ontology by definitions of mathematical concepts. OntoMathEdu is a new educational mathematical ontology, intended to be used as a Linked Open Data hub for mathematical education, a linguistic resource for intelligent mathematical language processing and an end-user reference educational database. We propose a template-based method for auto-matical extraction of definitions from educational mathematical texts in Russian. The method has been implemented on the base of the “OntoIntegrator” system and evaluated on a collection of educational texts from the yaklass.ru website. The obtained F-measure is 89.2%. © 2020 Copyright for this paper by its authors.",Final,
Cheng L.; Wu D.; Bing L.; Zhang Y.; Jie Z.; Lu W.; Si L.,"Cheng, Liying (57219738126); Wu, Dekun (57216965763); Bing, Lidong (24314897600); Zhang, Yan (57223748565); Jie, Zhanming (57155963900); Lu, Wei (57220644305); Si, Luo (7006717974)",57219738126; 57216965763; 24314897600; 57223748565; 57155963900; 57220644305; 7006717974,ENT-DESC: Entity description generation by exploring knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098436623&partnerID=40&md5=8ab49be60e4ae7b308d8bbbec1cd8093,"Previous works on knowledge-to-text generation take as input a few RDF triples or key-value pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of information loss and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture. © 2020 Association for Computational Linguistics",Final,
Ji Z.; Dai L.; Pang J.; Shen T.,"Ji, Zizheng (57215773951); Dai, Lin (36068815200); Pang, Jin (57217177082); Shen, Tingting (57215774614)",57215773951; 36068815200; 57217177082; 57215774614,Leveraging Concept-Enhanced Pre-Training Model and Masked-Entity Language Model for Named Entity Disambiguation,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086635606&doi=10.1109%2fACCESS.2020.2994247&partnerID=40&md5=8880e05eb1e0572c34ce6bb7e12fa3c4,"Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in an input-text sequence to their correct references in a knowledge graph. We tackle NED problem by leveraging two novel objectives for pre-training framework, and propose a novel pre-training NED model. Especially, the proposed pre-training NED model consists of: (i) concept-enhanced pre-training, aiming at identifying valid lexical semantic relations with the concept semantic constraints derived from external resource Probase; and (ii) masked entity language model, aiming to train the contextualized embedding by predicting randomly masked entities based on words and non-masked entities in the given input-text. Therefore, the proposed pre-training NED model could merge the advantage of pre-training mechanism for generating contextualized embedding with the superiority of the lexical knowledge (e.g., concept knowledge emphasized here) for understanding language semantic. We conduct experiments on the CoNLL dataset and TAC dataset, and various datasets provided by GERBIL platform. The experimental results demonstrate that the proposed model achieves significantly higher performance than previous models. © 2020 IEEE.",Final,All Open Access; Gold Open Access
Kalo J.-C.; Fichtel L.; Ehler P.; Balke W.-T.,"Kalo, Jan-Christoph (56241812800); Fichtel, Leandra (57220026231); Ehler, Philipp (57212020133); Balke, Wolf-Tilo (55882125200)",56241812800; 57220026231; 57212020133; 55882125200,KnowlyBERT - Hybrid Query Answering over Language Models and Knowledge Graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096523582&doi=10.1007%2f978-3-030-62419-4_17&partnerID=40&md5=298df314572f6ae44a99122047f6bfa2,"Providing a plethora of entity-centric information, Knowledge Graphs have become a vital building block for a variety of intelligent applications. Indeed, modern knowledge graphs like Wikidata already capture several billions of RDF triples, yet they still lack a good coverage for most relations. On the other hand, recent developments in NLP research show that neural language models can easily be queried for relational knowledge without requiring massive amounts of training data. In this work, we leverage this idea by creating a hybrid query answering system on top of knowledge graphs in combination with the masked language model BERT to complete query results. We thus incorporate valuable structural and semantic information from knowledge graphs with textual knowledge from language models to achieve high precision query results. Standard techniques for dealing with incomplete knowledge graphs are either (1) relation extraction which requires massive amounts of training data or (2) knowledge graph embeddings which have problems to succeed beyond simple baseline datasets. Our hybrid system KnowlyBERT requires only small amounts of training data, while outperforming state-of-the-art techniques by boosting their precision by over 30% in our large Wikidata experiment. © 2020, Springer Nature Switzerland AG.",Final,
Moon S.; Shah P.; Kumar A.; Subba R.,"Moon, Seungwhan (57216616433); Shah, Pararth (57207854850); Kumar, Anuj (57204045069); Subba, Rajen (55100251100)",57216616433; 57207854850; 57204045069; 55100251100,Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082383935&partnerID=40&md5=6d03b54489b80a0eca5f0a51d5300161,"We study a conversational reasoning model that strategically traverses through a large-scale common fact knowledge graph (KG) to introduce engaging and contextually diverse entities and attributes. For this study, we collect a new Open-ended Dialog ? KG parallel corpus called OpenDialKG, where each utterance from 15K human-to-human role-playing dialogs is manually annotated with ground-truth reference to corresponding entities and paths from a large-scale KG with 1M+ facts. We then propose the DialKG Walker model that learns the symbolic transitions of dialog contexts as structured traversals over KG, and predicts natural entities to introduce given previous dialog contexts via a novel domain-agnostic, attention-based graph path decoder. Automatic and human evaluations show that our model can retrieve more natural and human-like responses than the state-of-the-art baselines or rule-based models, in both in-domain and cross-domain tasks. The proposed model also generates a KG walk path for each entity retrieved, providing a natural way to explain conversational reasoning. © 2019 Association for Computational Linguistics",Final,
Capshaw R.; Kuhlmann M.; Blomqvist E.,"Capshaw, Riley (55343041300); Kuhlmann, Marco (55391940200); Blomqvist, Eva (8968017800)",55343041300; 55391940200; 8968017800,Probing a semantic dependency parser for translational relation embeddings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091084830&partnerID=40&md5=75ebc3a2ee20b9fa4aa7cfa8e54d50f1,"Translational relation models are primarily applied to the task of Knowledge Graph embedding. We present a structural probe for testing whether a state-of-the-art semantic dependency parser learns contextualized word representations which fit a translational relation model. We find that the parser does not explicitly learn a translational relation model. We do, however, find that a simple transformation of the word representations is enough to induce a TransE model with 73.45% label recall, indicating that translational relation models are at least implicitly learned by the parser. We believe that our findings can in the future be used to develop new Natural Language Understanding systems that are more useful for Knowledge Graph generation and completion. Copyright © 2020 for this paper by its authors.",Final,
Quaresma P.; Beires Nogueira V.; Raiyani K.; Bayot R.; Gonçalves T.,"Quaresma, Paulo (6602524705); Beires Nogueira, Vitor (14825682800); Raiyani, Kashyap (57203265515); Bayot, Roy (55232963600); Gonçalves, Teresa (8054218100)",6602524705; 14825682800; 57203265515; 55232963600; 8054218100,From Textual Information Sources to Linked Data in the Agatha Project,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084699925&doi=10.1007%2f978-3-030-46714-2_5&partnerID=40&md5=8860e37198ceca16d6eec1416c612e82,"Automatic reasoning about textual information is a challenging task in modern Natural Language Processing (NLP) systems. In this work we describe our proposal for representing and reasoning about Portuguese documents by means of Linked Data like ontologies and thesauri. Our approach resorts to a specialized pipeline of natural language processing (part-of-speech tagger, named entity recognition, semantic role labeling) to populate an ontology for the domain of criminal investigations. The provided architecture and ontology are language independent. Although some of the NLP modules are language dependent, they can be built using adequate AI methodologies. © 2020, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Zhang K.; Zhao X.; Zhuang L.; Xie Q.; Zan H.,"Zhang, Kunli (55009135800); Zhao, Xu (57221238881); Zhuang, Lei (8536867400); Xie, Qi (57220203668); Zan, Hongying (23391538300)",55009135800; 57221238881; 8536867400; 57220203668; 23391538300,Knowledge-Enabled Diagnosis Assistant Based on Obstetric EMRs and Knowledge Graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097276295&doi=10.1007%2f978-3-030-63031-7_32&partnerID=40&md5=9bc6fdf28da01c39c9cbe342a7e2e41d,"The obstetric Electronic Medical Record (EMR) contains a large amount of medical data and health information. It plays a vital role in improving the quality of the diagnosis assistant service. In this paper, we treat the diagnosis assistant as a multi-label classification task and propose a Knowledge-Enabled Diagnosis Assistant (KEDA) model for the obstetric diagnosis assistant. We utilize the numerical information in EMRs and the external knowledge from Chinese Obstetric Knowledge Graph (COKG) to enhance the text representation of EMRs. Specifically, the bidirectional maximum matching method and similarity-based approach are used to obtain the entities set contained in EMRs and linked to the COKG. The final knowledge representation is obtained by a weight-based disease prediction algorithm, and it is fused with the text representation through a linear weighting method. Experiment results show that our approach can bring about +3.53 F1 score improvements upon the strong BERT baseline in the diagnosis assistant task. © 2020, Springer Nature Switzerland AG.",Final,
Tao X.; Liua R.; Zhou X.,"Tao, Xin (57219327707); Liua, Renyuan (57212601567); Zhou, Xiaobing (55743213500)",57219327707; 57212601567; 55743213500,A tumor named entity recognition model based on pre-trained language model and attention mechanism,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092252349&partnerID=40&md5=417f36c546fb0ec909c407958b7d8684,"Named entity recognition is to recognize the mention of a certain thing or concept in a text in natural language processing, and it is the basis of many natural language processing tasks such as relation extraction, event extraction, knowledge graph, machine translation, and question answering systems. This paper describes the solution of CANTEMIST's named entity recognition subtask. The core idea of the method is to process it as a sequence labeling task and uses a neural sequence model to solve it. We use a pre-trained language model for semantic feature embedding, a recurrent neural network for semantic inference, and a label-based attention mechanism to predict the output. In the final test, our F1 score is 0.719. © 2020 Copyright for this paper by its authors. Use permitted under.",Final,
Kirillovich A.; Nevzorova O.; Falileeva M.; Lipachev E.; Shakirova L.,"Kirillovich, Alexander (55994716700); Nevzorova, Olga (6506234633); Falileeva, Marina (57204181811); Lipachev, Evgeny (6505830683); Shakirova, Liliana (56998615300)",55994716700; 6506234633; 57204181811; 6505830683; 56998615300,OntomathEdu: A linguistically grounded educational mathematical ontology,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089216152&doi=10.1007%2f978-3-030-53518-6_10&partnerID=40&md5=6c7f4cba07d2556bd3b09404b44af0ce,"We present the first release of OntoMathEdu, a new educational mathematical ontology. The ontology is intended to be used as a Linked Open Data hub for mathematical education, a linguistic resource for intelligent mathematical language processing and an end-user reference educational database. The ontology is organized in three layers: a foundational ontology layer, a domain ontology layer and a linguistic layer. The domain ontology layer contains language-independent concepts, covering secondary school mathematics curriculum. The linguistic layer provides linguistic grounding for these concepts, and the foundation ontology layer provides them with meta-ontological an-notations. The concepts are organized in two main hierarchies: the hierarchy of objects and the hierarchy of reified relationships. For our knowledge, OntoMathEdu is the first Linked Open Data mathematical ontology, that respects ontological distinctions provided by a foundational ontology; represents mathematical relationships as first-oder entities; and provides strong linguistic grounding for the represented mathematical concepts. © Springer Nature Switzerland AG 2020.",Final,
Xiao D.; Wang N.; Yu J.; Zhang C.; Wu J.,"Xiao, Dinghe (57219715001); Wang, Nannan (57220209445); Yu, Jiangang (57219710937); Zhang, Chunhong (17347108000); Wu, Jiaqi (57220210051)",57219715001; 57220209445; 57219710937; 17347108000; 57220210051,A Practice of Tourism Knowledge Graph Construction Based on Heterogeneous Information,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097289354&doi=10.1007%2f978-3-030-63031-7_12&partnerID=40&md5=8c013f791213ddc22498e7ebd071c391,"The increasing amount of semi-structured and unstructured data on tourism websites brings a need for information extraction (IE) so as to construct a Tourism-domain Knowledge Graph (TKG), which is helpful to manage tourism information and develop downstream applications such as tourism search engine, recommendation and Q & A. However, the existing TKG is deficient, and there are few open methods to promote the construction and widespread application of TKG. In this paper, we present a systematic framework to build a TKG for Hainan, collecting data from popular tourism websites and structuring it into triples. The data is multi-source and heterogeneous, which raises a great challenge for processing it. So we develop two pipelines of processing methods for semi-structured data and unstructured data respectively. We refer to tourism InfoBox for semi-structured knowledge extraction and leverage deep learning algorithms to extract entities and relations from unstructured travel notes, which are colloquial and high-noise, and then we fuse the extracted knowledge from two sources. Finally, a TKG with 13 entity types and 46 relation types is established, which totally contains 34,079 entities and 441,371 triples. The systematic procedure proposed by this paper can construct a TKG from tourism websites, which can further applied to many scenarios and provide detailed reference for the construction of other domain-specific knowledge graphs. © 2020, Springer Nature Switzerland AG.",Final,
,,,"22nd International Conference on Human-Computer Interaction,HCII 2020",-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092893826&partnerID=40&md5=e318dd6a48a35d61250d0316dea716bc,"The proceedings contain 140 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Human Factors Evaluation Principals for Civil Aircraft Flight Deck Controls Design and Integration; reviewing and Predicting Human-Machine Cooperation Based on Knowledge Graph Analysis; Adoption of the HTA Technique in the Open Source Software Development Process; exploring the Digital Native Assessment Scale as an Indicator for Building More Effective User Experiences; the Aware User Experience Model, Its Method of Construction and Derived Heuristics; is It Possible to Predict Human Perception of Video Quality? The Assessment of Sencogi Quality Metric; play to Improve: Gamifying Usability Evaluations in Virtual Reality; assessing the Human Factor of Cybersecurity: Can Surveys Tell the Truth?; creating a Feedback Loop Between Persona Development and User Research Towards Better Technology Acceptance; investigating a Design Space for Developing Design Thinking in Electronic Healthcare Records; research on Kansei of Visual Literacy of Regional Cultural Experience in Product Shaping Design; research on Servicesecape Innovation Methods Based on Design Thinking; cocreating Value with Customers: A Case Study of a Technology-Based Startup; strategies for Smart Service Prototypes - Implications for the Requirements Elicitation in the Early Development Stages; an Integrated Framework of Product Kansei Decision-Making Based on Hesitant Linguistic Fuzzy Term Sets; positioning Participant Engagement in Participatory Design; Increasing Awareness of Avalanche DANGER: Redesigning a Bulletin; explore an Evolution of Physical Education Based on Virtual Reality Lab for Traditional Ethnic Minorities’ Sports; information Design to Save Lives: Visualizing Data in the Design of Overdose Kits.",Final,
Xu C.; Li R.,"Xu, Canran (57205612086); Li, Ruijiang (55491414600)",57205612086; 55491414600,Relation embedding with dihedral group in knowledge graph,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084067724&partnerID=40&md5=a289b093b0f23d116e1cc530cbab47c9,"Link prediction is critical for the application of incomplete knowledge graph (KG) in the downstream tasks. As a family of effective approaches for link predictions, embedding methods try to learn low-rank representations for both entities and relations such that the bilinear form defined therein is a well-behaved scoring function. Despite of their successful performances, existing bilinear forms overlook the modeling of relation compositions, resulting in lacks of interpretability for reasoning on KG. To fulfill this gap, we propose a new model called DihEdral, named after dihedral symmetry group. This new model learns knowledge graph embeddings that can capture relation compositions by nature. Furthermore, our approach models the relation embeddings parametrized by discrete values, thereby decrease the solution space drastically. Our experiments show that DihEdral is able to capture all desired properties such as (skew-) symmetry, inversion and (non-) Abelian composition, and outperforms existing bilinear form based approach and is comparable to or better than deep learning models such as ConvE (Dettmers et al., 2018). © 2019 Association for Computational Linguistics",Final,
Nathani D.; Chauhan J.; Sharma C.; Kaul M.,"Nathani, Deepak (57204819578); Chauhan, Jatin (57216612072); Sharma, Charu (56508977400); Kaul, Manohar (55568300900)",57204819578; 57216612072; 56508977400; 55568300900,Learning attention-based embeddings for relation prediction in knowledge graphs,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078276909&partnerID=40&md5=a4dd91ff4cbe4f6292485d1e72dd0f88,"The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets. © 2019 Association for Computational Linguistics",Final,
,,,CEUR Workshop Proceedings,-1,,-1,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078480111&partnerID=40&md5=ce97ff75912e588b34452a0fa38df8a8,The proceedings contain 14 papers. The topics discussed include: knowledge graph based analysis and exploration of historical theatre photographs; putting research-based machine learning solutions for subject indexing into practice; a simple and efficient approach for the semi-automated curation for media reviews; ontology-based entity recognition and annotation; application of deep learning techniques to digital holographic microscopy for numerical reconstruction; a data-driven platform for creating educational content in language learning; crowdsourcing versus the laboratory: towards crowd-based linguistic text quality assessment of query-based extractive summarization; and QURATOR: innovative technologies for content and data curation.,Final,
Huang X.; Lin J.; Teng W.; Bao Y.,"Huang, Xiao (8958031300); Lin, Jialiang (57215565335); Teng, Wei (57215563314); Bao, Yanxiang (7202213509)",8958031300; 57215565335; 57215563314; 7202213509,Relation Classification via CNNs with Attention Mechanism for Multi-Window-Sized Kernels,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081180944&doi=10.1109%2fIAEAC47372.2019.8997966&partnerID=40&md5=b12a98a1e968347706a297b51b09a673,"Relation classification is an important ingredient task in the construction of knowledge graph, question answering system and numerous other natural language processing (NLP) tasks. With the application of deep neural networks (DNNs) such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs), relation classification task has achieved satisfactory results. However, many proposed models can not take well advantages of multiple window sizes for filters in CNNs and finally hurt the performance of this task. Moreover, unlike public and general dataset that has a large quantity of instances from natural languages or daily conversations, the performances of many deep neural networks with high complexity are not well enough for a small corpus in specific fields. To work out these problems, we propose a novel CNN model with attention mechanism for multi-window-sized kernels to capture the most important information and test our system not only on a general dataset of SemEval 2010 but also on a small dataset built from Chinese fundamentals of electric circuits textbook artificially. The experimental results show that our system outperforms the baseline systems for the SemEval 2010 relation classification task and validate the effectiveness of CNN on the specific Chinese small corpus relation classification task. © 2019 IEEE.",Final,
Zhang Y.; Qian S.; Fang Q.; Xu C.,"Zhang, Yingying (57215143073); Qian, Shengsheng (56038690300); Fang, Quan (55441705700); Xu, Changsheng (56153258200)",57215143073; 56038690300; 55441705700; 56153258200,Multi-modal knowledge-aware hierarchical attention network for explainable medical question answering,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074848363&doi=10.1145%2f3343031.3351033&partnerID=40&md5=bc8fb7162b002b6353a19f95f3e8669b,"Online healthcare services can offer public ubiquitous access to the medical knowledge, especially with the emergence of medical question answering websites, where patients can get in touch with doctors without going to hospital. Explainability and accuracy are two main concerns for medical question answering. However, existing methods mainly focus on accuracy and cannot provide a good explanation for retrieved medical answers. This paper proposes a novel Multi-Modal Knowledge-aware Hierarchical Attention Network (MKHAN) to effectively exploit multi-modal knowledge graph (MKG) for explainable medical question answering. MKHAN can generate path representation by composing the structural, linguistics, and visual information of entities, and infer the underlying rationale of question-answer interactions by leveraging the sequential dependencies within a path from MKG. Furthermore, a novel hierarchical attention network is proposed to discriminate the salience of paths endowing our model with explainability. We build a large-scale multi-modal medical knowledge graph and two real-world medical question answering datasets, the experimental results demonstrate the superior performance on our approach compared with the state-of-the-art methods. © 2019 Association for Computing Machinery.",Final,
Bamatraf S.A.; Binthalab R.A.,"Bamatraf, Seham A. (57216313133); Binthalab, Rasha A. (57216311644)",57216313133; 57216311644,Clustering RDF data using K-medoids,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083077906&doi=10.1109%2fICOICE48418.2019.9035160&partnerID=40&md5=334617dd9f6eaee26b43a372cedfb783,"Semantic web is a knowledge graph formed around semantic languages to enable computers and software to understand contents on the web. The content is explicitly annotated with semantic metadata using Resource Description Framework (RDF) language. However, the main issue is how to efficiently retrieve the RDF data taking into account a wide variety semantic and syntax nature and large-scale of such data. This paper aims to introduce a novel mechanism based on K-medoids algorithm for narrowing down the contents of the Web to clusters pertaining subset of information. We integrated sequence alignment algorithms with linguistic similarity measures to build a distance matrix which is used later in K-medoids clustering algorithm. The experimental outcomes showed a promised result for accuracy and quality of clustering. © 2019 IEEE.",Final,
Hei X.; Chen Y.; Zhu L.; Zhao Q.; Pan L.,"Hei, Xinhong (6603068061); Chen, Yi (57205604841); Zhu, Lei (57202316382); Zhao, Qin (55743367800); Pan, Long (57215501709)",6603068061; 57205604841; 57202316382; 55743367800; 57215501709,A Novel Chinese Word Segmentation Method for Rail Transit Codes,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084748251&doi=10.1109%2fAIAM48774.2019.00065&partnerID=40&md5=50e086722eeb73b2e47dbc76ec0e35ce,"The rail transit Codes contain a large number of schemaless data and text, which are difficult to extract and process. Knowledge Graph can handle large-scale schemaless data, thus it is used to effectively store and manipulate relevant information of rail transit Codes. As an essential component, Chinese word segmentation is a difficult problem for building the Knowledge Graph of rail transit Codes. In this paper, we propose a bi-directional maximum matching algorithm and some rules based Chinese word segmentation method, for design Codes of rail transit. In the proposed method, the item information, attribute values and Code names are first segmented by preprocessing. Then, the bidirectional matching algorithm with double dictionary is used to generate the preliminary results. Finally, the preliminary results are further optimized with rules to generate the final results. With testing some design Codes, the experimental results show that the proposed method can improve the accuracy and efficiency of Chinese word segmentation in this field, and it can deal with the update of noun entity library. © 2019 IEEE.",Final,
Gillis-Webber F.; Tittel S.; Keet C.M.,"Gillis-Webber, Frances (57204543421); Tittel, Sabine (36165030000); Keet, C. Maria (8964217800)",57204543421; 36165030000; 8964217800,A Model for Language Annotations on the Web,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066158918&doi=10.1007%2f978-3-030-21395-4_1&partnerID=40&md5=2f1e82ade354c7a4314cd6618e7ac3de,"Several annotation models have been proposed to enable a multilingual Semantic Web. Such models hone in on the word and its morphology and assume the language tag and URI comes from external resources. These resources, such as ISO 639 and Glottolog, have limited coverage of the world’s languages and have a very limited thesaurus-like structure at best, which hampers language annotation, hence constraining research in Digital Humanities and other fields. To resolve this ‘outsourced’ task of the current models, we developed a model for representing information about languages, the Model for Language Annotation (MoLA), such that basic language information can be recorded consistently and therewith queried and analyzed as well. This includes the various types of languages, families, and the relations among them. MoLA is formalized in OWL so that it can integrate with Linguistic Linked Data resources. Sufficient coverage of MoLA is demonstrated with the use case of French. © 2019, Springer Nature Switzerland AG.",Final,
Ali L.; Mathew L.S.,"Ali, Lamiya (57209241372); Mathew, Linda Sara (57190161560)",57209241372; 57190161560,Knowledge base construction from unstructured text,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067081618&partnerID=40&md5=16eb866101edb2a4b5990be6da0740c6,"Knowledge base assumes a critical job in numerous cutting edge applications. Developing learning base from unstructured content is a testing issue because of its inclination. Subsequently, numerous methodologies propose to change unstructured content to organized content so as to make an Knowledge base. Such methodologies can't yet give sensible outcomes to mapping an extricated predicate to its indistinguishable predicate in another information base. Predicate mapping is a basic system since it can lessen the heterogeneity issue and increment accessibility over the portrayal. A learning base development framework is proposed. In the framework, a mixture mix of a standard based methodology and a closeness based methodology is exhibited for mapping a predicate to its indistinguishable predicate in an information base portrayal. Changing unstructured content into a formal portrayal is a vital objective of the Semantic Web so as to encourage the mix and recovery of data. The development of Knowledge Graphs (KGs) seeks after such a thought, where named elements (genuine things) and their relations are separated from content. The procedure incorporates substance acknowledgment, element goals, element connecting, connection extraction lastly the RDF readiness. For such reason, procedures for favoring the extraction and connecting of named substances with KG people, and also, their relationship with syntactic units that lead to creating increasingly rational certainties are displayed. It likewise gives choices to choosing the extricated data components for making possibly valuable RDF triples for the KG. The incorporation of data extraction units with linguistic structures give a superior comprehension of recommendation based development of KGs. © BEIESP.",Final,
Kirillovich A.; Nevzorova O.; Falileeva M.; Lipachev E.; Shakirova L.,"Kirillovich, Alexander (55994716700); Nevzorova, Olga (6506234633); Falileeva, Marina (57204181811); Lipachev, Evgeny (6505830683); Shakirova, Liliana (56998615300)",55994716700; 6506234633; 57204181811; 6505830683; 56998615300,OntoMathEdu: Towards an educational mathematical ontology,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099404354&partnerID=40&md5=93ed7dffb2906f544896b1d8b2abc68b,"We present OntoMathEdu, a new educational mathematical ontology. This ontology is intended to be a Linked Open Data hub for mathematical education, a linguistic resource for intelligent mathematical language processing and an end-user reference educational database. OntoMathEdu is organized in three layers: a foundational ontology layer, a domain ontology layer and a linguistic layer. The domain ontology layer, in turn, consists of the following modules: a kind hierarchy, a hierarchy of reified relationships, a roles hierarchy, and a network of points of view. Currently, OntoMathEdu covers Euclidean plane geometry only, but we plan to extend it to the whole secondary school mathematics curriculum. We consider our work as a part of long-established trend of using Linked Open Data and ontologies in educational environments. © by the paper's authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Hyland-Wood D.; Harrison A.; Kolera B.,"Hyland-Wood, David (23488868100); Harrison, Anna (57209253201); Kolera, Ben (57209261947)",23488868100; 57209253201; 57209261947,Righting writing’s wrongs: Toward effective writing partnerships between humans and AI,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067084442&doi=10.13189%2fujer.2019.070516&partnerID=40&md5=ad0c6a4134d8473f8fcda8565dedf4b6,"In industrialised nations, we take for granted that knowledge is acquired and shared through a written medium, and yet the actual task of writing remains a hard skill to master. In this paper, we present a blueprint for the integration of artificial intelligence (AI) into Web-based text editors, and show that this contributes towards simplifying the writing task for authors. Our approach utilises the textual content of a document as input into existing artificial intelligence processes, extended with an RDF knowledge graph. The supplementary material from the AI partner is presented to an author for possible inclusion in their document. We separately evaluated two approaches to the presentation of linguistic tone analysis into editors. Our results from unmoderated observational user tests validate the premise that cognitive technology can simplify the writing task, and show that design is critical to the adoption of cognitive technologies. We conclude with lessons learned from deploying informal qualitative research sessions and online observational tests, and share opportunities for future work. We note that merely applying AI or any new technology to a human activity is patently insufficient. Our limited experience and evaluation suggest that design and user testing are necessary activities for adoption and acceptance. © 2019 by authors, all rights reserved.",Final,All Open Access; Gold Open Access
Nguyen D.Q.; Vu T.; Nguyen T.D.; Nguyen D.Q.; Phung D.,"Nguyen, Dai Quoc (56283158300); Vu, Thanh (56285989400); Nguyen, Tu Dinh (55884481900); Nguyen, Dat Quoc (35932254600); Phung, Dinh (7003397144)",56283158300; 56285989400; 55884481900; 35932254600; 7003397144,A capsule network-based embedding model for knowledge graph completion and search personalization,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084983993&partnerID=40&md5=04aeaf0f3b646ecb21e88b250ae5774b,"In this paper, we introduce an embedding model, named CapsE, exploring a capsule network to model relationship triples (subject, relation, object). Our CapsE represents each triple as a 3-column matrix where each column vector represents the embedding of an element in the triple. This 3-column matrix is then fed to a convolution layer where multiple filters are operated to generate different feature maps. These feature maps are reconstructed into corresponding capsules which are then routed to another capsule to produce a continuous vector. The length of this vector is used to measure the plausibility score of the triple. Our proposed CapsE obtains better performance than previous state-of-the-art embedding models for knowledge graph completion on two benchmark datasets WN18RR and FB15k-237, and outperforms strong search personalization baselines on SEARCH17. © 2019 Association for Computational Linguistics",Final,
Nastase V.; Kotnis B.,"Nastase, Vivi (8681915400); Kotnis, Bhushan (57344966200)",8681915400; 57344966200,Abstract graphs and abstract paths for knowledge graph completion,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103368360&partnerID=40&md5=0ff619db8faef37b349b0e0c1f87532d,"Knowledge graphs, which provide numerous facts in a machine-friendly format, are incomplete. Information that we induce from such graphs - e.g. entity embeddings, relation representations or patterns - will be affected by the imbalance in the information captured in the graph - by biasing representations, or causing us to miss potential patterns. To partially compensate for this situation we describe a method for representing knowledge graphs that capture an intensional representation of the original extensional information. This representation is very compact, and it abstracts away from individual links, allowing us to find better path candidates, as shown by the results of link prediction using this information. © 2019 Association for Computational Linguistics",Final,
Belz A.; Ford E.; Hoile R.; Mullick A.,"Belz, Anja (24831581600); Ford, Elizabeth (55357299700); Hoile, Richard (57207102125); Mullick, Azam (57340201300)",24831581600; 55357299700; 57207102125; 57340201300,Conceptualisation and annotation of drug nonadherence information for knowledge extraction from patient-generated texts,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107398817&partnerID=40&md5=607c7acfe33177c692ad5260b7f342a6,"Approaches to knowledge extraction (KE) in the health domain often start by annotating text to indicate the knowledge to be extracted, and then use the annotated text to train systems to perform the KE. This may work for annotating named entities or other contiguous noun phrases (drugs, some drug effects), but becomes increasingly difficult when items tend to be expressed across multiple, possibly noncontiguous, syntactic constituents (e.g. most descriptions of drug effects in user-generated text). Other issues include that it is not always clear how annotations map to actionable insights, or how they scale up to, or can form part of, more complex KE tasks. This paper reports our efforts in developing an approach to extracting knowledge about drug nonadherence from health forums which led us to conclude that development cannot proceed in separate steps but that all aspects-from conceptualisation to annotation scheme development, annotation, KE system training and knowledge graph instantiation-are interdependent and need to be co-developed. Our aim in this paper is two-fold: we describe a generally applicable framework for developing a KE approach, and present a specific KE approach, developed with the framework, for the task of gathering information about antidepressant drug nonadherence. We report the conceptualisation, the annotation scheme, the annotated corpus, and an analysis of annotated texts. © 2019 Association for Computational Linguistics",Final,
Wang R.; Wang M.; Liu J.; Chen W.; Cochez M.; Decker S.,"Wang, Ruijie (57219371499); Wang, Meng (56430062700); Liu, Jun (55904548100); Chen, Weitong (56477550000); Cochez, Michael (55814163300); Decker, Stefan (8846837500)",57219371499; 56430062700; 55904548100; 56477550000; 55814163300; 8846837500,Leveraging knowledge graph embeddings for natural language question answering,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065549868&doi=10.1007%2f978-3-030-18576-3_39&partnerID=40&md5=847d4a23bd13671acb5577eaec959c16,"A promising pathway for natural language question answering over knowledge graphs (KG-QA) is to translate natural language questions into graph-structured queries. During the translation, a vital process is to map entity/relation phrases of natural language questions to the vertices/edges of underlying knowledge graphs which can be used to construct target graph-structured queries. However, due to linguistic flexibility and ambiguity of natural language, the mapping process is challenging and has been a bottleneck of KG-QA models. In this paper, we propose a novel framework, called KemQA, which stands on recent advances in relation phrase dictionaries and knowledge graph embedding techniques to address the mapping problem and construct graph-structured queries of natural language questions. Extensive experiments were conducted on question answering benchmark datasets. The results demonstrate that our framework outperforms state-of-the-art baseline models in terms of effectiveness and efficiency. © Springer Nature Switzerland AG 2019.",Final,
,,,"4th International Conference on Human Centered Computing, HCC 2018",-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064610732&partnerID=40&md5=63386cfa37fffd63104b8ec8bf8afe1a,The proceedings contain 68 papers. The special focus in this conference is on Human Centered Computing. The topics include: Wi-Fi Attention Network for Indoor Fingerprint Positioning; Reinforcement Learning Based Cooperation Transmission Policy for HetNets with CoMP Technology; capacity Estimation of Time-Triggered Ethernet Network Based on Complex Network Theory; a New Communication P System Model Based on Hypergraph; Non-Orthogonal Multiple Access (NOMA) in Providing Services for High-Speed Railway and Local Users in DownLink MIMO System; research on Multi-agent Distributed Supply Chain Information Collaboration Based on Cloud Environment; mobile Internet Mobile Agent System Dynamic Trust Model for Cloud Computing; Single Image Super-Resolution by Parallel CNN with Skip Connections and ResNet; incorporating Description Embeddings into Medical Knowledge Graphs Representation Learning; Research on the Classification and Channel Selection of Emotional EEG; A Piezoelectric MEMS Harvester Suitable Adopt a New Two-Degree-of-Freedom Structure; spiking Neural P Systems with Time Delay; energy Efficiency MapReduce Job Scheduling of Shuffle and Reduce Phases in Data Center; research on Weibo Emotion Classification Based on Context; research on Data Visualization in Different Scenarios; model Checking for Turn-Based Probability Epistemic Game Structure; depressive Emotion Recognition Based on Behavioral Data; knowledge Graph Embedding by Translation Model on Subgraph; linguistic Signatures of Impulsive Buying Consumer Based on Microblog; Research on the Model of Anomaly Detection of FMCG Based on Time Series: Illustrated by the Case of Cosmetics; research on Real-Time Low Air Image Intelligence Image Acquisition and Processing Methods; research on Font Emotion Based on Semantic Difference Method; simulation Research on Aircraft Anti-collision Algorithm.,Final,
Li C.Y.; Liang X.; Hu Z.; Xing E.P.,"Li, Christy Y. (57208440165); Liang, Xiaodan (55926362100); Hu, Zhiting (56272615700); Xing, Eric P. (57685890100)",57208440165; 55926362100; 56272615700; 57685890100,"Knowledge-driven encode, retrieve, paraphrase for medical image report generation",-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079520690&partnerID=40&md5=6db4b8fd8ceb12ca11af1264322b2075,"Generating long and semantic-coherent reports to describe medical images poses great challenges towards bridging visual and linguistic modalities, incorporating medical domain knowledge, and generating realistic and accurate descriptions. We propose a novel Knowledge-driven Encode, Retrieve, Paraphrase (KERP) approach which reconciles traditional knowledge- and retrieval-based methods with modern learning-based methods for accurate and robust medical report generation. Specifically, KERP decomposes medical report generation into explicit medical abnormality graph learning and subsequent natural language modeling. KERP first employs an Encode module that transforms visual features into a structured abnormality graph by incorporating prior medical knowledge; then a Retrieve module that retrieves text templates based on the detected abnormalities; and lastly, a Paraphrase module that rewrites the templates according to specific cases. The core of KERP is a proposed generic implementation unit-Graph Transformer (GTR) that dynamically transforms high-level semantics between graph-structured data of multiple domains such as knowledge graphs, images and sequences. Experiments show that the proposed approach generates structured and robust reports supported with accurate abnormality description and explainable attentive regions, achieving the state-of-the-art results on two medical report benchmarks, with the best medical abnormality and disease classification accuracy and improved human evaluation performance. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
,,,"ICFET 2019 - Proceedings of 2019 5th International Conference on Frontiers of Educational Technologies, Workshop: ICKEA 2019 - 4th International Conference on Knowledge Engineering and Applications",-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123041241&partnerID=40&md5=b964bfa145e4b60bff0405ec0b7ac79b,The proceedings contain 32 papers. The topics discussed include: factors influencing student choice of transnational higher education in China; integration of linguistic and aesthetic education: an integrated cultural approach for teaching medical English; research on blended learning of equipment application courses in military academies; research on programming courses teaching based on blended learning; research of equipment comprehensive application course based on blended learning; cross-cultural adaptation questionnaire of South-Asian students in china mainland universities; research on teaching reform of educational technology public course under the background of educational information 2.0; representing experts’ interpretive trails with hyperknowledge specifications; explainable sequential recommendation using knowledge graphs; and application of visualization techniques in automatic identification system data analysis.,Final,
Laha A.; Jain P.; Mishra A.; Sankaranarayanan K.,"Laha, Anirban (57200078838); Jain, Parag (57214221258); Mishra, Abhijit (56349872900); Sankaranarayanan, Karthik (57204303874)",57200078838; 57214221258; 56349872900; 57204303874,Scalable micro-planned generation of discourse from structured data,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078461836&doi=10.1162%2fCOLIa00363&partnerID=40&md5=24a7437b8ccf6282d22036e6f07c8597,"We present a framework for generating natural language description from structured data such as tables; the problem comes under the category of data-to-text natural language generation (NLG). Modern data-to-text NLG systems typically use end-to-end statistical and neural architectures that learn from a limited amount of task-specific labeled data, and therefore exhibit limited scalability, domain-adaptability, and interpretability. Unlike these systems, ours is a modular, pipeline-based approach, and does not require task-specific parallel data. Rather, it relies on monolingual corpora and basic off-the-shelf NLP tools. This makes our system more scalable and easily adaptable to newer domains. Our system utilizes a three-staged pipeline that: (i) converts entries in the structured data to canonical form, (ii) generates simple sentences for each atomic entry in the canonicalized representation, and (iii) combines the sentences to produce a coherent, fluent, and adequate paragraph description through sentence compounding and co-reference replacement modules. Experiments on a benchmark mixed-domain data set curated for paragraph description from tables reveals the superiority of our system over existing data-to-text approaches. We also demonstrate the robustness of our system in accepting other popular data sets covering diverse data types such as knowledge graphs and key-value maps. © 2019 Association for Computational Linguistics.",Final,
Mehta A.; Singhal A.; Karlapalem K.,"Mehta, Aman (57203863789); Singhal, Aashay (57209222262); Karlapalem, Kamalakar (55908586300)",57203863789; 57209222262; 55908586300,Scalable knowledge graph construction over text using deep learning based predicate mapping,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066883504&doi=10.1145%2f3308560.3317708&partnerID=40&md5=a9f7161e47f9f88cb0bf4f6c7fbbf75e,"Automatic extraction of information from text and its transformation into a structured format is an important goal in both Semantic Web Research and computational linguistics. Knowledge Graphs (KG) serve as an intuitive way to provide structure to unstructured text. A fact in a KG is expressed in the form of a triple which captures entities and their interrelationships (predicates). Multiple triples extracted from text can be semantically identical but they may have a vocabulary gap which could lead to an explosion in the number of redundant triples. Hence, to get rid of this vocabulary gap, there is a need to map triples to a homogeneous namespace. In this work, we present an end-to-end KG construction system, which identifies and extracts entities and relationships from text and maps them to the homogenous DBpedia namespace. For Predicate Mapping, we propose a Deep Learning architecture to model semantic similarity. This mapping step is computation heavy, owing to the large number of triples in DBpedia. We identify and prune unnecessary comparisons to make this step scalable. Our experiments show that the proposed approach is able to construct a richer KG at a significantly lower computation cost with respect to previous work. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.",Final,
Bourns J.,"Bourns, Jeffrey (57209530209)",57209530209,Cherokee syllabary texts: Digital documentation and linguistic description,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068062009&doi=10.4230%2fOASIcs.LDK.2019.18&partnerID=40&md5=49a0ba022ee63af998e87b1e314e4a3c,"The Digital Archive of American Indian Languages Preservation and Perseverance (DAILP) is an innovative language revitalization project that seeks to provide digital infrastructure for the preservation and study of endangered languages among Native American speech communities. The project’s initial goal is to publish a digital collection of Cherokee-language documents to serve as the basis for language learning, cultural study, and linguistic research. Its primary texts derive from digitized manuscript images of historical Cherokee Syllabary texts, a written tradition that spans nearly two centuries. Of vital importance to DAILP is the participation and expertise of the Cherokee user community in processing such materials, specifically in Syllabary text transcription, romanization, and translation activities. To support the study and linguistic enrichment of such materials, the project is seeking to develop tools and services for the modeling, annotation, and sharing of DAILP texts and language data. © Jeffrey Bourns.",Final,
Abromeit F.; Chiarcos C.,"Abromeit, Frank (57198810784); Chiarcos, Christian (22333764800)",57198810784; 22333764800,Automatic detection of language and annotation model information in CoNLL corpora,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068049838&doi=10.4230%2fOASIcs.LDK.2019.23&partnerID=40&md5=19ac29ea35b92e82a2f68232bb5deaa5,"We introduce AnnoHub, an on-going effort to automatically complement existing language resources with metadata about the languages they cover and the annotation schemes (tagsets) that they apply, to provide a web interface for their curation and evaluation by means of domain experts, and to publish them as a RDF dataset and as part of the (Linguistic) Linked Open Data (LLOD) cloud. In this paper, we focus on tabular formats with tab-separated values (TSV), a de-facto standard for annotated corpora as popularized as part of the CoNLL Shared Tasks. By extension, other formats for which a converter to CoNLL and/or TSV formats does exist, can be processed analoguously. We describe our implementation and its evaluation against a sample of 93 corpora from the Universal Dependencies, v.2.3. © Frank Abromeit and Christian Chiarcos.",Final,
Ammanabrolu P.; Riedl M.O.,"Ammanabrolu, Prithviraj (57205542662); Riedl, Mark O. (7004421643)",57205542662; 7004421643,Playing text-adventure games with graph-based deep reinforcement learning,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084309358&partnerID=40&md5=d963a79c4d1dc698fbf1568ac13464d2,"Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN. © 2019 Association for Computational Linguistics",Final,
Zhang J.; Lertvittayakumjorn P.; Guo Y.,"Zhang, Jingqing (57201582643); Lertvittayakumjorn, Piyawat (57189246466); Guo, Yike (12765868000)",57201582643; 57189246466; 12765868000,Integrating semantic knowledge to tackle zero-shot text classification,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084312963&partnerID=40&md5=31fda81739e5648fc3effe72b16c09f9,"Insufficient or even unavailable training data of emerging classes is a big challenge of many classification tasks, including text classification. Recognising text documents of classes that have never been seen in the learning stage, so-called zero-shot text classification, is therefore difficult and only limited previous works tackled this problem. In this paper, we propose a two-phase framework together with data augmentation and feature augmentation to solve this problem. Four kinds of semantic knowledge (word embeddings, class descriptions, class hierarchy, and a general knowledge graph) are incorporated into the proposed framework to deal with instances of unseen classes effectively. Experimental results show that each and the combination of the two phases achieve the best overall accuracy compared with baselines and recent approaches in classifying real-world texts under the zero-shot scenario. © 2019 Association for Computational Linguistics",Final,
Li Y.; Chen X.; Bao Y.; Guo D.; Huang X.,"Li, Yuan (57221626262); Chen, Xiang (57192476724); Bao, Yanxiang (7202213509); Guo, Dongliang (55839236300); Huang, Xiao (8958031300)",57221626262; 57192476724; 7202213509; 55839236300; 8958031300,Relation extraction of Chinese fundamentals of electric circuits textbook based on CNN,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067892226&doi=10.1109%2fITNEC.2019.8729144&partnerID=40&md5=73dd4cf34e78a979c2a19cc7decce786,"Deep neural network has been widely used in a variety of natural language processing (NLP) tasks nowadays. As one of the most import research areas, entity relation extraction applies usual recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and has achieved good results. Most relation extraction tasks are about public and general datasets, they are usually natural languages or daily conversations, and have millions of samples, very few relates to small corpus in a specific field. We hope to construct a knowledge graph about Chinese fundamentals of electric circuits textbook for beginners. The knowledge graph shows students knowledge navigation and consists of important concepts about this field and logical relationships between them. To achieve the goal, the first step is to ensure entities and extract entity relationships from raw corpus automatically. In this paper, a relation extraction dataset is built from Chinese fundamentals of electric circuits textbook artificially and research the relation extraction performance of improved position-enhanced CNN model on this task. The experiment result validates the effectiveness of CNN on specific Chinese small corpus relation extraction task. © 2019 IEEE.",Final,
Liu Z.; Xiong C.; Sun M.; Liu Z.,"Liu, Zhenghao (57194902552); Xiong, Chenyan (56405071400); Sun, Maosong (7403180987); Liu, Zhiyuan (57191691341)",57194902552; 56405071400; 7403180987; 57191691341,Explore Entity Embedding Effectiveness in Entity Retrieval,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075754252&doi=10.1007%2f978-3-030-32381-3_9&partnerID=40&md5=b2803d0d3cebf59ff19a205adfb92933,"This paper explores entity embedding effectiveness in ad-hoc entity retrieval, which introduces distributed representation of entities into entity retrieval. The knowledge graph contains lots of knowledge and models entity semantic relations with the well-formed structural representation. Entity embedding learns lots of semantic information from the knowledge graph and represents entities with a low-dimensional representation, which provides an opportunity to establish interactions between query related entities and candidate entities for entity retrieval. Our experiments demonstrate the effectiveness of entity embedding based model, which achieves more than 5% improvement than the previous state-of-the-art learning to rank based entity retrieval model. Our further analysis reveals that the entity semantic match feature effective, especially for the scenario which needs more semantic understanding. © 2019, Springer Nature Switzerland AG.",Final,All Open Access; Green Open Access
Fu C.; Chen T.; Qu M.; Jin W.; Ren X.,"Fu, Cong (57204468052); Chen, Tong (57216695001); Qu, Meng (57052330900); Jin, Woojeong (57193517627); Ren, Xiang (58619993600)",57204468052; 57216695001; 57052330900; 57193517627; 58619993600,Collaborative policy learning for open knowledge graph reasoning,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084325498&partnerID=40&md5=e577b4d5a3073ec43306f199953c4c7d,"In recent years, there has been a surge of interests in interpretable graph reasoning methods. However, these models often suffer from limited performance when working on sparse and incomplete graphs, due to the lack of evidential paths that can reach target entities. Here we study open knowledge graph reasoning-a task that aims to reason for missing facts over a graph augmented by a background text corpus. A key challenge of the task is to filter out “irrelevant” facts extracted from corpus, in order to maintain an effective search space during path inference. We propose a novel reinforcement learning framework to train two collaborative agents jointly, i.e., a multi-hop graph reasoner and a fact extractor. The fact extraction agent generates fact triples from corpora to enrich the graph on the fly; while the reasoning agent provides feedback to the fact extractor and guides it towards promoting facts that are helpful for the interpretable reasoning. Experiments on two public datasets demonstrate the effectiveness of the proposed approach. Source code and datasets used in this paper can be downloaded at https://github.com/shanzhenren/CPL. © 2019 Association for Computational Linguistics",Final,
Gangemi A.; Gromann D.,"Gangemi, Aldo (55605133800); Gromann, Dagmar (55844075500)",55605133800; 55844075500,Analyzing the imagistic foundation of framality via prepositions,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077720082&partnerID=40&md5=ec11774d34efdfd2bba83471c665e2c9,"Natural language understanding is a vibrant research area in Artificial Intelligence that requires linguistic and commonsense knowledge. To unite both types of knowledge, FrameNet associates words with semantic frames, conceptual structures that describe a type of object, event or situation. Frames are interrelated and feature some image schematic foundations. However, the resource’s usefulness is limited by non-standard semantics. Framester, lying on a solid formal frame semantics, reengineers and links FrameNet to lexical and ontological resources to create one joint, powerful knowledge base. In this paper, we use Framester of FrameNet and of the Preposition Project (TPP) to systematically analyze the image-schematic foundation of frames via preposition senses. Framal knowledge is extracted from TPP, which contains senses for each English preposition, and frame interrelations are analyzed for the imagistic foundation of framality via preposition senses. Copyright © 2019 for this paper by its authors.",Final,
Zhang N.; Deng S.; Sun Z.; Wang G.; Chen X.; Zhang W.; Chen H.,"Zhang, Ningyu (55923601900); Deng, Shumin (57201556430); Sun, Zhanlin (57215718398); Wang, Guanying (57215717902); Chen, Xi (57218347633); Zhang, Wei (57970839200); Chen, Huajun (35268022500)",55923601900; 57201556430; 57215718398; 57215717902; 57218347633; 57970839200; 35268022500,Long-tail relation extraction via knowledge graph embeddings and graph convolution networks,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085555333&partnerID=40&md5=c86d6bb110af1f2b70bac3b2301cc74f,"We propose a distance supervised relation extraction approach for long-tailed, imbalanced data which is prevalent in real-world settings. Here, the challenge is to learn accurate”few-shot” models for classes existing at the tail of the class distribution, for which little data is available. Inspired by the rich semantic correlations between classes at the long tail and those at the head, we take advantage of the knowledge from data-rich classes at the head of the distribution to boost the performance of the data-poor classes at the tail. First, we propose to leverage implicit relational knowledge among class labels from knowledge graph embeddings and learn explicit relational knowledge using graph convolution networks. Second, we integrate that relational knowledge into relation extraction model by coarse-to-fine knowledge-aware attention mechanism. We demonstrate our results for a large-scale benchmark dataset which show that our approach significantly outperforms other baselines, especially for long-tail relations. © 2019 Association for Computational Linguistics",Final,
Prokhorov V.; Pilehvar M.T.; Collier N.,"Prokhorov, Victor (57215718201); Pilehvar, Mohammad Taher (56349749800); Collier, Nigel (7004876365)",57215718201; 56349749800; 7004876365,Generating knowledge graph paths from textual definitions using sequence-to-sequence models,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085580987&partnerID=40&md5=75fa179b9d98094c591880397d81fb45,"We present a novel method for mapping unrestricted text to knowledge graph entities by framing the task as a sequence-to-sequence problem. Specifically, given the encoded state of an input text, our decoder directly predicts paths in the knowledge graph, starting from the root and ending at the target node following hypernym-hyponym relationships. In this way, and in contrast to other text-to-entity mapping systems, our model outputs hierarchically structured predictions that are fully interpretable in the context of the underlying ontology, in an end-to-end manner. We present a proof-of-concept experiment with encouraging results, comparable to those of state-of-the-art systems. © 2019 Association for Computational Linguistics",Final,
Zhao W.; Chung T.; Goyal A.; Metallinou A.,"Zhao, Wenbo (57211273531); Chung, Tagyoung (46461029100); Goyal, Anuj (57216413714); Metallinou, Angeliki (26422331500)",57211273531; 46461029100; 57216413714; 26422331500,Simple question answering with subgraph ranking and joint-scoring,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085585112&partnerID=40&md5=ca516900d7646ea683baa65ab240ddb9,"Knowledge graph based simple question answering (KBSQA) is a major area of research within question answering. Although only dealing with simple questions, i.e., questions that can be answered through a single knowledge base (KB) fact, this task is neither simple nor close to being solved. Targeting on the two main steps, subgraph selection and fact selection, the research community has developed sophisticated approaches. However, the importance of subgraph ranking and leveraging the subject-relation dependency of a KB fact have not been sufficiently explored. Motivated by this, we present a unified framework to describe and analyze existing approaches. Using this framework as a starting point, we focus on two aspects: improving subgraph selection through a novel ranking method and leveraging the subject-relation dependency by proposing a joint scoring CNN model with a novel loss function that enforces the well-order of scores. Our methods achieve a new state of the art (85.44% in accuracy) on the SimpleQuestions dataset. © 2019 Association for Computational Linguistics",Final,
Linden J.; Wang X.; Forsstrom S.; Zhang T.,"Linden, Johanne (57204810248); Wang, Xutao (57215117102); Forsstrom, Stefan (35172962700); Zhang, Tingting (55729062100)",57204810248; 57215117102; 35172962700; 55729062100,Bilingual Auto-Categorization Comparison of Two LSTM Text Classifiers,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080902973&doi=10.1109%2fIIAI-AAI.2019.00127&partnerID=40&md5=da944f2be5a67958ba43fc947d5db575,"Multi linguistic problems such as auto-categorization is not an easy task. It is possible to train different models for each language, another way to do auto-categorization is to build the model in one base language and use automatic translation from other languages to that base language. Different languages have a bias to a language specific grammar and syntax and will therefore pose problems to be expressed in other languages. Translating from one language into a non-verbal language could potentially have a positive impact of the categorization results. A non-verbal language could for example be pure information in form of a knowledge graph relation extraction from the text. In this article a comparison is conducted between Chinese and Swedish languages. Two categorization models are developed and validated on each dataset. The purpose is to make an auto-categorization model that works for n'importe quel langage. One model is built upon LSTM and optimized for Swedish and the other is an improved Bidirectional-LSTM Convolution model optimized for Chinese. The improved algorithm is trained on both languages and compared with the LSTM algorithm. The Bidirectional-LSTM algorithm performs approximately 20% units better than the LSTM algorithm, which is significant. © 2019 IEEE.",Final,
,,,"18th China National Conference on Computational Linguistics, CCL 2019",-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075748859&partnerID=40&md5=b58084024db50850ae0f3e8d8ca6ea95,The proceedings contain 56 papers. The special focus in this conference is on 18th China National Conference on Computational Linguistics. The topics include: Improving a Syntactic Graph Convolution Network for Sentence Compression; comparative Investigation of Deep Learning Components for End-to-end Implicit Discourse Relationship Parser; syntax-Aware Attention for Natural Language Inference with Phrase-Level Matching; Sharing Pre-trained BERT Decoder for a Hybrid Summarization; title-Aware Neural News Topic Prediction; How to Fine-Tune BERT for Text Classification?; a Comprehensive Verification of Transformer in Text Classification; next News Recommendation via Knowledge-Aware Sequential Model; improving Relation Extraction with Relation-Based Gated Convolutional Selector; Testing the Reasoning Power for NLI Models with Annotated Multi-perspective Entailment Dataset; attention-Based Gated Convolutional Neural Networks for Distant Supervised Relation Extraction; relation and Fact Type Supervised Knowledge Graph Embedding via Weighted Scores; leveraging Multi-head Attention Mechanism to Improve Event Detection; short-Text Conceptualization Based on a Co-ranking Framework via Lexical Knowledge Base; denoising Distant Supervision for Relation Extraction with Entropy Weight Method; cross-View Adaptation Network for Cross-Domain Relation Extraction; character-Aware Low-Resource Neural Machine Translation with Weight Sharing and Pre-training; mongolian-Chinese Unsupervised Neural Machine Translation with Lexical Feature; learning Multilingual Sentence Embeddings from Monolingual Corpus; chinese Historical Term Translation Pairs Extraction Using Modern Chinese as a Pivot Language; enhancing Chinese Word Embeddings from Relevant Derivative Meanings of Main-Components in Characters; Point the Point: Uyghur Morphological Segmentation Using PointerNetwork with GRU; construction of an English-Uyghur WordNet Dataset; Endangered Tujia Language Speech Enhancement Research Based on Improved DCGAN; research for Tibetan-Chinese Name Transliteration Based on Multi-granularity.,Final,
Zhong Y.; Zhao L.; Jiang C.; Luo X.,"Zhong, Yanru (57189992866); Zhao, Leixian (57211430423); Jiang, Chaohao (57203884164); Luo, Xiaonan (8293331200)",57189992866; 57211430423; 57203884164; 8293331200,Improving Chinese named entity recognition with semantic information of character multi-position representation,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073894181&doi=10.1007%2f978-3-030-26354-6_24&partnerID=40&md5=f65ddd1cae265ffb248798604b7e8ee3,"Named entity recognition is an important basic task for information extraction and construction of knowledge graph, but the recognition rate needs to be further improved, especially in Chinese. There are two main implementations based on the sequence tagging method. Among them, the character-based method lacks the support of word information, and the word-based method is affected by the word segmentation efficiency. In order to comprehensively utilize the information of characters and words and to reflect the semantic information that changes due to different combinations of characters and words in a sentence. We designed a tagging scheme based on word segmentation and dictionaries. Then, neural networks are used for learning multi-position feature vectors and character-based tagging task. Experiments with MSRA datasets show that this method outperforms word-based and character-based baselines and achieves a higher recall rate compared to other methods. © Springer Nature Switzerland AG 2019.",Final,
Chen Z.-Y.; Chang C.-H.; Chen Y.-P.; Nayak J.; Ku L.-W.,"Chen, Zi-Yuan (57203096182); Chang, Chih-Hung (57216970042); Chen, Yi-Pei (57210909474); Nayak, Jijnasa (8561598300); Ku, Lun-Wei (14066125800)",57203096182; 57216970042; 57210909474; 8561598300; 14066125800,UHOP: An unrestricted-hop relation extraction framework for knowledge-based question answering,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078931467&partnerID=40&md5=848b379bc05192f761eae9408b6baf8d,"In relation extraction for knowledge-based question answering, searching from one entity to another entity via a single relation is called “one hop”. In related work, an exhaustive search from all one-hop relations, two-hop relations, and so on to the max-hop relations in the knowledge graph is necessary but expensive. Therefore, the number of hops is generally restricted to two or three. In this paper, we propose UHop, an unrestricted-hop framework which relaxes this restriction by use of a transition-based search framework to replace the relation-chain-based search one. We conduct experiments on conventional 1- and 2-hop questions as well as lengthy questions, including datasets such as WebQSP, PathQuestion, and Grid World. Results show that the proposed framework enables the ability to halt, works well with state-of-the-art models, achieves competitive performance without exhaustive searches, and opens the performance gap for long relation paths. © 2019 Association for Computational Linguistics",Final,
Moussallem D.; Wauer M.; Ngomo A.-C.N.,"Moussallem, Diego (57079181300); Wauer, Matthias (36160687500); Ngomo, Axel-Cyrille Ngonga (23397850200)",57079181300; 36160687500; 23397850200,Semantic web for machine translation: Challenges and directions,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082495045&partnerID=40&md5=bd7303d6b130c6e43985dad89be71aaf,"A large number of machine translation approaches have recently been developed to facilitate the fluid migration of content across languages. However, the literature suggests that many obstacles must still be dealt with to achieve better automatic translations. One of these obstacles is lexical and syntactic ambiguity. A promising way of overcoming this problem is using Semantic Web technologies. This article is an extended abstract of our systematic review on machine translation approaches that rely on Semantic Web technologies for improving the translation of texts. Overall, we present the challenges and opportunities in the use of Semantic Web technologies in Machine Translation. Moreover, our research suggests that while Semantic Web technologies can enhance the quality of machine translation outputs for various problems, the combination of both is still in its infancy. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Final,
Zhou B.; Chen Y.; Liu K.; Zhao J.,"Zhou, Bo (57224661310); Chen, Yubo (57935192700); Liu, Kang (55729555700); Zhao, Jun (57190004147)",57224661310; 57935192700; 55729555700; 57190004147,Relation and Fact Type Supervised Knowledge Graph Embedding via Weighted Scores,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075758552&doi=10.1007%2f978-3-030-32381-3_21&partnerID=40&md5=4ae7d11810f251dfb71efd43098a841a,"Knowledge graph embedding aims at learning low-dimensional representations for entities and relations in knowledge graph. Previous knowledge graph embedding methods use just one score to measure the plausibility of a fact, which can’t fully utilize the latent semantics of entities and relations. Meanwhile, they ignore the type of relations in knowledge graph and don’t use fact type explicitly. We instead propose a model to fuse different scores of a fact and utilize relation and fact type information to supervise the training process. Specifically, scores by inner product of a fact and scores by neural network are fused with different weights to measure the plausibility of a fact. For each fact, besides modeling the plausibility, the model learns to classify different relations and differentiate positive facts from negative ones which can be seen as a muti-task method. Experiments show that our model achieves better link prediction performance than multiple strong baselines on two benchmark datasets WN18 and FB15k. © 2019, Springer Nature Switzerland AG.",Final,
Chiarcos C.; Donandt K.; Ionov M.; Rind-Pawlowski M.; Sargsian H.; Schreur J.W.; Abromeit F.; Fäth C.,"Chiarcos, Christian (22333764800); Donandt, Kathrin (57195605992); Ionov, Maxim (57194612761); Rind-Pawlowski, Monika (57194613629); Sargsian, Hasmik (57205402787); Schreur, Jesse Wichers (57194609180); Abromeit, Frank (57198810784); Fäth, Christian (57194612424)",22333764800; 57195605992; 57194612761; 57194613629; 57205402787; 57194609180; 57198810784; 57194612424,Universal morphologies for the caucasus region,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059877569&partnerID=40&md5=e2628899a46c6b068ab18e7eeb615e28,"The Caucasus region is famed for its rich and diverse arrays of languages and language families, often challenging European-centered views established in traditional linguistics. In this paper, we describe ongoing efforts to improve the coverage of Universal Morphologies for languages of the Caucasus region. The Universal Morphologies (UniMorph) are a recent community project aiming to complement the Universal Dependencies which focus on morphosyntax and syntax. We describe the development of UniMorph resources for Nakh-Daghestanian and Kartvelian languages as a well as for Classical Armenian, we discuss challenges that the complex morphology of these and related languages poses to the current design of UniMorph, and suggest possibilities to improve the applicability of UniMorph for languages of the Caucasus region in particular and for low resource languages in general. We also criticize the UniMorph TSV format for its limited expressiveness, and suggest to complement the existing UniMorph workflow with support for additional source formats on grounds of Linked Open Data technology. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.",Final,
Li D.; Dadaneh S.Z.; Zhang J.; Li P.,"Li, Dingcheng (55301231800); Dadaneh, Siamak Zamani (57202151993); Zhang, Jingyuan (56717279600); Li, Ping (56558930800)",55301231800; 57202151993; 56717279600; 56558930800,Integration of knowledge graph embedding into topic modeling with hierarchical dirichlet process,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071153019&partnerID=40&md5=ee9ffcf1663cd95d39e3c0878e18d238,"Leveraging domain knowledge is an effective strategy for enhancing the quality of inferred low-dimensional representations of documents by topic models. In this paper, we develop topic modeling with knowledge graph embedding (TMKGE), a Bayesian nonparametric model to employ knowledge graph (KG) embedding in the context of topic modeling, for extracting more coherent topics. Specifically, we build a hierarchical Dirichlet process (HDP) based model to flexibly borrow information from KG to improve the interpretability of topics. An efficient online variational inference method based on a stick-breaking construction of HDP is developed for TMKGE, making TMKGE suitable for large document corpora and KGs. Experiments on three public datasets illustrate the superior performance of TMKGE in terms of topic coherence and document classification accuracy, compared to state-of-the-art topic modeling methods. © 2019 Association for Computational Linguistics",Final,
Kejriwal M.,"Kejriwal, Mayank (55588437600)",55588437600,Information Extraction,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063139094&doi=10.1007%2f978-3-030-12375-8_2&partnerID=40&md5=37ccf22d23bd0f3e8b67502eebc08401,"Extracting information from both Web and natural language documents is the central step in knowledge graph construction, since it is the first line of attack in going from a corpus that is not machine-understandable or queryable to a semi-structured corpus that can be queried and reasoned over. Wrapper induction techniques were developed early in the Web community to deal with the special problem of extracting information from webpages and web templates. However, wrapper induction is not enough. Many key attributes need to be extracted directly from text using information extraction algorithms developed in the natural language processing community. This is also true in cases where the raw data is not from the Web, but is a corpus of natural language documents to begin with. Therefore, we also cover some established research on information extraction, including named entity recognition, relation extraction and event extraction. While the first of these has been around for quite some time, the last is a relatively novel research area where improving quality continues to be a challenge. © 2019, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Final,
Hofmeester K.; Ashkpour A.; Depuydt K.; De Does J.,"Hofmeester, Karin (54406841900); Ashkpour, Ashkan (56032182300); Depuydt, Katrien (55642304900); De Does, Jesse (55642146900)",54406841900; 56032182300; 55642304900; 55642146900,Diamonds in Borneo: Commodities as concepts in context,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074890080&doi=10.1145%2f3322905.3322924&partnerID=40&md5=90b89ec05812217f669469ae6d462ad9,"The intensified circulation of people, commodities and ideas is one of the characteristics of a globalizing world. To understand the causes and consequences of these circulations, we have to know which commodities circulated when and where, on what scale and who made them circulate. In our paper we want to present the first results of a CLARIAH Research Pilot1 on diamonds in Borneo, using the large historical newspaper collection of the KB (Royal Library of the Netherlands) in Delpher2. So far the diamond industry in Borneo has been a true blind spot in our knowledge on the global diamond commodity chain. We have little information on where diamonds were found, who the miners and traders were and if there was really an ‘age-old’ diamond polishing industry as literature suggests. We believe that the newspapers can provide more information on this topic. To answer these questions, we developed a workflow that enables us to query the KB newspaper collection in an efficient and elaborate way that can also be used for research on other commodities. © 2019 Copyright held by the owner/author(s).",Final,
Ebisu T.; Ichise R.,"Ebisu, Takuma (57191724665); Ichise, Ryutaro (6602466212)",57191724665; 6602466212,Graph pattern entity ranking model for knowledge graph completion,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072275082&partnerID=40&md5=9c69b026b36fd07a6f2476d3804277c4,"Knowledge graphs have evolved rapidly in recent years and their usefulness has been demonstrated in many artificial intelligence tasks. However, knowledge graphs often have lots of missing facts. To solve this problem, many knowledge graph embedding models have been developed to populate knowledge graphs and these have shown outstanding performance. However, knowledge graph embedding models are so-called black boxes, and the user does not know how the information in a knowledge graph is processed and the models can be difficult to interpret. In this paper, we utilize graph patterns in a knowledge graph to overcome such problems. Our proposed model, the graph pattern entity ranking model (GRank), constructs an entity ranking system for each graph pattern and evaluates them using a ranking measure. By doing so, we can find graph patterns which are useful for predicting facts. Then, we perform link prediction tasks on standard datasets to evaluate our GRank method. We show that our approach outperforms other state-of-the-art approaches such as ComplEx and TorusE for standard metrics such as HITS@n and MRR. Moreover, our model is easily interpretable because the output facts are described by graph patterns. © 2019 Association for Computational Linguistics",Final,
Fauceglia N.R.; Gliozzo A.; Dash S.; Chowdhury M.F.M.; Mihindukulasooriya N.,"Fauceglia, Nicolas Rodolfo (57204209512); Gliozzo, Alfio (55893529800); Dash, Sarthak (57196468028); Chowdhury, Md Faisal Mahbub (55604498400); Mihindukulasooriya, Nandana (56406504100)",57204209512; 55893529800; 57196468028; 55604498400; 56406504100,Automatic taxonomy induction and expansion,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087435953&partnerID=40&md5=e6a757718ea22a1913f24ed788ad3a26,"The Knowledge Graph Induction Service (KGIS) is an end-to-end knowledge induction system. One of its main capabilities is to automatically induce taxonomies1 from input documents using a hybrid approach that takes advantage of linguistic patterns, semantic web and neural networks. KGIS allows the user to semi-automatically curate and expand the induced taxonomy through a component called smart spreadsheet by exploiting distributional semantics. In this paper, we describe these taxonomy induction and expansion features of KGIS. A screencast video demonstrating the system is available in https://ibm.box.com/v/emnlp-2019-demo . © 2019 Association for Computational Linguistics.",Final,
Lu Y.; Zhang J.; Zong C.,"Lu, Yu (57209874929); Zhang, Jiajun (51666026800); Zong, Chengqing (7005615574)",57209874929; 51666026800; 7005615574,Exploiting knowledge graph in neural machine translation,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060193831&doi=10.1007%2f978-981-13-3083-4_3&partnerID=40&md5=aeee8c44b5f0203e8fcbfecb6b958f64,"Neural machine translation (NMT) can achieve promising translation quality on resource-rich languages due to end-to-end learning. However, the widely-used NMT system only focuses on modeling the inner mapping from source to target without resorting to external knowledge. In this paper, we take English-Chinese translation as a case study to exploit the use of knowledge graph (KG) in NMT. The main idea is utilizing the entity relations in knowledge graph as constraints to enhance the connections between the source words and their translations. Specifically, we design two kinds of constraints. One is monolingual constraint that employs the entity relations in KG to augment the semantic representation of the source words. The other is bilingual constraint which enforces the entity relations between the source words to be shared by their translations. In this way, external knowledge can participate in the translation process and help to model semantic relationships between source and target words. Experimental results demonstrate that our method outperforms the state-of-the-art system. © 2019, Springer Nature Singapore Pte Ltd.",Final,
Zhou Z.; Guan H.; Bhat M.M.; Hsu J.,"Zhou, Zhixuan (57208440372); Guan, Huankang (57208446358); Bhat, Meghana Moorthy (58711788400); Hsu, Justin (55785613000)",57208440372; 57208446358; 58711788400; 55785613000,Fake news detection via NLP is vulnerable to adversarial attacks,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064814138&doi=10.5220%2f0007566307940800&partnerID=40&md5=375c826442cc6befdf27ad0b2e0fe4ce,"News plays a significant role in shaping people's beliefs and opinions. Fake news has always been a problem, which wasn't exposed to the mass public until the past election cycle for the 45th President of the United States. While quite a few detection methods have been proposed to combat fake news since 2015, they focus mainly on linguistic aspects of an article without any fact checking. In this paper, we argue that these models have the potential to misclassify fact-tampering fake news as well as under-written real news. Through experiments on Fakebox, a state-of-the-art fake news detector, we show that fact tampering attacks can be effective. To address these weaknesses, we argue that fact checking should be adopted in conjunction with linguistic characteristics analysis, so as to truly separate fake news from real news. A crowdsourced knowledge graph is proposed as a straw man solution to collecting timely facts about news events. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Torregrosa D.; Arcan M.; Ahmadi S.; McCrae J.P.,"Torregrosa, Daniel (57211633283); Arcan, Mihael (55453083200); Ahmadi, Sina (57210119212); McCrae, John P. (36666801700)",57211633283; 55453083200; 57210119212; 36666801700,TIAD 2019 shared task: Leveraging knowledge graphs with neural machine translation for automatic multilingual dictionary generation,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075108222&partnerID=40&md5=29a6a56bd8e86b5e8f98d2cebd5ddfa4,"This paper describes the different proposed approaches to the TIAD 2019 Shared Task, which consisted in the automatic discovery and generation of dictionaries leveraging multilingual knowledge bases. We present three methods based on graph analysis and neural machine translation and show that we can generate translations without parallel data.1 Copyright © 2019 for this paper by its authors.",Final,
Chu Q.; Liu G.; Sun H.; Zhou C.,"Chu, Qianfeng (57212023795); Liu, Gongshen (56136751400); Sun, Huanrong (57203788516); Zhou, Cheng (57204671974)",57212023795; 56136751400; 57203788516; 57204671974,Next News Recommendation via Knowledge-Aware Sequential Model,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075723740&doi=10.1007%2f978-3-030-32381-3_18&partnerID=40&md5=f7eb9d532941c6a398d404e356e498a3,"A news recommendation system aims to predict the next news based on users’ interaction histories. In general, the clicking sequences from the interaction histories indicate users’ latent preference, which plays an important role in predicting their future interest. Besides, news articles consist of considerable knowledge entities which have deep connections from common sense of human. In this paper, we propose a Self-Attention Sequential Knowledge-aware Recommendation (Saskr) system consisting of sequential-aware and knowledge-aware modelling. We use the self-attention mechanism to uncover sequential patterns in the sequential-aware modelling. The knowledge-aware modelling leverage the knowledge graph as side information to mine deep connections between news, thus improving diversity and extensibility of recommendation. Content-based news embeddings help to address the item cold-start problem. Through extensive experiments on the real-world news dataset, we demonstrate that the proposed model outperforms state-of-the-art deep neural sequential recommendation systems. © 2019, Springer Nature Switzerland AG.",Final,
Rasmussen Pennington D.; Cagnazzo L.,"Rasmussen Pennington, Diane (55855995500); Cagnazzo, Laura (57208578443)",55855995500; 57208578443,Connecting the silos: Implementations and perceptions of linked data across European libraries,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065198615&doi=10.1108%2fJD-07-2018-0117&partnerID=40&md5=a69aa87c08adf11502502eba3b931d21,"Purpose: The purpose of this paper is to determine how information professionals in Scotland and in European national libraries perceive linked data (LD) as well as if and how they are implementing it. Design/methodology/approach: The authors applied four data collection techniques: a literature review, semi-structured interviews (n=15), online resources analysis (n=26) and an online survey (n=113). They used constant comparative analysis to identify perceived benefits and challenges of LD implementation, reasons behind adoption or non-adoption of LD and the issues hindering its implementation in libraries. Findings: Some projects demonstrate LD’s potential to augment the visibility and discoverability of library data, alongside with overcoming linguistic barriers, and supporting interoperability. However, a strong need remains to demonstrate the Semantic Web’s potential within libraries. Participants identified lack of expertise and lack of resources/time/staff as implementation barriers. Several other issues remain unsolved, such as licensing constraints, as well as difficulties with obtaining management buy-in for LD initiatives, even where open data are government-mandated. Practical implications: Information professionals and vendors should collaborate to develop tools for implementation. Advocacy through disseminating and reviewing successful implementations can help to solve practical difficulties and to obtain management buy-in. Originality/value: This is the first known study to present a multinational, comprehensive picture of library LD implementations and associated librarians’ perceptions of LD. © 2019, Emerald Publishing Limited.",Final,All Open Access; Green Open Access
Godin F.; Kumar A.; Mittal A.,"Godin, Frederic (55694006500); Kumar, Anjishnu (57200080402); Mittal, Arpit (57205403729)",55694006500; 57200080402; 57205403729,Learning when not to answer: A ternary reward structure for reinforcement learning based question answering,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085571831&partnerID=40&md5=8a66e48af4e33516c1d5dd8588ebb427,"In this paper, we investigate the challenges of using reinforcement learning agents for question-answering over knowledge graphs for real-world applications. We examine the performance metrics used by state-of-the-art systems and determine that they are inadequate for such settings. More specifically, they do not evaluate the systems correctly for situations when there is no answer available and thus agents optimized for these metrics are poor at modeling confidence. We introduce a simple new performance metric for evaluating question-answering agents that is more representative of practical usage conditions, and optimize for this metric by extending the binary reward structure used in prior work to a ternary reward structure which also rewards an agent for not answering a question rather than giving an incorrect answer. We show that this can drastically improve the precision of answered questions while only not answering a limited number of previously correctly answered questions. Employing a supervised learning strategy using depth-first-search paths to bootstrap the reinforcement learning algorithm further improves performance. © 2019 Association for Computational Linguistics.",Final,
Wang C.; He X.; Fan Y.; Zhou A.,"Wang, Chengyu (55926354300); He, Xiaofeng (55641972700); Fan, Yan (57196223698); Zhou, Aoying (55183487900)",55926354300; 55641972700; 57196223698; 55183487900,A family of fuzzy orthogonal projection models for monolingual and cross-lingual hypernymy prediction,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066917337&doi=10.1145%2f3308558.3313439&partnerID=40&md5=077d17fd78628437b33d01e2a93e54e7,"Hypernymy is a semantic relation, expressing the “is-a” relation between a concept and its instances. Such relations are building blocks for large-scale taxonomies, ontologies and knowledge graphs. Recently, much progress has been made for hypernymy prediction in English using textual patterns and/or distributional representations. However, applying such techniques to other languages is challenging due to the high language dependency of these methods and the lack of large training datasets of lower-resourced languages. In this work, we present a family of fuzzy orthogonal projection models for both monolingual and cross-lingual hypernymy prediction. For the monolingual task, we propose a Multi-Wahba Projection (MWP) model to distinguish hypernymy vs. non-hypernymy relations based on word embeddings. This model establishes distributional fuzzy mappings from embeddings of a term to those of its hypernyms and non-hypernyms, which consider the complicated linguistic regularities of these relations. For cross-lingual hypernymy prediction, a Transfer MWP (TMWP) model is proposed to transfer the semantic knowledge from the source language to target languages based on neural word translation. Additionally, an Iterative Transfer MWP (ITMWP) model is built upon TMWP, which augments the training sets of target languages when target languages are lower-resourced with limited training data. Experiments show i) MWP outperforms previous methods over two hypernymy prediction tasks for English; and ii) TMWP and ITMWP are effective to predict hypernymy over seven non-English languages. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.",Final,
Pezeshkpour P.; Tian Y.; Singh S.,"Pezeshkpour, Pouya (56685603000); Tian, Yifan (57216963894); Singh, Sameer (58124003300)",56685603000; 57216963894; 58124003300,Investigating robustness and interpretability of link prediction via adversarial modifications,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085559217&partnerID=40&md5=6cb2a9eb44d2ffbb5ebcc27cd146b00b,"Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on improving accuracy and overlook other aspects such as robustness and interpretability. In this paper, we propose adversarial modifications for link prediction models: identifying the fact to add into or remove from the knowledge graph that changes the prediction for a target fact after the model is retrained. Using these single modifications of the graph, we identify the most influential fact for a predicted link and evaluate the sensitivity of the model to the addition of fake facts. We introduce an efficient approach to estimate the effect of such modifications by approximating the change in the embeddings when the knowledge graph changes. To avoid the combinatorial search over all possible facts, we train a network to decode embeddings to their corresponding graph components, allowing the use of gradient-based optimization to identify the adversarial modification. We use these techniques to evaluate the robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability through the facts most responsible for predictions (by identifying the most influential neighbors), and detect incorrect facts in the knowledge base. © 2019 Association for Computational Linguistics",Final,
Barbosa G.C.G.; Wong Z.; Hahn-Powell G.; Bell D.; Sharp R.; Valenzuela-Escarcega M.A.; Surdeanu M.,"Barbosa, George C. G. (57211219184); Wong, Zechy (57207771762); Hahn-Powell, Gus (56904144100); Bell, Dane (56493903800); Sharp, Rebecca (57158685900); Valenzuela-Escarcega, Marco A. (56904205300); Surdeanu, Mihai (23398535300)",57211219184; 57207771762; 56904144100; 56493903800; 57158685900; 56904205300; 23398535300,Enabling search and collaborative assembly of causal interactions extracted from multilingual and multi-domain free text,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085641989&partnerID=40&md5=6d5935ab7701707075be83b7e9341332,"Many of the most pressing current research problems (e.g., public health, food security, or climate change) require multi-disciplinary collaborations. In order to facilitate this process, we propose a system that incorporates multidomain extractions of causal interactions into a single searchable knowledge graph. Our system enables users to search iteratively over direct and indirect connections in this knowledge graph, and collaboratively build causal models in real time. To enable the aggregation of causal information from multiple languages, we extend an open-domain machine reader to Portuguese. The new Portuguese reader extracts over 600 thousand causal statements from 120 thousand Portuguese publications with a precision of 62%, which demonstrates the value of mining multilingual scientific information. © 2019 The Association for Computational Linguistics.",Final,
Koncel-Kedziorski R.; Bekal D.; Luan Y.; Lapata M.; Hajishirzi H.,"Koncel-Kedziorski, Rik (57188303100); Bekal, Dhanush (57216971880); Luan, Yi (56414288900); Lapata, Mirella (55910108500); Hajishirzi, Hannaneh (23008126600)",57188303100; 57216971880; 56414288900; 55910108500; 23008126600,Text generation from knowledge graphs with graph transformers,-1,,-1,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079655513&partnerID=40&md5=ca349cd558be9df6d472894bc5d0745f,"Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods. © 2019 Association for Computational Linguistics",Final,
Chakrabarti S.,"Chakrabarti, Soumen (58570163200)",58570163200,"Knowledge extraction and inference from text: Shallow, deep, and everything in between",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051501110&doi=10.1145%2f3209978.3210190&partnerID=40&md5=b3103e0dd9d3893a2ff0eb93e11c8003,"Systems for structured knowledge extraction and inference have made giant strides in the last decade. Starting from shallow linguistic tagging and coarse-grained recognition of named entities at the resolution of people, places, organizations, and times, modern systems link billions of pages of unstructured text with knowledge graphs having hundreds of millions of entities belonging to tens of thousands of types, and related by tens of thousands of relations. Via deep learning, systems build continuous representations of words, entities, types, and relations, and use these to continually discover new facts to add to the knowledge graph, and support search systems that go far beyond page-level ""ten blue links''. We will present a comprehensive catalog of the best practices in traditional and deep knowledge extraction, inference and search. We will trace the development of diverse families of techniques, explore their interrelationships, and point out various loose ends. © 2018 Author.",Final,
Li J.; Wang W.; Wang J.,"Li, Junxian (56155343600); Wang, Wei (56948522000); Wang, Jingjing (57203386241)",56155343600; 56948522000; 57203386241,Querying Linked Data Based on Hierarchical Multi-Hop Ranking Model,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051454048&doi=10.1007%2fs12204-018-1976-z&partnerID=40&md5=b6b8bfcbd1e986c85b2e1f8255ce680e,"How to query Linked Data effectively is a challenge due to its heterogeneous datasets. There are three types of heterogeneities, i.e., different structures representing entities, different predicates with the same meaning and different literal formats used in objects. Approaches based on ontology mapping or Information Retrieval (IR) cannot deal with all types of heterogeneities. Facing these limitations, we propose a hierarchical multi-hop language model (HMPM). It discriminates among three types of predicates, descriptive predicates, out-associated predicates and in-associated predicates, and generates multi-hop models for them respectively. All predicates’ similarities between the query and entity are organized into a hierarchy, with predicate types on the first level and predicates of this type on the second level. All candidates are ranked in ascending order. We evaluated HMPM in three datasets, DBpedia, LinkedMDB and Yago. The results of experiments show that the effectiveness and generality of HMPM outperform the existing approaches. © 2018, Shanghai Jiaotong University and Springer-Verlag GmbH Germany, part of Springer Nature.",Final,
Sun Y.; Wang L.; Zhu Z.,"Sun, Yuan (55737730600); Wang, Like (57204673736); Zhu, Zhen (57118514100)",55737730600; 57204673736; 57118514100,Knowledge points extraction of junior high school English exercises based on SVM method,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056617212&doi=10.1145%2f3241748.3241768&partnerID=40&md5=28d3e0b7b462d094657e68d127cc7e76,"In the process of learning English, students need to do a lot of exercises to improve English performance. The knowledge points of exercises are important to students, yet how to extract the knowledge points from exercises automatically is difficult, which is the foundation of the knowledge graph construction for students learning. In this paper, we use SVM to realize the knowledge points extraction of junior high school English exercises. Firstly, this paper obtains amounts of question data through analyzing electronic documents, and uses NLP tools to segment, POS tagging and named entity recognition. Secondly, we extract the knowledge points based on SVM model, which involves building multi-class feature vectors and constructing a hierarchical classification for question data. Finally, the experimental results prove the method is effective. © 2018 Association for Computing Machinery.",Final,
,,,"2018 4th International Conference on Web Research, ICWR 2018",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050088187&partnerID=40&md5=f99e2bc7150237336ac02a1728204401,"The proceedings contain 26 papers. The topics discussed include: a framework for comparing quantitative and qualitative criteria of IoT platforms; optimization of tasks in cloud computing based on MAX-MIN, MIN-MIN and priority; on user-centric XML keyword search; inbound e-marketing using neural network based visual and phonetic user experience analytics; fingerprint vulnerability: a survey; weighted estimation of information diffusion probabilities for independent cascade model; multi-emotion extraction from text based on linguistic analysis; Moodle meets linked data: publishing Moodle on the web of data using semantic links; a hybrid graph-structure-based webpage recommendation algorithm based on weighted association rules; personalization of interactive recommender systems for expert users; semantic code clone detection using abstract memory states and program dependency graphs; representation of Islam in social media discourse produced by an apostate; linked data geo-statistical analysis of air pollution in urban areas; a new method of IPv6 addressing based on EPCmapping in the Internet of Things; and uninorm operators for sentence-level score aggregation in sentiment analysis.",Final,
Jansen P.A.,"Jansen, Peter A. (20433726100)",20433726100,Multi-hop Inference for Sentence-level TextGraphs: How Challenging is Meaningfully Combining Information for Science Question Answering?,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180130011&partnerID=40&md5=143a122579260e61a0464b974ae4bc71,"Question Answering for complex questions is often modelled as a graph construction or traversal task, where a solver must build or traverse a graph of facts that answer and explain a given question. This “multi-hop” inference has been shown to be extremely challenging, with few models able to aggregate more than two facts before being overwhelmed by “semantic drift”, or the tendency for long chains of facts to quickly drift off topic. This is a major barrier to current inference models, as even elementary science questions require an average of 4 to 6 facts to answer and explain. In this work we empirically characterize the difficulty of building or traversing a graph of sentences connected by lexical overlap, by evaluating chance sentence aggregation quality through 9,784 manually-annotated judgements across knowledge graphs built from three free-text corpora (including study guides and Simple Wikipedia). We demonstrate semantic drift tends to be high and aggregation quality low, at between 0.04% and 3%, and highlight scenarios that maximize the likelihood of meaningfully combining information. © 2018 Association for Computational Linguistics.",Final,
Abgaz Y.; Dorn A.; Piringer B.; Wandl-Vogt E.; Way A.,"Abgaz, Yalemisew (36647328800); Dorn, Amelie (35179468300); Piringer, Barbara (57205093609); Wandl-Vogt, Eveline (24336963100); Way, Andy (16023406600)",36647328800; 35179468300; 57205093609; 24336963100; 16023406600,Semantic modelling and publishing of traditional data collection questionnaires and answers,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058988268&doi=10.3390%2finfo9120297&partnerID=40&md5=99d089d9dcaa5db644e70ed16e1a5fe7,"Extensive collections of data of linguistic, historical and socio-cultural importance are stored in libraries, museums and national archiveswith enormous potential to support research. However, a sizable portion of the data remains underutilised because of a lack of the required knowledge to model the data semantically and convert it into a format suitable for the semantic web. Although many institutions have produced digital versions of their collection, semantic enrichment, interlinking and exploration are still missing from digitised versions. In this paper, we present a model that provides structure and semantics to a non-standard linguistic and historical data collection on the example of the Bavarian dialects in Austria at the Austrian Academy of Sciences. We followed a semantic modelling approach that utilises the knowledge of domain experts and the corresponding schema produced during the data collection process. The model is used to enrich, interlink and publish the collection semantically. The dataset includes questionnaires and answers as well as supplementary information about the circumstances of the data collection (person, location, time, etc.). The semantic uplift is demonstrated by converting a subset of the collection to a Linked Open Data (LOD) format, where domain experts evaluated the model and the resulting dataset for its support of user queries. © 2018 by the authors.",Final,All Open Access; Gold Open Access; Green Open Access
Zhang J.; Chen Y.; Hei X.; Zhu L.; Zhao Q.; Wang Y.,"Zhang, Jie (57409513700); Chen, Yi (57205604841); Hei, Xinhong (6603068061); Zhu, Lei (57202316382); Zhao, Qin (55743367800); Wang, Yichuan (36976259700)",57409513700; 57205604841; 6603068061; 57202316382; 55743367800; 36976259700,A RMM based word segmentation method for Chinese design specifications of building stairs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060735147&doi=10.1109%2fCIS2018.2018.00068&partnerID=40&md5=65fee1aa7fa2691cce0b8c8a9161d568,"With the rapid development of information technology, knowledge graph extracts more and more attentions from researchers. However, Chinese knowledge graph of construction industry is still at the beginning stage, and Chinese word segmentation method, as the basis of natural language processing, plays a vital role on the process of building knowledge graph. In this paper, we study Chinese design specifications of building stairs, and proposes a reverse maximum matching (RMM) based word segmentation method to parse Chinese building specifications. The proposed method first converts the dictionary of building into a hash dictionary. And then, by traversing the design specifications of building stairs, the proposed method handles the non-Chinese symbols in the design specifications. Finally, the proposed method uses RMM algorithm to match contexts with Chinese design specifications and generate the goal results. Through performing experiments on Chinese design specifications of building stairs, the results can be shown that the proposed method is feasible. © 2018 IEEE.",Final,
Kejriwal M.; Gilley D.; Szekely P.; Crisman J.,"Kejriwal, Mayank (55588437600); Gilley, Daniel (57216896540); Szekely, Pedro (7003812369); Crisman, Jill (57217615980)",55588437600; 57216896540; 7003812369; 57217615980,THOR: Text-enabled Analytics for Humanitarian Operations,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078864173&doi=10.1145%2f3184558.3186965&partnerID=40&md5=d06bdf80316cc790c6aafd7c5fe8c033,"In this demonstration, we present the Text-enabled Humanitarian Operations in Real-time (THOR) framework, which is being prototyped to provide visual and analytical situational awareness to humanitarian and disaster relief (HADR) planners. THOR is a collaborative effort between industrial and university research laboratories, designed with an intent to support both military and civilian HADR operations. At its core, THOR is powered by a domain-specific knowledge graph, which is derived from natural language outputs and is amenable to real-time analytics. THOR is designed to operate in low-resource linguistic environments, process heterogeneous data, including news and social media, reason about arbitrary disasters not knowable in advance, and provide advanced graphical interaction capabilities. We will demo the latest prototype of THOR using an interactive case study situation. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.",Final,All Open Access; Bronze Open Access
Acula D.D.; Oblan L.A.C.; Pedroso T.B.; Riosa K.J.V.; Tolibas M.A.R.,"Acula, Donata D. (57195516506); Oblan, Louise Aster C. (57204178416); Pedroso, Tracy B. (57204171035); Riosa, Katrine Jee V. (57204185465); Tolibas, Michelle Arianne R. (57204176368)",57195516506; 57204178416; 57204171035; 57204185465; 57204176368,Implementing Fact-Checking in Journalistic Articles Shared on Social Media in the Philippines Using Knowledge Graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054785184&doi=10.1109%2fCCOMS.2018.8463282&partnerID=40&md5=d5782404303ce57425a35a6a25f2e46c,"In the technology age, articles with fraudulent content are rampant, especially articles shared on social media. Misinformation could just be an inaccuracy at its best, or it could lead to normalizing false information at worst. To aid the predicament, the researchers created a system that will 'fact check' suspicious articles against those articles that have been deemed credible, reliable, and more accurate, in order to help fight deceiving content that may be detrimental to society. The journal regarding computational fact checking that was published by Ciampaglia, et. al. (2015) from the Indiana University in the USA entitled Computational Fact Checking from Knowledge Networks, was used as the basis and inspiration for this thesis. The researchers made use of the undirected graph (UG) together with a part-of-speech (POS) tagging algorithm to create a knowledge graph (KG) that would serve as the center of the system. Five different POS tagging algorithms were paired with the UG to assess which combination would yield the best results, these are Conditional Random Fields, Logistic Regression, a Hybrid of CRF and LR, Random Forests, and K-Nearest Neighbors. Random Forests and K-Nearest Neighbors were classification algorithms used in Ciampaglia's study. It was concluded that among the 5 pairs of UG and POS Tagging algorithms, the Hybrid of CRF and LR used as a POS tagger, together with the UG, created the most efficient KG. © 2018 IEEE.",Final,
Gillis-Webber F.,"Gillis-Webber, Frances (57204543421)",57204543421,Conversion of the English-Xhosa dictionary for nurses to a linguistic linked data framework,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056087638&doi=10.3390%2finfo9110274&partnerID=40&md5=da258622780534a3b2bc0d10f07cd965,"The English-Xhosa Dictionary for Nurses (EXDN) is a bilingual, unidirectional printed dictionary in the public domain, with English and isiXhosa as the language pair. By extending the digitisation efforts of EXDN from a human-readable digital object to a machine-readable state, using Resource Description Framework (RDF) as the data model, semantically interoperable structured data can be created, thus enabling EXDN's data to be reused, aggregated and integrated with other language resources, where it can serve as a potential aid in the development of future language resources for isiXhosa, an under-resourced language in South Africa. The methodological guidelines for the construction of a Linguistic Linked Data framework (LLDF) for a lexicographic resource, as applied to EXDN, are described, where an LLDF can be defined as a framework: (1) which describes data in RDF, (2) using a model designed for the representation of linguistic information, (3) which adheres to Linked Data principles, and (4) which supports versioning, allowing for change. The result is a bidirectional lexicographic resource, previously bounded and static, now unbounded and evolving, with the ability to extend to multilingualism. © 2018 by the authors.",Final,All Open Access; Gold Open Access; Green Open Access
Valipour M.; Wang Y.,"Valipour, Mehrdad (24825338100); Wang, Yingxu (7601492153)",24825338100; 7601492153,Sentence Comprehension and Semantic Syntheses by Cognitive Machine Learning,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056452607&doi=10.1109%2fICCI-CC.2018.8482024&partnerID=40&md5=27da2970d1bc95a2a2b80b882e9140ef,"Recent development in machine learning and computational linguistics has enabled cognitive machines to understand the semantics of human expressions. A system for sentence syntactic analysis and semantic synthesis is developed based on denotational mathematics. Machine sentence learning and comprehension are reduced to the building of a composed concept that maps the semantics of the subject onto the counterpart of object(s) represented by formal concepts and phrases. A set of semantic operations such as concept composition, modification, generalization, specification, extension and reduction is formally specified based on concept algebra and semantic algebra for machine learning. An Algorithm for Unsupervised Sentence Learning (AUSL) is designed and implemented, which expresses a learnt sentence as a knowledge graph related to the semantic hierarchy of the machine's knowledge base. Experimental results demonstrate the autonomous learning algorithm and case studies on machine learning towards applications in cognitive robots and knowledge learning systems. © 2018 IEEE.",Final,
Cannaviccio M.; Barbosa D.; Merialdo P.,"Cannaviccio, Matteo (57190401219); Barbosa, Denilson (14027953400); Merialdo, Paolo (6602539867)",57190401219; 14027953400; 6602539867,Towards annotating relational data on the web with language models,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080461781&doi=10.1145%2f3178876.3186029&partnerID=40&md5=456bac81bb7ec280e1341dab14605e4c,"Tables and structured lists on Web pages are a potential source of valuable information, and several methods have been proposed to annotate them with semantics that can be leveraged for search, question answering and information extraction. This paper is concerned with the specific problem of finding and ranking relations from a given Knowledge Graph (KG) that hold over pairs of entities juxtaposed in a table or structured list. The state-of-the-art for this task is to attempt to link the entities mentioned in the table cells to objects in the KG and rank the relations that hold for those linked objects. As a result, these methods are hampered by the incompleteness and uneven coverage in even the best knowledge graphs available today. The alternative described here does not require entity linking, relying instead on ranking relations using generative language models derived from Web-scale corpora. As such, it can produce quality results even when the entities in the table are missing in the KG. The experimental validation, designed to expose the challenges posed by KG incompleteness, shows that our approach is robust and effective in practice. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.",Final,All Open Access; Bronze Open Access
Martinez-Rodriguez J.L.; Lopez-Arevalo I.; Rios-Alvarado A.B.,"Martinez-Rodriguez, Jose L. (55642245600); Lopez-Arevalo, Ivan (56000858100); Rios-Alvarado, Ana B. (35186366800)",55642245600; 56000858100; 35186366800,OpenIE-based approach for Knowledge Graph construction from text,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049879984&doi=10.1016%2fj.eswa.2018.07.017&partnerID=40&md5=be5f65badaf1ab20cf8b07fd9018350a,"Transforming unstructured text into a formal representation is an important goal of the Semantic Web in order to facilitate the integration and retrieval of information. The construction of Knowledge Graphs (KGs) pursues such an idea, where named entities (real world things) and their relations are extracted from text. In recent years, many approaches for the construction of KGs have been proposed by exploiting Discourse Analysis, Semantic Frames, or Machine Learning algorithms with existing Semantic Web data. Although such approaches are useful for processing taxonomies and connecting beliefs, they provide several linguistic descriptions, which lead to semantic data heterogeneity and thus, complicating data consumption. Moreover, Open Information Extraction (OpenIE) approaches have been slightly explored for the construction of KGs, which provide binary relations representing atomic units of information that could simplify the querying and representation of data. In this paper, we propose an approach to generate KGs using binary relations produced by an OpenIE approach. For such purpose, we present strategies for favoring the extraction and linking of named entities with KG individuals, and additionally, their association with grammatical units that lead to producing more coherent facts. We also provide decisions for selecting the extracted information elements for creating potentially useful RDF triples for the KG. Our results demonstrate that the integration of information extraction units with grammatical structures provides a better understanding of proposition-based representations provided by OpenIE for supporting the construction of KGs. © 2018 Elsevier Ltd",Final,
De Assis Costa G.; Parente de Oliveira J.M.,"De Assis Costa, Gustavo (56406393400); Parente de Oliveira, José Maria (35772749100)",56406393400; 35772749100,Linguistic frames as support for entity alignment in knowledge graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061147433&doi=10.1145%2f3282373.3282415&partnerID=40&md5=aa8be8ab2da1165fb6fc6aef867aa0f4,"Entity Alignment is a research topic that has drawn a lot of attention from practitioners and researchers from many different areas in the last years. Also referred to as Entity Resolution or Instance Matching, it involves aligning different entity representations that refer to the same real-world entity. However, it is still a challenging solution and existing works are based on iterative methods, blocking schemes and learning approaches. Among these latter, recent works have been using embedding models, focusing only on structural information. In this paper, we present an approach for entity alignment that enrich entity embeddings with different literal information. To be able to express complex relationships between properties and involving multiple entities we employ FrameBase Schema, which is based on linguistic frames to create complex mappings from external knowledge bases to a unique schema. Preliminary experiments showed competitive results to the performance of entity alignment task. © 2018 Association for Computing Machinery.",Final,
Štajner S.; Hulpuş I.,"Štajner, Sanja (55634787100); Hulpuş, Ioana (36188149800)",55634787100; 36188149800,Automatic assessment of conceptual text complexity using knowledge graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113796054&partnerID=40&md5=41dfe972929ede701199ee6b7358cd91,"Complexity of texts is usually assessed only at the lexical and syntactic levels. Although it is known that conceptual complexity plays a significant role in text understanding, no attempts have been made at assessing it automatically. We propose to automatically estimate the conceptual complexity of texts by exploiting a number of graph-based measures on a large knowledge base. By using a high-quality language learners corpus for English, we show that graph-based measures of individual text concepts, as well as the way they relate to each other in the knowledge graph, have a high discriminative power when distinguishing between two versions of the same text. Furthermore, when used as features in a binary classification task aiming to choose the simpler of two versions of the same text, our measures achieve high performance even in a default setup. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Mirza P.; Darari F.; Mahendra R.,"Mirza, Paramita (55967562700); Darari, Fariz (55014563600); Mahendra, Rahmad (55314037600)",55967562700; 55014563600; 55314037600,KOI at SemEval-2018 Task 5: Building Knowledge Graph of Incidents,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112636696&partnerID=40&md5=37253e118aae31bfe2541d126809a743,"We present KOI (Knowledge of Incidents), a system that given news articles as input, builds a knowledge graph (KOI-KG) of incidental events. KOI-KG can then be used to efficiently answer questions such as “How many killing incidents happened in 2017 that involve Sean?” The required steps in building the KG include: (i) document preprocessing involving word sense disambiguation, named-entity recognition, temporal expression recognition and normalization, and semantic role labeling; (ii) incidental event extraction and coreference resolution via document clustering; and (iii) KG construction and population. © 2018 Association for Computational Linguistics",Final,
Moon S.; Neves L.; Carvalho V.,"Moon, Seungwhan (56583246100); Neves, Leonardo (57189597632); Carvalho, Vitor (14831058900)",56583246100; 57189597632; 14831058900,Zeroshot multimodal named entity disambiguation for noisy social media posts,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063072770&partnerID=40&md5=62fa27e5949feb05727ce374c5b53d84,"We introduce the new Multimodal Named Entity Disambiguation (MNED) task for multimodal social media posts such as Snapchat or Instagram captions, which are composed of short captions with accompanying images. Social media posts bring significant challenges for disambiguation tasks because 1) ambiguity not only comes from polysemous entities, but also from inconsistent or incomplete notations, 2) very limited context is provided with surrounding words, and 3) there are many emerging entities often unseen during training. To this end, we build a new dataset called SnapCaptionsKB, a collection of Snapchat image captions submitted to public and crowd-sourced stories, with named entity mentions fully annotated and linked to entities in an external knowledge base. We then build a deep zeroshot multimodal network for MNED that 1) extracts contexts from both text and image, and 2) predicts correct entity in the knowledge graph embeddings space, allowing for zeroshot disambiguation of entities unseen in training set as well. The proposed model significantly outperforms the state-of-the-art text-only NED models, showing efficacy and potentials of the MNED task. © 2018 Association for Computational Linguistics",Final,
Bose A.J.; Ling H.; Cao Y.,"Bose, Avishek Joey (57209182963); Ling, Huan (57202059633); Cao, Yanshuai (57217803234)",57209182963; 57202059633; 57217803234,Adversarial contrastive estimation,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063095652&doi=10.18653%2fv1%2fp18-1094&partnerID=40&md5=e89bf8eca63931b31b4a6965a3797e10,"Learning by contrasting positive and negative samples is a general strategy adopted by many methods. Noise contrastive estimation (NCE) for word embeddings and translating embeddings for knowledge graphs are examples in NLP employing this approach. In this work, we view contrastive learning as an abstraction of all such methods and augment the negative sampler into a mixture distribution containing an adversarially learned sampler. The resulting adaptive sampler finds harder negative examples, which forces the main model to learn a better representation of the data. We evaluate our proposal on learning word embeddings, order embeddings and knowledge graph embeddings and observe both faster convergence and improved results on multiple metrics. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Lei K.; Chen D.; Li Y.; Du N.; Yang M.; Fan W.; Shen Y.,"Lei, Kai (55440390400); Chen, Daoyuan (57200530014); Li, Yaliang (56273199400); Du, Nan (23479332200); Yang, Min (56349712700); Fan, Wei (7401635674); Shen, Ying (56763084800)",55440390400; 57200530014; 56273199400; 23479332200; 56349712700; 7401635674; 56763084800,Cooperative denoising for distantly supervised relation extraction,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119405619&partnerID=40&md5=2d338ee255c369b1941010d748a8e7ab,"Distantly supervised relation extraction greatly reduces human efforts in extracting relational facts from unstructured texts. However, it suffers from noisy labeling problem, which can degrade its performance. Meanwhile, the useful information expressed in knowledge graph is still underutilized in the state-of-the-art methods for distantly supervised relation extraction. In the light of these challenges, we propose CORD, a novel COopeRative Denoising framework, which consists two base networks leveraging text corpus and knowledge graph respectively, and a cooperative module involving their mutual learning by the adaptive bi-directional knowledge distillation and dynamic ensemble with noisy-varying instances. Experimental results on a real-world dataset demonstrate that the proposed method reduces the noisy labels and achieves substantial improvement over the state-of-the-art methods. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Opitz J.; Born L.; Nastase V.,"Opitz, Juri (57209542025); Born, Leo (57211253781); Nastase, Vivi (8681915400)",57209542025; 57211253781; 8681915400,Induction of a Large-Scale Knowledge Graph from the Regesta Imperii,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074892443&partnerID=40&md5=6691326bfb7f78adb5073e09c7502b6e,"We induce and visualize a Knowledge Graph over the Regesta Imperii (RI), an important large-scale resource for medieval history research. The RI comprise more than 150,000 digitized abstracts of medieval charters issued by the Roman-German kings and popes distributed over many European locations and a time span of more than 700 years. Our goal is to provide a resource for historians to visualize and query the RI, possibly aiding medieval history research. The resulting medieval graph and visualization tools are shared publicly. © COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings of the 2nd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, LaTeCH-CLfL 2018.",Final,
,,,"4th Annual International Symposium on Information Management and Big Data, SIMBig 2017",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045989038&partnerID=40&md5=f8ff5289b2fa2509d6770b7e5c6218c8,The proceedings contain 10 papers. The special focus in this conference is on Information Management and Big Data. The topics include: Could machine learning improve the prediction of child labor in Peru?; impact of entity graphs on extracting semantic relations; predicting invariant nodes in large scale semantic knowledge graphs; privacy-aware data gathering for urban analytics; Purely synthetic and domain independent consistency-guaranteed populations in SHIQ(D); language identification with scarce data: A case study from Peru; a multi-modal data-set for systematic analyses of linguistic ambiguities in situated contexts; community detection in bipartite network: A modified coarsening approach.,Final,
Chen W.; Xiong W.; Yan X.; Wang W.Y.,"Chen, Wenhu (57207770141); Xiong, Wenhan (57204282857); Yan, Xifeng (36083601600); Wang, William Yang (57233559700)",57207770141; 57204282857; 36083601600; 57233559700,Variational knowledge graph reasoning,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064262684&partnerID=40&md5=31e9551733fea4f7f6ab2144f16a9ee9,"Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (DIVA) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, DIVA is better at handling noise and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-The-Art performances on both datasets. © 2018 The Association for Computational Linguistics.",Final,
Zheng W.; Yu J.X.; Zou L.; Cheng H.,"Zheng, Weiguo (7403566336); Yu, Jeffrey Xu (57203435589); Zou, Lei (8359099800); Cheng, Hong (7404284983)",7403566336; 57203435589; 8359099800; 7404284983,Question answering over knowledge graphs: Question understanding via template decomposition,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058894308&doi=10.14778%2f3236187.3236192&partnerID=40&md5=04adef421eeedb2bdccae3fe50adc119,"The gap between unstructured natural language and structured data makes it challenging to build a system that supports using natural language to query large knowledge graphs. Many existing methods construct a structured query for the input question based on a syntactic parser. Once the input question is parsed incorrectly, a false structured query will be generated, which may result in false or incomplete answers. The problem gets worse especially for complex questions. In this paper, we propose a novel systematic method to understand natural language questions by using a large number of binary templates rather than semantic parsers. As sufficient templates are critical in the procedure, we present a low-cost approach that can build a huge number of templates automatically. To reduce the search space, we carefully devise an index to facilitate the online template decomposition. Moreover, we design effective strategies to perform the two-level disambiguations (i.e., entity-level ambiguity and structure-level ambiguity) by considering the query semantics. Extensive experiments over several benchmarks demonstrate that our proposed approach is effective as it significantly outperforms state-of-the-art methods in terms of both precision and recall. © 2018 VLDB Endowment.",Final,
,,,"17th China National Conference on Computational Linguistics, CCL 2018 and 6th International Symposium on Natural Language Processing Based on Naturally Annotated Big Data, NLP-NABD 2018",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055448190&partnerID=40&md5=f994279f21eaabbb44ff7af82afd31b6,The proceedings contain 33 papers. The special focus in this conference is on Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. The topics include: Knowledge graph embedding with logical consistency; an end-to-end entity and relation extraction network with multi-head attention; attention-based convolutional neural networks for Chinese relation extraction; a study on improving end-to-end neural coreference resolution; type hierarchy enhanced heterogeneous network embedding for fine-grained entity typing in knowledge bases; scientific keyphrase extraction: Extracting candidates with semi-supervised data augmentation; using a Chinese lexicon to learn sense embeddings and measure semantic similarity; revisiting correlations between intrinsic and extrinsic evaluations of word embeddings; question-answering aspect classification with hierarchical attention network; syntax enhanced research method of stylistic features; end-to-end task-oriented dialogue system with distantly supervised knowledge base retriever; Attention-based CNN-BLSTM networks for joint intent detection and slot filling; multi-perspective fusion network for commonsense reading comprehension; a hierarchical hybrid neural network architecture for Chinese text summarization; TSABCNN: Two-stage attention-based convolutional neural network for frame identification; linked document classification by network representation learning; a word embedding transfer model for robust text categorization; review headline generation with user embedding; a joint model for sentiment classification and opinion words extraction; network representation learning based on community and text features; addressing domain adaptation for Chinese word segmentation with instances-based transfer learning; learning to detect verbose expressions in spoken texts; Medical knowledge attention enhanced neural model for named entity recognition in Chinese EMR; coherence-based automated essay scoring using self-attention; collaborative matching for sentence alignment.,Final,
Elsahar H.; Gravier C.; Laforest F.,"Elsahar, Hady (56151546900); Gravier, Christophe (35613820900); Laforest, Frederique (57203117196)",56151546900; 35613820900; 57203117196,Zero-shot question generation from knowledge graphs for unseen predicates and entity types,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083521483&partnerID=40&md5=f1f4b1740f695692f589a262368bb16d,"We present a neural model for question generation from knowledge base triples in a ""Zero-Shot"" setup, that is generating questions for triples containing predicates, subject types or object types that were not seen at training time. Our model leverages triples occurrences in the natural language corpus in an encoderdecoder architecture, paired with an original part-of-speech copy action mechanism to generate questions. Benchmark and human evaluation show that our model sets a new state-ofthe-art for zero-shot QG. © 2018 The Association for Computational Linguistics.",Final,
Vilnis L.; Li X.; Murty S.; McCallum A.,"Vilnis, Luke (56896163100); Li, Xiang (57208293863); Murty, Shikhar (57214561869); McCallum, Andrew (7003773569)",56896163100; 57208293863; 57214561869; 7003773569,Probabilistic embedding of knowledge graphs with box lattice measures,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063101402&doi=10.18653%2fv1%2fp18-1025&partnerID=40&md5=24fef23fb10142f9926252205779e5e1,"Embedding methods which enforce a partial order or lattice structure over the concept space, such as Order Embeddings (OE) (Vendrov et al., 2016), are a natural way to model transitive relational data (e.g. entailment graphs). However, OE learns a deterministic knowledge base, limiting expressiveness of queries and the ability to use uncertainty for both prediction and learning (e.g. learning from expectations). Probabilistic extensions of OE (Lai and Hockenmaier, 2017) have provided the ability to somewhat calibrate these denotational probabilities while retaining the consistency and inductive bias of ordered models, but lack the ability to model the negative correlations found in real-world knowledge. In this work we show that a broad class of models that assign probability measures to OE can never capture negative correlation, which motivates our construction of a novel box lattice and accompanying probability measure to capture anticorrelation and even disjoint concepts, while still providing the benefits of probabilistic modeling, such as the ability to perform rich joint and conditional queries over arbitrary sets of concepts, and both learning from and predicting calibrated uncertainty. We show improvements over previous approaches in modeling the Flickr and WordNet entailment graphs, and investigate the power of the model. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Liu Z.; Xiong C.; Sun M.; Liu Z.,"Liu, Zhenghao (57194902552); Xiong, Chenyan (56405071400); Sun, Maosong (7403180987); Liu, Zhiyuan (57191691341)",57194902552; 56405071400; 7403180987; 57191691341,Entity-duet neural ranking: Understanding the role of knowledge graph semantics in neural information retrieval,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061193161&doi=10.18653%2fv1%2fp18-1223&partnerID=40&md5=7fd9ea97f0d33a051b0d7f2ed46380cc,"This paper presents the Entity-Duet Neural Ranking Model (EDRM), which introduces knowledge graphs to neural search systems. EDRM represents queries and documents by their words and entity annotations. The semantics from knowledge graphs are integrated in the distributed representations of their entities, while the ranking is conducted by interaction-based neural ranking networks. The two components are learned end-to-end, making EDRM a natural combination of entity-oriented search and neural information retrieval. Our experiments on a commercial search log demonstrate the effectiveness of EDRM. Our analyses reveal that knowledge graph semantics significantly improve the generalization ability of neural ranking models. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Li S.; Li X.; Ye R.; Wang M.; Su H.; Ou Y.,"Li, Shengnan (57204469565); Li, Xin (56017148700); Ye, Rui (58358549600); Wang, Mingzhong (55899236200); Su, Haiping (57204467754); Ou, Yingzi (57204475342)",57204469565; 56017148700; 58358549600; 55899236200; 57204467754; 57204475342,Non-translational alignment for multi-relational networks,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055709675&doi=10.24963%2fijcai.2018%2f581&partnerID=40&md5=f2dd95000d574410acaaf03ddd27624d,"Most existing solutions for the alignment of multirelational networks, such as multi-lingual knowledge bases, are ""translation""-based which facilitate the network embedding via the trans-family, such as TransE. However, they cannot address triangular or other structural properties effectively. Thus, we propose a non-translational approach, which aims to utilize a probabilistic model to offer more robust solutions to the alignment task, by exploring the structural properties as well as leveraging on anchors to project each network onto the same vector space during the process of learning the representation of individual networks. The extensive experiments on four multi-lingual knowledge graphs demonstrate the effectiveness and robustness of the proposed method over a set of stateof-the-art alignment methods. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",Final,All Open Access; Bronze Open Access
Radhakrishnan P.; Talukdar P.; Varma V.,"Radhakrishnan, Priya (55936730300); Talukdar, Partha (25652280700); Varma, Vasudeva (16053729400)",55936730300; 25652280700; 16053729400,ELDEN: Improved entity linking using densified knowledge graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083504420&partnerID=40&md5=dbb1b33c24df23e2de72e92771f5e6cf,"Entity Linking (EL) systems aim to automatically map mentions of an entity in text to the corresponding entity in a Knowledge Graph (KG). Degree of connectivity of an entity in the KG directly affects an EL system's ability to correctly link mentions in text to the entity in KG. This causes many EL systems to perform well for entities well connected to other entities in KG, bringing into focus the role of KG density in EL. In this paper, we propose Entity Linking using Densified Knowledge Graphs (ELDEN). ELDEN is an EL system which first densifies the KG with co-occurrence statistics from a large text corpus, and then uses the densified KG to train entity embeddings. Entity similarity measured using these trained entity embeddings result in improved EL. ELDEN outperforms stateof-the-Art EL system on benchmark datasets. Due to such densification, ELDEN performs well for sparsely connected entities in the KG too. ELDEN's approach is simple, yet effective. We have made ELDEN's code and data publicly available. © 2018 The Association for Computational Linguistics.",Final,
Newman-Griffis D.; Lai A.M.; Fosler-Lussier E.,"Newman-Griffis, Denis (57201858761); Lai, Albert M. (30767629500); Fosler-Lussier, Eric (8578109100)",57201858761; 30767629500; 8578109100,Jointly Embedding Entities and Text with Distant Supervision,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122021773&partnerID=40&md5=f74bcaf9c956597c0a795a17b441c919,"Learning representations for knowledge base entities and concepts is becoming increasingly important for NLP applications. However, recent entity embedding methods have relied on structured resources that are expensive to create for new domains and corpora. We present a distantly-supervised method for jointly learning embeddings of entities and text from an unnanotated corpus, using only a list of mappings between entities and surface forms. We learn embeddings from open-domain and biomedical corpora, and compare against prior methods that rely on human-annotated text or large knowledge graph structure. Our embeddings capture entity similarity and relatedness better than prior work, both in existing biomedical datasets and a new Wikipedia-based dataset that we release to the community. Results on analogy completion and entity sense disambiguation indicate that entities and words capture complementary information that can be effectively combined for downstream use. © 2018 Association for Computational Linguistics.",Final,
,,,"COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings of System Demonstrations",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122034687&partnerID=40&md5=39636b3ab158169b86d225fe5495e234,The proceedings contain 34 papers. The topics discussed include: abbreviation expander - a web-based system for easy reading of technical documents; the INCEpTION platform: machine-assisted and knowledge-oriented interactive annotation; JESEME: a website for exploring diachronic changes in word meaning and emotion; T-know: a knowledge graph-based question answering and information retrieval system for traditional Chinese medicine; a Korean knowledge extraction system for enriching a KBox; real-time scholarly retweeting prediction system; document representation learning for patient history visualization; hide: a tool for unrestricted literature based discovery; and active DOP: a constituency treebank annotation tool with online learning.,Final,
Azmy M.; Shi P.; Lin J.; Ilyas I.F.,"Azmy, Michael (57503977000); Shi, Peng (57211717851); Lin, Jimmy (56824507200); Ilyas, Ihab F. (6603960193)",57503977000; 57211717851; 56824507200; 6603960193,Farewell freebase: Migrating the SimpleQuestions dataset to DBpedia,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059516001&partnerID=40&md5=a0320632393ad98021bf13988601f5ff,"Question answering over knowledge graphs is an important problem of interest both commercially and academically. There is substantial interest in the class of natural language questions that can be answered via the lookup of a single fact, driven by the availability of the popular SIMPLEQUESTIONS dataset. The problem with this dataset, however, is that answer triples are provided from Freebase, which has been defunct for several years. As a result, it is difficult to build “real-world” question answering systems that are operationally deployable. Furthermore, a defunct knowledge graph means that much of the infrastructure for querying, browsing, and manipulating triples no longer exists. To address this problem, we present SIMPLEDBPEDIAQA, a new benchmark dataset for simple question answering over knowledge graphs that was created by mapping SIMPLEQUESTIONS entities and predicates from Freebase to DBpedia. Although this mapping is conceptually straightforward, there are a number of nuances that make the task non-trivial, owing to the different conceptual organizations of the two knowledge graphs. To lay the foundation for future research using this dataset, we leverage recent work to provide simple yet strong baselines with and without neural networks. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Trivedi R.; Faloutsos C.; Sisman B.; Zha H.; Ma J.; Dong X.L.,"Trivedi, Rakshit (36976457200); Faloutsos, Christos (7006005166); Sisman, Bunyamin (55339063700); Zha, Hongyuan (57201737688); Ma, Jun (57207857806); Dong, Xin Luna (55800289000)",36976457200; 7006005166; 55339063700; 57201737688; 57207857806; 55800289000,Linknbed: Multi-graph representation learning with entity linkage,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063091270&doi=10.18653%2fv1%2fp18-1024&partnerID=40&md5=cfe476f2ed5e25608e58bd91b2c41549,"Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Wang Y.-S.; Liu C.; Zeng X.; Yuille A.,"Wang, Yu-Siang (57221510024); Liu, Chenxi (57195953884); Zeng, Xiaohui (57216432160); Yuille, Alan (7006372632)",57221510024; 57195953884; 57216432160; 7006372632,Scene graph parsing as dependency parsing,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078746440&partnerID=40&md5=f112e0e531ef71e22006a0502912b597,"In this paper, we study the problem of parsing structured knowledge graphs from textual descriptions. In particular, we consider the scene graph representation (Johnson et al., 2015) that considers objects together with their attributes and relations: This representation has been proved useful across a variety of vision and language applications. We begin by introducing an alternative but equivalent edgecentric view of scene graphs that connect to dependency parses. Together with a careful redesign of label and action space, we combine the two-stage pipeline used in prior work (generic dependency parsing followed by simple post-processing) into one, enabling end-Toend training. The scene graphs generated by our learned neural dependency parser achieve an F-score similarity of 49.67% to ground truth graphs on our evaluation set, surpassing best previous approaches by 5%. We further demonstrate the effectiveness of our learned parser on image retrieval applications. © 2018 The Association for Computational Linguistics.",Final,
Wu Y.; Wang Z.,"Wu, Yanrong (57215565536); Wang, Zhichun (55211881600)",57215565536; 55211881600,Knowledge Graph Embedding with Numeric Attributes of Entities,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066858876&partnerID=40&md5=adf0ccd44e39f07a0600f2df9362682c,"Knowledge Graph (KG) embedding projects entities and relations into low dimensional vector space, which has been successfully applied in KG completion task. The previous embedding approaches only model entities and their relations, ignoring a large number of entities' numeric attributes in KGs. In this paper, we propose a new KG embedding model which jointly model entity relations and numeric attributes. Our approach combines an attribute embedding model with a translation-based structure embedding model, which learns the embeddings of entities, relations, and attributes simultaneously. Experiments of link prediction on YAGO and Freebase show that the performance is effectively improved by adding entities' numeric attributes in the embedding model. © 2018 Association for Computational Linguistics.",Final,
Wang H.; Zhang X.; Ma S.; Sun X.; Wang H.; Wang M.,"Wang, Hao (57203364426); Zhang, Xiaodong (57203326595); Ma, Shuming (57200277125); Sun, Xu (55744667900); Wang, Houfeng (57193227507); Wang, Mengxiang (55978115500)",57203364426; 57203326595; 57200277125; 55744667900; 57193227507; 55978115500,A neural question answering model based on semi-structured tables,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108798869&partnerID=40&md5=749ef04ce6beca0769a96fbd7fac66fd,"Most question answering (QA) systems are based on raw text and structured knowledge graph. However, raw text corpora are hard for QA system to understand, and structured knowledge graph needs intensive manual work, while it is relatively easy to obtain semi-structured tables from many sources directly, or build them automatically. In this paper, we build an end-to-end system to answer multiple choice questions with semi-structured tables as its knowledge. Our system answers queries by two steps. First, it finds the most similar tables. Then the system measures the relevance between each question and candidate table cells, and choose the most related cell as the source of answer. The system is evaluated with TabMCQ dataset, and gets a huge improvement compared to the state of the art. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Kumar A.; Kawahara D.; Kurohashi S.,"Kumar, Abhishek (57211377755); Kawahara, Daisuke (6701580216); Kurohashi, Sadao (8935020500)",57211377755; 6701580216; 8935020500,Knowledge-enriched two-layered attention network for sentiment analysis,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059660544&partnerID=40&md5=4ec5e2b4078d1f79d129334ef87dfc49,We propose a novel two-layered attention network based on Bidirectional Long Short-Term Memory for sentiment analysis. The novel two-layered attention network takes advantage of the external knowledge bases to improve the sentiment prediction. It uses the Knowledge Graph Embedding generated using the Word- Net. We build our model by combining the two-layered attention network with the supervised model based on Support Vector Regression using a Multilayer Perceptron network for sentiment analysis. We evaluate our model on the benchmark dataset of SemEval 2017 Task 5. Experimental results show that the proposed model surpasses the top system of SemEval 2017 Task 5. The model performs significantly better by improving the state-of-the-art system at SemEval 2017 Task 5 by 1.7 and 3.7 points for sub-tracks 1 and 2 respectively. © 2018 Association for Computational Linguistics.,Final,
Yin W.; Yaghoobzadeh Y.; Schütze H.,"Yin, Wenpeng (55418415800); Yaghoobzadeh, Yadollah (55668303000); Schütze, Hinrich (7003432991)",55418415800; 55668303000; 7003432991,Recurrent one-hop predictions for reasoning over knowledge graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079053011&partnerID=40&md5=00b793fadec8d612dbbd087c59745e3f,"Large scale knowledge graphs (KGs) such as Freebase are generally incomplete. Reasoning over multi-hop (mh) KG paths is thus an important capability that is needed for question answering or other NLP tasks that require knowledge about the world. mh-KG reasoning includes diverse scenarios, e.g., given a head entity and a relation path, predict the tail entity; or given two entities connected by some relation paths, predict the unknown relation between them. We present ROPs, recurrent one-hop predictors, that predict entities at each step of mh-KB paths by using recurrent neural networks and vector representations of entities and relations, with two benefits: (i) modeling mh-paths of arbitrary lengths while updating the entity and relation representations by the training signal at each step; (ii) handling different types of mh-KG reasoning in a unified framework. Our models show state-of-the-art for two important multi-hop KG reasoning tasks: Knowledge Base Completion and Path Query Answering. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Jansen P.A.,"Jansen, Peter A. (20433726100)",20433726100,Multi-hop inference for sentence-level textgraphs: How challenging is meaningfully combining information for science question answering?,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083667747&partnerID=40&md5=5b37fdac1c2cf2e9004571e5f931ac9e,"Question Answering for complex questions is often modelled as a graph construction or traversal task, where a solver must build or traverse a graph of facts that answer and explain a given question. This ""multi-hop"" inference has been shown to be extremely challenging, with few models able to aggregate more than two facts before being overwhelmed by ""semantic drift"", or the tendency for long chains of facts to quickly drift off topic. This is a major barrier to current inference models, as even elementary science questions require an average of 4 to 6 facts to answer and explain. In this work we empirically characterize the difficulty of building or traversing a graph of sentences connected by lexical overlap, by evaluating chance sentence aggregation quality through 9,784 manually-annotated judgements across knowledge graphs built from three freetext corpora (including study guides and SimpleWikipedia). We demonstrate semantic drift tends to be high and aggregation quality low, at between 0.04% and 3%, and highlight scenarios that maximize the likelihood of meaningfully combining information. © 2018 Association for Computational Linguistics.",Final,
Futia G.; Vetro A.; Melandri A.; De Martin J.C.,"Futia, Giuseppe (56102561400); Vetro, Antonio (36133927600); Melandri, Alessio (57194417036); De Martin, Juan Carlos (6603594962)",56102561400; 36133927600; 57194417036; 6603594962,Training neural language models with SPARQL queries for semi-automatic semantic mapping,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061962055&doi=10.1016%2fj.procs.2018.09.018&partnerID=40&md5=2c924c7334bf28b3f7311fde374a628f,"Knowledge graphs are labeled and directed multi-graphs that encode information in the form of entities and relationships. They are gaining attention in different areas of computer science: from the improvement of search engines to the development of virtual personal assistants. Currently, an open challenge in building large-scale knowledge graphs from structured data available on the Web (HTML tables, CSVs, JSONs) is the semantic integration of heterogeneous data sources. In fact, such diverse and scattered information rarely provide a formal description of metadata that is required to accomplish the integration task. In this paper we propose an approach based on neural networks to reconstruct the semantics of data sources to produce high quality knowledge graphs in terms of semantic accuracy. We developed a neural language model trained on a set of SPARQL queries performed on knowledge graphs. Through this model it is possible to semi-automatically generate a semantic map between the attributes of a data source and a domain ontology. © 2018 The Authors. Published by Elsevier B.V.",Final,All Open Access; Gold Open Access; Green Open Access
,,,"18th Euralex International Congress, 2018, EURALEX 2016",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059387167&partnerID=40&md5=c00cb9099aa3aaf1db061d410602202e,"This proceedings contains 89 papers. The motto of EURALEX 2018 is “Lexicography in global contexts“, emphasising changes in the field of lexicography related to digital transformation, and the associated need to bring together lexicographic efforts on a global level. The conference papers demonstrate how the reciprocity of Czech verbs can be represented in a lexicon in a comprehensive and systematic way. Czech represents a language where reciprocity is a highly productive phenomenon. Also it shows the semantic and syntactic properties are relevant for the description of reciprocal verbs, and based on this a user (be it human or computer) can acquire their reciprocal constructions. The conference topics include: The Dictionary-Making Process; Research on Dictionary Use; Lexicography and Language Technologies; Lexicography and Corpus Linguistics; Bi- and Multilingual Lexicography; Lexicography for Specialised Languages, Terminology and Terminography; Lexicography of Lesser Used languages; Phraseology and Collocation; Historical Lexicography and Etymology; Lexicological Issues of Lexicographical Relevance; Reports on Lexicographical and Lexicological Projects, etc. The key terms of this proceedings include DHmine dictionary, linked data lexical resources, bilingual corpus lexicography, OIM database, Neologism, linguistics and communication science, verbal contexts, ParCoLab parallel corpus, word embeddings, ELEXIS.",Final,
Das M.; Fosler-Lussier E.; Lin S.; Moosavinasab S.; Chen D.; Rust S.; Huang Y.; Ramnath R.,"Das, Manirupa (57188843249); Fosler-Lussier, Eric (8578109100); Lin, Simon (9537284100); Moosavinasab, Soheil (55805893400); Chen, David (57221136746); Rust, Steve (57191569599); Huang, Yungui (24175782300); Ramnath, Rajiv (57202486543)",57188843249; 8578109100; 9537284100; 55805893400; 57221136746; 57191569599; 24175782300; 57202486543,Phrase2VecGLM: Neural generalized language model–based semantic tagging for complex query reformulation in medical IR,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085981067&partnerID=40&md5=06594d79866dbd5ee7547bc9494c3efa,"In fact-based information retrieval, state-of-the-art performance is traditionally achieved by knowledge graphs driven by knowledge bases, as they can represent facts about and capture relationships between entities very well. However, in domains such as medical information retrieval, where addressing specific information needs of complex queries may require understanding query intent by capturing novel associations between potentially latent concepts, these systems can fall short. In this work, we develop a novel, completely unsupervised, neural language model–based ranking approach for semantic tagging of documents, using the document to be tagged as a query into the model to retrieve candidate phrases from top–ranked related documents, thus associating every document with novel related concepts extracted from the text. For this we extend the word embedding–based generalized language model (GLM) due to (Ganguly et al., 2015), to employ phrasal embeddings, and use the semantic tags thus obtained for downstream query expansion, both directly and in feedback loop settings. Our method, evaluated using the TREC 2016 clinical decision support challenge dataset, shows statistically significant improvement not only over various baselines that use standard MeSH terms and UMLS concepts for query expansion, but also over baselines using human expert–assigned concept tags for the queries, on top of a standard Okapi BM25–based document retrieval system. ©2018 Association for Computational Linguistics",Final,
Du J.; Qi K.; Shen Y.,"Du, Jianfeng (26663076800); Qi, Kunxun (57188548765); Shen, Yuming (21740354500)",26663076800; 57188548765; 21740354500,Knowledge graph embedding with logical consistency,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055431437&doi=10.1007%2f978-3-030-01716-3_11&partnerID=40&md5=9e454b41bbcc12b19debc97c2e238fe6,"Existing methods for knowledge graph embedding do not ensure the high-rank triples predicted by themselves to be as consistent as possible with the logical background which is made up of a knowledge graph and a logical theory. Users must take great effort to filter consistent triples before adding new triples to the knowledge graph. To alleviate users’ burden, we propose an approach to enhancing existing embedding-based methods to encode logical consistency into the learnt distributed representation for the knowledge graph, enforcing high-rank new triples as consistent as possible. To evaluate this approach, four knowledge graphs with logical theories are constructed from the four great classical masterpieces of Chinese literature. Experimental results on these datasets show that our approach is able to guarantee high-rank triples as consistent as possible while preserving a comparable performance as baseline methods in link prediction and triple classification. © Springer Nature Switzerland AG 2018.",Final,
,,,"18th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing 2017",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055727486&partnerID=40&md5=0df6a9bfa7a34e88a742bda84eaf467b,"The proceedings contain 94 papers. The special focus in this conference is on Computational Linguistics and Intelligent Text Processing. The topics include: HANS: A service-oriented framework for chinese language processing; learning to rank for coordination detection; classifier ensemble approach to dependency parsing; evaluation and enrichment of stanford parser using an arabic property grammar; senseDependency-rank: A word sense disambiguation method based on random walks and dependency trees; domain adaptation for word sense disambiguation using word embeddings; “show me the cup”: Reference with continuous representations; improved best-first clustering for coreference resolution in indian classical music forums; a robust coreference chain builder for tamil; pooling word vector representations across models; Structured named entity recognition by cascading CRFs; Arabic named entity recognition: A bidirectional GRU-CRF approach; named entity recognition for amharic using stack-based deep learning; idioms: Humans or machines, it’s all about context; dialogue act taxonomy interoperability using a meta-model; textual entailment using machine translation evaluation metrics; supervised learning of entity disambiguation models by negative sample selection; the enrichment of arabic WordNet antonym relations; designing an ontology for physical exercise actions; visualizing textbook concepts: Beyond word co-occurrences; strategies to select examples for active learning with conditional random fields; matching, re-ranking and scoring: Learning textual similarity by incorporating dependency graph alignment and coverage features; text similarity function based on word embeddings for short text analysis; domain specific features driven information extraction from web pages of scientific conferences; classifier-based pattern selection approach for relation instance extraction; an ensemble architecture for linked data lexicalization.",Final,
Ishihara T.; Hayashi K.; Manabe H.; Shimbo M.; Nagata M.,"Ishihara, Takahiro (57216437486); Hayashi, Katsuhiko (55628535930); Manabe, Hitoshi (57205545195); Shimbo, Masahi (8226981900); Nagata, Masaaki (7402879306)",57216437486; 55628535930; 57205545195; 8226981900; 7402879306,Neural tensor networks with diagonal slice matrices,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081731425&partnerID=40&md5=9e040e44ead530afc26abdf0b99fb41a,"Although neural tensor networks (NTNs) have been successful in many natural language processing tasks, they require a large number of parameters to be estimated, which often results in overfitting and long training times. We address these issues by applying eigendecomposition to each slice matrix of a tensor to reduce the number of parameters. We evaluate our proposed NTN models in two tasks. First, the proposed models are evaluated in a knowledge graph completion task. Second, a recursive NTN (RNTN) extension of the proposed models is evaluated on a logical reasoning task. The experimental results show that our proposed models learn better and faster than the original (R)NTNs. © 2018 The Association for Computational Linguistics.",Final,
Chandrahas; Sharma A.; Talukdar P.,"Chandrahas (57207858418); Sharma, Aditya (57207856342); Talukdar, Partha (25652280700)",57207858418; 57207856342; 25652280700,Towards understanding the geometry of knowledge graph embeddings,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061694537&doi=10.18653%2fv1%2fp18-1012&partnerID=40&md5=1ce74cb037410e4c54e61f0bf79db10b,"Knowledge Graph (KG) embedding has emerged as a very active area of research over the last few years, resulting in the development of several embedding methods. These KG embedding methods represent KG entities and relations as vectors in a high-dimensional space. Despite this popularity and effectiveness of KG embeddings in various tasks (e.g., link prediction), geometric understanding of such embeddings (i.e., arrangement of entity and relation vectors in vector space) is unexplored - we fill this gap in the paper. We initiate a study to analyze the geometry of KG embeddings and correlate it with task performance and other hyperparameters. To the best of our knowledge, this is the first study of its kind. Through extensive experiments on real-world datasets, we discover several insights. For example, we find that there are sharp differences between the geometry of embeddings learnt by different classes of KG embeddings methods. We hope that this initial study will inspire other follow-up research on this important but unexplored problem. © 2018 Association for Computational Linguistics",Final,All Open Access; Hybrid Gold Open Access
Usbeck R.; Ngomo A.-C.N.; Conrads F.; Röder M.; Napolitano G.,"Usbeck, Ricardo (43661711000); Ngomo, Axel-Cyrille Ngonga (23397850200); Conrads, Felix (57196196974); Röder, Michael (56406159300); Napolitano, Giulio (8317036600)",43661711000; 23397850200; 57196196974; 56406159300; 8317036600,8th challenge on question answering over linked data (QALD-8),-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056810696&partnerID=40&md5=7f3a9a97546fb0920bf526d64f312a1e,"The QALD-8 challenge focused on the successful and long running multilingual QA task. For the first time, the participating teams were required to provide webservices of their systems to participate in the challenge, which will in turn support comparable research in the future. In this challenge, we also changed the underlying evaluation platform to account for the need for comparable experiments via webservices in contrast to former XML/JSON file submissions. This increased the entrance requirements for participating teams but ensures long term comparability of the system performance and a fair and open challenge. In the future, we will further simplify the participation process and offer leaderboards prior to the actual challenge to allow participants to see their performance beforehand. After feedback from the authors, we will likely add new key performance indicators for the capability of a system to know which questions it cannot answer and take confidence scores for answers into account. Moreover, we will remove most of the curve ball questions to reflect the original character of the QALD challenge, which provides a clean and linguistically challenging benchmark. © 2018 CEUR-WS. All Rights Reserved.",Final,
,,,"NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Demonstrations Session",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122284252&partnerID=40&md5=f98fce9b6b3a6f56053c17c883a2f6a2,"The proceedings contain 19 papers. The topics discussed include: NLP lean programming framework: developing NLP applications more effectively; pay-per-request deployment of neural network models using serverless architectures; an automated medical scribe for documenting clinical encounters; CL scholar: the ACL anthology knowledge graph miner; ClaimRank: detecting check-worthy claims in Arabic and English; DebugSL: an interactive tool for debugging sentiment lexicons; ELISA-EDL: a cross-lingual entity extraction, linking and localization system; entity resolution and location disambiguation in the ancient Hindu temples domain using web data; and madly ambiguous: a game for learning about structural ambiguity and why it’s hard for computers.",Final,
Mousselly-Sergieh H.; Botschen T.; Gurevych I.; Roth S.,"Mousselly-Sergieh, Hatem (49961968300); Botschen, Teresa (57205434991); Gurevych, Iryna (24474583400); Roth, Stefan (57217407745)",49961968300; 57205434991; 24474583400; 57217407745,A Multimodal Translation-Based Approach for Knowledge Graph Representation Learning,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122285010&partnerID=40&md5=53ab004e51746ae54029db94fccb44d5,"Current methods for knowledge graph (KG) representation learning focus solely on the structure of the KG and do not exploit any kind of external information, such as visual and linguistic information corresponding to the KG entities. In this paper, we propose a multimodal translation-based approach that defines the energy of a KG triple as the sum of sub-energy functions that leverage both multimodal (visual and linguistic) and structural KG representations. Next, a ranking-based loss is minimized using a simple neural network architecture. Moreover, we introduce a new large-scale dataset for multimodal KG representation learning. We compared the performance of our approach to other baselines on two standard tasks, namely knowledge graph completion and triple classification, using our as well as the WN9-IMG dataset.1 The results demonstrate that our approach outperforms all baselines on both tasks and datasets. © 2018 Association for Computational Linguistics.",Final,
Mohammed S.; Shi P.; Lin J.,"Mohammed, Salman (57195628088); Shi, Peng (57211717851); Lin, Jimmy (56824507200)",57195628088; 57211717851; 56824507200,Strong baselines for simple question answering over knowledge graphs with and without neural networks,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061740114&partnerID=40&md5=3e3623ffe598569020b4ca67f8637c28,"We examine the problem of question answering over knowledge graphs, focusing on simple questions that can be answered by the lookup of a single fact. Adopting a straightforward decomposition of the problem into entity detection, entity linking, relation prediction, and evidence combination, we explore simple yet strong baselines. On the popular SIMPLEQUESTIONS dataset, we find that basic LSTMs and GRUs plus a few heuristics yield accuracies that approach the state of the art, and techniques that do not use neural networks also perform reasonably well. These results show that gains from sophisticated deep learning techniques proposed in the literature are quite modest and that some previous models exhibit unnecessary complexity. © 2018 Association for Computational Linguistics.",Final,
Singh M.; Dogga P.; Patro S.; Barnwal D.; Dutt R.; Haldar R.; Goyal P.; Mukherjee A.,"Singh, Mayank (58609938800); Dogga, Pradeep (57211025213); Patro, Sohan (57219622798); Barnwal, Dhiraj (57219620410); Dutt, Ritam (57205030520); Haldar, Rajarshi (57507917800); Goyal, Pawan (57119093300); Mukherjee, Animesh (57203731567)",58609938800; 57211025213; 57219622798; 57219620410; 57205030520; 57507917800; 57119093300; 57203731567,CL Scholar: The ACL Anthology Knowledge Graph Miner,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084036960&partnerID=40&md5=6be0fee47a5b01c6603458ba291e83f5,"We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at http://cnerg.iitkgp.ac.in/aclakg. We also provide REST API support along with bulk download facility. Our code and data are available at https://github.com/CLScholar. © 2018 Association for Computational Linguistics.",Final,
Sharifirad S.; Jafarpour B.; Matwin S.,"Sharifirad, Sima (54279337600); Jafarpour, Borna (55658475900); Matwin, Stan (7003305494)",54279337600; 55658475900; 7003305494,Boosting Text Classification Performance on Sexist Tweets by Text Augmentation and Text Generation Using a Combination of Knowledge Graphs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122034405&partnerID=40&md5=e67cecc10a27bcbde6873a58fce6ca73,"Text classification models have been heavily utilized for a slew of interesting natural language processing problems. Like any other machine learning model, these classifiers are very dependent on the size and quality of the training dataset. Insufficient and imbalanced datasets will lead to poor performance. An interesting solution to poor datasets is to take advantage of the world knowledge in the form of knowledge graphs to improve our training data. In this paper, we use ConceptNet and Wikidata to improve sexist tweet classification by two methods (1) text augmentation and (2) text generation. In our text generation approach, we generate new tweets by replacing words using data acquired from ConceptNet relations in order to increase the size of our training set, this method is very helpful with frustratingly small datasets, preserves the label and increases diversity. In our text augmentation approach, the number of tweets remains the same but their words are augmented (concatenation) with words extracted from their ConceptNet relations and their description extracted from Wikidata. In our text augmentation approach, the number of tweets in each class remains the same but the range of each tweet increases. Our experiments show that our approach improves sexist tweet classification significantly in our entire machine learning models. Our approach can be readily applied to any other small dataset size like hate speech or abusive language and text classification problem usinganymachine learning model. © 2018 Association for Computational Linguistics",Final,
Cai L.; Wang W.Y.,"Cai, Liwei (57216430972); Wang, William Yang (57233559700)",57216430972; 57233559700,KBGAN: Adversarial learning for knowledge graph embeddings,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083519122&partnerID=40&md5=96a3d41853ceaeec274003fd522233d9,"We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings. © 2018 The Association for Computational Linguistics.",Final,
Frost R.A.; Peelar S.,"Frost, Richard A. (7202424559); Peelar, Shane (56022761300)",7202424559; 56022761300,An extensible natural-language query interface to an event-based semantic web triplestore,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056815729&partnerID=40&md5=9ad0d7a93947d10c1c9a47d4d4101e6e,"An advantage of the semantic web is that information can be easily added to existing data. Ideally, it should be possible to query the original and new data, using an extensible natural-language query interface. (NLQI). In order to facilitate the extension of an NLQI, it helps if the query language is based on a compositional semantics, and if the language processor is highly modular. Such an NLQI to an online event-based triplestore has been constructed and is available through a web interface. The NLQI is implemented as an executable specification of a highly modular attribute grammar using parser combinators in a pure functional programming language. The parser/interpreter can handle ambiguous left-recursive grammars and fully dependent synthesized and inherited attributes. This enables the integration of semantic rules with syntactic rules, in the style of Montague Grammars, which facilitates the addition of new constructs to the query language. © 2018 CEUR-WS. All Rights Reserved.",Final,
,,,"18th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing 2017",-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055431774&partnerID=40&md5=d3db1198c1c81566628680c7f8dfd78d,"The proceedings contain 94 papers. The special focus in this conference is on Computational Linguistics and Intelligent Text Processing. The topics include: HANS: A service-oriented framework for chinese language processing; learning to rank for coordination detection; classifier ensemble approach to dependency parsing; evaluation and enrichment of stanford parser using an arabic property grammar; senseDependency-rank: A word sense disambiguation method based on random walks and dependency trees; domain adaptation for word sense disambiguation using word embeddings; “show me the cup”: Reference with continuous representations; improved best-first clustering for coreference resolution in indian classical music forums; a robust coreference chain builder for tamil; pooling word vector representations across models; Structured named entity recognition by cascading CRFs; Arabic named entity recognition: A bidirectional GRU-CRF approach; named entity recognition for amharic using stack-based deep learning; idioms: Humans or machines, it’s all about context; dialogue act taxonomy interoperability using a meta-model; textual entailment using machine translation evaluation metrics; supervised learning of entity disambiguation models by negative sample selection; the enrichment of arabic WordNet antonym relations; designing an ontology for physical exercise actions; visualizing textbook concepts: Beyond word co-occurrences; strategies to select examples for active learning with conditional random fields; matching, re-ranking and scoring: Learning textual similarity by incorporating dependency graph alignment and coverage features; text similarity function based on word embeddings for short text analysis; domain specific features driven information extraction from web pages of scientific conferences; classifier-based pattern selection approach for relation instance extraction; an ensemble architecture for linked data lexicalization.",Final,
Ding B.; Wang Q.; Wang B.; Guo L.,"Ding, Boyang (57192369957); Wang, Quan (55584980300); Wang, Bin (55584805140); Guo, Li (56564475400)",57192369957; 55584980300; 55584805140; 56564475400,Improving knowledge graph embedding using simple constraints,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063106448&doi=10.18653%2fv1%2fp18-1011&partnerID=40&md5=b61eb1b06b99207eb8cdeda67f2fc784,"Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Early works performed this task via simple models developed over KG triples. Recent attempts focused on either designing more complicated triple scoring models, or incorporating extra information beyond triples. This paper, by contrast, investigates the potential of using very simple constraints to improve KG embedding. We examine non-negativity constraints on entity representations and approximate entailment constraints on relation representations. The former help to learn compact and interpretable representations for entities. The latter further encode regularities of logical entailment between relations into their distributed representations. These constraints impose prior beliefs upon the structure of the embedding space, without negative impacts on efficiency or scalability. Evaluation on WordNet, Freebase, and DBpedia shows that our approach is simple yet surprisingly effective, significantly and consistently outperforming competitive baselines. The constraints imposed indeed improve model interpretability, leading to a substantially increased structuring of the embedding space. Code and data are available at https://github.com/iieir-km/ComplEx-NNE_AER. © 2018 Association for Computational Linguistics",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Zhang X.; Lin E.; Lv Y.,"Zhang, Xiang (8400208700); Lin, Erjing (57192384209); Lv, Yulian (57192381571)",8400208700; 57192384209; 57192381571,Multi-target search on semantic associations in linked data,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038589774&doi=10.4018%2fIJSWIS.2018010103&partnerID=40&md5=93b711b54966c5e98e8973e3de860385,"In this article, the authors propose a novel search model: Multi-Target Search (MT search in brief). MT search is a keyword-based search model on Semantic Associations in Linked Data. Each search contains multiple sub-queries, in which each sub-query represents a certain user need for a certain object in a group relationship. They first formularize the problem of association search, and then introduce their approach to discover Semantic Associations in large-scale Linked Data. Next, they elaborate their novel search model, the notion of Virtual Document they use to extract linguistic features, and the details of search process. The authors then discuss the way search results are organized and summarized. Quantitative experiments are conducted on DBpedia to validate the effectiveness and efficiency of their approach. Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",Final,
An B.; Chen B.; Han X.; Sun L.,"An, Bo (57193229848); Chen, Bo (56683353000); Han, Xianpei (35302334000); Sun, Le (55453689000)",57193229848; 56683353000; 35302334000; 55453689000,Accurate text-enhanced knowledge graph representation learning,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065643962&partnerID=40&md5=cf0de02b4f0b09bf79a22ebb07737b95,"Previous representation learning techniques for knowledge graph representation usually represent the same entity or relation in different triples with the same representation, without considering the ambiguity of relations and entities. To appropriately handle the semantic variety of entities/relations in distinct triples, we propose an accurate text-enhanced knowledge graph representation learning method, which can represent a relation/entity with different representations in different triples by exploiting additional textual information. Specifically, our method enhances representations by exploiting the entity descriptions and triplespecific relation mention. And a mutual attention mechanism between relation mention and entity description is proposed to learn more accurate textual representations for further improving knowledge graph representation. Experimental results show that our method achieves the state-of-The-Art performance on both link prediction and triple classification tasks, and significantly outperforms previous text-enhanced knowledge representation models. © 2018 The Association for Computational Linguistics.",Final,
Lengerich B.J.; Maas A.L.; Potts C.,"Lengerich, Benjamin J. (56132063200); Maas, Andrew L. (25926014800); Potts, Christopher (57206534134)",56132063200; 25926014800; 57206534134,Retrofitting distributional embeddings to knowledge graphs with functional relations,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083094891&partnerID=40&md5=1b543e2a44f15bc08c2a72105b4779ea,"Knowledge graphs are a versatile framework to encode richly structured data relationships, but it can be challenging to combine these graphs with unstructured data. Methods for retrofitting pre-trained entity representations to the structure of a knowledge graph typically assume that entities are embedded in a connected space and that relations imply similarity. However, useful knowledge graphs often contain diverse entities and relations (with potentially disjoint underlying corpora) which do not accord with these assumptions. To overcome these limitations, we present Functional Retrofitting, a framework that generalizes current retrofitting methods by explicitly modeling pairwise relations. Our framework can directly incorporate a variety of pairwise penalty functions previously developed for knowledge graph completion. Further, it allows users to encode, learn, and extract information about relation semantics. We present both linear and neural instantiations of the framework. Functional Retrofitting significantly outperforms existing retrofitting methods on complex knowledge graphs and loses no accuracy on simpler graphs (in which relations do imply similarity). Finally, we demonstrate the utility of the framework by predicting new drug–disease treatment pairs in a large, complex health knowledge graph. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",Final,
Zhou K.; Zhang S.; Meng X.; Luo Q.; Wang Y.; Ding K.; Feng Y.; Chen M.; Cohen K.B.; Xia J.,"Zhou, Kaiyin (57204389898); Zhang, Sheng (57207781593); Meng, Xiangyu (56704007200); Luo, Qi (57207780789); Wang, Yuxing (57204397983); Ding, Ke (57396561400); Feng, Yukun (57396561500); Chen, Mo (57396450900); Cohen, Kevin B. (8314739900); Xia, Jingbo (57213811316)",57204389898; 57207781593; 56704007200; 57207780789; 57204397983; 57396561400; 57396561500; 57396450900; 8314739900; 57213811316,CRF-LSTM Text Mining Method Unveiling the Pharmacological Mechanism of Off-target Side Effect of Anti-Multiple Myeloma Drugs,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061195826&partnerID=40&md5=3af68b9d79dd15325cedd80cf874d134,"Off-target effects played a vital role in the pharmacological understanding of drug efficacy and this research aimed to use text mining strategy to curate molecular level information and unveil the mechanism of off-target effect caused by the usage of anti-multiple myeloma (MM) drugs. After training a hybrid CNN-CRF-LSTM neural network upon the training data from TAC 2017 benchmark database, we extracted all of the side effects of 16 anti-MM drugs from drug labels, and combined the results with existed database. Afterwards, gene targets of anti-MM drugs were obtained by using structure similarity, and their related phenotypes were retrieved from Human Phenotype Ontology. Furthermore, linked phenotypes to candidate genes and adverse reaction of known drugs formed a knowledge graph. Through regulation analysis upon intersected phenotypes of drugs and target genes, an off-target effect caused by SLC7A7 was found, which with high possibility unveiled the pharmacological mechanism of side effect after using combination of anti-MM drugs. ©2018 Association for Computational Linguistics",Final,
Annervaz K.M.; Chowdhury S.B.R.; Dukkipati A.,"Annervaz, K.M. (55097116000); Chowdhury, Somnath Basu Roy (58400675600); Dukkipati, Ambedkar (9248163900)",55097116000; 58400675600; 9248163900,Learning beyond datasets: Knowledge graph augmented neural networks for natural language processing,-1,,-1,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075751697&partnerID=40&md5=53881b9376f21b7c2dd77a987ac41ebb,"Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data. Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks. Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism. We introduce a convolutionbased model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base. © 2018 The Association for Computational Linguistics.",Final,
Maurits L.; Forkel R.; Kaiping G.A.; Atkinson Q.D.,"Maurits, Luke (55208185900); Forkel, Robert (57195331057); Kaiping, Gereon A. (56433669900); Atkinson, Quentin D. (22633898400)",55208185900; 57195331057; 56433669900; 22633898400,BEASTling: A software tool for linguistic phylogenetics using BEAST 2,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027222934&doi=10.1371%2fjournal.pone.0180908&partnerID=40&md5=9dc8cb489c85e8537f84c373ffaa9ce6,"We present a new open source software tool called BEASTling, designed to simplify the preparation of Bayesian phylogenetic analyses of linguistic data using the BEAST 2 platform. BEASTling transforms comparatively short and human-readable configuration files into the XML files used by BEAST to specify analyses. By taking advantage of Creative Commons-licensed data from the Glottolog language catalog, BEASTling allows the user to conveniently filter datasets using names for recognised language families, to impose monophyly constraints so that inferred language trees are backward compatible with Glottolog classifications, or to assign geographic location data to languages for phylogeographic analyses. Support for the emerging cross-linguistic linked data format (CLDF) permits easy incorporation of data published in cross-linguistic linked databases into analyses. BEASTling is intended to make the power of Bayesian analysis more accessible to historical linguists without strong programming backgrounds, in the hopes of encouraging communication and collaboration between those developing computational models of language evolution (who are typically not linguists) and relevant domain experts. © 2017 Maurits et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",Final,All Open Access; Gold Open Access; Green Open Access
Pagé-Perron É.; Sukhareva M.; Khait I.; Chiarcos C.,"Pagé-Perron, Émilie (57203468297); Sukhareva, Maria (56644499500); Khait, Ilya (57204704002); Chiarcos, Christian (22333764800)",57203468297; 56644499500; 57204704002; 22333764800,Machine Translation and Automated Analysis of the Sumerian Language,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059890337&partnerID=40&md5=318523f69de03ef659bd4218db0c5925,"This paper presents a newly funded international project for machine translation and automated analysis of ancient cuneiform languages where NLP specialists and Assyriologists collaborate to create an information retrieval system for Sumerian. This research is conceived in response to the need to translate large numbers of administrative texts that are only available in transcription, in order to make them accessible to a wider audience. The methodology includes creation of a specialized NLP pipeline and also the use of linguistic linked open data to increase access to the results. © 2017 Association for Computational Linguistics",Final,
Perera R.; Nand P.; Naeem A.,"Perera, Rivindu (56425389400); Nand, Parma (6506991350); Naeem, Asif (57204556515)",56425389400; 6506991350; 57204556515,Utilizing typed dependency subtree patterns for answer sentence generation in question answering systems,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055418047&doi=10.1007%2fs13748-017-0113-9&partnerID=40&md5=c3c87f2882b22e30a380ee879e713721,"Question Answering over Linked Data (QALD) refer to the use of Linked Data by question answering systems, and in recent times this has become increasingly popular as it opens up a massive Linked Data cloud which is a rich source of encoded knowledge. However, a major shortfall of current QALD systems is that they focus on presenting a single fact or factoid answer which is derived using SPARQL (SPARQL Protocol and RDF Query Language) queries. There is now an increased interest in development of human-like systems which would be able to answer questions and even hold conversations by constructing sentences akin to humans. In this paper, we introduce a new answer construction and presentation system, which utilizes the linguistic structure of the source question and the factoid answer to construct an answer sentence which closely emanates a human-generated answer. We employ both semantic Web technology and the linguistic structure to construct the answer sentences. The core of the research resides on extracting dependency subtree patterns from the questions and utilizing them in conjunction with the factoid answer to generate the answer sentence with a natural feel akin to an answer from a human when asked the question. We evaluated the system for both linguistic accuracy and naturalness using human evaluation. These evaluation processes showed that the proposed approach is able to generate answer sentences which have linguistic accuracy and natural readability quotients of more than 70%. In addition, we also carried out a feasibility analysis on using automatic metrics for answer sentence evaluation. The results from this phase showed that the there is not a strong correlation between the results from automatic metric evaluation and the human ratings of the machine-generated answers. © 2017, Springer-Verlag Berlin Heidelberg.",Final,
Alam M.; Recupero D.R.; Mongiovi M.; Gangemi A.; Ristoski P.,"Alam, Mehwish (57201532578); Recupero, Diego Reforgiato (57206674454); Mongiovi, Misael (24339046000); Gangemi, Aldo (55605133800); Ristoski, Petar (55321570300)",57201532578; 57206674454; 24339046000; 55605133800; 55321570300,Reconciling event-based knowledge through RDF2Vec,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045919780&partnerID=40&md5=03b9e4e233fc66c982b6cc1f02358b2f,"The reconciled knowledge graphs are typically used for multidocument summarization, or to detect knowledge evolution across document series. This paper focuses on reconciling knowledge graphs generated from two text documents about similar events described differently. Our approach employs and extends MERGILO, a tool for reconciling knowledge graphs extracted from text, using word similarity and graph alignment. Complete semantic representation of events are generated using FRED, a semantic web machine reader, jointly with Framester, a linguistic linked data hub represented using a novel formal semantics for frames. Event-reconciliation is mainly performed via similarities based on the graph structure of frames using RDF2Vec graph embeddings, and the subsumption hierarchy of semantic roles as defined in Framester. Our approach is evaluated over a coreference resolution task. © 2017 CEUR-WS. All rights reserved.",Final,
Padia A.,"Padia, Ankur (57193610060)",57193610060,Cleaning noisy knowledge graphs,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033728623&partnerID=40&md5=b8e8b6736a30fb6ba5c640c1e8398123,"My dissertation research is developing an approach to identify and explain errors in a knowledge graph constructed by extracting entities and relations from text. Information extraction systems can automatically construct knowledge graphs from a large collection of documents, which might be drawn from news articles, Web pages, social media posts or discussion forums. The language understanding task is challenging and current extraction systems introduce many kinds of errors. Previous work on improving the quality of knowledge graphs uses additional evidence from background knowledge bases or Web searches. Such approaches are difficult to apply when emerging entities are present and/or only one knowledge graph is available. In order to address the problem I am using multiple complementary techniques including entitylinking, common sense reasoning; and linguistic analysis.",Final,
Sasaki F.; Dojchinovski M.; Nehring J.,"Sasaki, Felix (8938640000); Dojchinovski, Milan (55453114000); Nehring, Jan (57191890693)",8938640000; 55453114000; 57191890693,Chainable and extendable knowledge integration web services,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033485889&doi=10.1007%2f978-3-319-68723-0_8&partnerID=40&md5=e46693343a10362da27d4f57c95faa3a,"This paper introduces the current state of the FREME framework. The paper puts FREME into the context of linguistic linked data and related approaches of multilingual and semantic processing. In addition, we focus on two specific aspects of FREME: the FREME NER e-Service, and chaining of FREME e-Services. We believe that the flexible and distributed combination of e-Services bears a potential for their mutual improvement. The FREME framework is an open source software available for free download (https://github.com/freme-project/). © Springer International Publishing AG 2017.",Final,
Du Y.; Li C.; Hu Q.; Li X.; Chen X.,"Du, YaJun (7402893744); Li, ChenXing (56937260700); Hu, Qiang (56146632100); Li, XiaoLei (55951842600); Chen, XiaoLiang (55908009800)",7402893744; 56937260700; 56146632100; 55951842600; 55908009800,Ranking webpages using a path trust knowledge graph,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023618311&doi=10.1016%2fj.neucom.2016.08.142&partnerID=40&md5=24e85bcfb3b1f6bcc03c9da7a93d2930,"The number of webpages on the Internet continues to increase rapidly. Countless webpages focus on user-related issues. Finding useful information on such webpages constitutes a real challenge in the realms of information retrieval and search engine management. Based on the Link Context Graph (LCG), Relevancy Context Graph (RCG) and Concept Context Graph (CCG), we propose and construct a Path Trust Knowledge Graph (PTKG) model for assigning priority values to unvisited webpages. The PTKG model guides a focused crawler to retrieve more relevant webpages with respect to user-specific topics. A given user-specific topic t includes a PTKG that involves six steps: (1) building context graph G(t)=(V,E), where V is the crawled history webpage set and E is the hyperlink set within the history webpages, (2) retrieving the knowledge implied in the paths among these webpages and finding the path lengths, (3) computing the trust degrees of webpages, (4) constructing topic-specific language models using the trust degrees, (5) establishing general language models, and (6) assigning priority values to webpages for ranking purposes. A framework of topic-specific web crawlers based on a PTKG is constructed to collect webpages on user-specific topics. Finally, we draw experimental comparisons between our proposed PTKG approach and the classic LCG and RCG approaches. We show that our method outperforms the LCG and RCG approaches. © 2017 Elsevier B.V.",Final,
Mauro N.; Ardissono L.; Savoca A.,"Mauro, Noemi (57191504166); Ardissono, Liliana (6603677372); Savoca, Adriano (56562912600)",57191504166; 6603677372; 56562912600,Concept-Aware geographic information retrieval,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031011379&doi=10.1145%2f3106426.3106498&partnerID=40&md5=5176d9735ac9b89e1e4e4be22fe2518d,"Textual queries are largely employed in information retrieval to let users specify search goals in a natural way. However, differences in user and system terminologies can challenge the identification of the user's information needs, and thus the generation of relevant results. We argue that the explicit management of ontological knowledge, and of the meaning of concepts (by integrating linguistic and encyclopaedic knowledge in the system ontology), can improve the analysis of search queries, because it enables a flexible identification of the topics the user is searching for, regardless of the adopted vocabulary,is paper proposes an information retrieval support model based on semantic concept identification. Starting from the recognition of the ontology concepts that the search query refers to, this model exploits the qualifiers specified in the query to select information items on the basis of possibly fine-grained features. Moreover, it supports query expansion and reformulation by suggesting the exploration of semantically similar concepts, as well as of concepts related to those referred in the query through thematic relations. A test on a data-set collected using the OnToMap Participatory GIS has shown that this approach provides accurate results. © 2017 ACM.",Final,All Open Access; Green Open Access
Agnoloni T.; Bacci L.; Peruginelli G.; Van Opijnen M.; Van Den Oever J.; Palmirani M.; Cervone L.; Bujor O.; Arsuaga Lecuona A.; Boada García A.; Di Caro L.; Siragusa G.,"Agnoloni, Tommaso (57199421725); Bacci, Lorenzo (6602189384); Peruginelli, Ginevra (19337767400); Van Opijnen, Marc (35575248900); Van Den Oever, Jos (57196393038); Palmirani, Monica (57193195959); Cervone, Luca (35179036800); Bujor, Octavian (56131429400); Arsuaga Lecuona, Arantxa (57199421173); Boada García, Alberto (56377187700); Di Caro, Luigi (57207954874); Siragusa, Giovanni (24759424600)",57199421725; 6602189384; 19337767400; 35575248900; 57196393038; 57193195959; 35179036800; 56131429400; 57199421173; 56377187700; 57207954874; 24759424600,"Linking European case law: BO-ECLI parser, an open framework for the automatic extraction of legal links",-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037995311&doi=10.3233%2f978-1-61499-838-9-113&partnerID=40&md5=51139dca54f7a6afe8aa7336cee2f60a,"In this paper we present the BO-ECLI Parser, an open framework for the extraction of legal references from case-law issued by judicial authorities of European member States. The problem of automatic legal links extraction from texts is tackled for multiple languages and jurisdictions by providing a common stack which is customizable through pluggable extensions in order to cover the linguistic diversity and specific peculiarities of national legal citation practices. The aim is to increase the availability in the public domain of machine readable references metadata for case-law by sharing common services, a guided methodology and efficient solutions to recurrent problems in legal references extraction, that reduce the effort needed by national data providers to develop their own extraction solution. © 2017 The authors and IOS Press.",Final,
Ulmschneider K.; Glimm B.,"Ulmschneider, Klaus (56747872600); Glimm, Birte (16318796700)",56747872600; 16318796700,Knowledge graph: Semantic representation and assessment of innovation ecosystems,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034227560&doi=10.1007%2f978-3-319-69548-8_15&partnerID=40&md5=e3e7ac8e9d38de71c02d73b255d1fd7b,"Innovative capacity is highly dependent upon knowledge and the possession of unique competences can be an important source of enduring strategic advantage. Hence, being able to identify, locate, measure, and assess competence occupants can be a decisive competitive edge. In this work, we introduce a framework that assists with performing such tasks. To achieve this, NLP-, rule-based, and machine learning techniques are employed to process raw data such as academic publications or patents. The framework gains normalized person and organization profiles and compiles identified entities (such as persons, organizations, or locations) into dedicated objects disambiguating and unifying where needed. The objects are then mapped with conceptual systems and stored along with identified semantic relations in a Knowledge Graph, which is constituted by RDF triples. An OWL reasoner allows for answering complex business queries, and in particular, to analyze and evaluate competences on multiple aggregation levels (i.e., single vs. collective) and dimensions (e.g., region, technological field of interest, time). In order to prove the general applicability of the framework and to illustrate how to solve concrete business cases from the automotive domain, it is evaluated with different datasets. © 2017, Springer International Publishing AG.",Final,
Zhu W.,"Zhu, Weiwu (55752703500)",55752703500,Using knowledge graph and search query click logs in statistical language model for speech recognition,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039169288&doi=10.21437%2fInterspeech.2017-1790&partnerID=40&md5=bb81a2ee3efba0f484921d9a29764a9d,"This paper demonstrates how Knowledge Graph (KG) and Search Query Click Logs (SQCL) can be leveraged in statistical language models to improve named entity recognition for online speech recognition systems. Due to the missing in the training data, some named entities may be recognized as other common words that have the similar pronunciation. KG and SQCL cover comprehensive and fresh named entities and queries that can be used to mitigate the wrong recognition. First, all the entities located in the same area in KG are clustered together, and the queries that contain the entity names are selected from SQCL as the training data of a geographical statistical language model for each entity cluster. These geographical language models make the unseen named entities less likely to occur during the model training, and can be dynamically switched according to the user location in the recognition phase. Second, if any named entities are identified in the previous utterances within a conversational dialog, the probability of the n-best word sequence paths that contain their related entities will be increased for the current utterance by utilizing the entity relationships from KG and SQCL. This way can leverage the long-Term contexts within the dialog. Experiments for the proposed approach on voice queries from a spoken dialog system yielded a 12.5% relative perplexity reduction in the language model measurement, and a 1.1% absolute word error rate reduction in the speech recognition measurement. Copyright © 2017 ISCA.",Final,
Geng D.,"Geng, Dawei (57197819788)",57197819788,Clinical name entity recognition using conditional random field with augmented features,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035049333&partnerID=40&md5=6dbd3e4a87a846ba0e89b565df7bb8f6,"In this paper, We presents a Chinese medical term recognition system submitted to the competition held by China Conference on Knowledge Graph and Semantic Computing. I compare the performance of Linear Chain Conditional Random Field (CRF) with that of Bi-Directional Long Short Term Memory (LSTM) with Convolutional Neural Network (CNN) and CRF layers performance and find that CRF with augmented features performs best with F1 0.927 on the offline competition dataset using cross-validation. Hence, this system was built by using a conditional random field model with linguistic features such as character identity, N-gram, and external dictionary features.",Final,
Simov K.; Boytcheva S.; Osenova P.,"Simov, Kiril (8835805500); Boytcheva, Svetla (8075484100); Osenova, Petya (8933829900)",8835805500; 8075484100; 8933829900,Towards lexical chains for knowledge-graph-based word embeddings,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045766451&doi=10.26615%2f978-954-452-049-6_087&partnerID=40&md5=11bfe483238afb8080f2a9987e5689fc,"Word vectors with varying dimensionalities and produced by different algorithms have been extensively used in NLP. The corpora that the algorithms are trained on can contain either natural language text (e.g. Wikipedia or newswire articles) or artificially-generated pseudo corpora due to natural data sparseness. We exploit Lexical Chain based templates over Knowledge Graph for generating pseudo-corpora with controlled linguistic value. These corpora are then used for learning word embeddings. A number of experiments have been conducted over the following test sets: WordSim353 Similarity, WordSim353 Relatedness and SimLex-999. Lhe results show that, on the one hand, the incorporation of many-relation lexical chains improves results, but on the other hand, unrestricted-length chains remain difficult to handle with respect to their huge quantity. © 2018 Association for Computational Linguistics (ACL). All rights reserved.",Final,All Open Access; Bronze Open Access
Castellanos A.; De Luca E.W.; García-Serrano A.; Cigaran J.,"Castellanos, Angel (55609197000); De Luca, Ernesto W. (14026533600); García-Serrano, Ana (55930769700); Cigaran, Juan (57203185307)",55609197000; 14026533600; 55930769700; 57203185307,Partially squeezing the resources of the web of data towards applications,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050860968&doi=10.1109%2fIntelliSys.2017.8324319&partnerID=40&md5=cf6f469011fa5bf2109fcf688bdecf45,"The Web of Data (WOD) contains a large amount of formalized and interconnected data, offering a valuable help for experimental tasks requiring an accurate data representation. However, the practical application of such data is often limited by the complexity when it comes to extracting the necessary information, mainly because of the lack of a proper structure and organization in the WOD-resources. The (re)organization of the knowledge contained in these resources might facilitate the identification of the necessary information and, consequently, limit the problems arising in their practical application. In this context, this paper proposes the application of Formal Concept Analysis (FCA) to create a concept-based abstraction that better organizes the knowledge contained in the WOD-resources. In order to test, to what extent this enhanced organization is able to improve the data representation process, the obtained FCA models will be tested in a practical application to represent a set of Twitter contents in a specific task: the Topic Detection task at Replab 2013. The results demonstrate that the better data representation obtained through FCA improves the operation of the topic detection process, outperforming state-of-the-art results. © 2017 IEEE.",Final,
Cabaleiro B.; Peñas A.; Manandhar S.,"Cabaleiro, Bernardo (55358337300); Peñas, Anselmo (35619424200); Manandhar, Suresh (14041838600)",55358337300; 35619424200; 14041838600,Grounding proposition stores for question answering over linked data,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018939241&doi=10.1016%2fj.knosys.2017.04.016&partnerID=40&md5=52a63cf40f4ba66e2a794ef049e4c2d6,"Grounding natural language utterances into semantic representations is crucial for tasks such as question answering and knowledge base population. However, the importance of the lexicons that are central to this mapping remains unmeasured because question answering systems are evaluated as end-to-end systems. This article proposes a methodology to enable a standalone evaluation of grounding natural language propositions into semantic relations by fixing all the components of a question answering system other than the lexicon itself. Thus, we can explore different configurations trying to conclude which are the ones that contribute better to improve overall system performance. Our experiments show that grounding accounts with close to 80% of the system performance without training, whereas training supposes a relative improvement of 7.6%. Finally we show how lexical expansion using external linguistic resources can consistently improve the results from 0.8% up to 2.5%. © 2017 Elsevier B.V.",Final,All Open Access; Green Open Access
Alam M.; Reforgiato Recupero D.; Mongiovi M.; Gangemi A.; Ristoski P.,"Alam, Mehwish (57201532578); Reforgiato Recupero, Diego (57206674454); Mongiovi, Misael (24339046000); Gangemi, Aldo (55605133800); Ristoski, Petar (55321570300)",57201532578; 57206674454; 24339046000; 55605133800; 55321570300,Event-based knowledge reconciliation using frame embeddings and frame similarity,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028078061&doi=10.1016%2fj.knosys.2017.08.014&partnerID=40&md5=8f695c52caef9a4cb351a2cc13352268,"This paper proposes an evolution over MERGILO, a tool for reconciling knowledge graphs extracted from text, using graph alignment and word similarity. The reconciled knowledge graphs are typically used for multi-document summarization, or to detect knowledge evolution across document series. The main point of improvement focuses on event reconciliation i.e., reconciling knowledge graphs generated by text about two similar events described differently. In order to gather a complete semantic representation of events, we use FRED semantic web machine reader, jointly with Framester, a linguistic linked data hub represented using a novel formal semantics for frames. Framester is used to enhance the extracted event knowledge with semantic frames. We extend MERGILO with similarities based on the graph structure of semantic frames and the subsumption hierarchy of semantic roles as defined in Framester. With an effective evaluation strategy similarly as used for MERGILO, we show the improvement of the new approach (MERGILO plus semantic frame/role similarities) over the baseline. © 2017 Elsevier B.V.",Final,
He H.; Balakrishnan A.; Eric M.; Liang P.,"He, He (55700423600); Balakrishnan, Anusha (57200339474); Eric, Mihail (57194688892); Liang, Percy (56646712700)",55700423600; 57200339474; 57194688892; 56646712700,Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931116&doi=10.18653%2fv1%2fP17-1162&partnerID=40&md5=c6484eddfd9dbadea164ad122779386a,"We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models. © 2017 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Lubiano M.A.; Salas A.; Carleos C.; de la Rosa de Sáa S.; Gil M.Á.,"Lubiano, María Asunción (6603291955); Salas, Antonia (56089870700); Carleos, Carlos (6507243146); de la Rosa de Sáa, Sara (55515452200); Gil, María Ángeles (57203278365)",6603291955; 56089870700; 6507243146; 55515452200; 57203278365,Hypothesis testing-based comparative analysis between rating scales for intrinsically imprecise data,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020462429&doi=10.1016%2fj.ijar.2017.05.007&partnerID=40&md5=ea333093a136fd3df61d845e4127af1e,"In previous papers, it has been empirically proved that descriptive (summary measures) and inferential conclusions (in particular, tests about means p-values) with imprecise-valued data are often affected by the scale considered to model such data. More concretely, conclusions from the numerical and fuzzy linguistic encodings of Likert-type data have been compared with those for fuzzy data obtained by using a totally free fuzzy assessment: the so-called fuzzy rating scale. These previous comparisons have been performed separately for each of the scales. This paper aims to perform a joint comparison in such a way that means of linked data (one associated with the fuzzy rating and the other one with the encoded Likert scale) are to be tested for equality. Two real-life examples, as well as several simulation-based synthetic ones, have unequivocally shown that the fuzzy rating scale means are significantly different from those for the encoded Likert scales. © 2017 Elsevier Inc.",Final,All Open Access; Green Open Access
Hayashi K.; Shimbo M.,"Hayashi, Katsuhiko (55628535930); Shimbo, Masashi (8226981900)",55628535930; 8226981900,On the equivalence of holographic and complex embeddings for link prediction,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038254723&doi=10.18653%2fv1%2fP17-2088&partnerID=40&md5=128185cc8868436b1313a66f28a351e9,"We show the equivalence of two state-of-the-art models for link prediction/ knowledge graph completion: Nickel et al’s holographic embeddings and Trouillon et al.’s complex embeddings. We first consider a spectral version of the holographic embeddings, exploiting the frequency domain in the Fourier transform for efficient computation. The analysis of the resulting model reveals that it can be viewed as an instance of the complex embeddings with a certain constraint imposed on the initial vectors upon training. Conversely, any set of complex embeddings can be converted to a set of equivalent holographic embeddings. © 2017 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Liu X.; Yu Y.; Jiang Z.; Guo C.; Jensen S.,"Liu, Xiaozhong (55218252500); Yu, Yingying (55595732000); Jiang, Zhuoren (36173693000); Guo, Chun (55301193600); Jensen, Scott (36842114800)",55218252500; 55595732000; 36173693000; 55301193600; 36842114800,Personalized navigation and random walk on a complex heterogeneous graph,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033217202&doi=10.1145%2f3121050.3121068&partnerID=40&md5=333c807e04b6d6342dc0f5fbe8194cdd,"As data in many disciplines continues to grow at a frantic pace, a more heterogeneous set of information sources both can and need to be connected in innovative ways to improve information search and recommendation systems. Using information retrieval (IR) as an example, classical search techniques are based on limited information, including query terms, the content of documents, and basic user characteristics. However, recent studies have started to investigate additional information resources, including semantic web data, knowledge graphs, linguistic features, user email account content, social networks, user behavior, the search context, and other sources. Intuitively, a heterogeneous graph integrating all these information sources could enhance search performance. However, the complexity of such graphs challenge most existing graph mining algorithms. In this study, we propose a novel approach for a personalized random walk over a complex heterogeneous graph; which we refer to as Personalized Graph Navigation (PGN). Unlike earlier expert-guided random walk approaches, by using an EM framework, PGN estimates the personalized usefulness probability distribution for each edge type (the latent variable), which can be used as a random walk navigation profile for a user on a heterogeneous graph. While PGN can cope with information retrieval/recommendation problems at a low cost, this method also transforms a complex heterogeneous graph into a homogeneous graph, allowing existing homogeneous graph mining algorithms to be applied to a heterogeneous graph. © 2017 Copyright held by the owner/author(s).",Final,
Palumbo E.; Rizzo G.; Troncy R.,"Palumbo, Enrico (57191754892); Rizzo, Giuseppe (57194127652); Troncy, Raphaël (23986650400)",57191754892; 57194127652; 23986650400,Entity2rec: Learning user-item relatedness from knowledge graphs for top-N item recommendation,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029219579&doi=10.1145%2f3109859.3109889&partnerID=40&md5=a97aea5f4decf28f1cd53f96f7e9509c,"Knowledge Graphs have proven to be extremely valuable to recommender systems, as they enable hybrid graph-based recommendation models encompassing both collaborative and content information. Leveraging this wealth of heterogeneous information for top-N item recommendation is a challenging task, as it requires the ability of effectively encoding a diversity of semantic relations and connectivity patterns. In this work, we propose entity2rec, a novel approach to learning user-item relatedness from knowledge graphs for top-N item recommendation. We start from a knowledge graph modeling user-item and item-item relations and we learn property specific vector representations of users and items applying neural language models on the network. These representations are used to create property-specific user-item relatedness features, which are in turn fed into learning to rank algorithms to learn a global relatedness model that optimizes top-N item recommendations. We evaluate the proposed approach in terms of ranking quality on the MovieLens 1M dataset, outperforming a number of state-of-the-art recommender systems, and we assess the importance of property-specific relatedness scores on the overall ranking quality. © 2017 ACM.",Final,
Meloni A.; Reforgiato Recupero D.; Gangemi A.,"Meloni, Antonello (57208786109); Reforgiato Recupero, Diego (57206674454); Gangemi, Aldo (55605133800)",57208786109; 57206674454; 55605133800,"AMR2FRED, A Tool for Translating Abstract Meaning Representation to Motif-Based Linguistic Knowledge Graphs",-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034257137&doi=10.1007%2f978-3-319-70407-4_9&partnerID=40&md5=e2cc2a215b7d4eb03ca854f83907c155,"In this paper we present AMR2FRED, a software application to translate Abstract Meaning Representation (AMR) to RDF using the knowledge patterns applied by the FRED machine reading method. AMR and FRED representations are both graph-based, and event-centric (neo-Davidsonian), but they differ in several logical, conceptual, and design assumptions. The former has become a de facto standard for the Natural Language Processing community, whereas FRED adds semantics to the extracted information using several ontologies and best practices from the Semantic Web. With the increasing availability of manually AMR-annotated datasets, this tool provides straightforward means to adapt annotated datasets for AMR according to the design patterns used by FRED, and to evaluate machine reading tools with gold-standard data. AMR2FRED takes as input an AMR representation of a text, and prints a FRED-like RDF output. The system is open source and can be freely downloaded from https://github.com/infovillasimius/amr2Fred. © Springer International Publishing AG 2017.",Final,
Yan B.; Mai G.; Janowicz K.; Gao S.,"Yan, Bo (57187582800); Mai, Gengchen (57191421180); Janowicz, Krzysztof (13610913700); Gao, Song (57762528900)",57187582800; 57191421180; 13610913700; 57762528900,From ITDL to Place2Vec – Reasoning About Place Type Similarity and Relatedness by Learning Embeddings From Augmented Spatial Contexts,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040990379&doi=10.1145%2f3139958.3140054&partnerID=40&md5=808adcdb76756d0dd47ba0868b5a5ed0,"Understanding, representing, and reasoning about Points Of Interest (POI) types such as Auto Repair, Body Shop, Gas Stations, or Planetarium, is a key aspect of geographic information retrieval, recommender systems, geographic knowledge graphs, as well as studying urban spaces in general, e.g., for extracting functional or vague cognitive regions from user-generated content. One prerequisite to these tasks is the ability to capture the similarity and relatedness between POI types. Intuitively, a spatial search that returns body shops or even gas stations in the absence of auto repair places is still likely to satisfy some user needs while returning planetariums will not. Place hierarchies are frequently used for query expansion, but most of the existing hierarchies are relatively shallow and structured from a single perspective, thereby putting POI types that may be closely related regarding some characteristics far apart from another. This leads to the question of how to learn POI type representations from data. Models such as Word2Vec that produces word embeddings from linguistic contexts are a novel and promising approach as they come with an intuitive notion of similarity. However, the structure of geographic space, e.g., the interactions between POI types, differs substantially from linguistics. In this work, we present a novel method to augment the spatial contexts of POI types using a distance-binned, information-theoretic approach to generate embeddings. We demonstrate that our work outperforms Word2Vec and other models using three different evaluation tasks and strongly correlates with human assessments of POI type similarity. We published the resulting embeddings for 570 place types as well as a collection of human similarity assessments online for others to use. © 2017 Copyright held by the owner/author(s).",Final,
Paulheim H.,"Paulheim, Heiko (35095438500)",35095438500,Knowledge graph refinement: A survey of approaches and evaluation methods,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002556154&doi=10.3233%2fSW-160218&partnerID=40&md5=b9da4c83c0929156a337fb3fc199c1bf,"In the recent years, different Web knowledge graphs, both free and commercial, have been created. While Google coined the term Knowledge Graph in 2012, there are also a few openly available knowledge graphs, with DBpedia, YAGO, and Freebase being among the most prominent ones. Those graphs are often constructed from semi-structured knowledge, such as Wikipedia, or harvested from the web with a combination of statistical and linguistic methods. The result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness. In order to further increase the utility of such knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information. In this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used. © 2017 - IOS Press and the authors. All rights reserved.",Final,
Marsi E.; Øzturk P.; Ardelan M.V.,"Marsi, Erwin (6507015146); Øzturk, Pinar (55904973800); Ardelan, Murat V. (28367531500)",6507015146; 55904973800; 28367531500,Marine variable linker: Exploring relations between changing variables in marine science literature,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021681301&doi=10.18653%2fv1%2fe17-3023&partnerID=40&md5=3df635031763e232a2f01d33ce24dc06,"We report on a demonstration system for text mining of literature in marine science and related disciplines. It automatically extracts variables (e.g. CO2) involved in events of change/increase/decrease (e.g increasing CO2), as well as cooccurrence and causal relations among these events (e.g. increasing CO2 causes a decrease in pH in seawater), resulting in a big knowledge graph. A web-based graphical user interface targeted at marine scientists facilitates searching, browsing and visualising events and their relations in an interactive way. © 2017 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Faralli S.; Panchenko A.; Biemann C.; Ponzetto S.P.,"Faralli, Stefano (57193656573); Panchenko, Alexander (55632785700); Biemann, Chris (8538613800); Ponzetto, Simone Paolo (15056538200)",57193656573; 55632785700; 8538613800; 15056538200,The contrastmedium algorithm: Taxonomy induction from noisy knowledge graphswith just a few links,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021666675&doi=10.18653%2fv1%2fe17-1056&partnerID=40&md5=724453cf4550b1bb679c4c0c2f60cd06,"In this paper, we present ContrastMedium, an algorithm that transforms noisy semantic networks into full-fledged, clean taxonomies. ContrastMedium is able to identify the embedded taxonomy structure from a noisy knowledge graph without explicit human supervision such as, for instance, a set of manually selected input root and leaf concepts. This is achieved by leveraging structural information from a companion reference taxonomy, to which the input knowledge graph is linked (either automatically or manually). When used in conjunction with methods for hypernym acquisition and knowledge base linking, our methodology provides a complete solution for end-to-end taxonomy induction. We conduct experiments using automatically acquired knowledge graphs, as well as a SemEval benchmark, and show that our method is able to achieve high performance on the task of taxonomy induction. © 2017 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Indurthi S.; Raghu D.; Khapra M.M.; Joshi S.,"Indurthi, Sathish (57191256379); Raghu, Dinesh (55218086800); Khapra, Mitesh M. (36028388700); Joshi, Sachindra (55466287100)",57191256379; 55218086800; 36028388700; 55466287100,Generating natural language question-answer pairs from a knowledge graph using a RNN based question generation model,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021669255&doi=10.18653%2fv1%2fe17-1036&partnerID=40&md5=a0c5d4c9b14990e04e1684a304c25941,"In recent years, knowledge graphs such as Freebase that capture facts about entities and relationships between them have been used actively for answering factoid questions. In this paper, we explore the problem of automatically generating question answer pairs from a given knowledge graph. The generated question answer (QA) pairs can be used in several downstream applications. For example, they could be used for training better QA systems. To generate such QA pairs, we first extract a set of keywords from entities and relationships expressed in a triple stored in the knowledge graph. From each such set, we use a subset of keywords to generate a natural language question that has a unique answer. We treat this subset of keywords as a sequence and propose a sequence to sequence model using RNN to generate a natural language question from it. Our RNN based model generates QA pairs with an accuracy of 33.61 percent and performs 110.47 percent (relative) better than a state-of-the-art template based method for generating natural language question from keywords. We also do an extrinsic evaluation by using the generated QA pairs to train a QA system and observe that the F1-score of the QA system improves by 5.5 percent (relative) when using automatically generated QA pairs in addition to manually generated QA pairs available for training. © 2017 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
,,,CEUR Workshop Proceedings,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029142973&partnerID=40&md5=4fdb3a1b5624ef40da4c7a1bba5d03f5,The proceedings contain 21 papers. The topics discussed include: towards revised system of verb WordNet relations for polish; towards a public multilingual knowledge management infrastructure for the European digital single market; how stable are WordNet synsets?; overview and future of Czech WordNet; an API for Ontolex lime datasets; from language documentation data to LLOD: a case study in Turkic lemon dictionaries; the challenges of converting legacy lexical resources to linked open data using OntolexLemon: the case of the intermediate Liddell-Scott lexicon; lexinfo as a model for creating ontology-based dictionary of Russian grammatical forms; Ontolex and onomasiological ordering: supporting topical thesauri; proposing an Ontolexmmoon alignment: towards an interconnection of two linguistic domain models; towards a module for lexicography in Ontolex; autogenerating bilingual dictionaries: results of the TIAD2017 shared task baseline algorithm; translation inference across dictionaries via a combination of graph-based methods and co-occurrence statistics; using machine learning for translation inference across dictionaries; two corpus based experiments with the Portuguese and English WordNets; challenges behind the data-driven Bulgarian WordNet (Bultreebank Bulgarian WordNet); the revision history of Estonian WordNet; towards revised system of verb WordNet relations for polish; and classification of adjectives in Bulnet: notes on an effort.,Final,
Nogales A.; Sicilia-Urban M.A.; García-Barriocanal E.,"Nogales, Alberto (56278130700); Sicilia-Urban, Miguel Angel (8266687800); García-Barriocanal, Elena (8951086800)",56278130700; 8266687800; 8951086800,Measuring vocabulary use in the Linked Data Cloud,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017264831&doi=10.1108%2fOIR-06-2015-0183&partnerID=40&md5=de61495c56e1ee5d1bcb35f57423b824,"Purpose - This paper reports on a quantitative study of data gathered from the Linked Open Vocabularies (LOV) catalogue, including the use of network analysis and metrics. The purpose of this paper is to gain insights into the structure of LOV and the use of vocabularies in the Web of Data. It is important to note that not all the vocabularies in it are registered in LOV. Given the de-centralised and collaborative nature of the use and adoption of these vocabularies, the results of the study can be used to identify emergent important vocabularies that are shaping the Web of Data. Design/methodology/approach - The methodology is based on an analytical approach to a data set that captures a complete snapshot of the LOV catalogue dated April 2014. An initial analysis of the data is presented in order to obtain insights into the characteristics of the vocabularies found in LOV. This is followed by an analysis of the use of Vocabulary of a Friend properties that describe relations among vocabularies. Finally, the study is complemented with an analysis of the usage of the different vocabularies, and concludes by proposing a number of metrics. Findings - The most relevant insight is that unsurprisingly the vocabularies with more presence are those used to model Semantic Web data, such as Resource Description Framework, RDF Schema and OWL, as well as broadly used standards as Simple Knowledge Organization System, DCTERMS and DCE. It was also discovered that the most used language is English and the vocabularies are not considered to be highly specialised in a field. Also, there is not a dominant scope of the vocabularies. Regarding the structural analysis, it is concluded that LOV is a heterogeneous network. Originality/value - The paper provides an empirical analysis of the structure of LOV and the relations between its vocabularies, together with some metrics that may be of help to determine the important vocabularies from a practical perspective. The results are of interest for a better understanding of the evolution and dynamics of the Web of Data, and for applications that attempt to retrieve data in the Linked Data Cloud. These applications can benefit from the insights into the important vocabularies to be supported and the value added when mapping between and using the vocabularies. © Emerald Publishing Limited.",Final,
Klimek B.; McCrae J.P.; Lehmann C.; Chiarcos C.; Hellmann S.,"Klimek, Bettina (57194613467); McCrae, John P. (36666801700); Lehmann, Christian (36946688000); Chiarcos, Christian (22333764800); Hellmann, Sebastian (35199882400)",57194613467; 36666801700; 36946688000; 22333764800; 35199882400,OnLiT: An ontology for linguistic terminology,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021210616&doi=10.1007%2f978-3-319-59888-8_4&partnerID=40&md5=c0c709f1de6f2febb8d616eab1c09095,"Understanding the differences underlying the scope, usage and content of language data requires the provision of a clarifying terminological basis which is integrated in the metadata describing a particular language resource. While terminological resources such as the SIL Glossary of Linguistic Terms, ISOcat or the GOLD ontology provide a considerable amount of linguistic terms, their practical usage is limited to a look up of a defined term whose relation to other terms is unspecified or insufficient. Therefore, in this paper we propose an ontology for linguistic terminology, called OnLiT. It is a data model which can be used to represent linguistic terms and concepts in a semantically interrelated data structure and, thus, overcomes prevalent isolating definition-based term descriptions. OnLiT is based on the LiDo Glossary of Linguistic Terms and enables the creation of RDF datasets, that represent linguistic terms and their meanings within the whole or a subdomain of linguistics. © Springer International Publishing AG 2017.",Final,
Thoma S.; Rettinger A.; Both F.,"Thoma, Steffen (56727815200); Rettinger, Achim (23092350400); Both, Fabian (57190138261)",56727815200; 23092350400; 57190138261,"Towards holistic concept representations: Embedding relational knowledge, visual attributes, and distributional word semantics",-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032216290&doi=10.1007%2f978-3-319-68288-4_41&partnerID=40&md5=e6019b231eb1199aeed8bc0be97f9987,"Knowledge Graphs (KGs) effectively capture explicit relational knowledge about individual entities. However, visual attributes of those entities, like their shape and color and pragmatic aspects concerning their usage in natural language are not covered. Recent approaches encode such knowledge by learning latent representations (‘embeddings’) separately: In computer vision, visual object features are learned from large image collections and in computational linguistics, word embeddings are extracted from huge text corpora which capture their distributional semantics. We investigate the potential of complementing the relational knowledge captured in KG embeddings with knowledge from text documents and images by learning a shared latent representation that integrates information across those modalities. Our empirical results show that a joined concept representation provides measurable benefits for (i) semantic similarity benchmarks, since it shows a higher correlation with the human notion of similarity than uni- or bi-modal representations, and (ii) entity-type prediction tasks, since it clearly outperforms plain KG embeddings. These findings encourage further research towards capturing types of knowledge that go beyond today’s KGs. © Springer International Publishing AG 2017.",Final,
Hazrina S.; Sharef N.M.; Ibrahim H.; Murad M.A.A.; Noah S.A.M.,"Hazrina, Sofian (56211266300); Sharef, Nurfadhlina Mohd (35749213900); Ibrahim, Hamidah (8925431000); Murad, Masrah Azrifah Azmi (57210313353); Noah, Shahrul Azman Mohd (35087633200)",56211266300; 35749213900; 8925431000; 57210313353; 35087633200,Review on the advancements of disambiguation in semantic question answering system,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027923512&doi=10.1016%2fj.ipm.2016.06.006&partnerID=40&md5=0bc9131b66bff800ad04a151931fd850,"Ambiguity is a potential problem in any semantic question answering (SQA) system due to the nature of idiosyncrasy in composing natural language (NL) question and semantic resources. Thus, disambiguation of SQA systems is a field of ongoing research. Ambiguity occurs in SQA because a word or a sentence can have more than one meaning or multiple words in the same language can share the same meaning. Therefore, an SQA system needs disambiguation solutions to select the correct meaning when the linguistic triples matched with multiple KB concepts, and enumerate similar words especially when linguistic triples do not match with any KB concept. The latest development in this field is a solution for SQA systems that is able to process a complex NL question while accessing open-domain data from linked open data (LOD). The contributions in this paper include (1) formulating an SQA conceptual framework based on an in-depth study of existing SQA processes; (2) identifying the ambiguity types, specifically in English based on an interdisciplinary literature review; (3) highlighting the ambiguity types that had been resolved by the previous SQA studies; and (4) analysing the results of the existing SQA disambiguation solutions, the complexity of NL question processing, and the complexity of data retrieval from KB(s) or LOD. The results of this review demonstrated that out of thirteen types of ambiguity identified in the literature, only six types had been successfully resolved by the previous studies. Efforts to improve the disambiguation are in progress for the remaining unresolved ambiguity types to improve the accuracy of the formulated answers by the SQA system. The remaining ambiguity types are potentially resolved in the identified SQA process based on ambiguity scenarios elaborated in this paper. The results of this review also demonstrated that most existing research on SQA systems have treated the processing of the NL question complexity separate from the processing of the KB structure complexity. © 2016 Elsevier Ltd",Final,
van Aggelen A.; Hollink L.; van ssenbruggen J.,"van Aggelen, Astrid (57192316244); Hollink, Laura (55949222600); van ssenbruggen, Jacco (57194338667)",57192316244; 55949222600; 57194338667,Combining distributional semantics and structured data to study lexical change,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019708804&doi=10.1007%2f978-3-319-58694-6_4&partnerID=40&md5=300b36a56e9b4f4925526b0e48a4aeb6,"Statistical Natural Language Processing (NLP) techniques allow to quantify lexical semantic change using large text corpora. Wordlevel results of these methods can be hard to analyse in the context of sets of semantically or linguistically related words. On the other hand, structured knowledge sources represent semantic relationships explicitly, but ignore the problem of semantic change. We aim to address these limitations by combining the statistical and symbolic approach: we enrich WordNet, a structured lexical database, with quantitative lexical change scores provided by HistWords, a dataset produced by distributional NLP methods. We publish the result as Linked Open Data and demonstrate how queries on the combined dataset can provide new insights. © Springer International Publishing AG 2017.",Final,All Open Access; Green Open Access
Shekarpour S.; Marx E.; Auer S.; Sheth A.,"Shekarpour, Saeedeh (55298471100); Marx, Edgard (42161628400); Auer, Sören (23391879500); Sheth, Amit (57200763252)",55298471100; 42161628400; 23391879500; 57200763252,RQUERY: Rewriting natural language queries on knowledge graphs to alleviate the vocabulary mismatch problem,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030448541&partnerID=40&md5=9a33d64ba2803cba60bb6be0020d6269,"For non-expert users, a textual query is the most popular and simple means for communicating with a retrieval or question answering system. However, there is a risk of receiving queries which do not match with the background knowledge. Query expansion and query rewriting are solutions for this problem but they are in danger of potentially yielding a large number of irrelevant words, which in turn negatively influences runtime as well as accuracy. In this paper, we propose a new method for automatic rewriting input queries on graph-structured RDF knowledge bases. We employ a Hidden Markov Model to determine the most suitable derived words from linguistic resources. We introduce the concept of triple-based co-occurrence for recognizing co-occurred words in RDF data. This model was bootstrapped with three statistical distributions. Our experimental study demonstrates the superiority of the proposed approach to the traditional n-gram model. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Final,
Ehrmann M.; Jacquet G.; Steinberger R.,"Ehrmann, Maud (55237793100); Jacquet, Guillaume (34976798000); Steinberger, Ralf (6603917290)",55237793100; 34976798000; 6603917290,JRC-Names: Multilingual entity name variants and titles as Linked Data,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003828540&doi=10.3233%2fSW-160228&partnerID=40&md5=839a96d9627e697206e5fda4a8fd7312,"Since 2004 the European Commission's Joint Research Centre (JRC) has been analysing the online version of printed media in over twenty languages and has automatically recognised and compiled large amounts of named entities (persons and organisations) and their many name variants. The collected variants not only include standard spellings in various countries, languages and scripts, but also frequently found spelling mistakes or lesser used name forms, all occurring in real-life text (e.g. Benjamin/Binyamin/Bibi/Benyamín/Biniamin/Netanyahu/Netanjahu/Nétanyahou/Netahny/). This entity name variant data, known as JRC-Names, has been available for public download since 2011. In this article, we report on our efforts to render JRC-Names as Linked Data (LD), using the lexicon model for ontologies lemon. Besides adhering to Semantic Web standards, this new release goes beyond the initial one in that it includes titles found next to the names, as well as date ranges when the titles and the name variants were found. It also establishes links towards existing datasets, such as DBpedia and Talk-Of-Europe. As multilingual linguistic linked dataset, JRC-Names can help bridge the gap between structured data and natural languages, thus supporting large-scale data integration, e.g. cross-lingual mapping, and web-based content processing, e.g. entity linking. JRC-Names is publicly available through the dataset catalogue of the European Union's Open Data Portal. © 2017 - IOS Press and the authors. All rights reserved.",Final,All Open Access; Green Open Access
Hamon T.; Grabar N.; Mougin F.,"Hamon, Thierry (14833874000); Grabar, Natalia (6602326045); Mougin, Fleur (6601993691)",14833874000; 6602326045; 6601993691,Querying biomedical Linked Data with natural language questions,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010931331&doi=10.3233%2fSW-160244&partnerID=40&md5=3ba408d004ae8c464423351122602532,"Recent and intensive research in the biomedical area enabled to accumulate and disseminate biomedical knowledge through various knowledge bases increasingly available on the Web. The exploitation of this knowledge requires to create links between these bases and to use them jointly. Linked Data, the SPARQL language and interfaces in natural language question answering provide interesting solutions for querying such knowledge bases. However, while using biomedical Linked Data is crucial, life-science researchers may have difficulties using the SPARQL language. Interfaces based on natural language question answering are recognized to be suitable for querying knowledge bases. In this paper, we propose a method for translating natural language questions into SPARQL queries. We use Natural Language Processing tools, semantic resources and RDF triple descriptions. We designed a four-step method which allows to linguistically and semantically annotate questions, to perform an abstraction of these questions, then to build a representation of the SPARQL queries, and finally to generate the queries. The method is designed on 50 questions over three biomedical knowledge bases used in the task 2 of the QALD-4 challenge framework and evaluated on 27 new questions. It achieves good performance with 0.78 F-measure on the test set. The method for translating questions into SPARQL queries is implemented as a Perl module and is available at http://search.cpan.org/∼thhamon/RDF-NLP-SPARQLQuery/. © 2017-IOS.",Final,All Open Access; Green Open Access
Iglesias C.A.; Sánchez-Rada J.F.; Vulcu G.; Buitelaar P.,"Iglesias, C.A. (56357213400); Sánchez-Rada, J.F. (56426347900); Vulcu, G. (36176660600); Buitelaar, P. (14041096000)",56357213400; 56426347900; 36176660600; 14041096000,Linked Data Models for Sentiment and Emotion Analysis in Social Networks,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023632610&doi=10.1016%2fB978-0-12-804412-4.00004-8&partnerID=40&md5=a5e749ad460f061ede49fd912d4c186e,"Language resource interoperability is still a major challenge in sentiment analysis. One of the current trends for solving this issue is the adoption of a linked data perspective for semantically modeling, interlinking, and publishing lexical and other linguistic resources. This chapter contributes to the development of the linguistic linked open data through a linked data model for sentiment and emotion analysis in social networks that is based on two vocabularies: Marl and Onyx for sentiment and emotion modeling respectively. These vocabularies are used for (1) affective corpus annotation, (2) affective lexicon annotation, and (3) sentiment and emotion services interoperability. Several aspects of the solution are discussed, such as the transformation of legacy resources, the generation of domain-specific sentiment lexicons, and the benefits of interlinking language resources for sentiment analysis with other resources such as WordNet or DBpedia. © 2017 Elsevier Inc.",Final,
Stanovsky G.; Gruhl D.; Mendes P.N.,"Stanovsky, Gabriel (56901231200); Gruhl, Daniel (6603111677); Mendes, Pablo N. (23477938000)",56901231200; 6603111677; 23477938000,Recognizing mentions of adverse drug reaction in social media using knowledge-infused recurrent models,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021649640&doi=10.18653%2fv1%2fe17-1014&partnerID=40&md5=be3fb20651f6379666265ea716297679,"Recognizing mentions of Adverse Drug Reactions (ADR) in social media is challenging: ADR mentions are contextdependent and include long, varied and unconventional descriptions as compared to more formal medical symptom terminology. We use the CADEC corpus to train a recurrent neural network (RNN) transducer, integrated with knowledge graph embeddings of DBpedia, and show the resulting model to be highly accurate (93.4 F1). Furthermore, even when lacking high quality expert annotations, we show that by employing an active learning technique and using purpose built annotation tools, we can train the RNN to perform well (83.9 F1). © 2017 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
Atzeni M.; Atzori M.,"Atzeni, Mattia (57195407967); Atzori, Maurizio (56962767500)",57195407967; 56962767500,CodeOntology: RDF-ization of source code,-1,,-1,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032190783&doi=10.1007%2f978-3-319-68204-4_2&partnerID=40&md5=b4a9581416850bcec47dd44a92366420,"In this paper, we leverage advances in the Semantic Web area, including data modeling (RDF), data management and querying (JENA and SPARQL), to develop CodeOntology, a community-shared software framework supporting expressive queries over source code. The project consists of two main contributions: an ontology that provides a formal representation of object-oriented programming languages, and a parser that is able to analyze Java source code and serialize it into RDF triples. The parser has been successfully applied to the source code of OpenJDK 8, gathering a structured dataset consisting of more than 2 million RDF triples. CodeOntology allows to generate Linked Data from any Java project, thereby enabling the execution of highly expressive queries over source code, by means of a powerful language like SPARQL. © Springer International Publishing AG 2017.",Final,
Michel F.; Zucker C.F.; Montagnat J.,"Michel, Franck (36559861300); Zucker, Catherine Faron (55665070200); Montagnat, Johan (55887022200)",36559861300; 55665070200; 55887022200,A mapping-based method to query mongoDB documents with SPARQL,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981266423&doi=10.1007%2f978-3-319-44406-2_6&partnerID=40&md5=2fc14292d894babab7c92a404668e84d,"Accessing legacy data as virtual RDF stores is a key issue in the building of the Web of Data. In recent years, the MongoDB database has become a popular actor in the NoSQL market, making it a significant potential contributor to the Web of Linked Data. Therefore, in this paper we address the question of how to access arbitrary MongoDB documents with SPARQL. We propose a two-step method to (i) translate a SPARQL query into a pivot abstract query under MongoDB-to-RDF mappings represented in the xR2RML language, then (ii) translate the pivot query into a concrete MongoDB query.We elaborate on the discrepancy between the expressiveness of SPARQL and the MongoDB query language, and we show that we can always come up with a rewriting that shall produce all correct answers. © Springer International Publishing Switzerland 2016.",Final,All Open Access; Green Open Access
Charvat K.; Cerba O.; Kozuch D.; Splichal M.,"Charvat, Karel (55218452200); Cerba, Otakar (55293610300); Kozuch, Dmitrij (56717778300); Splichal, Marek (57191475299)",55218452200; 55293610300; 56717778300; 57191475299,Geospatial Data Based Environment in INSPIRE4Youth,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016029979&doi=10.1016%2fj.procs.2017.01.101&partnerID=40&md5=e2b3f1be6238ebb987c1683ca42a79f9,"The SDI4Apps Open INSPIRE4Youth supports creativity, technical capabilities, skills, knowledge and also relations, through the sharing of spatial based content and educational materials around environment. Using new methods of digital cartography enables to go beyond linguistic barriers. Using principles of Linked Open Data INSPIRE4Youth offer new possibilities of analyzing relation among different types of objects. The pilot is focused on building of Environmental and Geographical Web based atlas and educational quizzes based on utilization of Geospatial data, Linked Open data and other environmental data (maps) for educational and gaming purposes. The main components of the environment introduced are - water, air, soil, forests, nature protection, climate information, landscape, waste management, forest management etc. Each component has its actual condition measured for the region. All this will be made available in an entertaining manner - no school textbooks. Pilot also re uses database of Smart Point of Interest from Smart Tourist Data pilot. The main user group for this Atlas are students - higher grades of elementary schools, high schools and universities. However it should be appealing also for any adult person interested in topic. © 2017 The Authors.",Final,All Open Access; Gold Open Access
Bao J.; Duan N.; Yan Z.; Zhou M.; Zhao T.,"Bao, Junwei (57224540005); Duan, Nan (52163366000); Yan, Zhao (56305783700); Zhou, Ming (55587890800); Zhao, Tiejun (57204333045)",57224540005; 52163366000; 56305783700; 55587890800; 57204333045,Constraint-based question answering with knowledge graph,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034261067&partnerID=40&md5=869fde72520a8d3d7450bf206dfd5fd2,"WebQuestions and SimpleQuestions are two benchmark data-sets commonly used in recent knowledge-based question answering (KBQA) work. Most questions in them are 'simple' questions which can be answered based on a single relation in the knowledge base. Such data-sets lack the capability of evaluating KBQA systems on complicated questions. Motivated by this issue, we release a new data-set, namely ComplexQuestions1 aiming to measure the quality of KBQA systems on 'multi-constraint' questions which require multiple knowledge base relations to get the answer. Beside, we propose a novel systematic KBQA approach to solve multi-constraint questions. Compared to state-of-the-art methods, our approach not only obtains comparable results on the two existing benchmark data-sets, but also achieves significant improvements on the ComplexQuestions. © 1963-2018 ACL.",Final,
Franco-Salvador M.; Rosso P.; Montes-y-Gómez M.,"Franco-Salvador, Marc (55533434300); Rosso, Paolo (8960238100); Montes-y-Gómez, Manuel (6602768949)",55533434300; 8960238100; 6602768949,A systematic study of knowledge graph analysis for cross-language plagiarism detection,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954289499&doi=10.1016%2fj.ipm.2015.12.004&partnerID=40&md5=40fa998dcf27ac1599bf0496d8aa31e5,"Cross-language plagiarism detection aims to detect plagiarised fragments of text among documents in different languages. In this paper, we perform a systematic examination of Cross-language Knowledge Graph Analysis; an approach that represents text fragments using knowledge graphs as a language independent content model. We analyse the contributions to cross-language plagiarism detection of the different aspects covered by knowledge graphs: word sense disambiguation, vocabulary expansion, and representation by similarities with a collection of concepts. In addition, we study both the relevance of concepts and their relations when detecting plagiarism. Finally, as a key component of the knowledge graph construction, we present a new weighting scheme of relations between concepts based on distributed representations of concepts. Experimental results in Spanish–English and German–English plagiarism detection show state-of-the-art performance and provide interesting insights on the use of knowledge graphs. © 2015 Elsevier Ltd",Final,All Open Access; Green Open Access
Meimaris M.; Papastefanatos G.; Viglas S.; Stavrakas Y.; Pateritsas C.; Anagnostopoulos I.,"Meimaris, Marios (55488969600); Papastefanatos, George (23390448100); Viglas, Stratis (6507979151); Stavrakas, Yannis (55901687900); Pateritsas, Christos (8234853200); Anagnostopoulos, Ioannis (35423350900)",55488969600; 23390448100; 6507979151; 55901687900; 8234853200; 35423350900,A query language for multi-version data web archives,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978252505&doi=10.1111%2fexsy.12157&partnerID=40&md5=d74bc8d8d02b6a2e94d94c4460b0d35e,"The Data Web refers to the vast and rapidly increasing quantity of scientific, corporate, government and crowd-sourced data published in the form of Linked Open Data, which encourages the uniform representation of heterogeneous data items on the web and the creation of links between them. The growing availability of open linked datasets has brought forth significant new challenges regarding their proper preservation and the management of evolving information within them. In this paper, we focus on the evolution and preservation challenges related to publishing and preserving evolving linked data across time. We discuss the main problems regarding their proper modelling and querying and provide a conceptual model and a query language for modelling and retrieving evolving data along with changes affecting them. We present in details the syntax of the query language and demonstrate its functionality over a real-world use case of evolving linked dataset from the biological domain. © 2016 Wiley Publishing Ltd",Final,All Open Access; Green Open Access
Ferré S.; Cellier P.,"Ferré, Sébastien (8974579900); Cellier, Peggy (23388216000)",8974579900; 23388216000,Graph-FCA in practice,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977517030&doi=10.1007%2f978-3-319-40985-6_9&partnerID=40&md5=e994cf0af68793c72bb8adbf3357eed7,"With the rise of the SemanticWeb, more and more relational data are made available in the form of knowledge graphs (e.g., RDF, conceptual graphs). A challenge is to discover conceptual structures in those graphs, in the same way as Formal Concept Analysis (FCA) discovers conceptual structures in tables. Graph-FCA has been introduced in a previous work as an extension of FCA for such knowledge graphs. In this paper, algorithmic aspects and use cases are explored in order to study the feasibility and usefulness of G-FCA. We consider two use cases. The first one extracts linguistic structures from parse trees, comparing two graph models. The second one extracts workflow patterns from cooking recipes, highlighting the benefits of n-ary relationships and concepts. © Springer International Publishing Switzerland 2016.",Final,All Open Access; Green Open Access
Zhang X.; Lv Y.,"Zhang, Xiang (8400208700); Lv, Yulian (57192381571)",8400208700; 57192381571,Towards multi-target search of semantic association,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006867386&doi=10.1007%2f978-3-319-50112-3_19&partnerID=40&md5=847706594ff54afb1dd567e2bd06bbdb,"Semantic association represents group relationship among objects in linked data. Searching semantic associations is complicated, which involves the search of multiple objects and the search of their group relationships simultaneously. In this paper, we propose this kind of search as a multi-target search, and we compare it to traditional search tasks, which we classify as single-target search. A novel search model is introduced, and the notion of virtual document is used to extract linguistic information of semantic associations. Multi-target search is finally fulfilled by a PageRank-like ranking scheme and a top-K selection policy considering object affinity. Experiments show that our approach is effective in improving retrieval precision on semantic associations. © Springer International Publishing AG 2016.",Final,
Yoon H.-G.; Song H.-J.; Park S.-B.; Park S.-Y.,"Yoon, Hee-Geun (24722061700); Song, Hyun-Je (35175084000); Park, Seong-Bae (7501838676); Park, Se-Young (14045781800)",24722061700; 35175084000; 7501838676; 14045781800,A translation-based knowledge graph embedding preserving logical property of relations,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994102703&doi=10.18653%2fv1%2fn16-1105&partnerID=40&md5=dec119a812543ef9af2ad6e492ed39e6,"This paper proposes a novel translation-based knowledge graph embedding that preserves the logical properties of relations such as transitivity and symmetricity. The embedding space generated by existing translation-based embeddings do not represent transitive and symmetric relations precisely, because they ignore the role of entities in triples. Thus, we introduce a role-specific projection which maps an entity to distinct vectors according to its role in a triple. That is, a head entity is projected onto an embedding space by a head projection operator, and a tail entity is projected by a tail projection operator. This idea is applied to TransE, TransR, and TransD to produce lppTransE, lppTransR, and lppTransD, respectively. According to the experimental results on link prediction and triple classification, the proposed logical property preserving embeddings show the state-of-the-art performance at both tasks. These results prove that it is critical to preserve logical properties of relations while embedding knowledge graphs, and the proposed method does it effectively. ©2016 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
Fadili H.; Jouis C.,"Fadili, Hammou (36166240400); Jouis, Christophe (25641340700)",36166240400; 25641340700,Towards an automatic analyze and standardization of unstructured data in the context of big and linked data,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009786849&doi=10.1145%2f3012071.3012103&partnerID=40&md5=6979bb37b722ac0917adf7940c3f6bad,"Unstructured data refers to information that either does not have a pre-defined data model or is not organized in a pre-defined manner. Many studies confirm that around 80-90% of all produced information is in unstructured form. So this kind of content, rich and most importantly too precious, must be integrated and taken into consideration for processing and exploitation: extraction of relevant information from heterogeneous textual data. The goal of the research described here is to present an approach for automating the detection and the extraction of meaning from unstructured Web using its normalized part: Web of data & Linked Open data (LOD) such as RDF Word Net, DB pedia, etc. The process follows a ""cyclical process"" that consists of two phases (a) creating & generating normalized smart data by the experts or automatically, (b) exploiting the created data in (a), as ""validated expert data"", to analyze the Big Data and generate automatically new ones by learning from Linked Open Data (LOD). The approach is based on a range of linguistic and ontological techniques, in the context of Big Data. A software, EC3, is being implemented and at LIP6. EC3 is actually tested on very large corpuses on electronic supports, provided by the labex OBVIL (http://obvil.parissorbonne. fr) and the BNF (National Library of France). © 2016 ACM.",Final,
Ehrmann M.; Nouvel D.; Rosset S.,"Ehrmann, Maud (55237793100); Nouvel, Damien (55229362400); Rosset, Sophie (14018236100)",55237793100; 55229362400; 14018236100,Named entity resources - Overview and outlook,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020016963&partnerID=40&md5=037dfd57ab737d916c9ffa8f9958e14d,"Recognition of real-world entities is crucial for most NLP applications. Since its introduction some twenty years ago, named entity processing has undergone a significant evolution with, among others, the definition of new tasks (e.g. entity linking) and the emergence of new types of data (e.g. speech transcriptions, micro-blogging). These pose certainly new challenges which affect not only methods and algorithms but especially linguistic resources. Where do we stand with respect to named entity resources? This paper aims at providing a systematic overview of named entity resources, accounting for qualities such as multilingualism, dynamicity and interoperability, and to identify shortfalls in order to guide future developments.",Final,
Pareja-Lora A.,"Pareja-Lora, Antonio (6504385937)",6504385937,Enabling linked-data-based semantic annotations-the ontological modeling of semantics in the ontolingannot model,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984832214&partnerID=40&md5=5925a8f711b58f74c849aaf01ce16927,"This paper presents the ontology-based, linked-data-aware modeling of the vocabulary of Semantics included in the OntoLingAnnot model, aiming at a linguistic linked data compatible [semantic] annotation of texts. In particular, it introduces the different semantic units and attributes that can be used to annotate texts at the semantic level using the framework. These semantic units and attributes are included in the set of ontologies associated to OntoLingAnnot, whose main design assumptions are also described here. These main assumptions and the modeling performed has already helped different semantic (or linguistic, in general) annotations interoperate.",Final,
Hietanen E.; Lehto L.; Latvala P.,"Hietanen, E. (57190578616); Lehto, L. (8922118000); Latvala, P. (56540036600)",57190578616; 8922118000; 56540036600,Providing geographic datasets as linked data in sdi,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981229127&doi=10.5194%2fisprsarchives-XLI-B2-583-2016&partnerID=40&md5=893669c711f9afe5b30ec0087945bb1f,"In this study, a prototype service to provide data from Web Feature Service (WFS) as linked data is implemented. At first, persistent and unique Uniform Resource Identifiers (URI) are created to all spatial objects in the dataset. The objects are available from those URIs in Resource Description Framework (RDF) data format. Next, a Web Ontology Language (OWL) ontology is created to describe the dataset information content using the Open Geospatial Consortium's (OGC) GeoSPARQL vocabulary. The existing data model is modified in order to take into account the linked data principles. The implemented service produces an HTTP response dynamically. The data for the response is first fetched from existing WFS. Then the Geographic Markup Language (GML) format output of the WFS is transformed on-the-fly to the RDF format. Content Negotiation is used to serve the data in different RDF serialization formats. This solution facilitates the use of a dataset in different applications without replicating the whole dataset. In addition, individual spatial objects in the dataset can be referred with URIs. Furthermore, the needed information content of the objects can be easily extracted from the RDF serializations available from those URIs. A solution for linking data objects to the dataset URI is also introduced by using the Vocabulary of Interlinked Datasets (VoID). The dataset is divided to the subsets and each subset is given its persistent and unique URI. This enables the whole dataset to be explored with a web browser and all individual objects to be indexed by search engines.",Final,All Open Access; Gold Open Access
Kim A.-Y.; Song H.-J.; Park S.-B.; Lee S.-J.,"Kim, A-Yeong (42661508900); Song, Hyun-Je (35175084000); Park, Seong-Bae (7501838676); Lee, Sang-Jo (55716479700)",42661508900; 35175084000; 7501838676; 55716479700,A re-ranking model for dependency parsing with knowledge graph embeddings,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969926578&doi=10.1109%2fIALP.2015.7451560&partnerID=40&md5=f873a6ba0d40b84ed88203aa0f6743f9,"Re-ranking models of parse trees have been focused on re-ordering parse trees with a syntactic view. However, also a semantic view should be considered in re-ranking parse trees, because the fact that a word pair has a dependency implies that the pair has both syntactic and semantic relations. This paper proposes a re-ranking model for dependency parsing based on a combination of syntactic and semantic plausibilities of dependencies. The syntactic probability is used as a syntactic plausibility of a parse tree, and a knowledge graph embedding is adopted to represent its semantic plausibility. The knowledge graph embedding allows the semantic plausibility of parse trees to be expressed effectively with ease. The experiments on the standard Penn Treebank corpus prove that the proposed model improves the base parser regardless of the number of candidate parse trees. © 2015 IEEE.",Final,
Bigdely-Shamlo N.; Cockfieid J.; Makeig S.; Rognon T.; La Valle C.; Miyakoshi M.; Robbins K.A.,"Bigdely-Shamlo, Nima (25639688900); Cockfieid, Jeremy (57191744944); Makeig, Scott (7004563459); Rognon, Thomas (56102525900); La Valle, Chris (57191746336); Miyakoshi, Makoto (15835074500); Robbins, Kay A. (7201662444)",25639688900; 57191744944; 7004563459; 56102525900; 57191746336; 15835074500; 7201662444,Hierarchical event descriptors (HED): Semi-structured tagging for real-world events in large-scale EEG,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992640290&doi=10.3389%2ffninf.2016.00042&partnerID=40&md5=5a386d40e43988c81668c00a4f0481d6,"Real-world brain imaging by EEG requires accurate annotation of complex subject-environment interactions in event-rich tasks and paradigms. This paper describes the evolution of the Hierarchical Event Descriptor (HED) system for systematically describing both laboratory and real-world events. HED version 2, first described here, provides the semantic capability of describing a variety of subject and environmental states. HED descriptions can include stimulus presentation events on screen or in virtual worlds, experimental or spontaneous events occurring in the real world environment, and events experienced via one or multiple sensory modalities. Furthermore, HED 2 can distinguish between the mere presence of an object and its actual (or putative) perception by a subject. Although the HED framework has implicit ontological and linked data representations, the user-interface for HED annotation is more intuitive than traditional ontological annotation. We believe that hiding the formal representations allows for a more user-friendly interface, making consistent, detailed tagging of experimental, and real-world events possible for research users. HED is extensible while retaining the advantages of having an enforced common core vocabulary. We have developed a collection of tools to support HED tag assignment and validation; these are available at hedtags.org. A plug-in for EEGLAB (sccn.ucsd.edu/eeglab), CTAGGER, is also available to speed the process of tagging existing studies. ï¿½ 2016 Bigdely-Shamlo, Cockfield, Makeig, Rognon, La Valle, Miyakoshi and Robbins.",Final,All Open Access; Gold Open Access; Green Open Access
Grainger T.; Aljadda K.; Korayem M.; Smith A.,"Grainger, Trey (56495183100); Aljadda, Khalifeh (56495608100); Korayem, Mohammed (36959521600); Smith, Andries (57193159875)",56495183100; 56495608100; 36959521600; 57193159875,"The semantic knowledge graph: A compact, auto-generated model for real-time traversal and ranking of any relationship within a domain",-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011264001&doi=10.1109%2fDSAA.2016.51&partnerID=40&md5=fd4a3c8640ff6b4594e55e9455ac9bdc,"This paper describes a new kind of knowledge representation and mining system which we are calling the Semantic Knowledge Graph. At its heart, the Semantic Knowledge Graph leverages an inverted index, along with a complementary uninverted index, to represent nodes (terms) and edges (the documents within intersecting postings lists for multiple terms/nodes). This provides a layer of indirection between each pair of nodes and their corresponding edge, enabling edges to materialize dynamically from underlying corpus statistics. As a result, any combination of nodes can have edges to any other nodes materialize and be scored to reveal latent relationships between the nodes. This provides numerous benefits: The knowledge graph can be built automatically from a real-world corpus of data, new nodes-Along with their combined edges-can be instantly materialized from any arbitrary combination of preexisting nodes (using set operations), and a full model of the semantic relationships between all entities within a domain can be represented and dynamically traversed using a highly compact representation of the graph. Such a system has widespread applications in areas as diverse as knowledge modeling and reasoning; natural language processing, anomaly detection, data cleansing, semantic search, analytics, data classification, root cause analysis, and recommendations systems. The main contribution of this paper is the introduction of a novel system-The Semantic Knowledge Graph-which is able to dynamically discover and score interesting relationships between any arbitrary combination of entities (words, phrases, or extracted concepts) through dynamically materializing nodes and edges from a compact graphical representation built automatically from a corpus of data representative of a knowledge domain. The source code for our Semantic Knowledge Graph implementation is being published along with this paper to facilitate further research and extensions of this work. © 2016 IEEE.",Final,All Open Access; Green Open Access
Franco-Salvador M.; Gupta P.; Rosso P.; Banchs R.E.,"Franco-Salvador, Marc (55533434300); Gupta, Parth (57199836973); Rosso, Paolo (8960238100); Banchs, Rafael E. (15050125000)",55533434300; 57199836973; 8960238100; 15050125000,Cross-language plagiarism detection over continuous-space- and knowledge graph-based representations of language,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990949304&doi=10.1016%2fj.knosys.2016.08.004&partnerID=40&md5=7a599f0b89dc2cbdbc68c19359febd14,"Cross-language (CL) plagiarism detection aims at detecting plagiarised fragments of text among documents in different languages. The main research question of this work is on whether knowledge graph representations and continuous space representations can complement to each other and improve the state-of-the-art performance in CL plagiarism detection methods. In this sense, we propose and evaluate hybrid models to assess the semantic similarity of two segments of text in different languages. The proposed hybrid models combine knowledge graph representations with continuous space representations aiming at exploiting their complementarity in capturing different aspects of cross-lingual similarity. We also present the continuous word alignment-based similarity analysis, a new model to estimate similarity between text fragments. We compare the aforementioned approaches with several state-of-the-art models in the task of CL plagiarism detection and study their performance in detecting different length and obfuscation types of plagiarism cases. We conduct experiments over Spanish-English and German-English datasets. Experimental results show that continuous representations allow the continuous word alignment-based similarity analysis model to obtain competitive results and the knowledge-based document similarity model to outperform the state-of-the-art in CL plagiarism detection. © 2016",Final,All Open Access; Green Open Access
Pauwels P.; Terkaj W.,"Pauwels, Pieter (36661189900); Terkaj, Walter (35759509700)",36661189900; 35759509700,EXPRESS to OWL for construction industry: Towards a recommendable and usable ifcOWL ontology,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952362213&doi=10.1016%2fj.autcon.2015.12.003&partnerID=40&md5=7b68d6f1ef26264826834638644175ab,"An increasing number of information management and information exchange applications in construction industry is relying on semantic web technologies or tools from the Linked Open Data (LOD) domain to support data interoperability, flexible data exchange, distributed data management and the development of reusable tools. These goals tend to be overlapped with the purposes of the Industry Foundation Classes (IFC), which is a standard for the construction industry defined through an EXPRESS schema. A connecting point between semantic web technologies and the IFC standard would be represented by an agreed Web Ontology Language (OWL) ontology for IFC (termed ifcOWL) that allows to (1) keep on using the well-established IFC standard for representing construction data, (2) exploit the enablers of semantic web technologies in terms of data distribution, extensibility of the data model, querying, and reasoning; and (3) re-use general purpose software implementations for data storage, consistency checking and knowledge inference. Therefore, in this paper we will look into existing efforts in obtaining an ifcOWL ontology from the EXPRESS schemas of IFC and analyse which features would be required in a usable and recommendable ifcOWL ontology. In making this analysis, we present our implementations of an EXPRESS-to-OWL converter and the key features of the resulting ifcOWL ontology. © 2015 Elsevier B.V. All rights reserved.",Final,
Dragoni M.; Cabrio E.; Tonelli S.; Villata S.,"Dragoni, Mauro (19638448200); Cabrio, Elena (36704505300); Tonelli, Sara (14036670900); Villata, Serena (25928094300)",19638448200; 36704505300; 14036670900; 25928094300,Enriching a small artwork collection through semantic linking,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979009960&doi=10.1007%2f978-3-319-34129-3_44&partnerID=40&md5=e24d4d0060e3546b91e10796ff7dc8e9,"Cultural heritage institutions have recently started to explore the added value of sharing their data, opening to initiatives that are using the Linked Open Data cloud to integrate and enrich metadata of their cultural heritage collections. However, each museum and each collection shows peculiarities, which make it difficult to generalize this process and offer one-size-fits-all solutions. In this paper, we report on the integration, enrichment and interlinking activities of metadata from a small collection of verbo-visual artworks in the context of the Verbo-Visual-Virtual project. We investigate how to exploit Semantic Web technologies and languages combined with natural language processing methods to transform and boost the access to documents providing cultural information, i.e., artist descriptions, collection notices, information about technique. We also discuss the open challenges raised by working with a small collection including little-known artists and information gaps, for which additional data can be hardly retrieved from the Web. © Springer International Publishing Switzerland 2016.",Final,
Zhang X.; Lv Y.; Lin E.,"Zhang, Xiang (8400208700); Lv, Yulian (57192381571); Lin, Erjing (57192384209)",8400208700; 57192381571; 57192384209,Object clustering in linked data using centrality,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006021798&doi=10.1007%2f978-981-10-3168-7_17&partnerID=40&md5=56c1f6d6a3f2b5368099596057d05460,"Large-scale linked data is becoming a challenge to many Semanti Web tasks. While clustering of graphs has been deeply researched in network science and machine learning, not many researches are carried on clustering in linked data. To identify meta-structures in large-scale linked data, the scalability of clustering should be considered. In this paper, we propose a scalable approach of centrality-based clustering, which works on a model of Object Graph derived from RDF graph. Centrality of objects is calculated as indicators for clustering. Both relational and linguistic closeness between objects are considered in clustering to produce coherent clusters. © Springer Nature Singapore Pte Ltd. 2016.",Final,
Charvat K.; Cerba O.; Kozuch D.; Splichal M.,"Charvat, Karel (55218452200); Cerba, Otakar (55293610300); Kozuch, Dmitrij (56717778300); Splichal, Marek (57191475299)",55218452200; 55293610300; 56717778300; 57191475299,Geospatial data based environment for educational and gaming purposes: The pilot INSPIRE4Youth,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990868189&partnerID=40&md5=54e0644092864e7d83284f4aca553b87,"The SDI4Apps Open INSPIRE4Youth supports creativity, technical capabilities, skills, knowledge and also relations, through the sharing of spatial based content and educational materials around environment. Using new methods of digital cartography enables to go beyond linguistic barriers. Using principles of Linked Open Data INSPIRE4Youth offer new possibilities of analyzing relation among different types of objects. The pilot is focused on building of Environmental and Geographical Web based atlas and educational quizzes based on utilization of Geospatial data, Linked Open data and other environmental data (maps) for educational and gaming purposes. The main components of the environment introduced are-water, air, soil, forests, nature protection, climate information, landscape, waste management, forest management etc. Each component has its actual condition measured for the region. All this will be made available in an entertaining manner-no school textbooks. Pilot also re uses database of Smart Point of Interest from Smart Tourist Data pilot. The main user group for this Atlas are students-higher grades of elementary schools, high schools and universities. However it should be appealing also for any adult person interested in topic.",Final,
Mongiovì M.; Recupero D.R.; Gangemi A.; Presutti V.; Consoli S.,"Mongiovì, Misael (24339046000); Recupero, Diego Reforgiato (57206674454); Gangemi, Aldo (55605133800); Presutti, Valentina (55885160000); Consoli, Sergio (24168054400)",24339046000; 57206674454; 55605133800; 55885160000; 24168054400,Merging open knowledge extracted from text with MERGILO,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969610650&doi=10.1016%2fj.knosys.2016.05.014&partnerID=40&md5=c4826eadc066e629c08af0a3a45c63e8,"This paper presents MERGILO, a method for reconciling knowledge extracted from multiple natural language sources, and for delivering it as a knowledge graph. The underlying problem is relevant in many application scenarios requiring the creation and dynamic evolution of a knowledge base, e.g. automatic news summarization, human–robot dialoguing, etc. After providing a formal definition of the problem, we propose our holistic approach to handle natural language input – typically independent texts as in news from different sources – and we output a knowledge graph representing their reconciled knowledge. MERGILO is evaluated on its ability to identify corresponding entities and events across documents against a manually annotated corpus of news, showing promising results. © 2016",Final,All Open Access; Green Open Access
Xiao H.; Huang M.; Zhu X.,"Xiao, Han (57210123996); Huang, Minlie (7404260571); Zhu, Xiaoyan (7406185137)",57210123996; 7404260571; 7406185137,TransG: A generative model for knowledge graph embedding,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011965453&doi=10.18653%2fv1%2fp16-1219&partnerID=40&md5=558cd079d3182b09f3575251c0c66739,"Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper proposes a novel generative model (TransG) to address the issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples. The new model can discover latent semantics for a relation and leverage a mixture of relation-specific component vectors to embed a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, and at the first time, the issue of multiple relation semantics is formally discussed. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines. © 2016 Association for Computational Linguistics.",Final,All Open Access; Hybrid Gold Open Access
,,,"Term Bases and Linguistic Linked Open Data - TKE 2016, 12th International Conference on Terminology and Knowledge Engineering",-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984793118&partnerID=40&md5=dda2e0d440daa5cd06242d366956853f,The proceedings contain 23 papers. The topics discussed include: can big national term banks maintain complex cross-domain conceptual relations?; cross-lingual structural correspondence between terminologies: the case of English and Japanese; quality control in terminology management; web interfaces of terminological databases that are available on the Internet from a usability perspective; a bilingual KRC concordancer for assisted translation revision based on specialized comparable corpora; self-tuning ongoing terminology extraction retrained on terminology validation decisions; acquiring Vern frames for a text simplification lexicon in the medical domain; and enabling linked-data-based semantic annotations - the ontological modeling of semantics in the OntoLingAnnot model.,Final,
Aghaebrahimian A.; Jurčíček F.,"Aghaebrahimian, Ahmad (57193027501); Jurčíček, Filip (14018134000)",57193027501; 14018134000,Constraint-based open-domain question answering using knowledge graph search,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010190057&doi=10.1007%2f978-3-319-45510-5_4&partnerID=40&md5=ade7ce454944c0b2763d03181022f653,"We introduce a highly scalable approach for open-domain question answering with no dependence on any logical form to surface form mapping data set or any linguistic analytic tool such as POS tagger or named entity recognizer. We define our approach under the Constrained Conditional Models framework which lets us scale to a full knowledge graph with no limitation on the size. On a standard benchmark, we obtained competitive results to state-of-the-art in open-domain question answering task. © Springer International Publishing Switzerland 2016.",Final,
Heyvaert P.; Dimou A.; Herregodts A.-L.; Verborgh R.; Schuurman D.; Mannens E.; Van de Walle R.,"Heyvaert, Pieter (56912288000); Dimou, Anastasia (55236344100); Herregodts, Aron-Levi (57190302013); Verborgh, Ruben (36716974600); Schuurman, Dimitri (24176232000); Mannens, Erik (24464045700); Van de Walle, Rik (7005287415)",56912288000; 55236344100; 57190302013; 36716974600; 24176232000; 24464045700; 7005287415,RMLEditor: A graph-based mapping editor for linked data mappings,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978935173&doi=10.1007%2f978-3-319-34129-3_43&partnerID=40&md5=f33c97e6879d2f549540eb98378ce248,"Although several tools have been implemented to generate Linked Data from raw data, users still need to be aware of the underlying technologies and Linked Data principles to use them. Mapping languages enable to detach the mapping definitions from the implementation that executes them. However, no thorough research has been conducted on how to facilitate the editing of mappings. We propose the rmleditor, a visual graph-based user interface, which allows users to easily define the mappings that deliver the rdf representation of the corresponding raw data. Neither knowledge of the underlying mapping language nor the used technologies is required. The rmleditor aims to facilitate the editing of mappings, and thereby lowers the barriers to create Linked Data. The rmleditor is developed for use by data specialists who are partners of (i) a companies-driven pilot and (ii) a community group. The current version of the rmleditor was validated: participants indicate that it is adequate for its purpose and the graph-based approach enables users to conceive the linked nature of the data. © Springer International Publishing Switzerland 2016.",Final,
,,,"15th China National Conference on Chinese Computational Linguistics, CCL 2016 and 4th International Symposium on Natural Language Processing Based on Naturally Annotated Big Data, NLP NABD 2016",-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992524385&partnerID=40&md5=cadcbb47d07e4c02b9f118b8ded3cb64,"The proceedings contain 37 papers. The special focus in this conference is on Semantics, Machine Translation, Multilinguality in NLP, Knowledge Graph, Information Extraction, Linguistic Resource Annotation, Evaluation, Social Computing and Sentiment Analysis. The topics include: Improving Chinese semantic role labeling with English proposition bank; transition-based Chinese semantic dependency graph parsing; error analysis of English-Chinese machine translation; keeping the meanings of the source text; using collaborative training method to build Vietnamese dependency Treebank; improved joint Kazakh POS tagging and chunking; Tibetan person attributes extraction based on BP neural network; definition extraction with LSTM recurrent neural networks; a new focus strategy for efficient dialog management; news abridgement algorithm based on word alignment and syntactic parsing; enhancing neural disfluency detection with hand-crafted features; identifying suspected cybermob on Tieba; Chinese sentiment analysis exploiting heterogeneous segmentations; automatic naming of speakers in video via name-face mapping; image tag recommendation via deep cross-modal correlation mining and is local window essential for neural network based Chinese word segmentation?.",Final,
Varga J.; Etcheverry L.; Vaisman A.A.; Romero O.; Pedersen T.B.; Thomsen C.,"Varga, Jovan (56347546200); Etcheverry, Lorena (36550241400); Vaisman, Alejandro A. (7006229550); Romero, Oscar (35318898200); Pedersen, Torben Bach (7202189773); Thomsen, Christian (35318849500)",56347546200; 36550241400; 7006229550; 35318898200; 7202189773; 35318849500,QB2OLAP: Enabling OLAP on Statistical Linked Open Data,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980329071&doi=10.1109%2fICDE.2016.7498341&partnerID=40&md5=1dfec825c44260e2e8d122f6b39de6fa,"Publication and sharing of multidimensional (MD) data on the Semantic Web (SW) opens new opportunities for the use of On-Line Analytical Processing (OLAP). The RDF Data Cube (QB) vocabulary, the current standard for statistical data publishing, however, lacks key MD concepts such as dimension hierarchies and aggregate functions. QB4OLAP was proposed to remedy this. However, QB4OLAP requires extensive manual annotation and users must still write queries in SPARQL, the standard query language for RDF, which typical OLAP users are not familiar with. In this demo, we present QB2OLAP, a tool for enabling OLAP on existing QB data. Without requiring any RDF, QB(4OLAP), or SPARQL skills, it allows semi-automatic transformation of a QB data set into a QB4OLAP one via enrichment with QB4OLAP semantics, exploration of the enriched schema, and querying with the high-level OLAP language QL that exploits the QB4OLAP semantics and is automatically translated to SPARQL. © 2016 IEEE.",Final,All Open Access; Green Open Access
Tian F.; Gao B.; Chen E.-H.; Liu T.-Y.,"Tian, Fei (56175375700); Gao, Bin (57198734259); Chen, En-Hong (35228685900); Liu, Tie-Yan (8536446600)",56175375700; 57198734259; 35228685900; 8536446600,Learning Better Word Embedding by Asymmetric Low-Rank Projection of Knowledge Graph,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969920163&doi=10.1007%2fs11390-016-1651-5&partnerID=40&md5=0ca88e505f792fd1149ac1e3712af344,"Word embedding, which refers to low-dimensional dense vector representations of natural words, has demon-strated its power in many natural language processing tasks. However, it may suffer from the inaccurate and incomplete information contained in the free text corpus as training data. To tackle this challenge, there have been quite a few studies that leverage knowledge graphs as an additional information source to improve the quality of word embedding. Although these studies have achieved certain success, they have neglected some important facts about knowledge graphs: 1) many relationships in knowledge graphs are many-to-one, one-to-many or even many-to-many, rather than simply one-to-one; 2) most head entities and tail entities in knowledge graphs come from very different semantic spaces. To address these issues, in this paper, we propose a new algorithm named ProjectNet. ProjectNet models the relationships between head and tail entities after transforming them with different low-rank projection matrices. The low-rank projection can allow non one-to-one relationships between entities, while different projection matrices for head and tail entities allow them to originate in different semantic spaces. The experimental results demonstrate that ProjectNet yields more accurate word embedding than previous studies, and thus leads to clear improvements in various natural language processing tasks. © 2016, Springer Science+Business Media New York.",Final,All Open Access; Green Open Access
Kjolstad F.; Kamil S.; Ragan-Kelley J.; Levin D.I.W.; Sueda S.; Chen D.; Vouga E.; Kaufman D.M.; Kanwar G.; Matusik W.; Amarasinghe S.,"Kjolstad, Fredrik (37117054100); Kamil, Shoaib (14632097100); Ragan-Kelley, Jonathan (18435174100); Levin, David I. W. (57964894200); Sueda, Shinjiro (24537957000); Chen, Desai (55286115100); Vouga, Etienne (56377625000); Kaufman, Danny M. (13008436500); Kanwar, Gurtej (57189353018); Matusik, Wojciech (56230515000); Amarasinghe, Saman (7004682134)",37117054100; 14632097100; 18435174100; 57964894200; 24537957000; 55286115100; 56377625000; 13008436500; 57189353018; 56230515000; 7004682134,Simit: A language for physical simulation,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969627181&doi=10.1145%2f2866569&partnerID=40&md5=dc13ee3cdc9109e3b489e178d3610f86,"With existing programming tools, writing high-performance simulation code is labor intensive and requires sacrificing readability and portability. The alternative is to prototype simulations in a high-level language like Matlab, thereby sacrificing performance. The Matlab programming model naturally describes the behavior of an entire physical system using the language of linear algebra. However, simulations also manipulate individual geometric elements, which are best represented using linked data structures likemeshes. Translating between the linked data structures and linear algebra comes at significant cost, both to the programmer and to the machine. Highperformance implementations avoid the cost by rephrasing the computation in terms of linked or index data structures, leaving the code complicated and monolithic, often increasing its size by an order of magnitude. In this article, we present Simit, a new language for physical simulations that lets the programmer view the system both as a linked data structure in the form of a hypergraph and as a set of global vectors, matrices, and tensors depending on what is convenient at any given time. Simit provides a novel assembly construct that makes it conceptually easy and computationally efficient to move between the two abstractions. Using the information provided by the assembly construct, the compiler generates efficient in-place computation on the graph.We demonstrate that Simit is easy to use: A Simit program is typically shorter than a Matlab program; that it is high performance: A Simit program running sequentially on a CPU performs comparably to hand-optimized simulations; and that it is portable: Simit programs can be compiled for GPUs with no change to the program, delivering 4 to 20× speedups over our optimized CPU code. © 2016 Copyright is held by the owner/author(s). Publication rights licensed to ACM.",Final,All Open Access; Bronze Open Access; Green Open Access
Pandit H.; Hamed R.G.; Lawless S.; Lewis D.,"Pandit, Harshvardhan (57190943010); Hamed, Roghaiyeh Gachpaz (54400923700); Lawless, Shay (14041908200); Lewis, David (57035492800)",57190943010; 54400923700; 14041908200; 57035492800,The use of open data to improve the repeatability of adaptivity and personalisation experiment,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984653442&partnerID=40&md5=e0a870ed1dfe4b3a38fc14f39c54753e,"Reproducibility of results is a key element for the verification of scientific experiments and an important indicator of the quality of a published experiment. It is vital therefore to precisely and transparently share both the method and the data associated with an experiment. Data associated with an experiment is often linked within peer-reviewed scientific publications, and is difficult to assess in a consistent manner. In this paper we explore how emerging linked data standards can be applied to the description and data of published adaptivity and personalisation experiments in a manner that can be linked from publications and easily located, accessed and reused to repeat an experiment. The approach also provides possibilities for published experiments to be extended or modified to provide a firmer grounding for publishing new results and conclusions.",Final,
,,,"54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 - System Demonstrations",-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019287955&partnerID=40&md5=f09870053861d3b5b0a9ed345c48baaf,"The proceedings contain 28 papers. The topics discussed include: online information retrieval for language learning; terminology extraction with term variant detection; DeepLife: an entity-aware search, analytics and exploration platform for health and life sciences; visualizing and curating knowledge graphs over time and space; a web-framework for ODIN annotation; TranscRater: a tool for automatic speech recognition quality estimation; language muse: automated linguistic activity generation for English language learners; Jigg: a framework for an easy natural language processing pipeline; an advanced press review system combining deep news analysis and machine learning algorithms; personalized exercises for preposition learning; creating interactive Macaronic interfaces for language learning; and MediaGist: a cross-lingual analyzer of aggregated news and commentaries.",Final,
Bogers T.; Bordea G.; Buitelaar P.; Ferro N.; Silvello G.,"Bogers, Toine (14035145000); Bordea, Georgeta (36162852900); Buitelaar, Paul (14041096000); Ferro, Nicola (6507005996); Silvello, Gianmaria (23398794400)",14035145000; 36162852900; 14041096000; 6507005996; 23398794400,IR Scientific data: How to semantically represent and enrich them,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009259773&partnerID=40&md5=9719462873a506d6bd589b1bc70b0d49,"Experimental evaluation carried out in international large-scale campaigns is a fundamental pillar of the scientific and technological advancement of Information Retrieval (IR) systems. Such evaluation activities produce a large quantity of scientific and experimental data, which are the foundation for all the subsequent scientific production and development of new systems. We discuss how to annotate and interlink this data, by proposing a method for exposing experimental data as Linked Open Data (LOD) on the Web and as a basis for enriching and automatically connecting this data with expertise topics and expert profiles. In this context, a topiccentric approach for expert search is proposed, addressing the extraction of expertise topics, their semantic grounding with the LOD cloud, and their connection to IR experimental data.",Final,
,,,"20th International Conference on Knowledge Engineering and Knowledge Management, EKAW 2016",-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997112272&partnerID=40&md5=cde0a799329a09a281c0a40403637b81,The proceedings contain 51 papers. The special focus in this conference is on Knowledge Engineering and Knowledge Management. The topics include: Automatic key selection for data linking; selection and combination of heterogeneous mappings to enhance biomedical ontology matching; populating a knowledge base with object-location relations using distributional semantics; leveraging the impact of ontology evolution on semantic annotations; active integrity constraints for multi-context systems; evolutionary discovery of multi-relational association rules from ontological knowledge bases; an incremental learning method to support the annotation of workflows with data-to-data relations; a query model to capture event pattern matching in RDF stream processing query languages; automatic property mapping for tabular data; semantic authoring of ontologies by exploration and elimination of possible worlds; an RDF design pattern for the structural representation and querying of expressions; a comparative analysis of multilingual semantic relatedness using machine translation; on emerging entity detection; a wide coverage linguistic linked data hub; an investigation of definability in ontology alignment; a deductive approach for the integration of industry 4.0 standards; combining textual and graph-based features for named entity disambiguation using undirected probabilistic graphical models; an integrated environment to support version controlled vocabulary development; event-based recognition of lived experiences in user reviews; improving place name disambiguation from short texts by combining entity co-occurrence with topic modeling; relating some stuff to other stuff; a model for verbalising relations with roles in multiple languages and travel attractions recommendation with knowledge graphs.,Final,
Suchowolec K.; Lang C.; Schneider R.,"Suchowolec, Karolina (56311403200); Lang, Christian (57191404900); Schneider, Roman (55449219800)",56311403200; 57191404900; 55449219800,Re-designing Online Terminology Resources for German Grammar Project Report,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989931686&partnerID=40&md5=22ec0c638e5becd539ceaddff7653c7a,"The compilation of terminological vocabularies plays a central role in the organization and retrieval of scientific texts. Both simple keyword lists as well as sophisticated modellings of relationships between terminological concepts can make a most valuable contribution to the analysis, classification, and finding of appropriate digital documents, either on the Web or within local repositories. This seems especially true for longestablished scientific fields with various theoretical and historical branches, such as linguistics, where the use of terminology within documents from different origins is sometimes far from being consistent. In this short paper, we report on the early stages of a project that aims at the redesign of an existing domainspecific KOS for grammatical content grammis. In particular, we deal with the terminological part of grammis and present the stateoftheart of this online resource as well as the key redesign principles. Further, we propose questions regarding ramifications of the Linked Open Data and Semantic Web approaches for our redesign decisions.",Final,
Nikolaev F.; Kotov A.; Zhiltsov N.,"Nikolaev, Fedor (57044816700); Kotov, Alexander (56284550800); Zhiltsov, Nikita (36163731000)",57044816700; 56284550800; 36163731000,Parameterized fielded term dependence models for ad-hoc entity retrieval from knowledge graph,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980322286&doi=10.1145%2f2911451.2911545&partnerID=40&md5=618b62638d25ca97ed58ec49cdb7130d,"Accurate projection of terms in free-text queries onto structured entity representations is one of the fundamental problems in entity retrieval from knowledge graph. In this paper, we demonstrate that existing retrieval models for ad-hoc structured and unstructured document retrieval fall short of addressing this problem, due to their rigid assumptions. According to these assumptions, either all query concepts of the same type (unigrams and bigrams) are projected onto the fields of entity representations with identical weights or such projection is determined based only on one simple statistic, which makes it sensitive to data sparsity. To address this issue, we propose the Parametrized Fielded Sequential Dependence Model (PFSDM) and the Parametrized Fielded Full Dependence Model (PFFDM), two novel models for entity retrieval from knowledge graphs, which infer the user's intent behind each individual query concept by dynamically estimating its projection onto the fields of structured entity representations based on a small number of statistical and linguistic features. Experimental results obtained on several publicly available benchmarks indicate that PFSDM and PFFDM consistently outperform state-of-the-art retrieval models for the task of entity retrieval from knowledge graph. © 2016 ACM.",Final,
Saloot M.A.; Idris N.; Mahmud R.; Ja’afar S.; Thorleuchter D.; Gani A.,"Saloot, Mohammad Arshi (56180599100); Idris, Norisma (13608179100); Mahmud, Rohana (36666779200); Ja’afar, Salinah (57197898100); Thorleuchter, Dirk (55922241500); Gani, Abdullah (57218294440)",56180599100; 13608179100; 36666779200; 57197898100; 55922241500; 57218294440,Hadith data mining and classification: a comparative analysis,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953432757&doi=10.1007%2fs10462-016-9458-x&partnerID=40&md5=c7dbd63303cf80763c0774de2bfd6d34,"Hadiths are important textual sources of law, tradition, and teaching in the Islamic world. Analyzing the unique linguistic features of Hadiths (e.g. ancient Arabic language and story-like text) results to compile and utilize specific natural language processing methods. In the literature, no study is solely focused on Hadith from artificial intelligence perspective, while many new developments have been overlooked and need to be highlighted. Therefore, this review analyze all academic journal and conference publications that using two main methods of artificial intelligence for Hadith text: Hadith classification and mining. All Hadith relevant methods and algorithms from the literature are discussed and analyzed in terms of functionality, simplicity, F-score and accuracy. Using various different Hadith datasets makes a direct comparison between the evaluation results impossible. Therefore, we have re-implemented and evaluated the methods using a single dataset (i.e. 3150 Hadiths from Sahih Al-Bukhari book). The result of evaluation on the classification method reveals that neural networks classify the Hadith with 94 % accuracy. This is because neural networks are capable of handling complex (high dimensional) input data. The Hadith mining method that combines vector space model, Cosine similarity, and enriched queries obtains the best accuracy result (i.e. 88 %) among other re-evaluated Hadith mining methods. The most important aspect in Hadith mining methods is query expansion since the query must be fitted to the Hadith lingo. The lack of knowledge based methods is evident in Hadith classification and mining approaches and this absence can be covered in future works using knowledge graphs. © 2016, Springer Science+Business Media Dordrecht.",Final,
Ilievski F.; Rizzo G.; Van Erp M.; Plu J.; Troncy R.,"Ilievski, Filip (57188757237); Rizzo, Giuseppe (57194127652); Van Erp, Marieke (56458465100); Plu, Julien (23978555300); Troncy, Raphaël (23986650400)",57188757237; 57194127652; 56458465100; 23978555300; 23986650400,Context-enhanced adaptive entity linking,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021244632&partnerID=40&md5=5d3a19e6d8132c5eb19e3a7d3ffc3d2e,"More and more knowledge bases are publicly available as linked data. Since these knowledge bases contain structured descriptions of real-world entities, they can be exploited by entity linking systems that anchor entity mentions from text to the most relevant resources describing those entities. In this paper, we investigate adaptation of the entity linking task using contextual knowledge. The key intuition is that entity linking can be customized depending on the textual content, as well as on the application that would make use of the extracted information. We present an adaptive approach that relies on contextual knowledge from text to enhance the performance of ADEL, a hybrid linguistic and graph-based entity linking system. We evaluate our approach on a domain-specific corpus consisting of annotated WikiNews articles.",Final,
Yahya M.; Barbosa D.; Berberich K.; Wang Q.; Weikum G.,"Yahya, Mohamed (57197692817); Barbosa, Denilson (14027953400); Berberich, Klaus (55953919200); Wang, Qiuyue (56097692500); Weikum, Gerhard (56270327600)",57197692817; 14027953400; 55953919200; 56097692500; 56270327600,Relationship queries on extended knowledge graphs,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964403394&doi=10.1145%2f2835776.2835795&partnerID=40&md5=807652a0f2806ca29a2f906dd8523754,"Entity search over text corpora is not geared for relationship queries where answers are tuples of related entities and where a query often requires joining cues from multiple documents. With large knowledge graphs, structured querying on their relational facts is an alternative, but often sufiers from poor recall because of mismatches between user queries and the knowledge graph or because of weakly populated relations. This paper presents the TriniT search engine for querying and ranking on extended knowledge graphs that combine relational facts with textual web contents. Our query language is designed on the paradigm of SPO triple patterns, but is more expressive, supporting textual phrases for each of the SPO arguments. We present a model for automatic query relaxation to compensate for mismatches between the data and a user's query. Query answers - tuples of entities - are ranked by a statistical language model. We present experiments with different benchmarks, including complex relationship queries, over a combination of the Yago knowledge graph and the entity-annotated ClueWeb'09 corpus. © 2015 Copyright held by the owner/author(s).",Final,
Wang C.; Song Y.; Roth D.; Zhang M.; Han J.,"Wang, Chenguang (56367840700); Song, Yangqiu (14039604300); Roth, Dan (7401669040); Zhang, Ming (57853084000); Han, Jiawei (24325399900)",56367840700; 14039604300; 7401669040; 57853084000; 24325399900,World knowledge as indirect supervision for document clustering,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008881028&doi=10.1145%2f2953881&partnerID=40&md5=b9da262ac2fe28a83f57e7c83c679a23,"One of the key obstacles in making learning protocols realistic in applications is the need to supervise them, a costly process that often requires hiring domain experts. We consider the framework to use the world knowledge as indirect supervision. World knowledge is general-purpose knowledge, which is not designed for any specific domain. Then, the key challenges are how to adapt the world knowledge to domains and how to represent it for learning. In this article, we provide an example of using world knowledge for domain-dependent document clustering. We provide three ways to specify the world knowledge to domains by resolving the ambiguity of the entities and their types, and represent the data with world knowledge as a heterogeneous information network. Then, we propose a clustering algorithm that can cluster multiple types and incorporate the sub-type information as constraints. In the experiments, we use two existing knowledge bases as our sources of world knowledge. One is Freebase, which is collaboratively collected knowledge about entities and their organizations. The other is YAGO2, a knowledge base automatically extracted from Wikipedia and maps knowledge to the linguistic knowledge base, WordNet. Experimental results on two text benchmark datasets (20newsgroups and RCV1) show that incorporating world knowledge as indirect supervision can significantly outperform the state-of-the-art clustering algorithms as well as clustering algorithms enhanced with world knowledge features. A preliminary version of this work appeared in the proceedings of KDD 2015 [Wang et al. 2015a]. This journal version has made several major improvements. First, we have proposed a new and general learning framework for machine learning with world knowledge as indirect supervision, where document clustering is a special case in the original paper. Second, in order to make our unsupervised semantic parsing method more understandable, we add several real cases from the original sentences to the resulting logic forms with all the necessary information. Third, we add details of the three semantic filtering methods and conduct deep analysis of the three semantic filters, by using case studies to show why the conceptualization-based semantic filter can produce more accurate indirect supervision. Finally, in addition to the experiment on 20 newsgroup data and Freebase, we have extended the experiments on clustering results by using all the combinations of text (20 newsgroup, MCAT, CCAT, ECAT) and world knowledge sources (Freebase, YAGO2). © 2016 ACM.",Final,All Open Access; Bronze Open Access; Green Open Access
Hkiri E.; Mallat S.; Zrigui M.,"Hkiri, Emna (55735205600); Mallat, Souheyl (55735211200); Zrigui, Mounir (8951841700)",55735205600; 55735211200; 8951841700,Improving coverage of rule based NER systems,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988383399&doi=10.1109%2fICTA.2015.7426925&partnerID=40&md5=1417254f249a4cea8d2848e1b5de5d4a,"Named entity recognition (NER) is the problem of identifying (locating and categorizing) atomic entities in a given text that fall into predefined categories or classes. In this work, we developed a bilingual Arabic-English lexicon of named entities (NE) to improve the performance of Arabic rule-based systems. To reach our goal, we followed different steps starting by the pre-editing of the DBpedia linked data entities and the parallel corpus and then applying our automatic model for detection, extraction and translation of Arabic-English Named Entities. Our approach is fully automatic and hybrid, it combines linguistic and statistical methods. © 2015 IEEE.",Final,All Open Access; Bronze Open Access
Rospocher M.; Van Erp M.; Vossen P.; Fokkens A.; Aldabe I.; Rigau G.; Soroa A.; Ploeger T.; Bogaard T.,"Rospocher, Marco (14010314000); Van Erp, Marieke (56458465100); Vossen, Piek (57204791557); Fokkens, Antske (37021343400); Aldabe, Itziar (14047967300); Rigau, German (22735472300); Soroa, Aitor (7801335998); Ploeger, Thomas (56001601000); Bogaard, Tessel (57191896905)",14010314000; 56458465100; 57204791557; 37021343400; 14047967300; 22735472300; 7801335998; 56001601000; 57191896905,Building event-centric knowledge graphs from news,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994652650&doi=10.1016%2fj.websem.2015.12.004&partnerID=40&md5=5d75f084f17f1cc849685d4f6acbc9db,"Knowledge graphs have gained increasing popularity in the past couple of years, thanks to their adoption in everyday search engines. Typically, they consist of fairly static and encyclopedic facts about persons and organizations-e.g. a celebrity's birth date, occupation and family members-obtained from large repositories such as Freebase or Wikipedia. In this paper, we present a method and tools to automatically build knowledge graphs from news articles. As news articles describe changes in the world through the events they report, we present an approach to create Event-Centric Knowledge Graphs (ECKGs) using state-of-the-art natural language processing and semantic web techniques. Such ECKGs capture long-term developments and histories on hundreds of thousands of entities and are complementary to the static encyclopedic information in traditional knowledge graphs. We describe our event-centric representation schema, the challenges in extracting event information from news, our open source pipeline, and the knowledge graphs we have extracted from four different news corpora: general news (Wikinews), the FIFA world cup, the Global Automotive Industry, and Airbus A380 airplanes. Furthermore, we present an assessment on the accuracy of the pipeline in extracting the triples of the knowledge graphs. Moreover, through an event-centered browser and visualization tool we show how approaching information from news in an event-centric manner can increase the user's understanding of the domain, facilitates the reconstruction of news story lines, and enable to perform exploratory investigation of news hidden facts. © 2016 Elsevier B.V. All rights reserved.",Final,
Balaceanu O.; Takeda H.,"Balaceanu, Oana (57184304000); Takeda, Hideaki (7403064748)",57184304000; 7403064748,ArtViz: A web platform for artist data visualization and exploration,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961141968&partnerID=40&md5=c817e705403fb6ec072d3221262b2244,"Browsing through the available data nowadays can be a difficult task for the unexperienced users. Every day, the Internet is flooded by unstructured information that sometimes needs time to be extracted and analyzed. When it comes to art data, there aren't any concrete sources that offer consistent information about artists in an interactive way. In this paper we describe the prototype of ArtViz, a web platform that displays art linked data to unexperienced users and helps them discover new information through interactive visualization. Furthermore we will present additional useful features like natural language querying or recommending similar entities (artists).",Final,
Lopez V.; Tommasi P.; Kotoulas S.; Wu J.,"Lopez, Vanessa (8928407100); Tommasi, Pierpaolo (56104140600); Kotoulas, Spyros (16238993900); Wu, Jiewen (55570097400)",8928407100; 56104140600; 16238993900; 55570097400,QuerioDALI: Question answering over dynamic and linked knowledge graphs,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992665500&doi=10.1007%2f978-3-319-46547-0_32&partnerID=40&md5=a3eb0990d419508fa4fe6f5cfa5e3c96,"We present a domain-agnostic system for Question Answering over multiple semi-structured and possibly linked datasets without the need of a training corpus. The system is motivated by an industry use-case where Enterprise Data needs to be combined with a large body of Open Data to fulfill information needs not satisfied by prescribed application data models. Our proposed Question Answering pipeline combines existing components with novel methods to perform, in turn, linguistic analysis of a query, named entity extraction, entity/graph search, fusion and ranking of possible answers. We evaluate QuerioDALI with two open-domain benchmarks and a biomedical one over Linked Open Data sources, and show that our system produces comparable results to systems that require training data and are domain-dependent. In addition, we analyze the current challenges and shortcomings. © Springer International Publishing AG 2016.",Final,
,,,CEUR Workshop Proceedings,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992665506&partnerID=40&md5=ffb4744afe0b8888b6766d9cb9e1b41e,The proceedings contain 7 papers. The topics discussed include: knowledge extraction and linked data: playing with frames; a tool for creating and visualizing semantic annotations on relational tables; a linked open data approach for sentiment lexicon adaptation; word frame disambiguation: evaluating linguistic linked data on frame detection; freedom for bibliographic references: OpenCitations arise [canonical URL]; enhancing open data to linked open data with ODMiner; and multilingual dictionary linking and aggregation: quality from consistency.,Final,
Zhao J.; Yang Y.; Liu T.; Shi J.,"Zhao, Jiapeng (57191729783); Yang, Yan (57007434100); Liu, Tingwen (35956637400); Shi, Jinqiao (7404494984)",57191729783; 57007434100; 35956637400; 7404494984,Towards personal relation extraction based on sentence pattern tree,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006001637&doi=10.1007%2f978-981-10-3168-7_9&partnerID=40&md5=c96d1eb0cafc061392d66ef9762b6b1b,"Extracting personal relation triple (S, P, O) from large number of unstructured text is crucial to the construction of knowledge graph, knowledge representation and reasoning of personal relation. Aiming at low accuracy in extracting triples from unstructured text, we present a supervised approach to judge whether extracted triples are correct. The approach need to build a knowledge base which contain peoples attributes first, then a sentence pattern tree is learnt according the people attribute knowledge base and the training data. When training, triples are extracted from the text automatically and labelled whether correct or not manually. Then patterns are constructed layer-by-layer according the position of “triple”, “pronoun” and “word” in sentence. At the same time, the correct and error number of triples are recorded on each pattern. When testing, the correctness of triples can be judged by the number recorded in matched patterns. According the test result, our approach does better in the training time, the testing time and the F1- value (76.6%) than the ordinary approach based on feature engineering (75.7%). At last, we make the judgement result of sentence pattern tree as a feature to improve the feature engineering approach (77.5%). In addition, this approach has a better expansibility than the traditional one and has guiding significance to the construction of the training set. © Springer Nature Singapore Pte Ltd. 2016.",Final,
Yang E.; Kim Y.-B.; Sarikaya R.; Kim Y.-S.,"Yang, Eunsuk (55803934100); Kim, Young-Bum (53873830900); Sarikaya, Ruhi (6602907269); Kim, Yu-Seop (55669181800)",55803934100; 53873830900; 6602907269; 55669181800,Drop-out conditional random fields for twitter with huge mined gazetteer,-1,,-1,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994140813&doi=10.18653%2fv1%2fn16-1032&partnerID=40&md5=61577cbe47276f68efe5ee8c630b2b1d,"In named entity recognition task especially for massive data like Twitter, having a large amount of high quality gazetteers can alleviate the problem of training data scarcity. One could collect large gazetteers from knowledge graph and phrase embeddings to obtain high coverage of gazetteers. However, large gazetteers cause a side-effect called ""feature under-training"", where the gazetteer features overwhelm the context features. To resolve this problem, we propose the dropout conditional random fields, which decrease the influence of gazetteer features with a high weight. Our experiments on named entity recognition with Twitter data lead to higher F1 score of 69.38%, about 4% better than the strong baseline presented in Smith and Osborne (2006). ©2016 Association for Computational Linguistics.",Final,All Open Access; Green Open Access; Hybrid Gold Open Access
Svátek V.; Homola M.; Kl'uka J.; Vacura M.,"Svátek, Vojtěch (35563252500); Homola, Martin (8935340300); Kl'uka, Ján (55838403000); Vacura, Miroslav (8543560300)",35563252500; 8935340300; 55838403000; 8543560300,Metamodeling-based coherence checking of OWL vocabulary background models,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923963777&partnerID=40&md5=36e5a10fdfd84e0ca71ad063a1f1017d,"The surface (or, foreground) structure of linked data and their associated OWL vocabularies can be complemented by background models expressing valid ontological distinctions that may have become obscured by the modeling style chosen by the vocabulary designer. Background models can generally serve for debugging, visualization, matching, or even pattern-based design of operational ontologies such as linked data vocabularies. An example of a well-known background model language, primarily suited for taxonomic ontologies, is the system of OntoClean meta-properties. We present an alternative type of background model language, dubbed PURO, which is oriented towards linked data ontologies, and relies on particular-universal and relationship-object dichotomies. Typical 'foreground' manifestations of background language terms are then discussed. We demonstrate how a PURO background structure of OWL vocabularies can be itself modeled in OWL using a dedicated PURO ontology, and how reasoning over such a metamodel can verify ontological coherence of the original OWL vocabularies.",Final,
Pareja-Lora A.; Blume M.; Lust B.,"Pareja-Lora, Antonio (6504385937); Blume, María (56744389500); Lust, Barbara (6603567875)",6504385937; 56744389500; 6603567875,Transforming the Data Transcription and Analysis Tool Metadata and Labels into a Linguistic Linked Open Data Cloud Resource,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028444869&partnerID=40&md5=3516f6abbea2935f9de60a8c994d741c,"Developing language resources requires much time, funding and effort. This is why they need to be reused in new projects and developments, so that they may both serve a wider scientific community and sustain their cost. The main problems that prevent this from happening are that (1) language resources are rarely free and/or easy to locate; and (2) they are hardly ever interoperable. Therefore, the language resource community is now working to transform their most valuable assets into open and interoperable resources, which can then be shared and linked with other open and interoperable resources. This will allow data to be reanalyzed and re-purposed. In this paper, we present the first steps taken to transform a set of such resources, namely the Data Transcription and Analysis Tool’s (DTA) metadata and data, into an open and interoperable language resource. These first steps include the development of two ontologies that formalize the conceptual model underlying the DTA metadata and the labels used in the DTA to annotate both utterances and their transcriptions at several annotation levels. © LDL 2013.All right reserved.",Final,
Ferre S.,"Ferre, Sebastien (8974579900)",8974579900,Squall2sparql: A Translator from controlled English to full SPARQL 1.1,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922031801&partnerID=40&md5=241f69a2c32c3b812c627ffd880c0078,"This paper reports on the participation of the system squall2sparql in the QALD-3 question answering challenge for DBpedia. squall2sparql is a translator from SQUALL, a controlled natural language for English, to SPARQL 1.1, a standard expressive query and update language for linked open data. It covers nearly all features of SPARQL 1.1, and is directly applicable to any SPARQL endpoint.",Final,
Pradel C.; Peyet G.; Haemmerle O.; Hernandez N.,"Pradel, Camille (46061492800); Peyet, Guillaume (56500695700); Haemmerle, Ollivier (6602418271); Hernandez, Nathalie (15845708700)",46061492800; 56500695700; 6602418271; 15845708700,"SWIP at QALD-3: Results, criticisms and lesson learned",-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922041568&partnerID=40&md5=0ab957a303877f1569bb8b85cbac1119,"This paper presents the results obtained by the SWIP system while participating in the QALD-3 (Question Answering over Linked Data) challenge, co-located with CLEF 2013 (Conference and Labs of the Evaluation Forum). We tackled task 1, multilingual question answering, whose purpose is to interpret natural language questions in order to return the answers contained in a graph knowledge base. We answered queries of both proposed datasets (one concerning DBpedia, the other Musicbrainz) and took into consideration only questions in English. The system SWIP (Semantic Web Interface using Patterns) aims at automatically generating formal queries from user queries expressed in natural language. For this, it relies on the use of query patterns which enable the complex task of interpreting natural language queries. The results obtained on the Musicbrainz dataset (precision = 0:51, recall = 0:51, F-measure = 0:51) are very satisfactory and encouraging. The results on DBpedia (precision = 0:16, recall = 0:15, F-measure = 0:16) are more disappointing. In this paper, we present both the SWIP approach and its implementation. We then present the results of the challenge in more detail and their analysis. Finally we draw some conclusions on the strengths and weaknesses of our approach, and suggest ways to improve its performance.",Final,
Zhang Z.; Gentile A.L.; Augenstein I.; Blomqvist E.; Ciravegna F.,"Zhang, Ziqi (14326468700); Gentile, Anna Lisa (23392611200); Augenstein, Isabelle (55236320300); Blomqvist, Eva (8968017800); Ciravegna, Fabio (8957737400)",14326468700; 23392611200; 55236320300; 8968017800; 8957737400,Mining equivalent relations from linked data,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898886261&partnerID=40&md5=5d96cdbc43ef6541e62478a523891fb4,"Linking heterogeneous resources is a major research challenge in the Semantic Web. This paper studies the task of mining equivalent relations from Linked Data, which was insufficiently addressed before. We introduce an unsupervised method to measure equivalency of relation pairs and cluster equivalent relations. Early experiments have shown encouraging results with an average of 0.75∼0.87 precision in predicting relation pair equivalency and 0.78∼0.98 precision in relation clustering. © 2013 Association for Computational Linguistics.",Final,
Varanka D.E.; Caro H.K.,"Varanka, Dalia E. (55948673400); Caro, Holly K. (57196220586)",55948673400; 57196220586,Spatial relation predicates in topographic feature semantics,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961723698&doi=10.1007%2f978-3-642-34359-9_10&partnerID=40&md5=65da343b5df73dcc279eb8e4f40a7767,"Topographic data are designed and widely used for base maps of diverse applications, yet the power of these information sources largely relies on the interpretive skills of map readers and relational database expert users once the data are in map or geographic information system (GIS) form. Advances in geospatial semantic technology offer data model alternatives for explicating concepts and articulating complex data queries and statements. To understand and enrich the vocabulary of topographic feature properties for semantic technology, English language spatial relation predicates were analyzed in three standard topographic feature glossaries. The analytical approach drew from disciplinary concepts in geography, linguistics, and information science. Five major classes of spatial relation predicates were identified from the analysis; representations for most of these are not widely available. The classes are: part-whole (which are commonly modeled throughout semantic and linked-data networks), geometric, processes, human intention, and spatial prepositions. These are commonly found in the ‘real world’ and support the environmental science basis for digital topographical mapping. The spatial relation concepts are based on sets of relation terms presented in this chapter, though these lists are not prescriptive or exhaustive. The results of this study make explicit the concepts forming a broad set of spatial relation expressions, which in turn form the basis for expanding the range of possible queries for topographical data analysis and mapping. © Springer-Verlag Berlin Heidelberg 2013.",Final,
Dima C.,"Dima, Corina (35185949800)",35185949800,Intui2: A prototype system for question answering over linked data,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922021658&partnerID=40&md5=190e4b5763cd173fc9d5ed2eee524312,"An ever increasing amount of Linked Data is made available every day. Public triple stores offer the possibility of querying hundreds of millions of triples. But this information can only be retrieved using specialized query languages like SPARQL, so for the majority of Internet users, it is still unavailable. This paper presents a prototype system aimed at streamlining the access to the information stored as RDF. The system takes as input a natural language question formulated in English and generates an equivalent SPARQL query. The mapping is based on the analysis of the syntactic patterns present in the input question. In the initial evaluation results, against the 99 questions in the QALD-3 DBpedia test set, the system provides a correct answer to 30 questions and a partial answer for another 3 questions, achieving an F-measure of 0.32.",Final,
Heck L.; Hakkani-Tür D.; Tur G.,"Heck, Larry (7005241213); Hakkani-Tür, Dilek (6603261445); Tur, Gokhan (15060858000)",7005241213; 6603261445; 15060858000,Leveraging knowledge graphs forweb-scale unsupervised semantic parsing,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906262369&partnerID=40&md5=36e1ac1c8478ec59d79c09727bc43104,"The past decade has seen the emergence of web-scale structured and linked semantic knowledge resources (e.g., Freebase, DBPedia). These semantic knowledge graphs provide a scalable ""schema for the web"", representing a significant opportunity for the spoken language understanding (SLU) research community. This paper leverages these resources to bootstrap a web-scale semantic parser with no requirement for semantic schema design, no data collection, and no manual annotations. Our approach is based on an iterative graph crawl algorithm. From an initial seed node (entity-type), the method learns the related entity-types from the graph structure, and automatically annotates documents that can be linked to the node (e.g., Wikipedia articles, web search documents). Following the branches, the graph is crawled and the procedure is repeated. The resulting collection of annotated documents is used to bootstrap webscale conditional random field (CRF) semantic parsers. Finally, we use a maximum-a-posteriori (MAP) unsupervised adaptation technique on sample data from a specific domain to refine the parsers. The scale of the unsupervised parsers is on the order of thousands of domains and entity-types, millions of entities, and hundreds of millions of relations. The precision-recall of the semantic parsers trained with our unsupervised method approaches those trained with supervised annotations. Copyright © 2013 ISCA.",Final,
Maali F.; Decker S.,"Maali, Fadi (36606544900); Decker, Stefan (8846837500)",36606544900; 8846837500,Towards an RDF analytics language: Learning from successful experiences,-1,,-1,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924777657&partnerID=40&md5=0cf7674ae43d2bfdd5e14605d407064f,"SPARQL, the W3C standard querying language for RDF, provides rich capabilities for slicing and dicing RDF data. The latest version, SPARQL 1.1, added support for aggregation, nested and distributed queries among others. Nevertheless, the purely declarative nature of SPARQL and the lack of support for common programming patterns, such as recursion and iteration, make it challenging to perform complex data processing and analysis in SPARQL. In the database community, similar limitations of SQL resulted in a surge of proposals of analytics languages and frameworks. These languages are carefully designed to run on top of distributed computation platforms. In this paper, we review these efforts of the database community, identify a number of common themes they bear and discuss their applicability in the Semantic Web and Linked Data realm. In particular, design decisions related to the data model, schema restrictions, data transformation and the programming paradigm are examined and a number of related challenges for defining an RDF analytics language are outlined.",Final,
Wendt M.; Gerlach M.; Düwiger H.,"Wendt, Matthias (56022755600); Gerlach, Martin (57196529674); Düwiger, Holger (55654868400)",56022755600; 57196529674; 55654868400,Linguistic modeling of linked open data for question answering,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893212165&partnerID=40&md5=14f5cb91775c9ea979a3e7d8dce0e9a1,"With the evolution of linked open data sources, question answering regains importance as a way to make data accessible and explorable to the public. The triple structure of RDF-data at the same time seems to predetermine question answering for being devised in its native subject-verb-object form. The devices of natural language, however, often exceed this triple-centered model. But RDF does not preclude this point of view. Rather, it depends on the modeling. As part of a government funded research project named Alexandria, we implemented an approach to question answering that enables the user to ask questions in ways that may involve more than binary relations.",Final,
Yahya M.; Berberich K.; Elbassuoni S.; Ramanath M.; Tresp V.; Weikum G.,"Yahya, Mohamed (57197692817); Berberich, Klaus (55953919200); Elbassuoni, Shady (25823803400); Ramanath, Maya (6603292414); Tresp, Volker (6603805670); Weikum, Gerhard (56270327600)",57197692817; 55953919200; 25823803400; 6603292414; 6603805670; 56270327600,Natural language questions for the web of data,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881338456&partnerID=40&md5=55bf1c317ff27c809d2c85c0fe0ee187,"The Linked Data initiative comprises structured databases in the Semantic-Web data model RDF. Exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users. To ease the task, this paper presents a methodology for translating natural language questions into structured SPARQL queries over linked-data sources. Our method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of SPARQL triple patterns. Our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function. We present experiments on both the question translation and the resulting query answering. © 2012 Association for Computational Linguistics.",Final,
Santos H.; Furtado V.,"Santos, Henrique (55575740500); Furtado, Vasco (22333909800)",55575740500; 22333909800,A service-oriented architecture for assisting the authoring of semantic crowd maps,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951962584&partnerID=40&md5=dca4187207d1a3e5996fa0151bc82505,"Although there are increasingly more initiatives for the generation of semantic knowledge based on user participation, there is still a shortage of plat- forms for regular users to create applications on which semantic data can be exploited and generated automatically. We propose anarchitecture, called Semantic Maps (SeMaps), for assisting the authoring and hosting of applications in which the maps combine the aggregation of a Geographic Information System and crowd-generated content (called here crowd maps). In these systems, the digital map works as a blackboard for accommodating stories told by people about events they want to share with others typically participating in their social net- works. SeMaps offers an environment for the creation and maintenance of sites based on crowd maps with the possibility for the user to characterize semantically that which s/he intends to mark on the map. The designer of a crowd map, by in- forming a linguistic expression that designates what has to be marked on the maps, is guided in a process that aims to associate a concept from a common- sense base to this linguistic expression. Thus, the crowd maps start to have dominion over common-sense inferential relations that define the meaning of the marker, and are able to make inferences about the network of linked data. This makes it possible to generate maps that have the power to perform inferences and access external sources (such as D Bpedia) that constitute information that is useful and appropriate to the context of the map. In this paper we describe the architecture of Se Maps and how it was applied in a crowd map authoring tool. © Springer-Verlag Berlin Heidelberg 2012.",Final,
Bergamaschi S.; Cruz I.,"Bergamaschi, Sonia (7006782238); Cruz, Isabel (7006046571)",7006782238; 7006046571,ODBASE 2012 PC co-chairs message,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872782875&doi=10.1007%2f978-3-642-33615-7_13&partnerID=40&md5=2b7a322e10b67a43faf4790f33a7d90e,"We are happy to present the papers of the 11th International Conference on Ontologies, DataBases, and Applications of Semantics (ODBASE) held in Rome (Italy) on September 11th and 12th, 2012. The ODBASE Conference series provides a forum for research on the use of ontologies and data semantics in novel applications, and continues to draw a highly diverse body of researchers and practitioners. ODBASE is part of On the Move to Meaningful Internet Systems (OnTheMove) that co-locates three conferences: ODBASE, DOA-SVI (International Symposium on Secure Virtual Infrastructures), and CoopIS (International Conference on Cooperative Information Systems). Of particular interest in the 2012 edition of the ODBASE Conference are the research and practical experience papers that bridge across traditional boundaries between disciplines such as databases, networking, mobile systems, artificial intelligence, information retrieval, and computational linguistics. In this edition, we received 52 paper submissions and had a program committee of 82 people, which included researchers and practitioners from diverse research areas. Special arrangements were made during the review process to ensure that each paper was reviewed by members of different research areas. The result of this effort is the selection of high quality papers: fifteen as regular papers (29%), six as short papers (12%), and three as posters (15%). Their themes included studies and solutions to a number of modern challenges such as search and management of linked data and RDF documents, modeling, management, alignment and storing of ontologies, application of mining techniques, semantics discovery, and data uncertainty management. © 2012 Springer-Verlag.",Final,
Neumayer R.; Balog K.; Nørvåg K.,"Neumayer, Robert (23012858400); Balog, Krisztian (15043772700); Nørvåg, Kjetil (6701624663)",23012858400; 15043772700; 6701624663,Ranking distributed knowledge repositories,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867681994&doi=10.1007%2f978-3-642-33290-6_56&partnerID=40&md5=3c694bfce71cfa0f26da7332aa624851,"Increasingly many knowledge bases are published as Linked Data, driving the need for effective and efficient techniques for information access. Knowledge repositories are naturally organised around objects or entities and constitute a promising data source for entity-oriented search. There is a growing body of research on the subject, however, it is almost always (implicitly) assumed that a centralised index of all data is available. In this paper, we address the task of ranking distributed knowledge repositories-a vital component of federated search systems-and present two probabilistic methods based on generative language modeling techniques. We present a benchmarking testbed based on the test suites of the Semantic Search Challenge series to evaluate our approaches. In our experiments, we show that both our ranking approaches provide competitive performance and offer a viable alternative to centralised retrieval. © 2012 Springer-Verlag.",Final,All Open Access; Green Open Access
Granitzer M.; Hristakeva M.; Knight R.; Jack K.; Kern R.,"Granitzer, Michael (8714519100); Hristakeva, Maya (36113559300); Knight, Robert (55303142500); Jack, Kris (55217748200); Kern, Roman (24476445300)",8714519100; 36113559300; 55303142500; 55217748200; 24476445300,A comparison of layout based bibliographic metadata extraction techniques,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863977669&doi=10.1145%2f2254129.2254154&partnerID=40&md5=8d1ee505aa3f82087c2b0f39a446edbb,"Social research networks such as Mendeley and CiteULike offer various services for collaboratively managing bibliographic metadata. Compared with traditional libraries, metadata quality is of crucial importance in order to create a crowdsourced bibliographic catalog for search and browsing. Artifacts, in particular PDFs which are managed by the users of the social research networks, become one important metadata source and the starting point for creating a homogeneous, high quality, bibliographic catalog. Natural Language Processing and Information Extraction techniques have been employed to extract structured information from unstructured sources. However, given highly heterogeneous artifacts that cover a range of publication styles, stemming from different publication sources, and imperfect PDF processing tools, how accurate are metadata extraction methods in such real-world settings? This paper focuses on answering that question by investigating the use of Conditional Random Fields and Support Vector Machines on real-world data gathered from Mendeley and Linked-Data repositories. We compare style and content features on existing state-of-the-art methods on two newly created real-world data sets for metadata extraction. Our analysis shows that two-stage SVMs provide reasonable performance in solving the challenge of metadata extraction for crowdsourcing bibliographic metadata management. Copyright 2012 ACM.",Final,
,,,"Proceedings of the Workshop on Interacting with Linked Data 2012, ILD 2012 - Workshop Co-located with the 9th Extended Semantic Web Conference",-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893257800&partnerID=40&md5=4a195f3f13de188b3f240addcbdb94de,The proceedings contain 10 papers. The topics discussed include: putting linked data to use in a large higher-education organisation; facets and pivoting for flexible and usable linked data exploration; interacting with statistical linked data via OLAP operations; SPARTIQULATION: verbalizing SPARQL queries; improving semantic search using query log analysis; linguistic modeling of linked open data for question answering; QAKiS @ QALD-2; a system description of natural language query over DBpedia; and TypeCraft: collaborative databasing and resource sharing for linguists.,Final,
Bergamaschi S.; Cruz I.,"Bergamaschi, Sonia (7006782238); Cruz, Isabel (7006046571)",7006782238; 7006046571,ODBASE 2012 PC co-chairs message,-1,,-1,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873861507&doi=10.1007%2f978-3-642-33618-8_89&partnerID=40&md5=89c89d4af57a38fc5cac37d6a122b31f,"We are happy to present the papers of the 11th International Conference on Ontologies, DataBases, and Applications of Semantics (ODBASE) held in Rome (Italy) on September 11th and 12th, 2012. The ODBASE Conference series provides a forum for research on the use of ontologies and data semantics in novel applications, and continues to draw a highly diverse body of researchers and practitioners. ODBASE is part of On the Move to Meaningful Internet Systems (OnTheMove) that co-locates three conferences: ODBASE, DOA-SVI (International Symposium on Secure Virtual Infrastructures), and CoopIS (International Conference on Cooperative Information Systems). Of particular interest in the 2012 edition of the ODBASE Conference are the research and practical experience papers that bridge across traditional boundaries between disciplines such as databases, networking, mobile systems, artificial intelligence, information retrieval, and computational linguistics. In this edition, we received 52 paper submissions and had a program committee of 82 people, which included researchers and practitioners from diverse research areas. Special arrangements were made during the review process to ensure that each paper was reviewed by members of different research areas. The result of this effort is the selection of high quality papers: fifteen as regular papers (29%), six as short papers (12%), and three as posters (15%). Their themes included studies and solutions to a number of modern challenges such as search and management of linked data and RDF documents, modeling, management, alignment and storing of ontologies, application of mining techniques, semantics discovery, and data uncertainty management. © 2012 Springer-Verlag.",Final,
Gupta A.; Viswanathan K.K.; Joshi A.; Finin T.; Kumaraguru P.,"Gupta, Archit (57198676842); Viswanathan, Krishnamurthy Koduvayur (57198412214); Joshi, Anupam (7402452908); Finin, Timothy (7003679538); Kumaraguru, Ponnurangam (14042000100)",57198676842; 57198412214; 7402452908; 7003679538; 14042000100,Integrating linked open data with unstructured text for intelligence gathering tasks,-1,,-1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958753937&doi=10.1145%2f1982624.1982627&partnerID=40&md5=40e572a1d3eee7b6606e72a65716470b,"We present techniques for uncovering links between terror incidents, organizations, and people involved with these incidents. Our methods involve performing shallow NLP tasks to extract entities of interest from documents and using linguistic pattern matching and filtering techniques to assign specific relations to the entities discovered. We also gather more information about these entities from the Linked Open Data Cloud, and further allow human analysts to add intelligent inference rules appropriate to the domain. All this information is integrated in a knowledge base in the form of a graph that maintains the semantics between different types of nodes involved in the graph. This knowledge base can then be queried by the analysts to create actionable intelligence. © 2011 ACM.",Final,All Open Access; Green Open Access
Cheng G.; Tran T.; Qu Y.,"Cheng, Gong (36103954800); Tran, Thanh (56025377800); Qu, Yuzhong (8400208900)",36103954800; 56025377800; 8400208900,RELIN: Relatedness and informativeness-based centrality for entity summarization,-1,,-1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80055046015&doi=10.1007%2f978-3-642-25073-6_8&partnerID=40&md5=c9eaccaf7c7a6987a7ff14d333f39928,"Linked Data is developing towards a large, global repository for structured, interlinked descriptions of real-world entities. An emerging problem in many Web applications making use of data like Linked Data is how a lengthy description can be tailored to the task of quickly identifying the underlying entity. As a solution to this novel problem of entity summarization, we propose RELIN, a variant of the random surfer model that leverages the relatedness and informativeness of description elements for ranking. We present an implementation of this conceptual model, which captures the semantics of description elements based on linguistic and information theory concepts. In experiments involving real-world data sets and users, our approach outperforms the baselines, producing summaries that better match handcrafted ones and further, shown to be useful in a concrete task. © 2011 Springer-Verlag.",Final,All Open Access; Bronze Open Access
,,,"Proceedings of the 2nd International Workshop on the Multilingual Semantic Web 2011, MSW 2011 - In Conjunction with the International Semantic Web Conference, ISWC 2011",-1,,-1,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897369666&partnerID=40&md5=6f7939707e6c6ad19de6f51555e8ed88,"The proceedings contain 10 papers. The topics discussed include: Cross-lingual web API classification and annotation; OntoVerbal-M: a multilingual verbalizer for SNOMED CT; representing translations on the semantic web; a semantic model for integrated content management, localization and language technology processing; an expert system on linguistics to support natural multilingual collaborative management of interlingual semantic web knowledge bases; direct and indirect linking of lexical objects for evolving lexical linked data; linking domain-specific knowledge to encyclopedic knowledge: an initial approach to linked data; squeezing LEMON with GATE; accessing multilingual data on the web for the semantic annotation of cultural heritage texts; and XSLT conversion between XLIFF and RDF.",Final,
Brunsmann J.,"Brunsmann, Jörg (36719939100)",36719939100,The design of a social semantic search engine preserving archived collaborative engineering knowledge with ontology matching,-1,,-1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651430780&partnerID=40&md5=574d79105a262cd35bfa961cd442814a,"Private and business related knowledge acquisition is either performed via learning by doing or via human dialogue that includes transmission of social or collaborative questions and answers. Unfortunately it can be a time consuming task to find a trusted friend on the web for private recommendations or to find a qualified expert colleague in a (virtual) organisation for work-related questions or to find a suitable company contact person as a customer. Recently, such social question and answering is conducted with internet based technologies like social search engines which route a question to a appropriate human selected from a social or expert network. However, even if social search engines are involved, it is unlikely that existing social search approaches exploit machine-readable lightweight ontologies that enable classifying, publishing and sharing questions and answers to support subsequent semantic search without human involvement. This paper proposes the combination of semantic web and social search technologies in order to publish and archive social and collaborative generated knowledge for future reuse. Since knowledge classifying vocabularies evolve over time the paper also describes why archived knowledge may become obsolete and how ontology matching methods are used to migrate knowledge to conform to contemporary vocabularies.",Final,
Gangemi A.; Presutti V.,"Gangemi, Aldo (55605133800); Presutti, Valentina (55885160000)",55605133800; 55885160000,Towards a pattern science for the Semantic Web,-1,,-1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893306708&doi=10.3233%2fSW-2010-0020&partnerID=40&md5=e9144a6d57fc5dc3be695e8740740bb3,"With the web of data, the semantic web can be an empirical science. Two problems have to be dealt with. The knowledge soup problem is about semantic heterogeneity, and can be considered a difficult technical issue, which needs appropriate transformation and inferential pipelines that can help making sense of the different knowledge contexts. The knowledge boundary problem is at the core of empirical investigation over the semantic web: what are the meaningful units that constitute the research objects for the semantic web? This question touches many aspects of semantic web studies: data, schemata, representation and reasoning; interaction, linguistic grounding, etc. © 2010 - IOS Press and the authors. All rights reserved.",Final,
Speiser S.; Studer R.,"Speiser, Sebastian (36163573100); Studer, Rudi (7005848242)",36163573100; 7005848242,Usage policies for document compositions,-1,,-1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954415968&doi=10.1007%2f978-3-642-13489-0_6&partnerID=40&md5=a5d7b5e7d0fa619163e613b0f2e93330,"The availability of contents and information as linked data or Web services, i.e. over standardized interfaces, fosters the integration and reuse of data. One common form of information integration is the creation of composed documents, e.g. in form of dynamic Web pages. Service and data providers restrict allowed usage of their resources and and link it to obligations, e.g. only non-commercial usage is allowed and requires an attribution of the provider. These terms and conditions are currently typically available in natural language which makes checking, if a document composition is compliant with the policies of the used services, a tedious task. In order to make it easier for users to adhere to these usage policies, we propose to formalize them, which enables policy-aware tools that support the creation of compliant compositions. In this paper we propose an OWL model of document compositions and show how it can be used together with the policy language AIR to build a policy-aware document composition platform. We furthermore present a use case and illustrate how it can be realized with our approach. © 2010 Springer-Verlag.",Final,All Open Access; Bronze Open Access
Latif A.; Afzal M.T.; Tochtermann K.,"Latif, Atif (25927157000); Afzal, Muhammad Tanvir (57214808953); Tochtermann, Klaus (16053767400)",25927157000; 57214808953; 16053767400,Constructing experts profiles from Linked Open Data,-1,,-1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650317897&doi=10.1109%2fICET.2010.5638386&partnerID=40&md5=0b6a5721baac6f594940afe2ea7f7e84,"Identification and assignment of (potential) experts to subject field is an important task in various settings and environments. In scientific domain, the identification of experts is normally based on number of factors like: number of publications, citation record, and experience etc. However, the discovered experts cannot be assigned reviewing duties immediately. One also need further information about expert like the country, university, service record, contributions, honors, and name of conferences/journals where the discovered expert is already serving as editor/reviewer. To some extent, this information can be found from search engines using heuristics, by applying Natural Language Processing, and Machine Learning techniques. However, the emergence of many semantically rich and structured datasets from Linked Open Data movement (LOD) can facilitate in more controlled search and fruitful results. This paper employs an automatic technique to find the required information about experts using LOD dataset. The expert profile is discovered, aggregated, clustered, structured, and visualized to the administration of peer-review system. The system has been implemented for an electronic journal such as Journal of Universal Computer Science (J.UCS). The proposed system facilitates J.UCS administration to find potential reviewers for scientific papers to assign reviewing duties and to call new editors for computer science topics. © 2010 IEEE.",Final,
Van Der Spek H.L.A.; Holm C.W.M.; Wijshoff H.A.G.,"Van Der Spek, Harmen L. A. (24476702200); Holm, C. W. Mattias (36162821600); Wijshoff, Harry A. G. (7003802546)",24476702200; 36162821600; 7003802546,Automatic restructuring of linked data structures,-1,,-1,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954399064&doi=10.1007%2f978-3-642-13374-9_18&partnerID=40&md5=27725062b7a1743a75b84937df70058b,"The memory subsystem is one of the major performance bottlenecks in modern computer systems. While much effort is spent on the optimization of codes which access data regularly, not all codes will do so. Programs using pointer linked data structures are notorious for producing such so called irregular memory access patterns. In this paper, we present a compilation and run-time framework that enables fully automatic restructuring of pointer-linked data structures for type-unsafe languages, such as C. The restructuring framework is based on run-time restructuring using run-time trace information. The compiler transformation chain first identifies disjoint data structures that are stored in type-homogeneous memory pools. Access to these pools is traced and from these run-time traces, a permutation vector is derived. The memory pool is restructured at run-time using this permutation, after which all pointers (both stack and heap) that refer to the restructured pool must be updated. While the run-time tracing incurs a considerable overhead, we show that restructuring pointer-linked data structures can yield substantial speedups and that in general, the incurred overhead is compensated for by the performance improvements. © 2010 Springer-Verlag.",Final,
Rinard M.,"Rinard, Martin (7003321126)",7003321126,Integrated reasoning and proof choice point selection in the jahob system - Mechanisms for program survival,-1,,-1,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949174818&doi=10.1007%2f978-3-642-02959-2_1&partnerID=40&md5=5020981a725c70d2b771e1b234eabd1d,"In recent years researchers have developed a wide range of powerful automated reasoning systems. We have leveraged these systems to build Jahob, a program specification, analysis, and verification system. In contrast to many such systems, which use a monolithic reasoning approach, Jahob provides a general integrated reasoning framework, which enables multiple automated reasoning systems to work together to prove the desired program correctness properties. We have used Jahob to prove the full functional correctness of a collection of linked data structure implementations. The automated reasoning systems are able to automatically perform the vast majority of the reasoning steps required for this verification. But there are some complex verification conditions that they fail to prove. We have therefore developed a proof language, integrated into the underlying imperative Java programming language, that developers can use to control key choice points in the proof search space. Once the developer has resolved these choice points, the automated reasoning systems are able to complete the verification. This approach appropriately leverages both the developer's insight into the high-level structure of the proof and the ability of the automated reasoning systems to perform the mechanical steps required to prove the verification conditions. Building on Jahob's success with this challenging program verification problem, we contemplate the possibility of verifying the complete absence of fatal errors in large software systems. We envision combining simple techniques that analyze the vast majority of the program with heavyweight techniques that analyze those more sophisticated parts of the program that may require arbitrarily sophisticated reasoning. Modularity mechanisms such as abstract data types enable the sound division of the program for this purpose. The goal is not a completely correct program, but a program that can survive any remaining errors to continue to provide acceptable service. © 2009 Springer Berlin Heidelberg.",Final,All Open Access; Green Open Access
Grobe M.,"Grobe, Michael (55701274800)",55701274800,"RDF, Jena, SparQL and the ""semantic web""",-1,,-1,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-72149107829&doi=10.1145%2f1629501.1629525&partnerID=40&md5=0c45969ddd64a840ad9794c059ae522a,"The Resource Description Format (RDF) is used to represent information modeled as a ""graph"": a set of individual objects, along with a set of connections among those objects. In that role, RDF is one of the pillars of the so-called Semantic Web. This paper describes how RDF-XML is used to serialize information represented using graphs, how RDF graphs can be read and written by using the Jena software package, and how distributed graphs can be queried using the SparQL query language. It includes examples showing how SparQL can be used to query data (such as the Gene Ontology) that is structured in hierarchies, and how SparQL queries can be submitted through SparQL endpoints. It does not, however, delve into inference or the Web Ontology Language (OWL), but should provide a foundation for understanding those topics. Copyright 2009 ACM.",Final,
Jarrar M.; Dikaiakos M.D.,"Jarrar, Mustafa (22733926000); Dikaiakos, Marios D. (6701707151)",22733926000; 6701707151,MashQL: A query-by-diagram topping SPARQL towards semantic data mashups,-1,,-1,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349418592&doi=10.1145%2f1458484.1458499&partnerID=40&md5=74a83845d790ef66c99a21b26980e3fb,"This article is motivated by the importance of building web data mashups. Building on the remarkable success of Web 2.0 mashups, and specially Yahoo Pipes, we generalize the idea of mashups and regard the Internet as a database. Each internet data source is seen as a table, and a mashup is seen as a query on these tables. We assume that web data sources are represented in RDF, and SPARQL is the query language. We propose a query-by-diagram language called MashQL. The goal is to allow people to build data mashups diagrammatically. In the background, MashQL queries are translated into and executed as SPARQL queries. The novelty of MashQL is that it allows querying a data source without any prior understanding of the schema or the structure of this source. Users also do not need any knowledge about RDF/SPARQL to get started. © 2008 ACM.",Final,
Zee K.; Kuncak V.; Rinard M.C.,"Zee, Karen (23011099300); Kuncak, Viktor (6602919120); Rinard, Martin C. (7003321126)",23011099300; 6602919120; 7003321126,Full functional verification of linked data structures,-1,,-1,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349111788&doi=10.1145%2f1375581.1375624&partnerID=40&md5=49083c98e6854b727caa21976578b7eb,"We present the first verification of full functional correctness for a range of linked data structure implementations, including mutable lists, trees, graphs, and hash tables. Specifically, we present the use of the Jahob verification system to verify formal specifications, written in classical higher-order logic, that completely capture the desired behavior of the Java data structure implementations (with the exception of properties involving execution time and/or memory consumption). Given that the desired correctness properties include intractable constructs such as quantifiers, transitive closure, and lambda abstraction, it is a challenge to successfully prove the generated verification conditions. Our Jahob verification system uses integrated reasoning to split each verification condition into a conjunction of simpler subformulas, then apply a diverse collection of specialized decision procedures, first-order theorem provers, and, in the worst case, interactive theorem provers to prove each subformula. Techniques such as replacing complex subformulas with stronger but simpler alternatives, exploiting structure inherently present in the verification conditions, and, when necessary, inserting verified lemmas and proof hints into the imperative source code make it possible to seamlessly integrate all of the specialized decision procedures and theorem provers into a single powerful integrated reasoning system. By appropriately applying multiple proof techniques to discharge different subformulas, this reasoning system can effectively prove the complex and challenging verification conditions that arise in this context. Copyright © 2008 ACM.",Final,All Open Access; Green Open Access
Kasneci G.; Suchanek F.M.; Ifrim G.; Elbassuoni S.; Ramanath M.; Weikum G.,"Kasneci, Gjergji (22834642800); Suchanek, Fabian M. (14831857200); Ifrim, Georgiana (14831251200); Elbassuoni, Shady (25823803400); Ramanath, Maya (6603292414); Weikum, Gerhard (56270327600)",22834642800; 14831857200; 14831251200; 25823803400; 6603292414; 56270327600,"NAGA: Harvesting, searching and ranking knowledge",-1,,-1,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57149125427&doi=10.1145%2f1376616.1376756&partnerID=40&md5=0382d8360b5654628c6597f786f61f0a,"The presence of encyclopedic Web sources, such as Wikipedia, the Internet Movie Database (IMDB), World Factbook, etc. calls for new querying techniques that are simple and yet more expressive than those provided by standard keyword-based search engines. Searching for explicit knowledge needs to consider inherent semantic structures involving entities and relationships. In this demonstration proposal, we describe a semantic search system named NAGA. NAGA operates on a knowledge graph, which contains millions of entities and relationships derived from various encyclopedic Web sources, such as the ones above. NAGA's graph-based query language is geared towards expressing queries with additional semantic information. Its scoring model is based on the principles of generative language models, and formalizes several desiderata such as confidence, informativeness and compactness of answers. We propose a demonstration of NAGA which will allow users to browse the knowledge base through a user interface, enter queries in NAGA's query language and tune the ranking parameters to test various ranking aspects.",Final,
Nagabhushan P.; Anami B.S.,"Nagabhushan, P. (6603674866); Anami, Basavaraj S. (57202336738)",6603674866; 57202336738,A knowledge-based approach for recognition of handwritten Pitman shorthand language strokes,-1,,-1,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036995598&doi=10.1007%2fBF02703359&partnerID=40&md5=e86c467059e18d9ab4b46914412852d5,"The Pitman shorthand language (PSL) is a recording medium practised in all organizations, where English is the transaction medium. It has the practical advantage of high speed of recording, more than 120-200 words per minute, because of which it is universally acknowledged. This recording medium has its continued existence in spite of considerable developments in speech processing systems, which are not universally established yet. In order to exploit the vast transcribing potential of PSL a new area of research on automation of PSL processing is conceived. It has three major steps, namely, shape recognition of PSL strokes, their validation and English text production from these strokes. The paper describes a knowledge-based approach for the recognition of PSL strokes. Information about location and the direction of the starting point and final point of strokes are considered the knowledge base for recognition of strokes. The work comprises preprocessing, determination of starting and final points, acquisition of quadrant knowledge, graph-based traversal and finally a rule-based inference process for generating phonetic equivalent of English language characters for the strokes. The proposed work is thoroughly tested for a large number of handwritten strokes.",Final,All Open Access; Bronze Open Access
Annavaram M.; Tyson G.S.; Davidson E.S.,"Annavaram, M. (57195496128); Tyson, G.S. (7004371079); Davidson, E.S. (7402237735)",57195496128; 7004371079; 7402237735,Instruction overhead and data locality effects in superscalar processors,-1,,-1,2000,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962140599&doi=10.1109%2fISPASS.2000.842287&partnerID=40&md5=34c8f123f9f9839d6cebe1d051050fb2,"To reduce software development and maintenance costs, programmers are increasingly using object oriented programming languages, such as C++, and relying on highly flexible data structures, such as linked lists. Object oriented programming languages provide features that help manage complex software systems, but object oriented programs tend to suffer increased instruction counts, e.g. due to generalized class implementations and many more calls to small functions. Using linked data structures increases programming flexibility by allowing easy addition and deletion of nodes, and by dynamically allocating memory to satisfy applications that use large memory space. However, successive elements in linked data structures may be allocated noncontinuously in memory, leading to poor spatial locality for list traversals which in turn increases cache misses and reduces performance. This paper evaluates the impact of both the increased instruction overhead and poor spatial locality on superscalar processor performance as issue width increases. We show that underutilized resources of wide-issue processors can partially alleviate the impact of the instruction overhead. However, poor locality tends to cause more performance degradation as the processor issue width increases. Finally we show that the spatial locality of some programs can be improved by using a vector representation to replace linked list structures. Vectors exhibit better spatial locality during list traversals, but suffer from instruction overhead and memory copy overhead when nodes are added to and deleted from the structure. © 2000 IEEE.",Final,